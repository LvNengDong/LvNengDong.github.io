<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hexo</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">235</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">70</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/19/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/06/19/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">网络编程理论基础</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-06-19 09:37:55 / Modified: 10:47:53" itemprop="dateCreated datePublished" datetime="2022-06-19T09:37:55+08:00">2022-06-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">网络编程</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="客户端-服务器网络编程模型"><a href="#客户端-服务器网络编程模型" class="headerlink" title="客户端-服务器网络编程模型"></a>客户端-服务器网络编程模型</h2><p>服务器端需要一开始就监听在某一个众所周知的端口上，等待客户端发送请求，一旦有客户端连接建立，服务器端就会消耗一定的计算机资源为它服务。服务器端是需要同时为成千上万的客户端服务的。如何保证服务器端在数据量巨大的客户端访问时仍能维持效率和稳定，这正是高性能网络编程要解决的问题。</p>
<p>客户端相对来说更为简单，它向服务器端监听的端口发起连接请求，连接建立之后，通过连接桐庐和服务器端进行通信。</p>
<p><strong>还有一点需要强调的是，无论是客户端，还是服务器端，它们运行的单位都是进程(process)，而不是机器。</strong>一个客户端，比如我们的手机终端，同一个时刻可以建立多个到不同服务器的连接，比如同时打游戏，上知乎，逛天猫；而服务器端更是可能在一台机器上部署运行了多个服务，比如同时开启了 SSH 服务和 HTTP 服务。</p>
<h2 id="IP和端口"><a href="#IP和端口" class="headerlink" title="IP和端口"></a>IP和端口</h2><p>端口号是一个 16 位的整数，最多为 65536。当一个客户端发起连接请求时，客户端的端口是由操作系统内核临时分配的，称为临时端口；然而，前面也提到过，服务器端的端口通常是一个众所周知的端口。</p>
<p>一个连接可以通过客户端-服务器端的IP和端口唯一确定，这叫做套接字对，按照下面的四元组表示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(clientaddr: clientport, serveraddr: serverport)</span><br></pre></td></tr></table></figure>

<p>下图表示了一个客户端-服务器之间的连接：</p>
<p><img src="https://static001.geekbang.org/resource/image/54/2a/543b5488f9422558069df507cfaa462a.png?wh=1004*328" alt="img"></p>
<h2 id="数据报和字节流"><a href="#数据报和字节流" class="headerlink" title="数据报和字节流"></a>数据报和字节流</h2><p>TCP，又被叫做字节流套接字（Stream Socket），注意我们这里先引入套接字 socket，套接字 socket 在后面几讲中将被反复提起，因为它实际上是网络编程的核心概念。</p>
<p>当然，UDP 也有一个类似的叫法, 数据报套接字（Datagram Socket），一般分别以“SOCK_STREAM”与“SOCK_DGRAM”分别来表示 TCP 和 UDP 套接字。</p>
<h2 id="Socket到底是什么？"><a href="#Socket到底是什么？" class="headerlink" title="Socket到底是什么？"></a>Socket到底是什么？</h2><p><img src="https://static001.geekbang.org/resource/image/0b/64/0ba3f3d04b1466262c02d6f24ee76a64.jpg" alt="img"></p>
<p>这张图是网络编程中，客户端和服务器工作的核心逻辑。</p>
<p>我们先从右侧的服务器端开始看，因为客户端在发起连接请求之前，服务器端必须先初始化好。右侧的图显示的是服务器端初始化的过程。</p>
<ul>
<li>  首先初始化 socket；</li>
<li>  之后服务器端需要执行 bind 函数，将自己的服务能力绑定在一个众所周知的地址和端口上；</li>
<li>  接着，服务器端执行 listen 操作，将原先的 socket 转化为服务端的 socket；</li>
<li>  最后，服务端阻塞在 accept 上等待客户端请求的到来。</li>
</ul>
<p>此时，服务器端已经准备就绪。客户端需要：</p>
<ul>
<li>  先初始化 socket，</li>
<li>  再执行 connect 向服务端的地址和端口号发起连接请求(这里的地址和端口必须是客户端预先知晓的)。这个过程，就是著名的 <strong>TCP三次握手</strong>。</li>
</ul>
<p>一旦三次握手完成，客户端和服务器端建立连接，就进入了数据传输过程。</p>
<p>具体来说，</p>
<ul>
<li>  客户端进程向操作系统内核发起 write 字节流写操作，</li>
<li>  内核协议栈将字节流通过网络设备传输到服务器端，</li>
<li>  服务器端从内核得到消息，将字节流从内核读入到进程中，并开始业务逻辑的处理。</li>
<li>  完成之后，服务器端再将得到的结果以同样的方式写给客户端。</li>
</ul>
<p>可以看到，一旦连接建立，数据的传输就不再是单向的，而是双向的，这也是 TCP 的一个显著特性。</p>
<p>当客户端完成和服务器端的交互后，比如执行一次 Telnet 操作，或者一次 HTTP 请求，需要和服务器端断开连接，就会执行 close 函数……</p>
<p>将这幅图的真正意义在于引入 socket 的概念。请注意，以上所有的操作，都是通过 socket 来完成的。无论是客户端的 connect，还是服务器端的 accept，或者 read/write 操作等，<strong>socket 是我们用来建立连接，传输数据的唯一途径。</strong></p>
<h3 id="更好地理解socket：一个更直观的解释"><a href="#更好地理解socket：一个更直观的解释" class="headerlink" title="更好地理解socket：一个更直观的解释"></a>更好地理解socket：一个更直观的解释</h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/14/Guava/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/06/14/Guava/" class="post-title-link" itemprop="url">Guava</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-06-14 21:28:16" itemprop="dateCreated datePublished" datetime="2022-06-14T21:28:16+08:00">2022-06-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-07-17 19:29:07" itemprop="dateModified" datetime="2022-07-17T19:29:07+08:00">2022-07-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/JavaExt/" itemprop="url" rel="index"><span itemprop="name">JavaExt</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p>  <strong>声明</strong></p>
<p>  本文所有内容均参考自<a target="_blank" rel="noopener" href="https://github.com/google/guava/wiki">Guava官方文档</a>，是在对官方文档汉化的基础上形成的。</p>
</blockquote>
<p>Guava 工程是Google公司开发的一个类库，它被广泛应用在Google公司开发的Java项目中，其中包含了对：</p>
<ul>
<li>  集合[collections]</li>
<li>  缓存[chahing]</li>
<li>  原生类型支持[primitives support]</li>
<li>  并发库[concurrency libraries]</li>
<li>  通用注释[common annotations]</li>
<li>  字符串处理[string processing]</li>
<li>  I/O</li>
<li>  ……</li>
</ul>
<p>等多个模块的支持。所有这些工具每天都被Google工程师应用在产品服务中。</p>
<p><img src="http://processon.com/chart_image/62a88f780e3e747c5c433c56.png"></p>
<p>Guava依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/com.google.guava/guava --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.google.guava<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>guava<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>23.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h1 id="目-录"><a href="#目-录" class="headerlink" title="目  录"></a>目  录</h1><h2 id="1-基本工具-Basic-utilities"><a href="#1-基本工具-Basic-utilities" class="headerlink" title="1.基本工具[Basic utilities]"></a>1.基本工具[Basic utilities]</h2><p>让使用Java语言变得更舒适。</p>
<ol>
<li> 避免使用null：null是模棱两可的，过度使用null会引起不必要的错误。因此很多Guava工具类都不会使用null值代表失败。</li>
<li> 参数检查：让方法中的条件检查更简单。</li>
<li> 常见Object方法：简化Object方法的实现，如hashCode()和toString()</li>
<li> 排序：Guava强大的流畅风格比较器</li>
<li> Throwables：简化了异常和错误的传播与检查。</li>
</ol>
<h1 id="基本工具-Basic-utilities"><a href="#基本工具-Basic-utilities" class="headerlink" title="基本工具[Basic utilities]"></a>基本工具[Basic utilities]</h1><h2 id="1-避免和使用null"><a href="#1-避免和使用null" class="headerlink" title="1 避免和使用null"></a>1 避免和使用null</h2><h3 id="1-1-为什么要避免使用null？"><a href="#1-1-为什么要避免使用null？" class="headerlink" title="1.1 为什么要避免使用null？"></a>1.1 为什么要避免使用null？</h3><blockquote>
<p><strong>使用 null 的缺点：</strong></p>
</blockquote>
<p>null 代表不确定的对象，是一个很模糊的概念，非常容易产生歧义。</p>
<p>大多数情况下，使用 null 是为了表示<strong>某种缺失</strong>情况，但这并非是绝对的，还有一种情况是：就是想给某个对象赋值为 null。这种情况下就会产生歧义。比如：</p>
<blockquote>
<p><strong>问题：</strong></p>
</blockquote>
<p>如果 <code>Map.get(key)</code> 返回的 value 为 null，其代表的含义可能是该 key 指向的 value 是 null，也可能是该 key 在 map 中不存在。</p>
<blockquote>
<p><strong>优点：</strong></p>
</blockquote>
<p>当然，使用 null 也并非一无是处，null 本身不是对象（不是 Object 实例）。从内存消耗和效率方面来看，使用 null 是更为廉价的。</p>
<h3 id="1-2-对null进行的优化：Optional"><a href="#1-2-对null进行的优化：Optional" class="headerlink" title="1.2 对null进行的优化：Optional"></a>1.2 对null进行的优化：Optional</h3><p>为了解决使用 null 存在的种种弊端，Guava 引入了 <code>Optional&lt;T&gt;</code> 作为对 null 的上位替代。</p>
<p>Guava 中的 <code>Optional&lt;T&gt;</code> 表示了一种<strong>可能为null</strong>的 T 类型对象的引用。Optional 实例中可能包含对非 null 对象的引用（<em>引用存在</em>），也可能什么也不包括（<strong>引用缺失</strong>）。</p>
<h4 id="1-2-1-Optional快速入门"><a href="#1-2-1-Optional快速入门" class="headerlink" title="1.2.1 Optional快速入门"></a>1.2.1 Optional快速入门</h4><ul>
<li>API 所在包：<code>com.google.common.base.Optional</code> </li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Optional&lt;T&gt; possible = Optional.fromNullable(t); <span class="comment">// 将一个T类型的实例包装成一个Optional对象（t可以为null）</span></span><br><span class="line"><span class="type">boolean</span> <span class="variable">present</span> <span class="operator">=</span> possible.isPresent(); <span class="comment">// 若Optional包含的T实例不为null，则返回true；否则返回false</span></span><br><span class="line"><span class="type">T</span> <span class="variable">t</span> <span class="operator">=</span> possible.get(); <span class="comment">// 返回Optional包含T的实例，该T实例必须不为空，否则会抛出一个IllegalStateException异常</span></span><br></pre></td></tr></table></figure>

<h4 id="1-2-2-创建一个Optional对象"><a href="#1-2-2-创建一个Optional对象" class="headerlink" title="1.2.2 创建一个Optional对象"></a>1.2.2 创建一个Optional对象</h4><p>Guava 没有提供对 Optional 类公开的构造方法，而是使用工厂模式通过 Optional 类提供了3个创建 Optional 对象的静态方法。</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>注意事项</th>
</tr>
</thead>
<tbody><tr>
<td><code>Optional&lt;T&gt; fromNullable(T nullableReference)</code></td>
<td>T对象可以为null，也可以不为null</td>
</tr>
<tr>
<td><code>Optional&lt;T&gt; of(T reference)</code></td>
<td>T对象不能为null</td>
</tr>
<tr>
<td><code>Optional&lt;T&gt; absent()</code></td>
<td>得到的<code>Optional&lt;T&gt;</code>实例内的T实例一定为null</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Optional&lt;T&gt; optional1 = Optional.of(t); <span class="comment">//将一个T类型的实例转换为Optional对象（t不可以为null）</span></span><br><span class="line">Optional&lt;Object&gt; optional2 = Optional.absent(); <span class="comment">// 获得一个Optional对象，其内部为null</span></span><br><span class="line">Optional&lt;T&gt; optional3 = Optional.fromNullable(t); <span class="comment">// 将一个T类型的实例转换为Optional对象，实例t可以不为空，也可以为空</span></span><br><span class="line"><span class="comment">// Optional.fromNullable(null) 等同于 Optional.absent()</span></span><br></pre></td></tr></table></figure>

<h4 id="1-2-3-Optional实例方法"><a href="#1-2-3-Optional实例方法" class="headerlink" title="1.2.3 Optional实例方法"></a>1.2.3 Optional实例方法</h4><table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>boolean isPresent()</td>
<td>若Optional包含的T实例不为null，返回true；否则，返回false。</td>
</tr>
<tr>
<td>T get()</td>
<td>若Optional包含的T实例不为null，返回T；否则，抛出IllegalStateException</td>
</tr>
<tr>
<td>T or(T t)</td>
<td>若Optional包含的T实例不为null，返回T；否则，返回参数输入的T实例。</td>
</tr>
<tr>
<td>T orNull()</td>
<td>若Optional包含的T实例不为null，返回T；否则，返回null。</td>
</tr>
</tbody></table>
<h3 id="1-3-Java中的Optional"><a href="#1-3-Java中的Optional" class="headerlink" title="1.3 Java中的Optional"></a>1.3 Java中的Optional</h3><p>正是受到 Guava 的启发，Java8 将 Optional 类作为一个新特性引入自身的类库。所以在大多数时候，我们可以直接使用 Java8 的 Optional 类，以减少对外部 jar 包的依赖。</p>
<blockquote>
<p><strong>链接：<a href>Java8中的Optional新特性</a></strong></p>
<ul>
<li>TODO</li>
</ul>
</blockquote>
<hr>
<h2 id="2-优雅的检验参数-Preconditions"><a href="#2-优雅的检验参数-Preconditions" class="headerlink" title="2 优雅的检验参数[Preconditions]"></a>2 优雅的检验参数[Preconditions]</h2><p><strong>问题：</strong></p>
<p>当对外暴露的接口方法中的参数过多时，需要对参数进行必要的检查，以便将预期外的请求快速驳回。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">someMethod</span><span class="params">(<span class="type">int</span> arg1, String arg2, String arg3, Object arg4)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (arg1&gt;<span class="number">0</span> &amp;&amp; isNotEmpty(arg2) &amp;&amp; isNotEmpty(arg3) &amp;&amp; arg4!=<span class="literal">null</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// maybe需要将具体的错误类型告诉调用方</span></span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>方案：</strong></p>
<p><code>com.google.common.base.Preconditions</code></p>
<table>
<thead>
<tr>
<th>方法</th>
</tr>
</thead>
<tbody><tr>
<td>checkArgument(boolean expression, String errorMessageTemplate, Object… errorMessageArgs)</td>
</tr>
<tr>
<td>checkNotNull(T reference, String errorMessageTemplate, Object… errorMessageArgs)</td>
</tr>
<tr>
<td>checkState(boolean expression, String errorMessageTemplate, Object… errorMessageArgs)</td>
</tr>
<tr>
<td>checkElementIndex(int index, int size, String desc);</td>
</tr>
<tr>
<td>checkPositionIndex(int index, int size, String desc);</td>
</tr>
<tr>
<td>checkPositionIndexes(int start, int end, int size)</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 检查 boolean 类型的 expression 值是否为 true，</span></span><br><span class="line"><span class="comment"> * 失败时(值为false)抛出IllegalArgumentException并携带错误信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Preconditions.checkArgument(<span class="type">boolean</span> expression, String errorMessageTemplate, Object... errorMessageArgs);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 检查reference对象是否为null，失败时抛出NullPointerException并携带错误信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Preconditions.checkNotNull(T reference, String errorMessageTemplate, Object... errorMessageArgs);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 检查 expression 是否为 true，失败时抛出IllegalStateException并携带错误信息</span></span><br><span class="line"><span class="comment"> * 相比于checkArgument，该方法在某些场景下更有语义</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Preconditions.checkState(<span class="type">boolean</span> expression, String errorMessageTemplate, Object... errorMessageArgs);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 检查index是否在合法范围 [0,size) 内(不包含size)，若不在合法范围内，</span></span><br><span class="line"><span class="comment"> * 则抛出IndexOutOfBoundsException并携带错误信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Preconditions.checkElementIndex(<span class="type">int</span> index, <span class="type">int</span> size, String desc);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 检查index是否在合法范围 [0,size] 内(包含size)，若不在合法范围内，</span></span><br><span class="line"><span class="comment"> * 则抛出IndexOutOfBoundsException并携带错误信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Preconditions.checkPositionIndex(<span class="type">int</span> index, <span class="type">int</span> size, String desc);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 检查[start, end)是否在 (0, size) 集合的合法子集范围内</span></span><br><span class="line"><span class="comment"> * 失败时抛出IndexOutOfBoundsException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Preconditions.checkPositionIndexes(<span class="type">int</span> start, <span class="type">int</span> end, <span class="type">int</span> size);</span><br></pre></td></tr></table></figure>

<p>上述六个方法是 Preconditions 类中的主要方法，当然，Preconditions 还提供了这些类不同参数的重载方法。</p>
<p>以 checkNotNull 为例，它的基本使用如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.base.Preconditions;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2022/6/21 16:38</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PreconditionsTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">            checkNotNull(<span class="literal">null</span>);</span><br><span class="line">       &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">           System.out.println(e); <span class="comment">// java.lang.NullPointerException</span></span><br><span class="line">           System.out.println(e.getMessage()); <span class="comment">// null</span></span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test02</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            checkNotNullWithErrorMessage(<span class="literal">null</span>);</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            System.out.println(e); <span class="comment">// java.lang.NullPointerException</span></span><br><span class="line">            System.out.println(e.getMessage()); <span class="comment">// list不能为空</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test03</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            checkNotNullWithFormatErrorMessage(<span class="literal">null</span>);</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            System.out.println(e); <span class="comment">// java.lang.NullPointerException</span></span><br><span class="line">            System.out.println(e.getMessage()); <span class="comment">// list不能为空，errorCode为 9528</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 检查参数是否为null，若为null则抛出NullPointerException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> list</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">checkNotNull</span><span class="params">(List&lt;String&gt; list)</span>&#123;</span><br><span class="line">        Preconditions.checkNotNull(list);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 检查参数是否为null，若为null则抛出NullPointerException，</span></span><br><span class="line"><span class="comment">     * 并将 errorMessage 设置到 NullPointerException 对象的 message 中。</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> list</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">checkNotNullWithErrorMessage</span><span class="params">(List&lt;String&gt; list)</span> &#123;</span><br><span class="line">        Preconditions.checkNotNull(list, <span class="string">&quot;list不能为空&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 检查参数是否为null，若为null则抛出NullPointerException，</span></span><br><span class="line"><span class="comment">     * 并将 errorMessage 设置到 NullPointerException 对象的 message 中；</span></span><br><span class="line"><span class="comment">     * 还提供对 errorMessage 进行格式化的功能</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> list</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">checkNotNullWithFormatErrorMessage</span><span class="params">(List&lt;String&gt; list)</span> &#123;</span><br><span class="line">        Preconditions.checkNotNull(list, <span class="string">&quot;list不能为空，errorCode为 %s&quot;</span>, <span class="number">9528</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>checkArgument</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_checkArgument</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">arg1</span> <span class="operator">=</span> <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Preconditions.checkArgument(arg1.equals(<span class="string">&quot;World&quot;</span>));</span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">        System.out.println(e); <span class="comment">// java.lang.IllegalArgumentException</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>checkElementIndex</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  现有一空数组，容量为 0。</span></span><br><span class="line"><span class="comment"> *  欲取数组中下标为 10 的位置上的元素，必然会抛出异常</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_checkElementIndex</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        ArrayList&lt;String&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        Preconditions.checkElementIndex(<span class="number">10</span>, list.size());</span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">        System.out.println(e); <span class="comment">// java.lang.IndexOutOfBoundsException: index (10) must be less than size (0)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>checkPositionIndexes(int start, int end, int size)</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Preconditions.checkPositionIndexes(<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>); <span class="comment">//OK。size为10，[0,5) 在[0,10)的范围内</span></span><br><span class="line">Preconditions.checkPositionIndexes(<span class="number">0</span>, <span class="number">5</span>, <span class="number">5</span>); <span class="comment">//OK</span></span><br><span class="line">Preconditions.checkPositionIndexes(<span class="number">0</span>, <span class="number">5</span>, <span class="number">4</span>); <span class="comment">// java.lang.IndexOutOfBoundsException: end index (5) must not be greater than size (4)</span></span><br><span class="line"><span class="comment">// size为4，[0,5) 不在[0,4) 的范围内</span></span><br></pre></td></tr></table></figure>







<hr>
<h2 id="3-常见的Object方法-Objects"><a href="#3-常见的Object方法-Objects" class="headerlink" title="3. 常见的Object方法[Objects]"></a>3. 常见的Object方法[Objects]</h2><p>帮助简化对象的 equals、hashCode、toString、compare、compareTo 等方法的编写。</p>
<h3 id="compareTo"><a href="#compareTo" class="headerlink" title="compareTo"></a>compareTo</h3><ul>
<li>实现 Comparable 接口；</li>
<li>重写 compareTo 方法，使用 ComparisonChain 简化比较过程。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.collect.ComparisonChain;</span><br><span class="line"><span class="keyword">import</span> lombok.AllArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"><span class="keyword">import</span> lombok.ToString;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2022/6/17 0:25</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@ToString</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> <span class="keyword">implements</span> <span class="title class_">Comparable</span>&lt;User&gt;&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> Integer age;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(User user)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> ComparisonChain.start()</span><br><span class="line">                .compare(<span class="built_in">this</span>.name, user.name)</span><br><span class="line">                .compare(<span class="built_in">this</span>.age, user.age)</span><br><span class="line">                .result();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h2 id="4-强大的比较器-Ordering"><a href="#4-强大的比较器-Ordering" class="headerlink" title="4. 强大的比较器(Ordering)"></a>4. 强大的比较器(Ordering)</h2><p>Ordering 是 Guava 类库提供的一个强大的比较器工具。和 JDK 中的 Comparator 相比，Guava 中的 Ordering 功能更强，它非常容易扩展，可以很轻松地构造复杂的 Comparator。用于在容器中进行比较、排序等操作。</p>
<p><strong>常用静态方法：</strong></p>
<p><code>com.google.common.collect.Ordering</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Ordering.natural(); <span class="comment">//使用Comparable类型的自然排序。比如：整数从小到大，字符串按字典顺序排序。</span></span><br><span class="line">Ordering.usingToString(); <span class="comment">//使用toString()返回的字符串按字典顺序进行排序</span></span><br><span class="line">Ordering.;</span><br><span class="line">Ordering.;</span><br><span class="line">Ordering.;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="集合-Collections"><a href="#集合-Collections" class="headerlink" title="集合[Collections]"></a>集合[Collections]</h1><p>Guava 中最成熟和为人所知的部分就是对 JDK 中集合的扩展。主要包括以下几部分：</p>
<ul>
<li>  <strong>不可变集合</strong></li>
<li>  <strong>新的集合类型</strong></li>
<li>  <strong>强大的集合工具类</strong></li>
<li>  <strong>扩展工具类</strong></li>
</ul>
<h2 id="不可变集合-Immutable-Collections"><a href="#不可变集合-Immutable-Collections" class="headerlink" title="不可变集合[Immutable Collections]"></a>不可变集合[Immutable Collections]</h2><h3 id="为什么要使用不可变集合？"><a href="#为什么要使用不可变集合？" class="headerlink" title="为什么要使用不可变集合？"></a>为什么要使用不可变集合？</h3><p>创建对象的<strong>不可变拷贝</strong>是一项很好的<strong>防御性编程</strong>技巧。因此，Guava 为所有 <strong>JDK标准集合</strong> 类型和 <strong>Guava新集合</strong> 类型都提供了简单易用的不可变版本。</p>
<p><strong>不可变对象的优点：</strong></p>
<ul>
<li>  当对象被不被信任的库调用时，不可变形式是安全的。</li>
<li>  不可变对象同时被多个线程调用时，不存在线程安全问题。</li>
<li>  不可变集合不需要考虑变化，因此可以节省时间和空间。</li>
<li>  不可变对象因为固定不变，可以作为常量来安全使用。</li>
</ul>
<p><strong>JDK中不可变集合的缺点：</strong></p>
<p>当然，JDK 的 Collections 工具类也为我们提供了诸多 <code>unmodifiableXxx()</code> 方法用于把集合包装为不可变形式。但相比 Guava 中的不可变集合存在如下缺点：</p>
<ul>
<li>  <strong>笨重而且累赘</strong>：不能舒适地用在所有想做防御性拷贝的场景；</li>
<li>  <strong>不安全</strong>：JDK 中的不可变集合是在原有集合的基础上进行包装产生的。如果原有集合被改变了，那么不可变集合也会随着改变。所以在使用时要保证没人通过原集合的引用进行修改，返回的集合才是真正不可变的。</li>
<li>  <strong>低效</strong>：包装过的集合仍然保有可变集合的开销，比如并发修改的检查、散列表的额外空间，等等。</li>
</ul>
<p>如果你没有修改某个集合的需求，或者希望某个集合保持不变时，把它防御性地拷贝到不可变集合是个很好的实践。</p>
<blockquote>
<p>  <strong>Tip</strong></p>
<p>  <em>所有Guava不可变集合的实现都不接受null值。我们对Google内部的代码库做过详细研究，发现只有5%的情况需要在集合中允许null元素，剩下的95%场景都是遇到null值就快速失败。如果你需要在不可变集合中使用null，请使用JDK中的Collections.unmodifiableXXX方法。</em></p>
</blockquote>
<h3 id="创建一个不可变集合对象"><a href="#创建一个不可变集合对象" class="headerlink" title="创建一个不可变集合对象"></a>创建一个不可变集合对象</h3><p>不可变集合可以通过如下多种方式创建：</p>
<table>
<thead>
<tr>
<th>方式</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>copyOf 方法</td>
<td>根据已存在的集合创建不可变集合</td>
</tr>
<tr>
<td>of 方法</td>
<td>直接通过多个值来创建不可变集合</td>
</tr>
<tr>
<td>Builder 工具</td>
<td>通过链式编程来创建不可变集合（灵活度高）</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 如何创建不可变集合？</span></span><br><span class="line"><span class="comment"> *  1、copyOf 方法</span></span><br><span class="line"><span class="comment"> *  2、of 方法</span></span><br><span class="line"><span class="comment"> *  3、Builder 工具</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">createTest</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">// 方式一：copyOf()</span></span><br><span class="line">    ImmutableList&lt;Integer&gt; USERS = ImmutableList.copyOf(Arrays.asList(<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方式二：of()</span></span><br><span class="line">    <span class="keyword">final</span> ImmutableSet&lt;String&gt; COLOR_NAMES = ImmutableSet.of(</span><br><span class="line">            <span class="string">&quot;red&quot;</span>,</span><br><span class="line">            <span class="string">&quot;green&quot;</span>,</span><br><span class="line">            <span class="string">&quot;purple&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方式三：Builder</span></span><br><span class="line">    ImmutableSet&lt;String&gt; NEW_COLOR_NAMES = ImmutableSet.&lt;String&gt;builder()</span><br><span class="line">            .addAll(COLOR_NAMES)</span><br><span class="line">            .add(<span class="string">&quot;black&quot;</span>)</span><br><span class="line">            .build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="使用不可变集合"><a href="#使用不可变集合" class="headerlink" title="使用不可变集合"></a>使用不可变集合</h3><p>Guava 很好的兼容了 Java 原生的集合类型，除了对集合的写操作，原先对 Java 中集合的操作都可以用在 Guava 中的不可变集合对象上。</p>
<p><img src="/2022/06/14/Guava/image-20220627185355351.png" alt="image-20220627185355351"></p>
<p>从图中可以看出所有写操作涉及的 API 都是不被支持的。</p>
<h4 id="asList-视图"><a href="#asList-视图" class="headerlink" title="asList 视图"></a>asList 视图</h4><p>所有的不可变集合都有一个 asList() 方法，用于提供 ImmutableList 视图，来帮助你用列表的形式方便地读取集合中的元素。</p>
<p>例如，你可以使用 <code>sortedSet.asList().get(k)</code> 从 ImmutableSortedSet 中读取第 k 个最小的元素。</p>
<h3 id="可变集合与不可变集合的对应关系"><a href="#可变集合与不可变集合的对应关系" class="headerlink" title="可变集合与不可变集合的对应关系"></a>可变集合与不可变集合的对应关系</h3><table>
<thead>
<tr>
<th>可变集合接口</th>
<th>属于JDK还是Guava？</th>
<th>不可变版本</th>
</tr>
</thead>
<tbody><tr>
<td>Collection</td>
<td>JDK</td>
<td>ImmutableCollection</td>
</tr>
<tr>
<td>List</td>
<td>JDK</td>
<td>ImmutableList</td>
</tr>
<tr>
<td>Set</td>
<td>JDK</td>
<td>ImmutableSet</td>
</tr>
<tr>
<td>SortedSet/NavigableSet</td>
<td>JDK</td>
<td>ImmutableSortedSet</td>
</tr>
<tr>
<td>Map</td>
<td>JDK</td>
<td>ImmutableMap</td>
</tr>
<tr>
<td>SortedMap</td>
<td>JDK</td>
<td>ImmutableSortedMap</td>
</tr>
<tr>
<td>Multiset</td>
<td>Guava</td>
<td>ImmutableMultiset</td>
</tr>
<tr>
<td>SortedMultiset</td>
<td>Guava</td>
<td>ImmutableSortedMultiset</td>
</tr>
<tr>
<td>Multimap</td>
<td>Guava</td>
<td>ImmutableMultimap</td>
</tr>
<tr>
<td>ListMultimap</td>
<td>Guava</td>
<td>ImmutableListMultimap</td>
</tr>
<tr>
<td>SetMultimap</td>
<td>Guava</td>
<td>ImmutableSetMultimap</td>
</tr>
<tr>
<td>BiMap</td>
<td>Guava</td>
<td>ImmutableBiMap</td>
</tr>
<tr>
<td>ClassToInstanceMap</td>
<td>Guava</td>
<td>ImmutableClassToInstanceMap</td>
</tr>
<tr>
<td>Table</td>
<td>Guava</td>
<td>ImmutableTable</td>
</tr>
</tbody></table>
<hr>
<h2 id="新的集合类型-New-Collection-Types"><a href="#新的集合类型-New-Collection-Types" class="headerlink" title="新的集合类型[New Collection Types]"></a>新的集合类型[New Collection Types]</h2><p>Guava 引入了很多 JDK 没有的，但在开发中很有用的新的集合类型。这些新集合类型的底层依然是 JDK 中的集合类型，并没有向 JDK 集合抽象中强加一些其它概念。</p>
<h3 id="Multiset"><a href="#Multiset" class="headerlink" title="Multiset"></a>Multiset</h3><p>Set 是一个无序的、其内元素不能重复的集合。</p>
<p>List 是一个有序的、其内元素可以重复的集合。</p>
<p>Multiset 集合了两者的特点。首先，其内的元素是无序的；其次，其内的元素是可以重复的。</p>
<h4 id="Multiset初体验"><a href="#Multiset初体验" class="headerlink" title="Multiset初体验"></a>Multiset初体验</h4><p>统计一个词在文档中出现了多少次，传统的做法是这样的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 统计一个词在文档中出现了多少次。</span></span><br><span class="line"><span class="comment">    *      1、传统做法、</span></span><br><span class="line"><span class="comment">    *      2、使用Multiset实现</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">statWordCount</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="type">String</span> <span class="variable">text</span> <span class="operator">=</span> <span class="string">&quot;A big black bug bit a big black bear and made the big black bear bleed blood&quot;</span>;</span><br><span class="line">       <span class="comment">// 将 text 按空格划分为多个单词</span></span><br><span class="line">       Iterable&lt;String&gt; words = Splitter.on(<span class="string">&quot; &quot;</span>).split(text);</span><br><span class="line"></span><br><span class="line">       <span class="comment">// 传统做法</span></span><br><span class="line">       Map&lt;String, Integer&gt; wordCountMap = oldStatWordCount(words);</span><br><span class="line">       System.out.println(wordCountMap);</span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">       <span class="comment">// 使用Multiset实现</span></span><br><span class="line">       Multiset&lt;String&gt; wordCount = newStatWordCount(words);</span><br><span class="line">       System.out.println(wordCount);</span><br><span class="line">       </span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> Map&lt;String, Integer&gt; <span class="title function_">oldStatWordCount</span><span class="params">(Iterable&lt;String&gt; words)</span>&#123;</span><br><span class="line">       HashMap&lt;String, Integer&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">       <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">           <span class="type">Integer</span> <span class="variable">count</span> <span class="operator">=</span> map.get(word);</span><br><span class="line">           <span class="keyword">if</span> (count == <span class="literal">null</span>)&#123;</span><br><span class="line">               map.put(word, <span class="number">1</span>);</span><br><span class="line">           &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">               map.put(word, count+<span class="number">1</span>);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> map;</span><br><span class="line">       <span class="comment">// &#123;the=1, A=1, big=3, a=1, bug=1, and=1, made=1, black=3, bear=2, bit=1, bleed=1, blood=1&#125;</span></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> Multiset&lt;String&gt; <span class="title function_">newStatWordCount</span><span class="params">(Iterable&lt;String&gt; words)</span> &#123;</span><br><span class="line">       HashMultiset&lt;String&gt; multiset = HashMultiset.create();</span><br><span class="line">       <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">           multiset.add(word);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> multiset;</span><br><span class="line">       <span class="comment">// [the, A, big x 3, a, bug, and, made, black x 3, bear x 2, bit, bleed, blood]</span></span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>这种写法很笨拙，也很容易出错，并且不支持同时收集多种统计信息，如：总词数。</p>
<p>Guava 提供了一个新的集合类型 <strong>Multiset</strong>，它支持多次添加相同的元素。</p>
<p>维基百科从数学的角度这样定义 Multiset：</p>
<blockquote>
<p>  Multiset 是 Set 概念的延伸，其内的元素可以重复出现。与 Set 相同而与 Tuple(元组) 相反的是，Multiset 中元素的顺序是无关紧要的，<code>Multiset&#123;a,a,b&#125;</code> 和 <code>Multiset&#123;a,b,a&#125;</code> 是相等的。</p>
</blockquote>
<h4 id="Multiset的两种视角"><a href="#Multiset的两种视角" class="headerlink" title="Multiset的两种视角"></a>Multiset的两种视角</h4><p>可以从两个角度来理解 Multiset：</p>
<ol>
<li><p>**无序的 <code>ArrayList&lt;E&gt;</code>**。比如：</p>
<ul>
<li>它可以通过 add(E) 方法向集合中添加单个给定元素。</li>
<li>通过 iterator() 方法返回一个迭代器，包含 Multiset 中的全部元素（包含重复元素）。</li>
<li>通过 size() 方法返回所有元素的总个数（包括重复元素）</li>
<li>……</li>
</ul>
</li>
<li><p><strong><code>Map&lt;E, Integer&gt;</code>，键为元素，值为元素的个数。</strong>比如：</p>
<ul>
<li>它可以通过 count(Object) 方法返回给定元素的计数。</li>
<li>通过 entrySet() 方法返回 <code>Set&lt;Multiset.Entry&lt;E&gt;&gt;</code>，这和 Map 的 entrySet() 方法类似。</li>
<li>通过 elementSet() 方法返回所有不重复元素的 <code>Set&lt;E&gt;</code>，和 Map 的 keySet() 方法类似。</li>
<li>……</li>
</ul>
</li>
</ol>
<p>值得注意的是，除了极少数情况，Multiset 和 JDK 中原生的 Collection 接口的约定完全一致。具体来说，TreeMultiset 在判断元素是否相等时，与 TreeSet 一样用 compare() 方法，而不是 Object.equals() 方法。</p>
<p>另外特别注意，<code>Multiset.addAll(Collection)</code> 可以向一个 Multiset 中添加 Collection 中的所有元素并进行计数，这比用 for 循环向 Map 中添加元素和计数方便多了。</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>count(E)</td>
<td>统计指定元素在Multiset中的数量</td>
</tr>
<tr>
<td>elementSet()</td>
<td>Multiset中不重复元素的集合，类型为<code>Set&lt;E&gt;</code></td>
</tr>
<tr>
<td>entrySet()</td>
<td></td>
</tr>
<tr>
<td>add(E, int)</td>
<td>增加指定元素在Multiset中的数量</td>
</tr>
<tr>
<td>remove(E, int)</td>
<td>减少指定元素在Multiset中的数量</td>
</tr>
<tr>
<td>setCount(E, int)</td>
<td>设置指定元素在Multiset中的数量，不可以为负数。</td>
</tr>
<tr>
<td>size()</td>
<td>返回集合元素总个数(包括重复的元素)</td>
</tr>
</tbody></table>
<h4 id="Multiset-不是-Map"><a href="#Multiset-不是-Map" class="headerlink" title="Multiset 不是 Map"></a>Multiset 不是 Map</h4><p>值得注意的是，<code>Multiset&lt;E&gt;</code> 不是 <code>Map&lt;E, Integer&gt;</code>。虽然 Map 可能是某些 Multiset 实现的一部分。</p>
<p>准确地来说，Multiset 是一种 Collection 类型，它实现了 Collection 接口的相关约定。</p>
<p>关于 Multiset 和 Map 的区别还包括：</p>
<ul>
<li>  Multiset 中元素的计数只能是正数（不能是负数或者0）。</li>
<li>  multiset.size() 返回集合的大小，等同于所有元素数量的总和。对于不重复元素的个数，应该使用 <code>elementSet.size()</code> 方法。</li>
<li>  multiset.iterator() 方法会迭代重复元素，因此迭代长度等于 multiset.size()。</li>
<li>  Multiset 支持直接增加、减少或设置元素的数量。setCount(elem, 0) 等同于移出所有的 elem。</li>
<li>  对 multiset 中没有的元素，multiset.count(elem) 始终返回0。而 Map 则返回 null。</li>
</ul>
<h4 id="Multiset-的各种实现"><a href="#Multiset-的各种实现" class="headerlink" title="Multiset 的各种实现"></a>Multiset 的各种实现</h4><p>Multiset 是一个接口，Guava 提供了多种 Multiset 的实现，大致对应 JDK 中 Map 的各种实现。</p>
<table>
<thead>
<tr>
<th>Map</th>
<th>对应的Multiset</th>
<th>是否支持Null元素</th>
</tr>
</thead>
<tbody><tr>
<td>HashMap</td>
<td>HashMultiset</td>
<td>是</td>
</tr>
<tr>
<td>TreeMap</td>
<td>TreeMultiset</td>
<td>是(如果comparator支持的话)</td>
</tr>
<tr>
<td>LinkedHashMap</td>
<td>LinkedHashMultiset</td>
<td>是</td>
</tr>
<tr>
<td>ConcurrentHashMap</td>
<td>ConcurrentHashMultiset</td>
<td>否</td>
</tr>
<tr>
<td>ImmutableMap</td>
<td>ImmutableMultiset</td>
<td>否</td>
</tr>
</tbody></table>
<h4 id="SortedMultiset"><a href="#SortedMultiset" class="headerlink" title="SortedMultiset"></a>SortedMultiset</h4><p>…</p>
<h3 id="Multimap"><a href="#Multimap" class="headerlink" title="Multimap"></a>Multimap</h3><p>一个有经验的 Java 程序员或多或少都在某个项目中编写过类似 <code>Map&lt;K, List&lt;V&gt;&gt;</code> 或 <code>Map&lt;K, Set&lt;V&gt;&gt;</code> 这种笨拙的结构。</p>
<p>而 Guava 的 Multimap 可以很容易地让一个键映射多个值。</p>
<p>从两个角度理解 Multimap 的设计理念：</p>
<ul>
<li><p>“键-单个值映射”的集合</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a-&gt;1</span><br><span class="line">a-&gt;2</span><br><span class="line">a-&gt;4</span><br><span class="line">b-&gt;3</span><br><span class="line">c-&gt;5</span><br></pre></td></tr></table></figure></li>
<li><p>或者是 “键-值集合的映射”</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a-&gt;[1,2,4]</span><br><span class="line">b-&gt;3</span><br><span class="line">c-&gt;5</span><br></pre></td></tr></table></figure></li>
</ul>
<p>一般来说，Multimap 接口应该以第一种方式来看待，但 <code>asMap()</code> 方法返回的视图为 <code>Map&lt;K, Collection&lt;V&gt;&gt;</code> 格式，让我们可以从另一种角度来看待 Multimap。</p>
<p>重要的是，不会有任何键映射到空集合。一个键要么至少一个值，要么就根本不在 Multimap 中。</p>
<p>Multimap 是一个顶级接口，很少被直接使用，更多的时候我们会使用它的子接口 ListMultimap 或 SetMultimap，它们分别把键映射到 List 和 Set。</p>
<h4 id="修改-Multimap"><a href="#修改-Multimap" class="headerlink" title="修改 Multimap"></a>修改 Multimap</h4><p><code>Multimap.get(key)</code> 会以集合的形式返回键所对应的值的视图。即使没有任何的返回值，也会返回空集合。</p>
<ul>
<li>  ListMultimap.get(key) 返回 List 集合；</li>
<li>  SetMultimap.get(key) 返回 Set 集合。</li>
</ul>
<p>对值视图集合进行的修改最终都会反映到底层的 Multimap。例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Set&lt;Person&gt; aliceChildren = childrenMultimap.get(alice);</span><br><span class="line">aliceChildren.clear();</span><br><span class="line">aliceChildren.add(bob);</span><br><span class="line">aliceChildren.add(carol);</span><br></pre></td></tr></table></figure>

<p>其它(更直接地)修改 Multimap 的方法还有：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
<th>等价表达</th>
</tr>
</thead>
<tbody><tr>
<td><code>put(K, V)</code></td>
<td>添加单个值到键映射的集合</td>
<td>multimap.get(key).add(value)</td>
</tr>
<tr>
<td><code>putAll(K, Iterable&lt;V&gt;)</code></td>
<td>添加多个值到键映射的集合</td>
<td></td>
</tr>
<tr>
<td><code>remove(K, V)</code></td>
<td>移除键到值的映射，如果有这样的映射并移除成功，返回true。</td>
<td></td>
</tr>
<tr>
<td><code>removeAll(K)</code></td>
<td>清空键对应的所有值，返回的集合包含了所有之前映射到K的值，但删除之后修改这个集合就不会影响Multimap了。</td>
<td>multimap.get(key).clear()</td>
</tr>
<tr>
<td><code>replaceValues(K, Iterable&lt;V&gt;)</code></td>
<td>清除键对应的所有值，并重新把key关联到Iterable中的每个元素，返回的集合包含所有之前映射到K的值。</td>
<td>multimap.get(key).clear();<br>Iterables.addAll(multimap.get(key), values)</td>
</tr>
</tbody></table>
<p>​    </p>
<h4 id="Multimap的视图"><a href="#Multimap的视图" class="headerlink" title="Multimap的视图"></a>Multimap的视图</h4><p>Multimap 还支持若干强大的视图：</p>
<ul>
<li><p><strong>asMap()</strong> 为 <code>Multimap&lt;K, V&gt;</code> 提供 <code>Map&lt;K, Collection&lt;V&gt;&gt;</code> 形式的视图。</p>
<ul>
<li>  返回的 Map 支持 remove 操作，并且会反映到底层的 Multimap，但不支持 put 和 putAll 操作。</li>
<li>  如果你想为 Multimap 中不存在的键返回 null，而不是一个空集合，你就可以使用 <code>asMap().get(key)</code>。</li>
<li>Java 类型系统不允许 ListMultimap 直接为 asMap().get(key) 返回 List。所以如果有需求，你需要手动把 asMap.get(key) 返回的结果转换为和是的集合类型。比如：<ul>
<li>  将 SetMultimap.asMap().get(key) 返回的结果转为 Set 类型；</li>
<li>  将 ListMultimap.asMap().get(key) 返回的结果转为 List 类型；</li>
<li>  也可以用 Multimaps 工具类中的静态方法 asMap() 帮你完成类型的转换。</li>
</ul>
</li>
</ul>
</li>
<li><p>**entries()**：</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Collection&lt;Map.Entry&lt;K, V&gt;&gt; entries();</span><br></pre></td></tr></table></figure>

<p>  用 <code>Collection&lt;Map.Entry&lt;K, V&gt;&gt;</code> 返回 Multimap 中所有 “键-单个值映射” (包括重复键)。</p>
</li>
<li><p>**keySet()**：用 Set 表示 Multimap 中所有不同的键</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Set&lt;K&gt; <span class="title function_">keySet</span><span class="params">()</span>;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>keys()</strong></p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Multiset&lt;K&gt; <span class="title function_">keys</span><span class="params">()</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>  用 Multiset 表示 Multimap 中所有的键，每个键重复出现的次数等于它映射的值的个数。</li>
<li>  可以从这个 Multiset 中移除元素，但不能做添加操作。移除操作会反映到底层的 Multimap。</li>
</ul>
</li>
<li><p><strong>values()</strong></p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Collection&lt;V&gt; <span class="title function_">values</span><span class="params">()</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>  用一个“扁平”的 <code>Collection&lt;V&gt;</code> 包含 Multimap 中的所有值。这一点类似于 <code>Iterables.concat(multimap.asMap().values())</code>，但它直接返回了单个的 Collection，而不像 <code>multimap.asMap().values()</code> 那样是分开的 Collection。</li>
</ul>
</li>
</ul>
<h4 id="Multimap不是Map"><a href="#Multimap不是Map" class="headerlink" title="Multimap不是Map"></a>Multimap不是Map</h4><p><code>Multimap&lt;K, V&gt;</code> 不是 <code>Map&lt;K, Collection&lt;V&gt;&gt;</code>，虽然某些 Multimap 的具体实现使用了 map。它们之间的显著区别有：</p>
<ul>
<li><code>Multimap.get(key)</code> 总是返回非 null，但可能是空的集合。<ul>
<li>  这并不意味着 Multimap 为相应的键花费内存创建了集合，而是……</li>
<li>  如果你更喜欢像 Map 那样，为 Multimap 中没有的键返回 null，请使用 asMap() 方法获取一个 <code>Map&lt;K, Collection&lt;V&gt;&gt;</code>。或者使用静态方法 <code>Multimaps.asMap()</code> 为 ListMultimap 返回一个 <code>Map&lt;K, List&lt;V&gt;&gt;</code>。对于 SetMultimap 和 SortedSetMultimap，也有类似的静态方法存在。</li>
</ul>
</li>
<li>当且仅当有 value 映射到 key 时，Multimap.containsKey(key) 才会返回 true。<ul>
<li>  需要注意的是：如果 key 之间映射过一个或多个值，但它们都被移出后，Multimap.containsKey(key) 返回 false。</li>
</ul>
</li>
<li>Multimap.entries() 返回 Multimap 中所有的 “键-单个值映射”，包括重复键。<ul>
<li>  如果你想要得到所有的 “键-值集合映射”，请使用 asMap.entrySet()。</li>
</ul>
</li>
<li>Multimap.size() 返回所有 “键-单个值映射” 的个数，而非不同键的个数。<ul>
<li>  要想获得不同键的个数，请使用 Multimap.keySet().size()。</li>
</ul>
</li>
</ul>
<h4 id="Multimap的各种实现"><a href="#Multimap的各种实现" class="headerlink" title="Multimap的各种实现"></a>Multimap的各种实现</h4><p>Multimap 提供了多种形式的实现，在大多数要使用 <code>Map&lt;K, Collection&lt;V&gt;&gt;</code> 的地方，你都可以使用它们。</p>
<table>
<thead>
<tr>
<th>实现类</th>
<th>键类型</th>
<th>值类型</th>
</tr>
</thead>
<tbody><tr>
<td>ArrayListMultimap</td>
<td></td>
<td>ArrayList</td>
</tr>
<tr>
<td>LinkedListMultimap</td>
<td></td>
<td>LinkedList</td>
</tr>
<tr>
<td>HashMultimap</td>
<td></td>
<td>HashSet</td>
</tr>
<tr>
<td>LinkedHashMultimap</td>
<td></td>
<td>LinkedHashMap</td>
</tr>
<tr>
<td>TreeMultimap</td>
<td></td>
<td>TreeSet</td>
</tr>
<tr>
<td>ImmutableListMultimap</td>
<td></td>
<td>ImmutableList</td>
</tr>
<tr>
<td>ImmutableSetMultimap</td>
<td></td>
<td>ImmutableSet</td>
</tr>
</tbody></table>
<p>除了两个不可变形式的实现，其它所有实现都支持 null 键和 null 值。</p>
<h3 id="BiMap"><a href="#BiMap" class="headerlink" title="BiMap"></a>BiMap</h3><p>在 JDK 中，实现键值对的双向映射(即既可以通过key找到value，也可以通过value找到key)需要维护两个单独的 map，并保持它们之间的同步。</p>
<p>但这种方式很容易出错，特别是对于值已经在 map 中的情况，会变得非常混乱。例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span>&#123;</span><br><span class="line">    HashMap&lt;String, Integer&gt; kToV = Maps.newHashMap();</span><br><span class="line">    HashMap&lt;Integer, String&gt; vToK = Maps.newHashMap();</span><br><span class="line">    kToV.put(<span class="string">&quot;Bob&quot;</span>, <span class="number">42</span>);</span><br><span class="line">    vToK.put(<span class="number">42</span>, <span class="string">&quot;Bob&quot;</span>);</span><br><span class="line">    <span class="comment">// 如果 &quot;Bob&quot; 和 42 已经在 map 中了，会发生什么？</span></span><br><span class="line">    <span class="comment">// 如果我们忘了同步两个map，则会有新的bug产生。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>BiMap&lt;K,V&gt;</code> 是特殊的 Map：</p>
<ul>
<li>  可以用 <code>inverse()</code> 反转 <code>BiMap&lt;K, V&gt;</code> 的键值映射；</li>
<li>  可以保证值是唯一的，因此 <code>values()</code> 返回 Set 而不是普通的 Collection。</li>
</ul>
<p>在 BiMap 中，如果你想把键映射到已经存在的值，会抛出 IllegalArgumentException 异常。如果对特定值，你想要强制替换它的键，可以使用 <code>BiMap.forcePut(key, value)</code>。</p>
<h4 id="BiMap的各种实现类"><a href="#BiMap的各种实现类" class="headerlink" title="BiMap的各种实现类"></a>BiMap的各种实现类</h4><table>
<thead>
<tr>
<th>键-值 实现</th>
<th>值-键 实现</th>
<th>对应的BiMap实现</th>
</tr>
</thead>
<tbody><tr>
<td>HashMap</td>
<td>HashMap</td>
<td>HashBiMap</td>
</tr>
<tr>
<td>ImmutableMap</td>
<td>ImmutableMap</td>
<td>ImmutableBiMap</td>
</tr>
<tr>
<td>EnumMap</td>
<td>EnumMap</td>
<td>EnumBiMap</td>
</tr>
<tr>
<td>EnumMap</td>
<td>HashMap</td>
<td>EnumHashBiMap</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>注</strong>：Map 类中还有一些诸如 synchronizedBiMap 的 BiMap 工具方法。</p>
</blockquote>
<h3 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h3><p>通常来说，当你想用多个键做索引时，你可能会使用类似 <code>Map&lt;FirstName, Map&lt;LastName， Person&gt;&gt;</code> 的结构来实现。这种方式很丑陋，使用上也不太友好。</p>
<p>为此，Guava 提供了新的集合类型 Table，它有两个键：“行”和“列”，通过这两个键唯一映射到一个值。</p>
<p>Table 提供了多种视图，以便你从各种角度去理解它。</p>
<ul>
<li>**rowMap()**：用 <code>Map&lt;R, Map&lt;C, V&gt;&gt;</code> 表现 <code>Table&lt;R, C, V&gt;</code>。<ul>
<li>同样的，<strong>rowKeySet()</strong> 返回“行”的集合 <code>Set&lt;R&gt;</code>。</li>
</ul>
</li>
<li>**row(r)**：返回给定“行”的所有列，返回值格式为 <code>Map&lt;C, V&gt;</code>。<ul>
<li>注意：对这个 map 进行的写操作也将反映到 Table 中。</li>
</ul>
</li>
<li>类似的“列”的访问方法：<strong>columnMap()<strong>、</strong>columnKeySet()<strong>、</strong>column(c)</strong><ul>
<li>基于“列”的访问会比基于“行”的访问效率略低。</li>
</ul>
</li>
<li>**cellSet()**：用元素类型为 <code>Table.Cell&lt;R, C, V&gt;</code> 的 Set 表现 <code>Table&lt;R, C, V&gt;</code>。Cell 类似于 Map.Entry，但它是用行和列两个键进行划分的。</li>
</ul>
<h4 id="Table的实现类"><a href="#Table的实现类" class="headerlink" title="Table的实现类"></a>Table的实现类</h4><ul>
<li><strong>HashBasedTable</strong>：底层使用 <code>HashMap&lt;R, HashMap&lt;C, V&gt;&gt;</code> 实现。</li>
<li><strong>TreeBasedTable</strong>：底层使用 <code>TreeMap&lt;R, TreeMap&lt;C, V&gt;&gt;</code> 实现。</li>
<li><strong>ImmutableTable</strong>：底层使用 <code>ImmutableMap&lt;R, ImmutableMap&lt;C, V&gt;&gt;</code> 实现。<ul>
<li>注：ImmutableTable 对稀疏或密集的数据集都有优化。</li>
</ul>
</li>
<li><strong>ArrayTable</strong>：要求在构造时就指定行和列的大小，本质上由一个二维数组实现，以提升访问速度和密集 Table 的内存利用率。</li>
</ul>
<h3 id="ClassToInstanceMap"><a href="#ClassToInstanceMap" class="headerlink" title="ClassToInstanceMap"></a>ClassToInstanceMap</h3><p>ClassToInstanceMap 是一种特殊的 Map：它的键是类型，而值是符合所指类型的对象实例。</p>
<p>为了扩展 Map 接口，ClassToInstance 额外声明了两个方法：</p>
<ul>
<li><code>getInstance(Class&lt;T&gt;)</code></li>
<li><code>T putInstance(Class&lt;T&gt;, T)</code></li>
</ul>
<p>从而避免强制类型转换，同时保证了类型安全。</p>
<p>ClassToInstanceMap 有唯一的泛型参数，通常称为 B，代表 Map 支持的所有类型的上界。例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ClassToInstanceMap&lt;Number&gt; numberDefaults = MutableClassToInstanceMap.create();</span><br><span class="line">numberDefaults.putInstance(Integer.class, Integer.valueOf(<span class="number">0</span>));</span><br></pre></td></tr></table></figure>

<p>从技术上讲，<code>ClassToInstanceMap&lt;B&gt;</code> 实现了 <code>Map&lt;Class&lt;? extends B&gt;, B&gt;</code>。或者换句话说就是：一个映射 B 的子类类型到对应实例的 Map。B 始终是 Map 所支持类型的上限，默认 B 就是 Object。</p>
<h4 id="ClassToInstanceMap的实现类"><a href="#ClassToInstanceMap的实现类" class="headerlink" title="ClassToInstanceMap的实现类"></a>ClassToInstanceMap的实现类</h4><ul>
<li>MutableClassToInstanceMap</li>
<li>ImmutableClassToInstanceMap</li>
</ul>
<h3 id="RangeSet"><a href="#RangeSet" class="headerlink" title="RangeSet"></a>RangeSet</h3><p>RangeSet 描述了一组不相连的、非空的区间。</p>
<p>当把一个区间添加到可变的 RangeSet 时，所有相连的区间会被合并，空区间会被忽略。</p>
<p>例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">RangeSet&lt;Integer&gt; rangeSet = TreeRangeSet.create();</span><br><span class="line">rangeSet.add(Range.closed(<span class="number">1</span>, <span class="number">10</span>)); <span class="comment">// [1.10]，前闭后闭</span></span><br><span class="line">rangeSet.add(Range.closedOpen(<span class="number">11</span>, <span class="number">15</span>)); <span class="comment">// [11,15)，前开后闭</span></span><br><span class="line"><span class="comment">// 不相连区间 ==&gt; &#123; [1.10], [11,15) &#125;</span></span><br><span class="line">rangeSet.add(Range.closedOpen(<span class="number">15</span>, <span class="number">20</span>)); <span class="comment">// [15,20)</span></span><br><span class="line"><span class="comment">// 相连区间 ==&gt; &#123; [1.10], [11,20) &#125;</span></span><br><span class="line">rangeSet.add(Range.openClosed(<span class="number">0</span> ,<span class="number">0</span>)); <span class="comment">// 空区间</span></span><br><span class="line"><span class="comment">// &#123; [1.10], [11,20) &#125;</span></span><br><span class="line"><span class="comment">// 删除区间</span></span><br><span class="line">rangeSet.remove(Range.open(<span class="number">5</span>, <span class="number">10</span>)); <span class="comment">// (5, 10)</span></span><br><span class="line"><span class="comment">// &#123; [1, 5], [10, 10], [11,20) &#125;</span></span><br><span class="line">System.out.println(rangeSet); <span class="comment">// [[1..5], [10..10], [11..20)]</span></span><br></pre></td></tr></table></figure>

<p>请注意：要合并 <code>Range.closed(1, 10)</code> 和 <code>Range.closedOpen(11, 15)</code> 这样的区间，你需要首先用 <strong>Range.canonical(DiscreteDomain)</strong> 对区间进行预处理。例如：<code>DiscreteDomain.integers()</code>。</p>
<blockquote>
<p>  <strong>注意</strong></p>
<p>  RangeSet 不支持 GWT，也不支持 JDK5 和更早版本。因为，RangeSet 需要充分利用 JDK6 中的 NavigableMap 的特性。</p>
</blockquote>
<p>​                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           </p>
<h3 id="RangeMap"><a href="#RangeMap" class="headerlink" title="RangeMap"></a>RangeMap</h3><h2 id="强大的集合工具类"><a href="#强大的集合工具类" class="headerlink" title="强大的集合工具类"></a>强大的集合工具类</h2><p>JDK 在 <code>java.util.Collections</code> 包中提供了很多对 Collection 进行操作的静态方法。Guava 沿着这些路线提供了更多的工具方法，这也是 Guava 最流行和最成熟的部分之一。</p>
<p>常见的工具类与集合接口的对应关系归纳如下：</p>
<table>
<thead>
<tr>
<th>集合接口</th>
<th>属于JDK还是Guava</th>
<th>对应的Guava工具类</th>
</tr>
</thead>
<tbody><tr>
<td>Collection</td>
<td>JDK</td>
<td>Collections2(不要和<code>java.util.Collections</code>混淆)</td>
</tr>
<tr>
<td>List</td>
<td>JDK</td>
<td>Lists</td>
</tr>
<tr>
<td>Set</td>
<td>JDK</td>
<td>Sets</td>
</tr>
<tr>
<td>SortedSet</td>
<td>JDK</td>
<td>Sets</td>
</tr>
<tr>
<td>Map</td>
<td>JDK</td>
<td>Maps</td>
</tr>
<tr>
<td>SortedMap</td>
<td>JDK</td>
<td>Maps</td>
</tr>
<tr>
<td>Queue</td>
<td>JDK</td>
<td>Queues</td>
</tr>
<tr>
<td>Multiset</td>
<td>Guava</td>
<td>Multisets</td>
</tr>
<tr>
<td>Multimap</td>
<td>Guava</td>
<td>Multimaps</td>
</tr>
<tr>
<td>BiMap</td>
<td>Guava</td>
<td>Maps</td>
</tr>
<tr>
<td>Table</td>
<td>Guava</td>
<td>Tables</td>
</tr>
</tbody></table>
<h3 id="使用Lists工具类操作List集合"><a href="#使用Lists工具类操作List集合" class="headerlink" title="使用Lists工具类操作List集合"></a>使用Lists工具类操作List集合</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Lists 工具类的常用方法</span></span><br><span class="line"><span class="comment"> *      1、对集合进行 反转 / 拆分</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testLists</span><span class="params">()</span>&#123;</span><br><span class="line">    ArrayList&lt;Integer&gt; list = Lists.newArrayList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拆分：将list集合拆分为每3个为一组</span></span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; listList = Lists.partition(list, <span class="number">3</span>);</span><br><span class="line">    System.out.println(JSON.toJSONString(listList));</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">        [</span></span><br><span class="line"><span class="comment">            [1,2,3],</span></span><br><span class="line"><span class="comment">            [4,5,6],</span></span><br><span class="line"><span class="comment">            [7]</span></span><br><span class="line"><span class="comment">        ]</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 反转</span></span><br><span class="line">    List&lt;Integer&gt; reverseList = Lists.reverse(list);</span><br><span class="line">    System.out.println(reverseList); <span class="comment">// [7, 6, 5, 4, 3, 2, 1]</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="使用Sets工具类操作Set集合"><a href="#使用Sets工具类操作Set集合" class="headerlink" title="使用Sets工具类操作Set集合"></a>使用Sets工具类操作Set集合</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Sets 工具类的常用方法</span></span><br><span class="line"><span class="comment"> *      1、取两个集合的 并集 / 交集 / 差集（标准差集 &amp; 对称差集）</span></span><br><span class="line"><span class="comment"> *      2、将一个集合拆解为其所有可能的子集</span></span><br><span class="line"><span class="comment"> *      3、求两个集合的笛卡尔积</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testSets</span><span class="params">()</span>&#123;</span><br><span class="line">    HashSet&lt;Integer&gt; set1 = Sets.newHashSet(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">    HashSet&lt;Integer&gt; set2 = Sets.newHashSet(<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 并集</span></span><br><span class="line">    Sets.SetView&lt;Integer&gt; union = Sets.union(set1, set2);</span><br><span class="line">    System.out.println(union); <span class="comment">// [1, 2, 3, 4, 5, 8, 6, 7]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 交集</span></span><br><span class="line">    Sets.SetView&lt;Integer&gt; intersection = Sets.intersection(set1, set2);</span><br><span class="line">    System.out.println(intersection); <span class="comment">// [4, 5]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 标准差集</span></span><br><span class="line">    Sets.SetView&lt;Integer&gt; difference1 = Sets.difference(set1, set2);</span><br><span class="line">    Sets.SetView&lt;Integer&gt; difference2 = Sets.difference(set2, set1);</span><br><span class="line">    System.out.println(difference1); <span class="comment">// [1, 2, 3]</span></span><br><span class="line">    System.out.println(difference2); <span class="comment">// [8, 6, 7]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 对称差集</span></span><br><span class="line">    Sets.SetView&lt;Integer&gt; difference = Sets.symmetricDifference(set1, set2);</span><br><span class="line">    System.out.println(difference); <span class="comment">// [1, 2, 3, 8, 6, 7]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将一个集合拆解为其所有可能的子集</span></span><br><span class="line">    HashSet&lt;String&gt; set = Sets.newHashSet(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>);</span><br><span class="line">    Set&lt;Set&lt;String&gt;&gt; setSet = Sets.powerSet(set);</span><br><span class="line">    System.out.println(JSON.toJSONString(setSet));</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">        [</span></span><br><span class="line"><span class="comment">            [],</span></span><br><span class="line"><span class="comment">            [&quot;a&quot;],</span></span><br><span class="line"><span class="comment">            [&quot;b&quot;],</span></span><br><span class="line"><span class="comment">            [&quot;a&quot;,&quot;b&quot;],</span></span><br><span class="line"><span class="comment">            [&quot;c&quot;],</span></span><br><span class="line"><span class="comment">            [&quot;a&quot;,&quot;c&quot;],</span></span><br><span class="line"><span class="comment">            [&quot;b&quot;,&quot;c&quot;],</span></span><br><span class="line"><span class="comment">            [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;]</span></span><br><span class="line"><span class="comment">        ]</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算两个集合的笛卡尔积</span></span><br><span class="line">    Set&lt;List&lt;Integer&gt;&gt; listSet = Sets.cartesianProduct(</span><br><span class="line">            Sets.newHashSet(<span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            Sets.newHashSet(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">    );</span><br><span class="line">    System.out.println(JSON.toJSONString(listSet));</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">        [</span></span><br><span class="line"><span class="comment">            [1,4],</span></span><br><span class="line"><span class="comment">            [1,3],</span></span><br><span class="line"><span class="comment">            [2,4],</span></span><br><span class="line"><span class="comment">            [2,3]</span></span><br><span class="line"><span class="comment">        ]</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="静态工厂方法"><a href="#静态工厂方法" class="headerlink" title="静态工厂方法"></a>静态工厂方法</h3><p>在 JDK7 之前，构造新的集合时要反复地声明泛型类型：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ArrayList&lt;User&gt; users = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;User&gt;();</span><br><span class="line"><span class="comment">// JDK7之前，在等号左边和右边都需要显式地声明泛型类型，否则编译时就会报错</span></span><br></pre></td></tr></table></figure>

<p>尽管从 JDK7 开始，钻石操作符 <code>&lt;&gt;</code> 已经做出了一些优化，我们可以只在 “=” 左边声明泛型的类型，右边的泛型类型通过自动推断得出。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ArrayList&lt;User&gt; users = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br></pre></td></tr></table></figure>

<p>但是如果你正在操作一个使用 JDK6 甚至更早的项目，显然反复地声明泛型类型是非常麻烦的。为此，Guava 提供了能够推断泛型的静态工厂方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ArrayList&lt;User&gt; list = Lists.newArrayList();</span><br><span class="line">LinkedHashMap&lt;String, User&gt; map = Maps.newLinkedHashMap();</span><br></pre></td></tr></table></figure>

<p>但是 Guava 的静态工厂方法远不止这么简答。使用工厂方法，我们可以方便地在初始化集合时指定初始元素。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HashSet&lt;Integer&gt; copySet = Sets.newHashSet(elements);</span><br><span class="line">List&lt;String&gt; list = Lists.newArrayList(<span class="string">&quot;张三&quot;</span>, <span class="string">&quot;李四&quot;</span>, <span class="string">&quot;王五&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>此外，通过工厂方法的名称，可以提高集合初始化大小时的可读性。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ArrayList&lt;Type&gt; exactly100 = Lists.newArrayListWithCapacity(<span class="number">100</span>);</span><br><span class="line">ArrayList&lt;Type&gt; approx100 = Lists.newArrayListWithExpectedSize(<span class="number">100</span>);</span><br><span class="line">HashSet&lt;Type&gt; approx100Set = Sets.newHashSetWithExpectedSize(<span class="number">100</span>);</span><br></pre></td></tr></table></figure>



<p><strong>注意</strong>：对于 Guava 中引入的新集合类型，在创建其实例时并没有暴露原始的构造器，也没有在 <code>Collections2</code> 工具类中提供初始化方法，而是直接在集合类中提供了静态工厂方法。例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HashMultiset&lt;String&gt; multiset = HashMultiset.create();</span><br></pre></td></tr></table></figure>





<h3 id="Iterables"><a href="#Iterables" class="headerlink" title="Iterables"></a>Iterables</h3><p>在条件允许的情况下，Guava 提供的工具方法更偏向于接受 Iterable 类型而不是 Collection 类型。</p>
<p>在 Google 公司，对于不存放在主存中的数据集，比如从数据库或其他数据中心收集到的结果集，因为其实际上还没有攫取全部数据，这类结果集都不能支持类似 size() 的操作，所以通常都不会用 Collection 类型来表示。</p>
<p>因此，很多你期望的支持所有集合的操作都保存在 Iterables 类中。</p>
<p>截至 Guava1.2 版本，Iterables 使用 FluentIterable 类进行了补充，它包装了一个 Iterable 实例，并对许多操作提供了 “fluent”(链式调用)语法。</p>
<p>下面列出了一些最常用的工具方法，但更多 Iterables 的函数式方法将在对应的“函数式编程”章节讨论。</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>concat()</td>
<td></td>
<td></td>
</tr>
<tr>
<td>frequency(Iterable, Object)</td>
<td>返回Object对象在Iterable中出现的次数</td>
<td></td>
</tr>
<tr>
<td>partition(Iterable, int)</td>
<td>把iterable按指定大小分割，得到的子集都不能进行修改操作</td>
<td></td>
</tr>
<tr>
<td>getFirst(Iterable, T default)</td>
<td>返回iterable中的第一个元素，若iterable为空则返回默认值。</td>
<td></td>
</tr>
<tr>
<td>getLast(Iterable)</td>
<td>返回iterable中的最后一个元素，若iterable为空则抛出NoSuchElementException。</td>
<td></td>
</tr>
<tr>
<td>elementsEqual(Iterable, Iterable)</td>
<td>如果两个iterable中的所有元素相等且顺序一致，返回true</td>
<td></td>
</tr>
<tr>
<td>unmodifableIterable(Iterable)</td>
<td>返回iterable的不可变视图。</td>
<td></td>
</tr>
<tr>
<td>limit(Iterable, int)</td>
<td>限制iterable的元素个数，限制给定值</td>
<td></td>
</tr>
<tr>
<td>getOnlyElement(Iterable)</td>
<td>获取iterable中唯一的元素。如果iterable为空或有多个元素，则快速失败。</td>
<td></td>
</tr>
</tbody></table>
<hr>
<h1 id="字符串工具"><a href="#字符串工具" class="headerlink" title="字符串工具"></a>字符串工具</h1><h2 id="连接器-Joiner"><a href="#连接器-Joiner" class="headerlink" title="连接器[Joiner]"></a>连接器[Joiner]</h2><p>Joiner 是一个字符串处理工具，它的作用就是：用一个分隔符把多个字符串连接起来，并且如果字符串序列中含有 <code>null</code> 也能够很好的处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个连接器，这个连接器使用&quot;$&quot;作为连接符，并且会自动跳过null值 </span></span><br><span class="line"><span class="type">Joiner</span> <span class="variable">joiner</span> <span class="operator">=</span> Joiner.on(<span class="string">&quot;$&quot;</span>).skipNulls();</span><br><span class="line"><span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> joiner.join(<span class="string">&quot;Harry&quot;</span>, <span class="literal">null</span>, <span class="string">&quot;Ron&quot;</span>, <span class="string">&quot;Hermione&quot;</span>);</span><br><span class="line">System.out.println(s); <span class="comment">//Harry$Ron$Hermione</span></span><br></pre></td></tr></table></figure>

<p>另外，<code>useForNull(String)</code> 方法可以用某个给定的字符串来替换 null，而不像 <code>skipNulls()</code> 方法那样直接忽略 null。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Joiner</span> <span class="variable">joiner</span> <span class="operator">=</span> Joiner.on(<span class="string">&quot;$&quot;</span>).useForNull(<span class="string">&quot;Empty&quot;</span>);</span><br><span class="line"><span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> joiner.join(<span class="string">&quot;Harry&quot;</span>, <span class="literal">null</span>, <span class="string">&quot;Ron&quot;</span>, <span class="string">&quot;Hermione&quot;</span>);</span><br><span class="line">System.out.println(s); Harry$Empty$Ron$Hermione</span><br></pre></td></tr></table></figure>

<p>joiner 也可以用来连接 Object 类型，这种情况下，它会将 Object 的 toString() 值连接起来。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">List&lt;User&gt; userList = Arrays.asList(</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">User</span>(<span class="string">&quot;张三&quot;</span>, <span class="number">13</span>),</span><br><span class="line">    <span class="literal">null</span>,</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">User</span>(<span class="string">&quot;李四&quot;</span>, <span class="number">24</span>)</span><br><span class="line">);</span><br><span class="line"><span class="type">Joiner</span> <span class="variable">joiner</span> <span class="operator">=</span> Joiner.on(<span class="string">&quot;^_^&quot;</span>).skipNulls();</span><br><span class="line"><span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> joiner.join(userList);</span><br><span class="line">System.out.println(s); <span class="comment">//User(name=张三, age=13)^_^User(name=李四, age=24)^_^User(name=王五, age=35)</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <strong>Tip</strong></p>
<p>  joiner 实例一旦创建是不可变的。每次执行定义 Joiner 的语句得到的都是一个新的 joiner 实例，这使得 joiner 实例都是安全的，所以你可以将其定义为 static final 常量。</p>
</blockquote>
<h3 id="静态方法-连接器工厂"><a href="#静态方法-连接器工厂" class="headerlink" title="静态方法(连接器工厂)"></a>静态方法(连接器工厂)</h3><p>Joiner 类只有两个静态方法，分别是：</p>
<ul>
<li><code>Joiner on(String separator)</code></li>
<li><code>Joiner on(char separator)</code></li>
</ul>
<p>这两个方法都是用于创建一个连接器实例 joiner，并在创建时指定要以哪种分隔符对字符串进行拼接。只不过一个使用 String 类型的分隔符，另一个使用 char 类型的分隔符。</p>
<p>我们可以将 Splitter 类理解为一个连接器工厂，它的作用就是创建 splitter 连接器实例。</p>
<h3 id="普通方法"><a href="#普通方法" class="headerlink" title="普通方法"></a>普通方法</h3><p><img src="/2022/06/14/Guava/image-20220620220652695.png" alt="image-20220620220652695"></p>
<p>与 JDK8 中的流式操作类似，joiner 中的方法也可以分为 **中间操作方法 **和 <strong>终止操作方法</strong> 两大类。</p>
<ul>
<li>中间操作方法主要用于设置 joiner 连接器的属性，主要包括 skipNulls、useForNull、withKeyValueSeparator 等等。中间操作仅仅只是用于设置对字符串的处理规则，并没有真正的执行处理字符串的过程。</li>
<li>而终止操作则是把待处理的数据交给 joiner 实例，让其真正地去处理数据。常见的终止操作方法有 join 和 appendTo 两个。<ul>
<li><code>String join(...)</code>：join 方法的返回值是一个字符串，表示它会将 joiner 处理后的数据写到 String 类型的字符串中。</li>
<li><code>&lt;A extends Appendable&gt; A appendTo()</code>：appendTo 方法的返回值是 Appendable 类型的对象，它比较灵活多变，常见的我们可以把处理后的数据写到 StringBuffer 或 StringBuilder 中，或者是写到 Writer 中(这些都是 Appendable  接口的子类对象)，进而写出到磁盘上。</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>join()</strong></p>
</blockquote>
<p>join 方法有三种变式：</p>
<ul>
<li><code>String join(Iterable&lt;?&gt; parts)</code></li>
<li><code>String join(Iterator&lt;?&gt; parts)</code></li>
<li><code>String join(Object first, Object second, Object... rest)</code></li>
</ul>
<p>前两种方法接收一个集合类型，返回值是 String，就是把集合类型中的所有元素拼接成一个字符串。如果集合的泛型是 Object 类型，返回的结果就是集合中每个元素的 toString() 方法返回值拼接的结果。</p>
<blockquote>
<p><strong>appendTo()</strong></p>
</blockquote>
<p>appendTo() 方法的作用将 joiner 处理后的数据写到一个 Appendable 类型的对象中。</p>
<p>该方法的第一个参数要求是 Appendable 类型的对象(StringBuffer 和 StringBuilder 都是 Appendable 接口的子类)；其余参数可以是 Object 类型，此时会将其 toString() 方法的返回值当做要追加的数据；也可以是 Iterable 或 Iterator 类型；或者是多个 Object 对象。</p>
<p>该方法设计的逻辑就是：对于 joiner 处理过的字符串，我们可能会在某个地方用到它，所以我们需要先找个地方把这个处理结果暂存起来。这个地方可以是 StringBuffer、也可以是本地磁盘。     </p>
<p><img src="/2022/06/14/Guava/image-20220620223152644.png" alt="image-20220620223152644"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2022/6/20 22:00</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JoinerDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;String&gt; stringList = Lists.newArrayList(</span><br><span class="line">            <span class="string">&quot;Java&quot;</span>, <span class="string">&quot;Python&quot;</span>, <span class="string">&quot;C&quot;</span>, <span class="string">&quot;Golang&quot;</span></span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;String&gt; stringListWithNullValue = Lists.newArrayList(</span><br><span class="line">            <span class="string">&quot;Java&quot;</span>, <span class="string">&quot;Python&quot;</span>, <span class="literal">null</span>, <span class="string">&quot;Golang&quot;</span></span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testJoin</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="type">Joiner</span> <span class="variable">joiner</span> <span class="operator">=</span> Joiner.on(<span class="string">&quot;#&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">res1</span> <span class="operator">=</span> joiner.join(stringList);</span><br><span class="line">        System.out.println(res1); <span class="comment">// Java#Python#C#Golang</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果集合中含有null值，直接使用join()拼接集合中的元素，会抛出 NullPointerException</span></span><br><span class="line">        <span class="comment">//String res2 = joiner.join(stringListWithNullValue); // NullPointerException</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 为了解决这个问题，可以为连接器实例 joiner 设置自动跳过 null 值的功能</span></span><br><span class="line">        <span class="type">Joiner</span> <span class="variable">joiner2</span> <span class="operator">=</span> joiner.skipNulls();</span><br><span class="line">        <span class="type">String</span> <span class="variable">res2</span> <span class="operator">=</span> joiner2.join(stringListWithNullValue);</span><br><span class="line">        System.out.println(res2); <span class="comment">// Java#Python#Golang</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对于null值，如果我们不想直接跳过，而是使用一个Default值替换Null，可以使用useForNull()方法</span></span><br><span class="line">        <span class="type">Joiner</span> <span class="variable">joiner3</span> <span class="operator">=</span> joiner.useForNull(<span class="string">&quot;Empty&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">res3</span> <span class="operator">=</span> joiner3.join(stringListWithNullValue);</span><br><span class="line">        System.out.println(res3); <span class="comment">// Java#Python#Empty#Golang</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testAppendToStringBuffer</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Joiner</span> <span class="variable">joiner</span> <span class="operator">=</span> Joiner.on(<span class="string">&quot;$&quot;</span>);</span><br><span class="line">        <span class="type">StringBuffer</span> <span class="variable">stringBuffer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuffer</span>();</span><br><span class="line">        <span class="type">StringBuffer</span> <span class="variable">res</span> <span class="operator">=</span> joiner.skipNulls().appendTo(stringBuffer, stringListWithNullValue);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 它的一个执行流程是，先用joiner对象处理集合中的数据。</span></span><br><span class="line"><span class="comment">         * 最后把处理后的结果数据写到目的地(这里是写到sb中)</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        System.out.println(res.toString()); <span class="comment">// Java$Python$Golang</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 并且 res 和 stringBuffer 是同一个 StringBuffer 实例</span></span><br><span class="line">        System.out.println(stringBuffer == res); <span class="comment">// true</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testAppendToWriter</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">// Writer 也实现了 Appendable 接口</span></span><br><span class="line">        <span class="type">FileWriter</span> <span class="variable">fileWriter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileWriter</span>(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;out.txt&quot;</span>));</span><br><span class="line">        <span class="comment">// 将 joiner 处理后得到的字符串写出到 Writer 中，最终写入磁盘上</span></span><br><span class="line">        Joiner.on(<span class="string">&quot;$&quot;</span>).skipNulls().appendTo(fileWriter, stringListWithNullValue);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="内部类MapJoiner"><a href="#内部类MapJoiner" class="headerlink" title="内部类MapJoiner"></a>内部类MapJoiner</h3><p>MapJoiner 是 Joiner 的内部类，它主要用来处理 Map 集合中的字符串数据，它可以先将 Map 中每个 Entry 的 key 和 value 用一个连接符连接起来，再用另一个连接符连接每一个 Entry。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2022/6/20 22:00</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JoinerDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    Map&lt;String, String&gt; map = ImmutableMap.of(</span><br><span class="line">            <span class="string">&quot;23&quot;</span>, <span class="string">&quot;张三&quot;</span>,</span><br><span class="line">            <span class="string">&quot;24&quot;</span>, <span class="string">&quot;李四&quot;</span>,</span><br><span class="line">            <span class="string">&quot;25&quot;</span>, <span class="string">&quot;王五&quot;</span></span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testMapJoiner</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        Joiner.<span class="type">MapJoiner</span> <span class="variable">mapJoiner</span> <span class="operator">=</span> Joiner.on(<span class="string">&quot; $ &quot;</span>)</span><br><span class="line">                .withKeyValueSeparator(<span class="string">&#x27;=&#x27;</span>)  <span class="comment">// key和value的分隔符</span></span><br><span class="line">                .useForNull(<span class="string">&quot;王五&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// join 和 appendTo 是终止操作方法。join是把结果写到字符串中；appendTo则比较灵活多变</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">res</span> <span class="operator">=</span> mapJoiner.join(map);</span><br><span class="line">        System.out.println(res); <span class="comment">// 23=张三 $ 24=李四 $ 25=王五</span></span><br><span class="line">        <span class="type">StringBuffer</span> <span class="variable">buffer</span> <span class="operator">=</span> mapJoiner.appendTo(<span class="keyword">new</span> <span class="title class_">StringBuffer</span>(), map);</span><br><span class="line">        System.out.println(buffer.toString()); <span class="comment">// 23=张三 $ 24=李四 $ 25=王五</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="拆分器-Splitter"><a href="#拆分器-Splitter" class="headerlink" title="拆分器[Splitter]"></a>拆分器[Splitter]</h2><p>与 Joiner 相反，Splitter 的作用是把一个字符串根据给定的分隔符进行分割。</p>
<p>JDK 内置的字符串拆分工具有一些奇怪的特性。比如，<code>String.split()</code> 方法会悄悄丢掉尾部的分隔符。</p>
<blockquote>
<p>  问题：</p>
<ul>
<li><code>&quot;,a,b,&quot;.split(&quot;,&quot;)</code> 会返回什么？<ol>
<li> <code>&quot;&quot;,&quot;a&quot;,&quot;b&quot;,&quot;&quot;</code></li>
<li> <code>null,&quot;a&quot;,&quot;b&quot;,null</code></li>
<li> <code>&quot;a&quot;,null,&quot;b&quot;</code></li>
<li> <code>&quot;a&quot;,&quot;b&quot;</code></li>
<li> 以上都不对</li>
</ol>
</li>
</ul>
</blockquote>
<p>正确答案是5。真正的结果是：<code>&quot;&quot;,&quot;a&quot;,&quot;b&quot;</code>，只有尾部的空字符串被忽略了，首部的空字符串没有被忽略。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">String[] strings = <span class="string">&quot;,a,b,&quot;</span>.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">System.out.println(strings.length); <span class="comment">// 3</span></span><br><span class="line">System.out.println(Arrays.toString(strings)); <span class="comment">// [, a, b]</span></span><br></pre></td></tr></table></figure>

<p>而 Guava 中的 <strong>Splitter</strong> 使用了令人放心的、直白流畅的 API 对这些混乱的特性做了优化。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Iterable&lt;String&gt; strings = Splitter.on(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    .trimResults()</span><br><span class="line">    .omitEmptyStrings() <span class="comment">//省略空字符串</span></span><br><span class="line">    .split(<span class="string">&quot;foo,bar,,    qux&quot;</span>);</span><br><span class="line">System.out.println(Iterables.toString(strings)); <span class="comment">// [foo, bar, qux]</span></span><br></pre></td></tr></table></figure>

<p>上述代码返回 <code>Iterable&lt;String&gt;</code> 类型的对象，其中包含 “foo”、“bar”和“qux”。</p>
<p>Splitter 可以被设置为按照任何模式、字符、字符串或者字符匹配器拆分。</p>
<h3 id="静态方法-拆分器工厂"><a href="#静态方法-拆分器工厂" class="headerlink" title="静态方法(拆分器工厂)"></a>静态方法(拆分器工厂)</h3><p>与 Joiner 类似，Splitter 中的静态方法也被用于创建 splitter 实例，并在创建时指定字符串拆分的规则。</p>
<p>我们可以将 Splitter 类理解为一个拆分器工厂，它的作用就是创建 splitter 拆分器。</p>
<p><img src="/2022/06/14/Guava/image-20220621123921407.png" alt="image-20220621123921407"></p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>Splitter.on(char)</td>
<td>按单个字符拆分</td>
<td>Splitter.on(‘;’)</td>
</tr>
<tr>
<td>Splitter.on(CharMatcher)</td>
<td>按字符匹配器拆分</td>
<td>Splitter.on(CharMatcher.BREAKING_WHITESPACE)</td>
</tr>
<tr>
<td>Splitter.on(String)</td>
<td>按字符串拆分</td>
<td>Splitter.on(“,”)</td>
</tr>
<tr>
<td>Splitter.on(Pattern)<br>Splitter.onPattern(String)</td>
<td>按正则表达式拆分</td>
<td>Splitter.onPattern(“\r?\n”)</td>
</tr>
<tr>
<td>Splitter.fixedLength(int)</td>
<td>按固定长度拆分(最后一段可能比给定长度短)</td>
<td>Splitter.fixedLength(3)</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_Splitter_onPattern</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">srcStr</span> <span class="operator">=</span> <span class="string">&quot;好$好$学$习$天$天$向$上&quot;</span>;</span><br><span class="line">    <span class="comment">// 正则表达式：通过&quot;$&quot;进行分割</span></span><br><span class="line">    List&lt;String&gt; dstList1 = Splitter.onPattern(<span class="string">&quot;\\$&quot;</span>).splitToList(srcStr);</span><br><span class="line">    List&lt;String&gt; dstList2 = Splitter.on(Pattern.compile(<span class="string">&quot;\\$&quot;</span>)).splitToList(srcStr);</span><br><span class="line">    System.out.println(dstList1.toString()); <span class="comment">// [好, 好, 学, 习, 天, 天, 向, 上]</span></span><br><span class="line">    System.out.println(dstList2.toString()); <span class="comment">// [好, 好, 学, 习, 天, 天, 向, 上]</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 以客户端发送报文给服务器为例。规定每4个长度为一组。</span></span><br><span class="line"><span class="comment"> * 现客户端发送了一串报文为：010010XR8764YTE3</span></span><br><span class="line"><span class="comment"> * 服务器端接收到报文后需要解析这串报文。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_Splitter_fixedLength</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">srcStr</span> <span class="operator">=</span> <span class="string">&quot;010010XR8764YTE3&quot;</span>;</span><br><span class="line">    <span class="comment">// 创建一个以字符长度为拆分依据的 splitter 实例</span></span><br><span class="line">    <span class="type">Splitter</span> <span class="variable">splitter</span> <span class="operator">=</span> Splitter.fixedLength(<span class="number">4</span>);</span><br><span class="line">    List&lt;String&gt; dstList = splitter.splitToList(srcStr);</span><br><span class="line">    System.out.println(dstList.toString()); <span class="comment">// [0100, 10XR, 8764, YTE3]</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="普通方法-1"><a href="#普通方法-1" class="headerlink" title="普通方法"></a>普通方法</h3><p>与 joiner 类似，splitter 实例可以调用的方法也可分为两类：<strong>拆分器修饰方法</strong> 和 <strong>拆分器执行方法</strong>。</p>
<ul>
<li>拆分器修饰方法主要用来定义 splitter 实例的执行规则，常见的有：trimResults、omitEmptyStrings、limit、withKeyValueSeparator 等等，这些方法仅仅是对 splitter 的修饰，并没有真正执行数据的处理流程。</li>
<li>拆分器执行方法则是通过连接到真正的数据源，使用 joiner 对数据源数据进行处理。常见的有 split() 和 splitToList()。</li>
</ul>
<p><img src="/2022/06/14/Guava/image-20220621125041695.png" alt="image-20220621125041695"></p>
<h4 id="拆分器修饰方法"><a href="#拆分器修饰方法" class="headerlink" title="拆分器修饰方法"></a>拆分器修饰方法</h4><table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
<th>举例</th>
</tr>
</thead>
<tbody><tr>
<td>omitEmptyStrings()</td>
<td>省略结果字符串中的空白元素</td>
<td>a,,c<code>-&gt;</code>a,c</td>
</tr>
<tr>
<td>trimResults()</td>
<td>移除结果字符串中的头部空白和尾部空白</td>
<td></td>
</tr>
<tr>
<td>trimResults(charMatcher)</td>
<td>给定匹配器，移除结果字符串的头部匹配字符和尾部匹配字符</td>
<td></td>
</tr>
<tr>
<td>limit(int)</td>
<td>限制拆分出的元素数量</td>
<td></td>
</tr>
</tbody></table>
<h4 id="拆分器执行方法"><a href="#拆分器执行方法" class="headerlink" title="拆分器执行方法"></a>拆分器执行方法</h4><table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>split(CharSequence sequence)</td>
<td>使用splitter实例对sequence数据进行拆分</td>
</tr>
<tr>
<td>splitToList(CharSequence sequence)</td>
<td>使用splitter实例对sequence数据进行拆分，并将拆分结果写到List中</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">srcStr</span> <span class="operator">=</span> <span class="string">&quot;阿福,成龙   ,,,小玉,    老爹&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1、创建 splitter 实例</span></span><br><span class="line">    <span class="type">Splitter</span> <span class="variable">splitter</span> <span class="operator">=</span> Splitter.on(<span class="string">&quot;,&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2、修饰 splitter 实例</span></span><br><span class="line">    <span class="comment">// 2.1 omitEmptyStrings</span></span><br><span class="line">    <span class="type">Splitter</span> <span class="variable">splitter1</span> <span class="operator">=</span> splitter.omitEmptyStrings(); <span class="comment">// 忽略空字符</span></span><br><span class="line">    <span class="comment">/*  &quot;阿福,成龙   ,,,小玉,    老爹&quot; --&gt; [阿福, 成龙   , 小玉,     老爹]  */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.2 trimResults</span></span><br><span class="line">    <span class="type">Splitter</span> <span class="variable">splitter2</span> <span class="operator">=</span> splitter.trimResults(); <span class="comment">// 忽略单个元素前面和后面的空白</span></span><br><span class="line">    <span class="comment">/*  &quot;阿福,成龙   ,,,小玉,    老爹&quot; --&gt; [阿福,成龙,,,小玉,老爹]  */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3、执行拆分</span></span><br><span class="line">    <span class="comment">// 将处理的结果写到Iterable类型的对象中</span></span><br><span class="line">    Iterable&lt;String&gt; iterable = splitter1.split(srcStr);</span><br><span class="line">    System.out.println(Iterables.toString(iterable));</span><br><span class="line">    <span class="comment">// 将处理的结果写到List类型的对象中</span></span><br><span class="line">    List&lt;String&gt; list = splitter2.splitToList(srcStr);</span><br><span class="line">    System.out.println(list.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_splitter_limit</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">srcStr</span> <span class="operator">=</span> <span class="string">&quot;好$好$学$习$天$天$向$上&quot;</span>;</span><br><span class="line">    List&lt;String&gt; dstList = Splitter.on(<span class="string">&#x27;$&#x27;</span>).limit(<span class="number">4</span>).splitToList(srcStr);</span><br><span class="line">    System.out.println(dstList.size()); <span class="comment">// 4。拆分的结果只有4部分</span></span><br><span class="line">    System.out.println(dstList.toString()); <span class="comment">// [好, 好, 学, 习$天$天$向$上]</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="内部类MapSplitter"><a href="#内部类MapSplitter" class="headerlink" title="内部类MapSplitter"></a>内部类MapSplitter</h3><p>MapSplitter 是 Splitter 的内部类，它是专门用于处理 KV 形式的字符串，并且会把处理后的字符串写到一个 Map 中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_Splitter_withKeyValueSeparator</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">srcStr</span> <span class="operator">=</span> <span class="string">&quot;科比=24;乔丹=24;库里=30&quot;</span>;</span><br><span class="line">    Map&lt;String, String&gt; map = Splitter.on(<span class="string">&#x27;;&#x27;</span>).withKeyValueSeparator(<span class="string">&#x27;=&#x27;</span>).split(srcStr);</span><br><span class="line">    System.out.println(map.toString()); <span class="comment">// &#123;科比=24, 乔丹=24, 库里=30&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<blockquote>
<p>  <strong>Tip</strong></p>
<p>  Splitter 实例总是不可变的。每次执行 Splitter 的定义语句返回的都是一个新的 splitter 实例。这保证了 splitter 实例都是线程安全的，你可以将其定义为 static final 常量。</p>
</blockquote>
<h2 id="字符串匹配器-CharMatcher"><a href="#字符串匹配器-CharMatcher" class="headerlink" title="字符串匹配器(CharMatcher)"></a>字符串匹配器(CharMatcher)</h2><p>在 Guava 早期的版本中，为了处理字符串，在 StringUtil 类中添加了很多处理字符串的方法。如 allSacii、collapse、collapseControlChars、collapseWhitespace、indexOfChars、lastIndexNotOf、numSharedChars、removeChars、removeCrLf、replaceChars、retainAllChars、strip、stripAndCollapse、stripNonDigits 等等。</p>
<p>但是归根结底，所有的字符串处理方法都只为了解决两个问题：</p>
<ul>
<li>如何匹配字符串？</li>
<li>如何处理匹配成功的字符串？</li>
</ul>
<p>为了解决这个难题，Guava 提供了 CharMatcher 工具类。</p>
<p>你可以简单地认为一个 CharMatcher 实例代表着某一<strong>类</strong>字符，如数字类、空白字符类、大写字符类、小写字符类等等。实际上，CharMatcher 实例就是对字符串中的每个字符进行布尔判断，判断其是否属于某一类。</p>
<p>CharMatcher 底层通过实现 <code>Predicate&lt;Character&gt;</code> 接口来实现断言功能（判断某个字符是否属于某一类）。</p>
<blockquote>
<p>  <code>public abstract class CharMatcher implements Predicate&lt;Character&gt; &#123;</code></p>
</blockquote>
<p>使用 CharMatcher 的好处在于它还提供了一系列方法，让你可以对字符串作特定的操作(如何处理匹配成功的字符串)，包括了：</p>
<ul>
<li>  修剪(trim)</li>
<li>  折叠(collapse)</li>
<li>  移除(remove)</li>
<li>  保留(retain)</li>
<li>  ……</li>
</ul>
<p>使用 CharMatcher 主要分为两步：</p>
<ul>
<li>  step1：匹配字符串；</li>
<li>  step2：对匹配成功的字符串执行特定的操作。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 只保留数字字符</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_digit_retain</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;control 1 control 2 control 3&quot;</span>;</span><br><span class="line">    <span class="type">String</span> <span class="variable">resStr</span> <span class="operator">=</span> CharMatcher</span><br><span class="line">            .digit() <span class="comment">//匹配数字</span></span><br><span class="line">            .retainFrom(str); <span class="comment">//执行“保留”操作</span></span><br><span class="line">    System.out.println(resStr); <span class="comment">//123</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 去掉两端的空格，并把中间的连续空格替换成字符 &#x27;*&#x27;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testWHITESPACE</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;  好好学习，    天天向上！  &quot;</span>;</span><br><span class="line">    <span class="type">String</span> <span class="variable">resStr</span> <span class="operator">=</span> CharMatcher</span><br><span class="line">            .whitespace() <span class="comment">//匹配空格</span></span><br><span class="line">            .trimAndCollapseFrom(str, <span class="string">&#x27;*&#x27;</span>); <span class="comment">//匹配到3组空格后：1.移除头部和尾部的2组空格；2.压缩中间一组空格，并使用*代替空格</span></span><br><span class="line">    System.out.println(resStr); <span class="comment">//好好学习，*天天向上！</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testJAVA_DIGIT</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;不3不4；3妻4妾；7上8下&quot;</span>;</span><br><span class="line">    <span class="comment">// 用 &#x27;*&#x27; 替换所有数字</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">resStr</span> <span class="operator">=</span> CharMatcher</span><br><span class="line">            .javaDigit() <span class="comment">//匹配数字</span></span><br><span class="line">            .replaceFrom(str, <span class="string">&#x27;*&#x27;</span>); <span class="comment">// 执行“替换”操作</span></span><br><span class="line">    System.out.println(resStr); <span class="comment">//不*不*；*妻*妾；*上*下</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 只保留数字和小写字母</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;Hello,I am 23 years!&quot;</span>;</span><br><span class="line">    <span class="type">String</span> <span class="variable">resStr</span> <span class="operator">=</span> CharMatcher.javaDigit() <span class="comment">//匹配数字</span></span><br><span class="line">            .or(CharMatcher.javaLowerCase()) <span class="comment">//匹配大写字母</span></span><br><span class="line">            .retainFrom(str); <span class="comment">//执行“保留”操作</span></span><br><span class="line">    System.out.println(resStr); <span class="comment">//elloam23years</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="获取字符串匹配器"><a href="#获取字符串匹配器" class="headerlink" title="获取字符串匹配器"></a>获取字符串匹配器</h3><p>如下图所示，CharMatcher 提供了很多方法可以满足日常使用中的大多数字符串匹配的需求。</p>
<p><img src="/2022/06/14/Guava/image-20220618182414129.png" alt="image-20220618182414129"></p>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
<th>使用场景</th>
</tr>
</thead>
<tbody><tr>
<td>any()</td>
<td>匹配全部字符</td>
<td></td>
</tr>
<tr>
<td>none()</td>
<td>所有字符都不匹配</td>
<td></td>
</tr>
<tr>
<td>anyof()</td>
<td>？</td>
<td></td>
</tr>
<tr>
<td>ascii()</td>
<td>判断字符是否为ASCII</td>
<td></td>
</tr>
<tr>
<td>breakingWhitespace()</td>
<td>匹配字符串中的空格。</td>
<td></td>
</tr>
<tr>
<td>digit()</td>
<td>根据Unicode确定字符是否为数字。</td>
<td></td>
</tr>
<tr>
<td>inRange(char, char)</td>
<td>给定字符范围匹配。</td>
<td></td>
</tr>
<tr>
<td>invisible()</td>
<td>确定字符是否不可见(根据字符的Unicode类别确定)</td>
<td></td>
</tr>
<tr>
<td>is(char match)</td>
<td>匹配单个字符</td>
<td></td>
</tr>
<tr>
<td>isNot(char match)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>javaDigit()</td>
<td>根据Java的定义确定字符是否为数字。</td>
<td></td>
</tr>
<tr>
<td>javaLetter()</td>
<td>根据Java的定义确定字符是否为字母。</td>
<td></td>
</tr>
<tr>
<td>javaLetterOrDigit()</td>
<td>根据Java的定义确定字符是字母或数字。</td>
<td></td>
</tr>
<tr>
<td>javaLowerCase</td>
<td>根据Java的定义确定字符是否为小写字母。</td>
<td></td>
</tr>
<tr>
<td>javaUpperCase</td>
<td>根据Java的定义确定字符是否为大写字母。</td>
<td></td>
</tr>
<tr>
<td>noneOf()</td>
<td>?</td>
<td></td>
</tr>
<tr>
<td>singleWidth()</td>
<td>判断字符是否为单字节宽度</td>
<td>汉字总是大于一个字节，可以根据这个特性区分出英文和中文</td>
</tr>
<tr>
<td>whitespace()</td>
<td>根据最新的Unicode标准确定字符是否为空格，</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><strong>CharMatcher breakingWhitespace()</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_breakingWhitespace</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> CharMatcher.breakingWhitespace().removeFrom(<span class="string">&quot;啊，   我爱你  中国&quot;</span>);</span><br><span class="line">    <span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> CharMatcher.breakingWhitespace().replaceFrom(<span class="string">&quot;啊，   我爱你  中国&quot;</span>, <span class="string">&quot;_&quot;</span>);</span><br><span class="line">    System.out.println(s); <span class="comment">// 啊，我爱你中国</span></span><br><span class="line">    System.out.println(s1); <span class="comment">// 啊，啊，___我爱你__中国</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<p><strong>is(char match)/isNot(char match)</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> CharMatcher.is(<span class="string">&#x27;a&#x27;</span>).removeFrom(<span class="string">&quot;abc_abc_abc&quot;</span>);</span><br><span class="line">System.out.println(s); <span class="comment">//bc_bc_bc</span></span><br></pre></td></tr></table></figure>

<p><strong>inRange(char, char)</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> CharMatcher.inRange(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;z&#x27;</span>).removeFrom(<span class="string">&quot;ABC_abc_123&quot;</span>);</span><br><span class="line">System.out.println(s); <span class="comment">//ABC__123</span></span><br></pre></td></tr></table></figure>



<h3 id="使用字符串匹配器"><a href="#使用字符串匹配器" class="headerlink" title="使用字符串匹配器"></a>使用字符串匹配器</h3><p>CharMatcher 提供了多种方法操作匹配到的字符。其中最常见的如下：</p>
<p><img src="/2022/06/14/Guava/image-20220618201827157.png" alt="image-20220618201827157"></p>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>String retainFrom(CharSequence sequence)</td>
<td>在字符序列中保留匹配到的字符，移出其它字符。</td>
</tr>
<tr>
<td>String removeFrom(CharSequence sequence)</td>
<td>从字符序列中移除所有匹配到的字符</td>
</tr>
<tr>
<td>String replaceFrom(CharSequence sequence, CharSequence replacement)</td>
<td>用特定的字符序列代替匹配到的字符</td>
</tr>
<tr>
<td>String trimFrom(CharSequence sequence)</td>
<td>移除字符序列的头部匹配字符和尾部匹配字符</td>
</tr>
<tr>
<td>String collapseFrom(CharSequence sequence, char replacement)</td>
<td>把匹配到的每组连续字符首先压缩为单个字符，再替换为指定字符。</td>
</tr>
<tr>
<td>boolean matchesAllOf(CharSequence sequence)</td>
<td>判断是否字符序列中的所有字符都匹配成功</td>
</tr>
<tr>
<td>boolean matches(char c)</td>
<td>判断某个字符是否匹配成功</td>
</tr>
<tr>
<td>int countIn(CharSequence sequence)</td>
<td>统计sequence中有多少个符合条件的字符</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><strong>matches(char c)</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_matches</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">// 判断字符&#x27;5&#x27;是否是Java中的数字类型</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> CharMatcher.javaDigit().matches(<span class="string">&#x27;5&#x27;</span>);</span><br><span class="line">    System.out.println(b); <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断字符&#x27;a&#x27;是否是Java中的数字类型</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">b1</span> <span class="operator">=</span> CharMatcher.javaDigit().matches(<span class="string">&#x27;a&#x27;</span>);</span><br><span class="line">    System.out.println(b1); <span class="comment">// false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ul>
<li><strong>int countIn(CharSequence sequence)</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_countIn</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">// 统计 content 中有多少个 &#x27;a&#x27; 字符</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">content</span> <span class="operator">=</span> <span class="string">&quot;A big black bear sat on a big black bug&quot;</span>;</span><br><span class="line">    <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> CharMatcher.is(<span class="string">&#x27;a&#x27;</span>).countIn(content);</span><br><span class="line">    System.out.println(count); <span class="comment">// 5</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>String collapseFrom(CharSequence sequence, char replacement)</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_collapseFrom</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    * 1、首先通过 breakingWhitespace 匹配到所有的空格</span></span><br><span class="line"><span class="comment">    * 2、压缩，如果存在多个空格，就压缩为一个空格</span></span><br><span class="line"><span class="comment">    * 3、替换空格为&#x27;!&#x27;</span></span><br><span class="line"><span class="comment">    * */</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> CharMatcher.breakingWhitespace().collapseFrom(<span class="string">&quot;啊   我爱你   中国&quot;</span>, <span class="string">&#x27;!&#x27;</span>);</span><br><span class="line">    System.out.println(s); <span class="comment">// 啊!我爱你!中国</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<hr>
<h2 id="字符集-Charsets"><a href="#字符集-Charsets" class="headerlink" title="字符集(Charsets)"></a>字符集(Charsets)</h2><p>Charsets 针对所有 Java 平台都会使用的6种字符集提供了常量引用。并建议我们在项目中使用这些常量引用，而不是通过字面量名称获取字符集实例。</p>
<ul>
<li><p>不要这样做字符集处理：</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 使用字符串“UTF-8”指定字符串编码格式</span></span><br><span class="line">    <span class="type">byte</span>[] bytes = <span class="string">&quot;Hello world&quot;</span>.getBytes(<span class="string">&quot;UTF-8&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>试试这样写：</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">byte</span>[] bytes = <span class="string">&quot;Hello world&quot;</span>.getBytes(Charsets.UTF_8);</span><br></pre></td></tr></table></figure>
<ul>
<li>避免因手动输出失误，导致 UnsupportedEncodingException 异常</li>
</ul>
</li>
</ul>
<p><img src="/2022/06/14/Guava/image-20220618203756169.png" alt="image-20220618203756169"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">Charset</span> <span class="variable">charset</span> <span class="operator">=</span> Charsets.UTF_8;</span><br><span class="line">    <span class="type">Charset</span> <span class="variable">charset1</span> <span class="operator">=</span> Charset.forName(<span class="string">&quot;UTF-8&quot;</span>);</span><br><span class="line">    System.out.println(charset.equals(charset1)); <span class="comment">//true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>Charsets.UTF_8 源码</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Charset</span> <span class="variable">UTF_8</span> <span class="operator">=</span> Charset.forName(<span class="string">&quot;UTF-8&quot;</span>);</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="大小写格式-CaseFormat"><a href="#大小写格式-CaseFormat" class="headerlink" title="大小写格式(CaseFormat)"></a>大小写格式(CaseFormat)</h2><p>CaseFormat 被用来进行字符串在各种书写格式之间进行转换。比如：大小写、驼峰等等。</p>
<p>CaseFormat 支持的格式如下：</p>
<p><img src="/2022/06/14/Guava/image-20220618204633138.png" alt="image-20220618204633138"></p>
<table>
<thead>
<tr>
<th>格式</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>LOWER_CAMEL</td>
<td>helloWorld</td>
</tr>
<tr>
<td>LOWER_HYPHEN</td>
<td>hello-world</td>
</tr>
<tr>
<td>LOWER_UNDERSCORE</td>
<td>hello_world</td>
</tr>
<tr>
<td>UPPER_CAMEL</td>
<td>HelloWorld</td>
</tr>
<tr>
<td>UPPER_UNDERSCORE</td>
<td>HELLO_WORLD</td>
</tr>
</tbody></table>
<p>CaseFormat 的用法非常直接：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 把 LOWER_CAMEL 格式的 helloWorld 转为 UPPER_UNDERSCORE 格式</span></span><br><span class="line"><span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> CaseFormat.LOWER_CAMEL.to(CaseFormat.UPPER_UNDERSCORE, <span class="string">&quot;helloWorld&quot;</span>);</span><br><span class="line">System.out.println(s); <span class="comment">//HELLO_WORLD</span></span><br></pre></td></tr></table></figure>







<h2 id="Strings工具类"><a href="#Strings工具类" class="headerlink" title="Strings工具类"></a>Strings工具类</h2><p>我们首先来看一下 Strings 工具类提供的一些静态方法。</p>
<p><img src="/2022/06/14/Guava/image-20220621181533957.png" alt="image-20220621181533957"></p>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>String emptyToNull(String string)</td>
<td>将空字符串转换为NULL</td>
</tr>
<tr>
<td>String nullToEmpty(String string)</td>
<td>将NULL转换为空字符串</td>
</tr>
<tr>
<td>String commonPrefix(CharSequence a, CharSequence b)</td>
<td>返回两个字符串的公共前缀</td>
</tr>
<tr>
<td>String commonSuffix(CharSequence a, CharSequence b)</td>
<td>返回两个字符串的公共后缀</td>
</tr>
<tr>
<td>String repeat(String string, int count)</td>
<td>返回由<code>输入字符串*特定数量</code>的连接组成的字符串</td>
</tr>
<tr>
<td>boolean isNullOrEmpty(String string)</td>
<td></td>
</tr>
<tr>
<td>String padStart(String string, int minLength, char padChar)</td>
<td>判断字符串是否满足给定的最小长度，若不<br>满足则使用指定字符填充到最小要求长度。</td>
</tr>
<tr>
<td>String padEnd(String string, int minLength, char padChar)</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><strong>emptyToNull</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.base.Strings;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2022/6/21 18:14</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StringTests</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_emptyToNull</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">// 1、emptyToNull</span></span><br><span class="line">        <span class="comment">// 如果一个字符串是空串，就可以调用 emptyToNull 方法把它转换成一个 NULL 值</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> Strings.emptyToNull(<span class="string">&quot;&quot;</span>);</span><br><span class="line">        System.out.println(s == <span class="literal">null</span>); <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注意：&quot;空格&quot; 不是空字符串</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> Strings.emptyToNull(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        System.out.println(s1 == <span class="literal">null</span>); <span class="comment">// false</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、nullToEmpty</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> Strings.nullToEmpty(<span class="literal">null</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;===&quot;</span> + s2 + <span class="string">&quot;===&quot;</span>); <span class="comment">// ======</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注意：如果传入的参数不是NULL，则将字符串原样返回</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s3</span> <span class="operator">=</span> Strings.nullToEmpty(<span class="string">&quot;Hello&quot;</span>);</span><br><span class="line">        System.out.println(s3); <span class="comment">// Hello</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、commonPrefix：返回两个字符串的公共前缀</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s4</span> <span class="operator">=</span> Strings.commonPrefix(<span class="string">&quot;张三风&quot;</span>, <span class="string">&quot;张三丰&quot;</span>);</span><br><span class="line">        System.out.println(s4); <span class="comment">// 张三</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注意：如果两个字符串没有公共的前缀，则返回空字符串</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s5</span> <span class="operator">=</span> Strings.commonPrefix(<span class="string">&quot;张三&quot;</span>, <span class="string">&quot;李四&quot;</span>);</span><br><span class="line">        System.out.println(s5.equals(<span class="string">&quot;&quot;</span>)); <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、commonPrefix：返回两个字符串的公共后缀</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s6</span> <span class="operator">=</span> Strings.commonSuffix(<span class="string">&quot;龙傲天&quot;</span>, <span class="string">&quot;帝释天&quot;</span>);</span><br><span class="line">        System.out.println(s6); <span class="comment">// 天</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5、repeat</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s7</span> <span class="operator">=</span> Strings.repeat(<span class="string">&quot;嗨 &quot;</span>, <span class="number">3</span>);</span><br><span class="line">        System.out.println(s7); <span class="comment">// 嗨 嗨 嗨</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6、isNullOrEmpty</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b1</span> <span class="operator">=</span> Strings.isNullOrEmpty(<span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b2</span> <span class="operator">=</span> Strings.isNullOrEmpty(<span class="literal">null</span>);</span><br><span class="line">        System.out.println(b1 + <span class="string">&quot;;&quot;</span> + b2); <span class="comment">// true;true</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 9、padStart/padEnd：判断字符串是否满足给定的最小长度，若不满足则填充到最小要求长度</span></span><br><span class="line">        <span class="comment">// 在原字符串的头部 padStart 填充</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s9</span> <span class="operator">=</span> Strings.padStart(<span class="string">&quot;hello&quot;</span>, <span class="number">9</span>, <span class="string">&#x27;x&#x27;</span>);</span><br><span class="line">        System.out.println(s9); <span class="comment">// xxxxhello</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 在原字符串的尾部填充</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s10</span> <span class="operator">=</span> Strings.padEnd(<span class="string">&quot;hello&quot;</span>, <span class="number">9</span>, <span class="string">&#x27;x&#x27;</span>);</span><br><span class="line">        System.out.println(s10); <span class="comment">// xxxxhello</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果字符串长度大于要求的最小长度，则无需填充</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s8</span> <span class="operator">=</span> Strings.padStart(<span class="string">&quot;hello&quot;</span>, <span class="number">3</span>, <span class="string">&#x27;x&#x27;</span>);</span><br><span class="line">        System.out.println(s8); <span class="comment">// helloxxxx</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<hr>
<h1 id="Guava的函数式编程-Functional"><a href="#Guava的函数式编程-Functional" class="headerlink" title="Guava的函数式编程[Functional]"></a>Guava的函数式编程[Functional]</h1><p>Guava 的函数式编程与 JDK8 的函数式编程非常类似，但是通过引入 Guava 可以在更早的 JDK 版本中使用函数式编程。</p>
<h2 id="Predicate"><a href="#Predicate" class="headerlink" title="Predicate"></a>Predicate</h2><p>一个 <code>&lt;X&gt; input</code>，一个 <code>boolean output</code></p>
<h2 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h2><p>一个 <code>&lt;X&gt; input</code>，一个 <code>&lt;Y&gt; output</code></p>
<h2 id="Supplier"><a href="#Supplier" class="headerlink" title="Supplier"></a>Supplier</h2><p>没有 input，有一个 <code>&lt;Y&gt; output</code></p>
<h2 id="Functional"><a href="#Functional" class="headerlink" title="Functional"></a>Functional</h2><h1 id="Guava之I-O"><a href="#Guava之I-O" class="headerlink" title="Guava之I/O"></a>Guava之I/O</h1><p>同类产品：Apache commons-io</p>
<h2 id="为字节流-字符流提供的工具类"><a href="#为字节流-字符流提供的工具类" class="headerlink" title="为字节流/字符流提供的工具类"></a>为字节流/字符流提供的工具类</h2><ul>
<li>ByteStreams：提供对 InputStream/OutputStream 的操作。</li>
<li>CharStreams：提供对 Reader/Writer 的操作。</li>
</ul>
<p>在已创建流的基础上，可以使用 ByteStreams 和 CharStreams 对已创建的流进行操作。</p>
<p>注意：在使用完这两个工具类之后，一定要记得手动关闭已创建的流，因为流对象并不是这两个工具类创建的，它们只是对流对象进行了各项操作，所以它们并不能自动关闭流。</p>
<h2 id="源（Source）与汇（Sink）：对I-O进一步的抽象"><a href="#源（Source）与汇（Sink）：对I-O进一步的抽象" class="headerlink" title="源（Source）与汇（Sink）：对I/O进一步的抽象"></a>源（Source）与汇（Sink）：对I/O进一步的抽象</h2><p>源（Source）与汇（Sink）是 Guava 对 IO 的进一步抽象。</p>
<blockquote>
<p>I/O 指的是：InputStream、OutputStream、Reader、Writer 四大基类及其各种子实现类</p>
</blockquote>
<ul>
<li><strong>源（Source）：可读的数据流</strong></li>
<li><strong>汇（Sink）：可写的数据流</strong></li>
</ul>
<p>创建流对象的源头可能是不同的，比如：</p>
<ul>
<li>数据源是一个网络资源(URL)</li>
<li>或者数据源是一个文件</li>
</ul>
<p>但是通过这些不同的数据源创建出来的流对象本质上是一致的。所以 Guava 在此基础上提出了<strong>源（Source）</strong>和<strong>汇（Sink）</strong>的抽象。</p>
<ul>
<li>源是可读的，</li>
<li>汇是可写的，</li>
</ul>
<p>对于不同的数据类型，源又分为：</p>
<ul>
<li>ByteSource</li>
<li>CharSource</li>
</ul>
<p>汇被分为：</p>
<ul>
<li>ByteSink</li>
<li>CharSink</li>
</ul>
<p>通过这两个概念，我们在使用时可以屏蔽掉流是如何创建的。通过统一的一组 API 就可以操作由不同的源创建出来的流。并且由于它（Source 和 Sink）还是流的创建者，所以在使用完毕后还会负责将流关闭。</p>
<blockquote>
<p>比如，之前在使用流时我们会创建 FileInputStream 表示源来自于文件，HttpInputStream 表示数据来源于 HTTP 消息，PipeInputStream 表示数据来源于管道。但是我们又没办法不使用具体的实现类，因为基类 InputStream 中只提供了很少的可供使用的公共方法。</p>
</blockquote>
<h2 id="实战案例：文件操作"><a href="#实战案例：文件操作" class="headerlink" title="实战案例：文件操作"></a>实战案例：文件操作</h2><blockquote>
<p>利用 Guava 提供的相关工具类，实现对文件的常见操作。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.base.Charsets;</span><br><span class="line"><span class="keyword">import</span> com.google.common.collect.ImmutableList;</span><br><span class="line"><span class="keyword">import</span> com.google.common.io.CharSink;</span><br><span class="line"><span class="keyword">import</span> com.google.common.io.CharSource;</span><br><span class="line"><span class="keyword">import</span> com.google.common.io.Files;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2022/6/26 21:26</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 使用源（Source）与汇（Sink）对文件进行操作</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">IOTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 文件拷贝</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">copyFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1、创建对应的 Source 和 Sink</span></span><br><span class="line">        <span class="type">CharSource</span> <span class="variable">charSource</span> <span class="operator">=</span> Files.asCharSource(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;data.txt&quot;</span>), Charsets.UTF_8);</span><br><span class="line">        <span class="type">CharSink</span> <span class="variable">charSink</span> <span class="operator">=</span> Files.asCharSink(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;data_backup.txt&quot;</span>), Charsets.UTF_8);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、文件拷贝：将源数据写入汇中</span></span><br><span class="line">        charSource.copyTo(charSink);</span><br><span class="line">        ImmutableList&lt;String&gt; strings = charSource.readLines();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>charSource 对象中的常用方法</p>
<p><img src="/2022/06/14/Guava/image-20220626213840626.png" alt="image-20220626213840626"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将文件中的全部数据读到 String 类型的字符串中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">read</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 读取文件中的第一行数据</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">readFirstLine</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 按行读取文件中的数据，并将读到的数据保存到不可变集合 ImmutableList 中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> ImmutableList&lt;String&gt; <span class="title function_">readLines</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 逐行读取文件中的数据，并对每一行数据都使用行处理器 LineProcessor 进行处理</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> &lt;T&gt; T <span class="title function_">readLines</span><span class="params">(LineProcessor&lt;T&gt; processor)</span> <span class="keyword">throws</span> IOException</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 按行形成一个Stream流对象</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Stream&lt;String&gt; <span class="title function_">lines</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span><br></pre></td></tr></table></figure>

<p>charSink 对象中的常用方法</p>
<p><img src="/2022/06/14/Guava/image-20220626215615258.png" alt="image-20220626215615258"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将 charSequence 中的数据写入“汇”（charSink对象）中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(CharSequence charSequence)</span> <span class="keyword">throws</span> IOException</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将 Readable 对象中的数据写入“汇”（charSink对象）中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">long</span> <span class="title function_">writeFrom</span><span class="params">(Readable readable)</span> <span class="keyword">throws</span> IOException</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 按行写入。数据来源于已划分好元素的集合</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeLines</span><span class="params">(Iterable&lt;? extends CharSequence&gt; lines)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 按行写入。对每行元素还可以通过 lineSeparator 进一步划分</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeLines</span><span class="params">(Iterable&lt;? extends CharSequence&gt; lines, String lineSeparator)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 按行写入。数据来源于 Stream 流对象</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeLines</span><span class="params">(Stream&lt;? extends CharSequence&gt; lines)</span></span><br></pre></td></tr></table></figure>







<h2 id="Files"><a href="#Files" class="headerlink" title="Files"></a>Files</h2><p>拷贝文件</p>
<p><img src="/2022/06/14/Guava/image-20220621210614019.png" alt="image-20220621210614019"></p>
<p>移动文件</p>
<p><img src="/2022/06/14/Guava/image-20220621212601535.png" alt="image-20220621212601535"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p>创建流与汇对象</p>
<p>创建临时文件</p>
<p>创建文件的父级目录</p>
<p>判断文件</p>
<p>CharSource</p>
<p>CharSink</p>
<p>CharStreams</p>
<p>ByteSource</p>
<p>ByteSink</p>
<p>ByteStreams</p>
<p>Closer</p>
<p>BaseEncoding</p>
<hr>
<h1 id="汪文君Collections"><a href="#汪文君Collections" class="headerlink" title="汪文君Collections"></a><strong>汪文君Collections</strong></h1><h2 id="FluentIterable"><a href="#FluentIterable" class="headerlink" title="FluentIterable"></a><strong>FluentIterable</strong></h2><h3 id="静态方法"><a href="#静态方法" class="headerlink" title="静态方法"></a><strong>静态方法</strong></h3><p><strong>FluentIterable 是一个工具类，提供了如下静态方法：</strong></p>
<p><strong><img src="/2022/06/14/Guava/image-20220620213131901.png" alt="image-20220620213131901"></strong></p>
<ul>
<li><p><strong>from()：从数组类型 <code>E[]</code> 或 Iterable 类型的容器中取出数据放入 FluentIterable 集合中。</strong></p>
<ul>
<li><strong><code>FluentIterable&lt;E&gt; from(E[] elements)</code></strong></li>
<li><strong><code>FluentIterable&lt;E&gt; from(FluentIterable&lt;E&gt; iterable)</code></strong></li>
</ul>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> FluentIterable <span class="title function_">build</span><span class="params">()</span>&#123;</span><br><span class="line">    List&lt;String&gt; nameList = Lists.newArrayList(<span class="string">&quot;张三&quot;</span>, <span class="string">&quot;李四&quot;</span>, <span class="string">&quot;王五&quot;</span>);</span><br><span class="line">    FluentIterable&lt;String&gt; fluentIterable = FluentIterable.from(nameList);</span><br><span class="line">    <span class="keyword">for</span> (String s : fluentIterable) &#123;</span><br><span class="line">        System.out.print(s); <span class="comment">// 张三 李四 王五</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> fluentIterable;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong><code>concat()</code> 将数据拼接起来</strong></p>
</li>
<li><p><strong><code>of()</code> 0 个元素</strong></p>
</li>
<li><p><strong><code>of(E element, E... elements)</code> 1到多个元素。可变长度的 elements 可以为 0 个，但 element 必须有一个。</strong></p>
</li>
</ul>
<h3 id="普通方法-2"><a href="#普通方法-2" class="headerlink" title="普通方法"></a><strong>普通方法</strong></h3><p><strong>通过构造一个 FluentIterable 实例，我们看到它可以调用如下普通方法。</strong></p>
<p><strong><img src="/2022/06/14/Guava/image-20220620214807393.png" alt="image-20220620214807393"></strong></p>
<blockquote>
<p><strong><code>transformAndConcat(Function&lt;? super E, ? extends Iterable&lt;? extends T&gt;&gt; function)</code></strong></p>
</blockquote>
<p><strong>转换和连接</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/03/Activiti7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/06/03/Activiti7/" class="post-title-link" itemprop="url">Activiti7</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-06-03 11:51:15" itemprop="dateCreated datePublished" datetime="2022-06-03T11:51:15+08:00">2022-06-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-06-05 18:31:25" itemprop="dateModified" datetime="2022-06-05T18:31:25+08:00">2022-06-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B7%A5%E4%BD%9C%E6%B5%81/" itemprop="url" rel="index"><span itemprop="name">工作流</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="第一章-工作流概述"><a href="#第一章-工作流概述" class="headerlink" title="第一章 工作流概述"></a>第一章 工作流概述</h1><h2 id="1、什么是工作流"><a href="#1、什么是工作流" class="headerlink" title="1、什么是工作流"></a>1、什么是工作流</h2><p>…</p>
<h2 id="2、工作流应用场景"><a href="#2、工作流应用场景" class="headerlink" title="2、工作流应用场景"></a>2、工作流应用场景</h2><ul>
<li>  业务类：合同审批流程、订单处理流程、出入库审批流程等。</li>
<li>  行政类：请假流程、出差流程、办公用品申请流程等。</li>
<li>  财务类：报销流程、支付流程等。</li>
<li>  客户服务类：售后跟踪、客户投诉等。</li>
</ul>
<h2 id="3、BPMN2-0规范"><a href="#3、BPMN2-0规范" class="headerlink" title="3、BPMN2.0规范"></a>3、BPMN2.0规范</h2><h3 id="3-1-BPMN2-0是什么"><a href="#3-1-BPMN2-0是什么" class="headerlink" title="3.1 BPMN2.0是什么"></a>3.1 BPMN2.0是什么</h3><p>BPMN，Business Process Modeling Notation，业务流程模型注解。</p>
<h3 id="3-2-BPMN2-0基本流程符号"><a href="#3-2-BPMN2-0基本流程符号" class="headerlink" title="3.2 BPMN2.0基本流程符号"></a>3.2 BPMN2.0基本流程符号</h3><h4 id="事件Event"><a href="#事件Event" class="headerlink" title="事件Event"></a>事件Event</h4><p><img src="/2022/06/03/Activiti7/image-20220605171023417.png" alt="image-20220605171023417"></p>
<h4 id="活动Activity"><a href="#活动Activity" class="headerlink" title="活动Activity"></a>活动Activity</h4><p>活动是工作或任务的一个通用术语。</p>
<p>一个活动可以是一个任务，还可以是一个当前流程的子处理流程；其次，你还可以为活动指定不同的类型。</p>
<p>常见的活动如下：</p>
<p><img src="/2022/06/03/Activiti7/image-20220605171205918.png" alt="image-20220605171205918"></p>
<h4 id="网关Gateway"><a href="#网关Gateway" class="headerlink" title="网关Gateway"></a>网关Gateway</h4><p>网关用来处理决策：</p>
<p><img src="/2022/06/03/Activiti7/image-20220605171309046.png" alt="image-20220605171309046"></p>
<p><strong>排他网关（X）</strong></p>
<ul>
<li>  只有一条路径会被选择。流程执行到该网关时，按照输出流的顺序逐个计算，当条件的计算结果为true时，继续执行当前网关的输出流。</li>
<li>  如果多条线路的计算结果都是true，则会执行第一个为true的线路。如果所有网关的计算没有true，则抛出异常。</li>
<li>  排他网关需要和条件顺序流结合使用。使用default属性指定默认的顺序流，当所有的条件都不满足时会执行默认顺序流。</li>
</ul>
<p><strong>并行网关（+）</strong></p>
<ul>
<li>所有路径会被同时选择。<ul>
<li>  分支：并行执行所有输出顺序流，为每一条顺序流创建一个并行执行线路。</li>
<li>  汇聚：所有从并行网关拆分并执行完的线路均在此等候，直到所有的线路都执行完成才继续向后执行。</li>
</ul>
</li>
</ul>
<p><strong>包含网关（o）</strong></p>
<ul>
<li>可以同时执行多条线路，也可以在网关上设置条件。<ul>
<li>  分支：计算每条线路上的表达式，当表达式的结果为true时，创建一个并行线路并继续执行。</li>
<li>  汇聚：所有从并行网关拆分并执行完成的线路均在此等候，直到所有的线路都执行完成才继续向下执行。</li>
</ul>
</li>
</ul>
<p><strong>事件网关（o+）</strong></p>
<ul>
<li>  专门为中间捕获事件设置的，允许设置多个输出流指向多个不同的中间捕获事件。当流程执行到事件网关后，流程处于等待状态，需要等待抛出事件才能将等待状态转换为活动状态。</li>
</ul>
<h4 id="定时器事件"><a href="#定时器事件" class="headerlink" title="定时器事件"></a>定时器事件</h4><p><img src="/2022/06/03/Activiti7/image-20220605172512814.png" alt="image-20220605172512814"></p>
<ul>
<li>开始定时器事件<ul>
<li>  可以设置时间，定时开始启动流程实例。</li>
</ul>
</li>
<li>中间定时器事件<ul>
<li>  设定延迟时间，当完成任务A后，到达延时时间后，流程才会走向任务B。</li>
</ul>
</li>
<li>边界定时器事件<ul>
<li>  用于向某节点上添加边界定时事件。在设定时间内没有完成，流程实例则自动走向下一节点。</li>
</ul>
</li>
</ul>
<h1 id="第二章-Activiti"><a href="#第二章-Activiti" class="headerlink" title="第二章 Activiti"></a>第二章 Activiti</h1><h2 id="1、什么是Activiti"><a href="#1、什么是Activiti" class="headerlink" title="1、什么是Activiti"></a>1、什么是Activiti</h2><p>官网：<a target="_blank" rel="noopener" href="https://www.activiti.org/">https://www.activiti.org/</a></p>
<h2 id="2、Activiti开发流程"><a href="#2、Activiti开发流程" class="headerlink" title="2、Activiti开发流程"></a>2、Activiti开发流程</h2><ol>
<li><p>绘制流程定义模型</p>
<p> 遵循BPMN的流程规范，使用BPMN的流程定义工具，通过<strong>流程符号</strong>把整个业务流程定义出来。可以将流程定义文件的字节流保存到模型数据表中（Model）。</p>
</li>
<li><p>部署流程定义：</p>
<p> 就是将第一步画好的流程定义模型进行部署。</p>
<p> 加载画好的流程定义文件，将它转换成流程定义数据（ProcessDefinition），保存到流程定义数据表中。</p>
</li>
<li><p>启动流程（提交流程申请）</p>
<p> 部署好了流程定义之后就可以使用这个流程了。</p>
<p> 启动流程实例就是提交申请，比如申请请假就是提交了一个流程实例、申请报销也是提交了一个流程实例</p>
<p> 生成流程实例数据（ProcessInstance），生成第一节点任务数据（Task）</p>
</li>
<li><p>处理人审批流程节点任务</p>
<p> 完成任务审批。生成审批结果，生成下一节点任务数据。</p>
</li>
</ol>
<p><img src="/2022/06/03/Activiti7/Activiti%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B.svg" alt="Activiti开发流程"></p>
<h2 id="3、开发环境"><a href="#3、开发环境" class="headerlink" title="3、开发环境"></a>3、开发环境</h2><h3 id="3-1-框架版本号"><a href="#3-1-框架版本号" class="headerlink" title="3.1 框架版本号"></a>3.1 框架版本号</h3><table>
<thead>
<tr>
<th align="center">开发环境</th>
<th align="center">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="center">SpringBoot</td>
<td align="center">2.5.0</td>
</tr>
<tr>
<td align="center">Activiti</td>
<td align="center">7.1.0.M6</td>
</tr>
<tr>
<td align="center">JDK</td>
<td align="center">1.8</td>
</tr>
<tr>
<td align="center">MySQL</td>
<td align="center">8.0</td>
</tr>
<tr>
<td align="center">Maven</td>
<td align="center">3.6.3</td>
</tr>
</tbody></table>
<h3 id="3-2-Activiti支持的数据库"><a href="#3-2-Activiti支持的数据库" class="headerlink" title="3.2 Activiti支持的数据库"></a>3.2 Activiti支持的数据库</h3><p>Activiti 实质上就是通过数据库的数据表来控制业务流程。其支持的数据库如下：</p>
<table>
<thead>
<tr>
<th>数据库类型</th>
<th>JDBC连接示例</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>h2</td>
<td><code>jdbc:h2:tcp://localhost/activiti</code></td>
<td>默认使用的数据库</td>
</tr>
<tr>
<td>mysql</td>
<td><code>jdbc:mysql://localhost:3306/activiti?autoReconnect=true</code></td>
<td>使用<code>mysql-connector-java</code>数据库驱动程序进行测试</td>
</tr>
<tr>
<td>oracle</td>
<td><code>jdbc:oracle:thin:@localhost:1521:xe</code></td>
<td></td>
</tr>
<tr>
<td>postgres</td>
<td><code>jdbc:postgresql://localhost:5432/activiti</code></td>
<td></td>
</tr>
<tr>
<td>db2</td>
<td><code>jdbc:db2://localhost:50000/activiti</code></td>
<td></td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody></table>
<h3 id="3-3-依赖坐标"><a href="#3-3-依赖坐标" class="headerlink" title="3.3 依赖坐标"></a>3.3 依赖坐标</h3><ul>
<li><p>Activiti核心依赖</p>
<ul>
<li>  在Maven项目中，只需导入该依赖即可使用Activiti的核心功能</li>
</ul>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--activiti核心依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.activiti<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>activiti-engine<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>7.1.0.M6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
<li><p>SpringBoot整合Activiti依赖</p>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">    </span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="4、Activiti配置入门"><a href="#4、Activiti配置入门" class="headerlink" title="4、Activiti配置入门"></a>4、Activiti配置入门</h2><blockquote>
<p>  <strong>前置：</strong></p>
<ol>
<li> 在MySQL服务器中创建一个 activiti01 数据库；</li>
<li> 创建Maven项目并导入相关依赖；</li>
</ol>
</blockquote>
<h3 id="4-1-activiti-cfg-xml-核心配置"><a href="#4-1-activiti-cfg-xml-核心配置" class="headerlink" title="4.1 activiti.cfg.xml 核心配置"></a>4.1 activiti.cfg.xml 核心配置</h3><p>Activiti 流程引擎通过名为 <code>activiti.cfg.xml</code> 的配置文件进行配置。所以需要在 resource 目录下创建 <code>activiti.cfg.xml</code> 文件。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://www.springframework.org/schema/beans&quot;</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--默认情况下，bean的id必须是processEngineConfiguration--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;processEngineConfiguration&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--配置数据源--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;jdbcUrl&quot;</span> <span class="attr">value</span>=<span class="string">&quot;jdbc:mysql://localhost:3306/activiti01?nullCatalogMeansCurrent=true<span class="symbol">&amp;amp;</span>autoReconnect=true<span class="symbol">&amp;amp;</span>characterEncoding=utf8&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--characterEncoding=utf8 ：防止向MySQL中插入中文数据时乱码--&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--nullCatalogMeansCurrent=true ：解决数据库初始化时自动创建表的问题--&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &amp;amp;  转义符+分隔符--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;jdbcDriver&quot;</span> <span class="attr">value</span>=<span class="string">&quot;com.mysql.cj.jdbc.Driver&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;jdbcUsername&quot;</span> <span class="attr">value</span>=<span class="string">&quot;mysql_lvnengdong&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;jdbcPassword&quot;</span> <span class="attr">value</span>=<span class="string">&quot;AdminLnd5639634&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--activiti 数据库表的生成策略--&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">            自动更新数据库结构：</span></span><br><span class="line"><span class="comment">                true：默认值，适用于开发环境。activiti会对数据库中所有表进行更新操作。如果表不存在，则自动创建。</span></span><br><span class="line"><span class="comment">                false：适用于生产环境。activiti在启动时，会对比当前数据库中表的版本，不过没有表或者版本不匹配，则抛出异常。</span></span><br><span class="line"><span class="comment">                create_drop：在activiti启动时创建表，在关闭时删除表（必须手动关闭引擎，才能删除表）</span></span><br><span class="line"><span class="comment">                drop_create：在activiti启动时删除原来的旧表，然后再创建新表（不需要手段关闭引擎）</span></span><br><span class="line"><span class="comment">        --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;databaseSchemaUpdate&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <strong>注意：</strong></p>
<ul>
<li>  为了防止向MySQL数据库中插入中文数据时乱码，需要设置插入数据的字符编码为UTF8。</li>
<li>  数据库连接URL后面可以添加多个属性，当存在多个属性时，彼此之间需要使用『转义符+封号』<code>&amp;amp;</code> 分隔。 </li>
</ul>
</blockquote>
<h3 id="4-2-创建ProcessEngine流程引擎实例和数据表"><a href="#4-2-创建ProcessEngine流程引擎实例和数据表" class="headerlink" title="4.2 创建ProcessEngine流程引擎实例和数据表"></a>4.2 创建ProcessEngine流程引擎实例和数据表</h3><p>加载类路径下的 <code>activiti.cfg.xml</code> 配置文件，根据该文件中的配置构造一个流程引擎实例。在创建该实例的时候，会执行数据库的初始化脚本创建数据表。</p>
<p>创建ProcessEngine流程引擎实例的方式如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.activiti.engine.ProcessEngine;</span><br><span class="line"><span class="keyword">import</span> org.activiti.engine.ProcessEngineConfiguration;</span><br><span class="line"><span class="keyword">import</span> org.activiti.engine.ProcessEngines;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2022/6/3 17:42</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ActivitiTest01</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建流程引擎实例。</span></span><br><span class="line"><span class="comment">     * 在创建流程引擎实例的时候，会执行数据库初始化脚本，在数据库中创建25张表</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getProcessEngine</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">// 方式一：使用工具类ProcessEngines获取默认的流程引擎实例</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        * 使用这种方式，要求核心配置文件中流程引擎实例的id必须是 “processEngineConfiguration”</span></span><br><span class="line"><span class="comment">        * */</span></span><br><span class="line">        <span class="type">ProcessEngine</span> <span class="variable">processEngine</span> <span class="operator">=</span> ProcessEngines.getDefaultProcessEngine();</span><br><span class="line">        System.out.println(<span class="string">&quot;processEngine：&quot;</span> + processEngine);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        * 方式二：使用配置类创建流程引擎实例（等同于方式一）</span></span><br><span class="line"><span class="comment">        *   查看源码可知，该方法底层调用了 createProcessEngineConfigurationFromResource 方法，并指定了</span></span><br><span class="line"><span class="comment">        *   配置文件的路径为 activiti.cfg.xml ，核心实例的 beanName 为 processEngineConfiguration</span></span><br><span class="line"><span class="comment">        *</span></span><br><span class="line"><span class="comment">        *   所以，举一反三可以知道，如果想自定义配置文件的路径和核心实例的 beanName，可直接调用</span></span><br><span class="line"><span class="comment">        *   createProcessEngineConfigurationFromResource 方法</span></span><br><span class="line"><span class="comment">        * */</span></span><br><span class="line">        <span class="type">ProcessEngineConfiguration</span> <span class="variable">configuration</span> <span class="operator">=</span> ProcessEngineConfiguration.createProcessEngineConfigurationFromResourceDefault();</span><br><span class="line">        <span class="type">ProcessEngine</span> <span class="variable">processEngine1</span> <span class="operator">=</span> configuration.buildProcessEngine();</span><br><span class="line">        System.out.println(<span class="string">&quot;processEngine1：&quot;</span> + processEngine1);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        * 方式三：显式指定配置文件路径和 beanName</span></span><br><span class="line"><span class="comment">        * */</span></span><br><span class="line">        <span class="type">ProcessEngineConfiguration</span> <span class="variable">configuration1</span> <span class="operator">=</span> ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(<span class="string">&quot;activiti.cfg.bak.xml&quot;</span>, <span class="string">&quot;myProcessEngineConfiguration&quot;</span>);</span><br><span class="line">        <span class="type">ProcessEngine</span> <span class="variable">processEngine2</span> <span class="operator">=</span> configuration1.buildProcessEngine();</span><br><span class="line">        System.out.println(<span class="string">&quot;processEngine2：&quot;</span> + processEngine2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="4-3-Activiti的25张数据表分析"><a href="#4-3-Activiti的25张数据表分析" class="headerlink" title="4.3 Activiti的25张数据表分析"></a>4.3 Activiti的25张数据表分析</h3><p>Activiti 在创建 ProcessEngine 流程实例的时候会自动创建25张数据表，这正是 Activiti 能实现工作流的基础。</p>
<p><img src="/2022/06/03/Activiti7/image-20220604091757471.png" alt="image-20220604091757471"></p>
<p>Activiti 数据库中表的命名都是以 <code>act_</code> 开头的。<code>act_</code> 代表 Activiti。</p>
<ul>
<li>  <code>act_ge_*</code>：ge 是 generate 的缩写。这些表存放通用数据。即在各种情况下都会使用的数据，比如资源文件（图片、规则等）。</li>
<li>  <code>act_hi_*</code>：hi 是 history 的缩写。这些表存放历史数据，如结束的流程实例（变量、任务等）</li>
<li>  <code>act_re_*</code>：re 是 repository 的缩写。这些表存放静态数据信息。比如，流程定义、流程的资源（图片、规则等）。Activiti 只在流程实例执行过程中保存这些数据，在流程结束时就会删除这些记录。这样运行时表就可以一直很小、速度很快。</li>
<li>  <code>act_ru_*</code>：ru 是 runtime 的缩写。这些表是运行时的流程变量，用户任务、职责等运行时的数据。Activiti 只存储实例执行期间的运行时数据，当流程实例结束时，将删除这些记录。这就保证了这些运行时的表小且快。</li>
<li>  <code>act_evt_log</code>：evt 是 event 的缩写。这张表是流程引擎通用事件的日志记录表，方便管理员跟踪处理。</li>
<li>  <code>act_procdef_info</code></li>
</ul>
<table>
<thead>
<tr>
<th>表名</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>通用数据</strong></td>
<td></td>
</tr>
<tr>
<td>act_ge_bytearray</td>
<td>二进制数据表。主要用来存储一些字节数据，比如涉及到的图片、画的流程图以及对应的XML文件，都会以二进制数据保存在这张表中。</td>
</tr>
<tr>
<td>act_ge_property</td>
<td>属性数据表。存储整个Activiti引擎的元数据信息。初始化表结构时，会插入版本号信息等。</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>历史数据</strong></td>
<td></td>
</tr>
<tr>
<td>act_hi_actinst</td>
<td>历史节点表</td>
</tr>
<tr>
<td>act_hi_attachment</td>
<td>历史附件表。比如审批可能会涉及到提交附件，就会保存在这张表中。</td>
</tr>
<tr>
<td>act_hi_comment</td>
<td>历史意见表。如果审批时除了“批准”或“不批准”外，还需要编辑“审批意见”，则“审批意见”会保存在这张表中。</td>
</tr>
<tr>
<td>act_hi_detail</td>
<td>历史详情表。提供历史变量查询。</td>
</tr>
<tr>
<td>act_hi_identitylink</td>
<td>历史流程人员表。每个节点对应的审批人/处理人的信息。</td>
</tr>
<tr>
<td>act_hi_procinst</td>
<td>历史流程实例表。procinst = process instance。每次提交申请，都会保存一份历史数据</td>
</tr>
<tr>
<td>act_hi_taskinst</td>
<td>历史任务实例表</td>
</tr>
<tr>
<td>act_hi_varinst</td>
<td>历史变量表</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>流程定义表</strong></td>
<td></td>
</tr>
<tr>
<td>act_re_deployment</td>
<td>部署信息表</td>
</tr>
<tr>
<td>act_re_model</td>
<td>流程设计模型表</td>
</tr>
<tr>
<td>act_re_procdef</td>
<td>流程定义数据表</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>流程运行数据表</strong></td>
<td></td>
</tr>
<tr>
<td>act_ru_deadletter_job</td>
<td>作业死亡信息表。如果作业失败超过重试次数，则写入到此表。</td>
</tr>
<tr>
<td>act_ru_event_subscr</td>
<td>throwEvent、catchEvent时间监听信息表</td>
</tr>
<tr>
<td>act_ru_execution</td>
<td>运行时流程执行实例表</td>
</tr>
<tr>
<td>act_ru_identitylink</td>
<td>运行时流程人员表。主要存储任务节点与参与者的相关信息。</td>
</tr>
<tr>
<td>act_ru_integration</td>
<td>运行时积分表。</td>
</tr>
<tr>
<td>act_ru_job</td>
<td>定时异步任务数据表。</td>
</tr>
<tr>
<td>act_ru_suspended_job</td>
<td>运行时作业暂停表。比如流程中有一个定时任务，如果把这个任务停止工作了，这个任务写入此表中。</td>
</tr>
<tr>
<td>act_ru_task</td>
<td>运行时任务节点表。</td>
</tr>
<tr>
<td>act_ru_timer_job</td>
<td>运行时定时器作业表。</td>
</tr>
<tr>
<td>act_ru_variable</td>
<td>运行时流程变量数据表。</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>其它表</strong></td>
<td></td>
</tr>
<tr>
<td>act_procdef_info</td>
<td>流程定义的动态变更信息。procdef = process definition。即如果流程的定义发生了变更，会在这张表中进行记录。</td>
</tr>
<tr>
<td>act_evt_log</td>
<td>通用事件日志记录表。</td>
</tr>
</tbody></table>
<p>act_hi_detail，提供历史变量查询。比如在请假流程中，如果“请假时间&lt;3天”由直接部门领导审批即可，如果“请假时间&gt;3天”，则需要总经理审核。这其中，“3天”就是一个历史变量，而历史变量就会保存在 act_hi_detail 表中。</p>
<h2 id="Activiti-API服务接口"><a href="#Activiti-API服务接口" class="headerlink" title="Activiti API服务接口"></a>Activiti API服务接口</h2><p>Activiti 流程引擎包含了 25 张表，而且表间关系复杂，理解难度高。</p>
<p>按照传统的方式，有了数据库表后，就应该为每张表创建 Entity 实体类，然后为其创建对应的 DAO 接口，然后再创建对应的 Service 来实现对表数据的增删改查。</p>
<p>但是这些表数量多，关系复杂，还要兼顾流程引擎的处理方式，自己去实现一套处理规则难度很大。</p>
<p>因此 Activiti 已经帮我们把这些东西都实现了，不需要我们手动去创建 Entity、Dao、Service、Controller，它提供了一套简单易用的 APi，我们直接调用即可完成对应的功能。</p>
<p><img src="/2022/06/03/Activiti7/image-20220604111356712.png" alt="image-20220604111356712"></p>
<blockquote>
<p>  <strong>Tip</strong></p>
<p>  Activiti7 中没有 IdentityService 和 FormService 接口。</p>
</blockquote>
<h3 id="Activiti7的Service核心接口"><a href="#Activiti7的Service核心接口" class="headerlink" title="Activiti7的Service核心接口"></a>Activiti7的Service核心接口</h3><ul>
<li><p>Service管理接口说明</p>
<table>
<thead>
<tr>
<th>Service接口</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>RuntimeService</strong></td>
<td>运行时Service，可以处理所有处于运行状态的流程实例和任务。</td>
</tr>
<tr>
<td><strong>RepositoryService</strong></td>
<td>流程仓库Service，主要用于管理流程仓库，比如流程模型的控制管理（部署、删除、挂起、激活…）</td>
</tr>
<tr>
<td><strong>TaskRepository</strong></td>
<td>任务Service。用于管理和查询任务，例如：签收、办理等。</td>
</tr>
<tr>
<td><strong>HistoryService</strong></td>
<td>历史Service。可以查询所有历史数据，例如，流程实例信息、参与者信息、完成时间…</td>
</tr>
<tr>
<td>ManagementService</td>
<td>引擎管理Service。和具体业务无关，主要用于对Activiti流程引擎进行管理和维护。</td>
</tr>
<tr>
<td>DynamicBpmnService</td>
<td>RepositoryService可以用来部署流程模型（使用XML定义好的），一旦部署到Activiti（解析后保存到DB）后，流程模型就不会再变了，除非修改XML文件内容并重新部署。而DynamicBpmnService则允许我们在程序运行的过程中去修改流程模型的内容。比如：修改流程定义中分配的角色、优先级、流程流转条件等。</td>
</tr>
</tbody></table>
</li>
<li><p>核心Service接口实例的获取方式</p>
<p>  <img src="/2022/06/03/Activiti7/image-20220604113226413.png" alt="image-20220604113226413"></p>
</li>
</ul>
<blockquote>
<p>  创建流程引擎实例</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>



<p>Activiti 在创建流程引擎实例时，会执行数据库初始化的脚本，除了创建 25 张表外，还会执行下列语句向 <code>ACT_GE_PROPERTY</code> 表中插入一些元数据信息。</p>
<p>总共插入了 4 条数据，也就是说：在成功创建流程引擎实例后，数据库中就存在了以下四条记录。</p>
<p><img src="/2022/06/03/Activiti7/Activiti%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%9D%E5%A7%8B%E5%8C%96-1654417958883.png" alt="Activiti数据库初始化"></p>
<h3 id="部署流程模型"><a href="#部署流程模型" class="headerlink" title="部署流程模型"></a>部署流程模型</h3><p>通过BPMN和png文件部署流程模型</p>
<p>BPMN 对应的 XML 文件是流程模型真正的数据来源，而png图片只是对XML数据的描述文件，更方便用户进行预览。</p>
<p>部署流程模型的实质就是通过 Activiti 提供的 API 向数据库表中添加数据。我们以创建一个“请假申请流程”为例，查看部署流程模型时都向哪些表中添加了数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.activiti.engine.ProcessEngine;</span><br><span class="line"><span class="keyword">import</span> org.activiti.engine.ProcessEngines;</span><br><span class="line"><span class="keyword">import</span> org.activiti.engine.RepositoryService;</span><br><span class="line"><span class="keyword">import</span> org.activiti.engine.repository.Deployment;</span><br><span class="line"><span class="keyword">import</span> org.activiti.engine.repository.DeploymentBuilder;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2022/6/5 10:51</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ActivitiTest02</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 部署流程模型</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deploymentTest</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">// 1、获取流程引擎实例</span></span><br><span class="line">        <span class="type">ProcessEngine</span> <span class="variable">processEngine</span> <span class="operator">=</span> ProcessEngines.getDefaultProcessEngine();</span><br><span class="line">        <span class="comment">// 2、获取部署流程模型的相关Service——RepositoryService</span></span><br><span class="line">        <span class="type">RepositoryService</span> <span class="variable">repositoryService</span> <span class="operator">=</span> processEngine.getRepositoryService();</span><br><span class="line">        <span class="comment">// 3、调用相关API部署流程模型</span></span><br><span class="line">        <span class="type">DeploymentBuilder</span> <span class="variable">builder</span> <span class="operator">=</span> repositoryService.createDeployment();</span><br><span class="line">        <span class="type">Deployment</span> <span class="variable">deployment</span> <span class="operator">=</span> builder.name(<span class="string">&quot;请假申请流程&quot;</span>)  <span class="comment">// 起名字</span></span><br><span class="line">                .addClasspathResource(<span class="string">&quot;processes/leave.bpmn&quot;</span>)  <span class="comment">// 加载资源文件</span></span><br><span class="line">                .addClasspathResource(<span class="string">&quot;processes/leave.png&quot;</span>)</span><br><span class="line">                .deploy();</span><br><span class="line">        <span class="comment">// 4、输出部署结果</span></span><br><span class="line">        System.out.println(<span class="string">&quot;部署ID=====&quot;</span> + deployment.getId());</span><br><span class="line">        System.out.println(<span class="string">&quot;部署名称=====&quot;</span> + deployment.getName());</span><br><span class="line">        <span class="comment">// 5、部署之后，流程模型数据就会保存到数据库表中</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 执行以上代码，输出结果为：</span></span><br><span class="line"><span class="comment">        --------------------------------------</span></span><br><span class="line"><span class="comment">                部署ID=====1</span></span><br><span class="line"><span class="comment">                部署名称=====请假申请流程</span></span><br><span class="line"><span class="comment">        ----------------------------------- */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对应数据库涉及到的写操作操作有：</p>
<p><img src="/2022/06/03/Activiti7/%E9%83%A8%E7%BD%B2%E6%B5%81%E7%A8%8B%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%98%E5%8C%96.png" alt="部署流程模型数据库变化"></p>
<p><img src="/2022/06/03/Activiti7/bpmn-structure.png" alt="bpmn-structure"></p>
<p><img src="/2022/06/03/Activiti7/activiti-flow.png" alt="activiti-flow"></p>
<h2 id="流程-amp-流程实例"><a href="#流程-amp-流程实例" class="headerlink" title="流程 &amp; 流程实例"></a>流程 &amp; 流程实例</h2><ul>
<li>  流程由遵守 BPMN2.0 规范的 XML 文件指定，定义流程即完成流程文件的设计。</li>
<li>  流程发布后，使用 RuntimeService 可以开启一个流程实例，每个流程可以开启 N 次流程实例，且实例之间的数据相互隔离。</li>
</ul>
<h2 id="用户任务"><a href="#用户任务" class="headerlink" title="用户任务"></a>用户任务</h2><p>用户任务是 BPMN 规范中 Activities 组件下的重要组成部分，在 Activiti 中对应 Task 类；区别于其它类型的任务，用户任务需要进行领取操作，不会自动执行，且领取后从待处理任务列表中移出，其它候选人不可见。</p>
<h2 id="用户-amp-角色"><a href="#用户-amp-角色" class="headerlink" title="用户 &amp; 角色"></a>用户 &amp; 角色</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/31/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/31/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-31 12:13:49" itemprop="dateCreated datePublished" datetime="2022-05-31T12:13:49+08:00">2022-05-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-11-06 15:36:06" itemprop="dateModified" datetime="2021-11-06T15:36:06+08:00">2021-11-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/31/temp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/31/temp/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-31 12:13:49" itemprop="dateCreated datePublished" datetime="2022-05-31T12:13:49+08:00">2022-05-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-04-03 22:07:59" itemprop="dateModified" datetime="2022-04-03T22:07:59+08:00">2022-04-03</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><img src="/2022/05/31/temp/image-20220403104256750.png" alt="image-20220403104256750"></p>
<p>Spring Framework 的设计理念非常着重的突出了一个分层的设计。它争取在每一层都让你可以进行自己的选择，比如，在上图中的数据访问层，你可以选择 JDBC，也可以选择 ORM 这样的方式。如果你选择 ORM，Spring 也提供了 ORM 的实现框架，如 Hibernate、也可以选择 iBatis 或者 MyBatis 这样的框架，所以说他其实把能够想到的主流的研发框架或者工具支持都已经考虑在里面了。</p>
<p>通过 <code>curl</code> 命令可以直接在控制窗口访问网页，非常的帅气。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E:\workspace_java\spring-all&gt;curl http://localhost:8080/hello</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/31/Spark-Core/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/31/Spark-Core/" class="post-title-link" itemprop="url">Spark_Core</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-31 12:13:49" itemprop="dateCreated datePublished" datetime="2022-05-31T12:13:49+08:00">2022-05-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-01-16 13:06:58" itemprop="dateModified" datetime="2022-01-16T13:06:58+08:00">2022-01-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="第-1-章-RDD-概述"><a href="#第-1-章-RDD-概述" class="headerlink" title="第 1 章 RDD 概述"></a>第 1 章 RDD 概述</h1><h2 id="1-1-什么是-RDD"><a href="#1-1-什么是-RDD" class="headerlink" title="1.1 什么是 RDD"></a>1.1 什么是 RDD</h2><blockquote>
<p>  RDD；Resilient Distributed Dataset；弹性分布式数据集</p>
</blockquote>
<p><strong>数据集</strong>：表示 RDD 是一个保存数据的集合</p>
<p><strong>分布式</strong>：RDD 中保存的数据可以位于多台不同的服务器上</p>
<p><strong>弹性：</strong>可扩展，易转换</p>
<p>RDD 是 Spark 中最基本的数据抽象。</p>
<p>RDD 在代码中是一个<strong>抽象类</strong>，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。</p>
<ul>
<li>  可并行计算：即可以使用多个线程处理同一个 RDD 中的数据</li>
</ul>
<hr>
<h2 id="1-2-RDD-的-5-个主要属性（property）"><a href="#1-2-RDD-的-5-个主要属性（property）" class="headerlink" title="1.2 RDD 的 5 个主要属性（property）"></a>1.2 RDD 的 5 个主要属性（property）</h2><ol>
<li><p><strong>A list of partitions</strong>：一个分区列表</p>
<p> RDD 是一个数据集，并且支持并行运算（多线程同时处理该数据集中的数据）。在并行运算时，需要对 RDD 数据集进行<strong>分区</strong>，每个线程负责执行一个分区的运算。记录每个分区元数据信息的列表就叫做<strong>分区列表</strong>。</p>
<ul>
<li>  一个 RDD 数据集在运行时会在逻辑上划分为多个分区。</li>
<li>  每个分区都会分配一个线程来执行数据的运算，分区数决定了并行数。</li>
<li>  用户可以在创建 RDD 对象时显式指定分区数目，如果未指定则采用默认值，默认值就是程序所分配到的 CPU Core 的数目。</li>
<li>  每个 <code>Partition</code> 存储的分配是由 <code>BlockManager</code> 决定的，每个分区都会被逻辑映射成 <code>BlockManager</code> 的一个 <code>Block</code>，而这个 <code>Block</code> 会被一个 <code>Task</code> 负责计算。</li>
</ul>
</li>
<li><p><strong>A function for computing each split</strong>：一个计算切片的函数</p>
<ul>
<li><p>  切片就是切分 RDD 数据集，切分后的数据保存在分区中。在 Spark 中，切片和分区可以视为等价的。</p>
</li>
<li><p>  切片函数就是定义切片规则的函数。</p>
</li>
<li><p>  Spark 中 RDD 的计算是以 <code>split</code> 为单位的，每个 RDD 都会实现 <code>compute()</code> 方法以达到这个目的。</p>
</li>
</ul>
</li>
</ol>
<p>​    </p>
<ol start="3">
<li><p><strong>A list of dependencies on other RDDs</strong>：保存当前 RDD 与其它 RDD 之间依赖关系的列表。</p>
<ul>
<li><p>  一个 RDD 可能会依赖多个 RDD，每个 RDD 都会维护一张保存自身所有依赖关系的列表。</p>
</li>
<li><p>RDD 是不可变的，每次转换都会生成一个新的 RDD。所以 RDD 之间会形成类似于流水线一样的前后依赖关系。在部分分区数据丢失时， Spark 可以通过这个依赖关系重新计算丢失的分区数据，而不是对 RDD 的所有分区进行重新计算。</p>
</li>
</ul>
</li>
<li><p><strong>Optionally，a Partitioner for key-value RDDs</strong> （e.g. to say that the RDD is hash-partitioned）</p>
<ul>
<li>  可选的。只有对于 <code>key-value</code> 结构的 RDD，才需要设置分区器<code>(Partitioner)</code>，对于非 <code>key-value</code> 结构的 RDD，其 <code>Partitioner</code> 的值是 <code>None</code>。</li>
<li>  <code>Partitiner</code> 不但决定了 RDD 的本区数量，也决定了 <code>parent RDD Shuffle</code> 输出时的分区数量。</li>
</ul>
</li>
<li><p><strong>Optionally，a list of preferred locations to compute each split on （e.g. block locations for an HDFS file）</strong></p>
<ul>
<li>  可选的。存储每个切片优先（preferred location）位置的列表。比如对于一个 HDFS 文件来说，这个列表保存的就是每个 <code>Partition</code> 所在文件块的位置。按照“移动数据不如移动计算”的理念， Spark 在进行任务调度的时候，会尽可能地将计算任务分配到其所要处理数据块的存储位置。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="1-3-理解-RDD"><a href="#1-3-理解-RDD" class="headerlink" title="1.3 理解 RDD"></a>1.3 理解 RDD</h2><p>一个 RDD 对象可以简单的理解为一个存储分布式数据的集合。</p>
<p>RDD 是一个只读数据集，对 RDD 进行改动，只能通过 RDD 的转换操作，然后得到新的 RDD，并不会对原 RDD 有任何的影响。</p>
<p>在 Spark 中，所有的工作要么是创建 RDD，要么是转换已经存在 RDD 成为新的 RDD，要么在 RDD 上去执行一些操作来得到一些计算结果。</p>
<p>每个 RDD 被切分到多个 <code>partition</code> 中去，每个 <code>partition</code> 可能会在集群中不同的节点上进行计算。</p>
<h3 id="1-3-1-RDD-特点"><a href="#1-3-1-RDD-特点" class="headerlink" title="1.3.1  RDD 特点"></a>1.3.1  RDD 特点</h3><h4 id="1-3-1-1-弹性"><a href="#1-3-1-1-弹性" class="headerlink" title="1.3.1.1   弹性"></a>1.3.1.1   弹性</h4><ul>
<li><p>存储的弹性：内存与磁盘的自动切换；</p>
<p>  【在进行内存运算时如果内存不够用了，就会切换到磁盘运算。反之亦然】</p>
</li>
<li><p>容错的弹性：数据丢失可以自动恢复；</p>
</li>
<li><p>计算的弹性：计算出错重试机制；</p>
</li>
<li><p>分片的弹性：可根据需要重新分片。</p>
</li>
</ul>
<hr>
<h4 id="1-3-1-2-分区"><a href="#1-3-1-2-分区" class="headerlink" title="1.3.1.2 分区"></a>1.3.1.2 分区</h4><p>RDD 逻辑上是分区的，每个分区的数据是抽象存在的，计算的时候会通过一个 <code>compute()</code> 函数得到每个分区的数据。</p>
<p>如果 RDD 是通过已有的文件系统构建，则 <code>compute()</code> 函数是读取指定文件系统中的数据，如果 RDD 是通过其它 RDD 转换而来，则 <code>compute()</code> 函数是执行转换逻辑将其它 RDD 的数据进行转换。</p>
<hr>
<h4 id="1-3-1-3-只读"><a href="#1-3-1-3-只读" class="headerlink" title="1.3.1.3   只读"></a>1.3.1.3   只读</h4><p>RDD 是只读的，要想改变 RDD 中的数据，只能在现有 RDD 基础上创建新的 RDD。</p>
<p>由一个 RDD 转换到另一个 RDD，可以通过丰富的转换算子实现，不再像 <code>MapReduce</code> 那样只能写 <code>map</code> 和 <code>reduce</code> 了。</p>
<p>RDD 的操作算子包括两类，</p>
<ul>
<li>一类叫做 <code>transformation</code>，它是用来对 RDD 进行转化，构建 RDD 的血缘关系；</li>
<li>另一类叫做 <code>action</code>，它是用来触发 RDD 进行计算，得到 RDD 的相关计算结果或者保存 RDD 数据到文件系统中。</li>
</ul>
<hr>
<h4 id="1-3-1-4-依赖（血缘）"><a href="#1-3-1-4-依赖（血缘）" class="headerlink" title="1.3.1.4   依赖（血缘）"></a>1.3.1.4   依赖（血缘）</h4><p>RDDs 通过操作算子进行转换，转换得到的新 RDD 包含了从其它 RDDs 衍生所必需的信息，RDDs 之间维护着这种血缘关系，也称之为依赖。</p>
<p>如下图所示，依赖包括两种，</p>
<ul>
<li><strong>窄依赖</strong>：上游 RDD 的一个分区只与下游 RDD 的一个分区有关，是一对一或多对一关系。</li>
<li><strong>宽依赖</strong>：上游 RDD 的一个分区与下游 RDD 的多个分区都有关，是一对多的关系。</li>
</ul>
<img src="/2022/05/31/Spark-Core/image-20211214122641729.png" alt="image-20211214122641729" style="zoom:150%;">





<hr>
<h4 id="1-3-1-5-缓存"><a href="#1-3-1-5-缓存" class="headerlink" title="1.3.1.5   缓存"></a>1.3.1.5   缓存</h4><p>如果在应用程序中多次使用到了同一个 RDD，可以将该 RDD 缓存起来，该 RDD 只有在第一次计算的时候会根据血缘关系依次计算得到分区的数据，在后续其它地方用到该 RDD 的时候，会直接从缓存中取而不用再根据血缘关系重头计算，这样可以加速后期的重用。</p>
<p>如下图所示，RDD-1 经过一系列的转换后得到 RDD-n 并保存到 HDFS，RDD-1 在这一过程中会有个中间结果，如果将其缓存到内存，那么在随后的 RDD-1 转换到 RDD-m 这一过程中，就不会计算其之前的 RDD-0 了。</p>
<img src="/2022/05/31/Spark-Core/image-20211214122828163.png" alt="image-20211214122828163" style="zoom：150%;">



<hr>
<h4 id="1-3-1-6-checkpoint"><a href="#1-3-1-6-checkpoint" class="headerlink" title="1.3.1.6    checkpoint"></a>1.3.1.6    checkpoint</h4><p>虽然 RDD 的血缘关系天然地可以实现容错，当 RDD 的某个分区数据计算失败或丢失，可以通过血缘关系重建。</p>
<p>但是对于长时间迭代型应用来说，随着迭代的进行，RDDs 之间的血缘关系会越来越长，一旦在后续迭代过程中出错，则需要通过非常长的血缘关系去重建，势必影响性能。</p>
<p>为此，RDD 支持 <code>checkpoint</code> 将数据持久化存储，这样就可以切断 <code>checkpoint</code> 点之前的血缘关系，在 <code>checkpoint</code> 后的 RDD 不需要知道它的父 RDDs 了，它可以直接从 <code>checkpoint</code> 处拿到数据。</p>
<hr>
<h1 id="第-2-章-RDD-编程"><a href="#第-2-章-RDD-编程" class="headerlink" title="第 2 章 RDD 编程"></a>第 2 章 RDD 编程</h1><h2 id="2-1-RDD-编程模型"><a href="#2-1-RDD-编程模型" class="headerlink" title="2.1 RDD 编程模型"></a>2.1 RDD 编程模型</h2><p>在 Spark 中，RDD 可视为一个对象，通过调用对象的方法来对 RDD 进行转换。</p>
<p>RDD 经过一系列的 <code>transformations</code> 转换操作之后，就可以调用 <code>actions</code> 触发 RDD 的计算。</p>
<p><code>action</code> 可以向应用程序返回结果（<code>count</code>，<code>collect</code>等），也可以向存储系统保存数据（<code>saveAsTextFile</code>等）。</p>
<p>在 Spark 中，只有遇到 <code>action</code> 后，才会执行 RDD 的计算（即延迟计算），这样在运行时可以通过管道的方式传输多个转换。</p>
<p>要使用 Spark，开发者需要编写一个 <code>Driver</code> 程序，它最终会被提交到集群上来调度运行 <code>Worker</code></p>
<p><code>Driver</code> 中定义了一个或多个 RDD，并调用 RDD 上的 <code>action</code>，<code>Worker</code> 则执行 RDD 分区计算任务。</p>
<hr>
<h2 id="2-2-RDD-的创建"><a href="#2-2-RDD-的创建" class="headerlink" title="2.2    RDD 的创建"></a>2.2    RDD 的创建</h2><p>在 Spark 中创建 RDD 的方式可以分为 2 种：</p>
<ol>
<li>从数据源得到 RDD<ul>
<li>  外部数据源：文件、数据库等</li>
<li>  集合数据源</li>
</ul>
</li>
<li> 从其它 RDD 转换得到新的 RDD</li>
</ol>
<hr>
<h3 id="2-2-1-从集合中创建-RDD"><a href="#2-2-1-从集合中创建-RDD" class="headerlink" title="2.2.1  从集合中创建 RDD"></a>2.2.1  从集合中创建 RDD</h3><ol>
<li> <code>parallelize()</code>方法</li>
<li> <code>makeRDD()</code> 方法</li>
</ol>
<p><strong>源码</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">  参数1：seq，传递一个Scala集合，作为RDD的数据源。</span></span><br><span class="line"><span class="comment">  Distribute a local Scala collection to form an RDD.</span></span><br><span class="line"><span class="comment">  </span></span><br><span class="line"><span class="comment">  参数2：numSlices，传递一个整型变量，表示以几个CPU核心执行该方法。默认使用SparkContext指定的核心数</span></span><br><span class="line"><span class="comment">  This method is identical to parallelize.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeRDD</span></span>[<span class="type">T</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    seq: <span class="type">Seq</span>[<span class="type">T</span>],	</span><br><span class="line">    numSlices: <span class="type">Int</span> = defaultParallelism): <span class="type">RDD</span>[<span class="type">T</span>] = withScope &#123;</span><br><span class="line">    <span class="comment">// makeRDD 底层调用的还是 parallelize 方法，所以这两个方法是等价的</span></span><br><span class="line">    parallelize(seq, numSlices)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>使用 <code>parallelize()</code> 函数创建 RDD</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1、准备数据源</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> arr = <span class="type">Array</span>(<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>,<span class="number">50</span>,<span class="number">60</span>)</span><br><span class="line">arr： <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">10</span>，<span class="number">20</span>，<span class="number">30</span>，<span class="number">40</span>，<span class="number">50</span>，<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2、创建 RDD 对象</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(arr)</span><br><span class="line">rdd1： org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;：<span class="number">26</span></span><br></pre></td></tr></table></figure>



<p><strong>使用 <code>makeRDD()</code> 函数创建 RDD</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">Array</span>(<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>,<span class="number">50</span>,<span class="number">60</span>))</span><br><span class="line">rdd1： org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at makeRDD at &lt;console&gt;：<span class="number">24</span></span><br></pre></td></tr></table></figure>



<p><strong>说明：</strong></p>
<ul>
<li>  一旦 RDD 创建成功，就可以通过并行的方式去操作这个分布式的数据集了。</li>
<li>  <code>parallelize()</code> 和 <code>makeRDD()</code> 还有一个重要的参数就是把数据集切分成的<strong>分区数</strong>。</li>
<li>  Spark 会为每个分区运行一个 Task 线程。默认情况下，Spark 会自动的根据你的集群来设置分区数。</li>
</ul>
<hr>
<h3 id="2-2-2-从外部存储创建-RDD"><a href="#2-2-2-从外部存储创建-RDD" class="headerlink" title="2.2.2  从外部存储创建 RDD"></a>2.2.2  从外部存储创建 RDD</h3><p>Spark 也可以从任意 Hadoop 支持的存储数据源来创建分布式数据集。可以是<strong>本地文件系统、HDFS、Cassandra、HBase、Amazon S3</strong> 等等。</p>
<p>Spark 支持<strong>文本文件、SequenceFiles</strong>、和其它<strong>所有的 Hadoop InputFormat</strong> 。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> rdd2 = sc.textFile（<span class="string">&quot;words.txt&quot;</span>）</span><br><span class="line">rdd2： org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = words.txt <span class="type">MapPartitionsRDD</span>[<span class="number">1</span>] at textFile at &lt;console&gt;：<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; distFile.collect</span><br><span class="line">res0： <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>（atguigu hello，hello world，how are you，abc efg）</span><br></pre></td></tr></table></figure>



<p><strong>说明：</strong></p>
<ul>
<li><p>  URL 可以是：<code>本地文件系统文件</code>，<code>hdfs：//...</code>，<code>s3n：//...</code> 等等</p>
</li>
<li><p>  如果使用的是本地文件系统的路径，则集群中的每个节点上都必须存在这个路径</p>
</li>
<li><p>所有基于文件的方法，都支持目录，压缩文件，和通配符（*）。例如： </p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">textFile(<span class="string">&quot;/my/directory&quot;</span>)</span><br><span class="line">textFile(<span class="string">&quot;/my/directory/.txt&quot;</span>) </span><br><span class="line">textFile(<span class="string">&quot;/my/directory/.gz&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>  <code>textFile()</code> 方法还可以有第二个参数，表示分区数。默认情况下，每个块对应一个分区（对 HDFS 来说，块大小默认是 128M），可以传递一个大于块数的分区数，但是不能传递一个比块数小的分区数。</p>
</li>
<li><p>  关于读取文件和保存文件的其它知识，后面专门的章节介绍。</p>
</li>
</ul>
<hr>
<h3 id="2-2-3-从其它-RDD-转换得到新的-RDD"><a href="#2-2-3-从其它-RDD-转换得到新的-RDD" class="headerlink" title="2.2.3  从其它 RDD 转换得到新的 RDD"></a>2.2.3  从其它 RDD 转换得到新的 RDD</h3><p>就是通过 RDD 的各种转换算子来得到新的 RDD.</p>
<hr>
<h2 id="2-3-RDD-的转换（transformation）"><a href="#2-3-RDD-的转换（transformation）" class="headerlink" title="2.3 RDD 的转换（transformation）"></a>2.3 RDD 的转换（transformation）</h2><p>在 RDD 上支持 2 种类型的操作：</p>
<ol>
<li> <strong>transformation</strong>：由一个已知的 RDD 转换得到一个新的 RDD。</li>
<li> <strong>action</strong>：在数据集上计算结束之后，给驱动程序 Driver 返回一个值。</li>
</ol>
<p>在 Spark 中几乎所有的 <code>transformation</code> 操作都是懒执行的，也就是说 <code>transformation</code> 操作并不会立即计算它们的结果，而是记住了这个操作，只有当通过一个 <code>action</code> 来获取结果返回给驱动程序的时候这些转换操作才开始执行。这种设计可以使 Spark 运行起来更加的高效。</p>
<p>默认情况下，你每次在一个 RDD 上运行一个 <code>action</code> 的时候，前面的每个 <code>transformed RDD</code> 都会被重新计算。</p>
<p>但是我们可以通过 <code>persist (or cache)</code> 方法来持久化一个 RDD 道内存中或磁盘上，来加快访问速度。 </p>
<p>根据 RDD 中数据类型的不同，整体分为 2 种 RDD：</p>
<ul>
<li>  <strong>Value 类型</strong></li>
<li>  <strong>Key-Value 类型</strong></li>
</ul>
<hr>
<h3 id="2-3-1-Value-类型"><a href="#2-3-1-Value-类型" class="headerlink" title="2.3.1  Value 类型"></a>2.3.1  Value 类型</h3><h4 id="1-map-func"><a href="#1-map-func" class="headerlink" title="1    map(func)"></a>1    <code>map(func)</code></h4><p><strong>作用：</strong>返回一个新的 RDD，该 RDD 是由原 RDD 中的每个元素经过函数转换后的值组成，就是对 RDD 中的每个数据做转换。</p>
<p><strong>案例：</strong>创建一个包含 1~10 的 RDD，然后将 <code>每个元素*2</code> 形成新的 RDD</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala &gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>)</span><br><span class="line">rdd1： org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;：<span class="number">24</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 得到一个新的 RDD，但是这个 RDD 中的元素并不是立即计算出来的</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = rdd1.map(_ * <span class="number">2</span>)</span><br><span class="line">rdd2： org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">1</span>] at map at &lt;console&gt;：<span class="number">26</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 开始计算 rdd2 中的元素，并把计算后的结果传递给 Driver 展示</span></span><br><span class="line">scala&gt; rdd2.collect</span><br><span class="line">res0： <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">2</span>，<span class="number">4</span>，<span class="number">6</span>，<span class="number">8</span>，<span class="number">10</span>，<span class="number">12</span>，<span class="number">14</span>，<span class="number">16</span>，<span class="number">18</span>，<span class="number">20</span>)</span><br></pre></td></tr></table></figure>



<hr>
<h4 id="2-mapPartitions-func"><a href="#2-mapPartitions-func" class="headerlink" title="2   mapPartitions(func)"></a>2   <code>mapPartitions(func)</code></h4><p><strong>源码：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">  参数1：f是一个函数，f函数的作用就是把一个集合转换成另一个集合。</span></span><br><span class="line"><span class="comment">  Iterator是一个迭代器，可以看做是一个集合，表示一个分区内所有的元素，</span></span><br><span class="line"><span class="comment">  Iterator[T] =&gt; Iterator[U] 表示处理 Iterator[T] 中的所有元素并将结</span></span><br><span class="line"><span class="comment">  果封装到另一个集合Iterator[U]中返回，</span></span><br><span class="line"><span class="comment">  </span></span><br><span class="line"><span class="comment">  参数2：preservesPartitioning，分区数量相关</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartitions</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">      f: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">Iterator</span>[<span class="type">U</span>],</span><br><span class="line">      preservesPartitioning: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>作用：</strong>类似于 <code>map(func)</code>，但是 <code>func</code> 的类型是：<code>Iterator&lt;T&gt; =&gt; Iterator&lt;U&gt;</code>，表示每次处理一个集合中的数据到另一个集合中，在 Spark 中每个分区的数据保存在一个集合中， 所以 <code>func</code> 在每个分区上只运行一次。</p>
<p>假设有 N 个元素，有 M 个分区，那么 <code>map</code> 函数将会被调用 N 次，而 <code>mapPartitions</code> 只会被调用 M 次，<code>func</code>函数一次处理一个分区内的所有数据。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> source = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>)</span><br><span class="line">source： org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">5</span>] at parallelize at &lt;console&gt;：<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; source.mapPartitions(it =&gt; it.map(x =&gt; x * <span class="number">2</span>))	<span class="comment">// 这里的 it 就表示某一个分区内的数据，保存在一个集合中</span></span><br><span class="line">res7： org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">6</span>] at mapPartitions at &lt;console&gt;：<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res7.collect</span><br><span class="line">res8： <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>（<span class="number">2</span>，<span class="number">4</span>，<span class="number">6</span>，<span class="number">8</span>，<span class="number">10</span>，<span class="number">12</span>，<span class="number">14</span>，<span class="number">16</span>，<span class="number">18</span>，<span class="number">20</span>）</span><br></pre></td></tr></table></figure>



<hr>
<h4 id="3-map-和-mapPartitions-的区别"><a href="#3-map-和-mapPartitions-的区别" class="headerlink" title="3   map() 和 mapPartitions() 的区别"></a>3   <code>map()</code> 和 <code>mapPartitions()</code> 的区别</h4><ol>
<li> <code>map(func)</code>：处理一个集合中的数据，集合中的每个元素都需要执行一次 <code>func</code> 函数。</li>
<li> <code>mapPartitions(func)</code>：也是处理一个集合中的数据，但是该集合按照数据存储的不同分区又被划分为了 M 个子集合，M 等于分区数，每个子集合保存一个分区内的所有数据，每执行一次 <code>func</code> 函数就处理一个分区中的数据。也就是说如果集合数据被分到三个分区中存储，那么 <code>func</code> 只需要执行三次，每次处理一个分区的数据。</li>
<li> 当内存空间较大的时候建议使用 <code>mapPartitions()</code>，以提高处理效率。</li>
</ol>
<hr>
<h4 id="4-mapPartitionsWithIndex-func"><a href="#4-mapPartitionsWithIndex-func" class="headerlink" title="4   mapPartitionsWithIndex(func)"></a>4   <code>mapPartitionsWithIndex(func)</code></h4><p><strong>作用：</strong> <code>mapPartitionsWithIndex(func)</code> 和 <code>mapPartitions(func)</code> 类似，但是会给 <code>func</code> 多提供一个 <code>Int</code> 值来表示分区编号，<code>index</code> 的含义就是数据所在分区的编号。所以 <code>func</code> 的类型是：<code>(Int, Iterator&lt;T&gt;) =&gt; Iterator&lt;U&gt;</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>,<span class="number">50</span>,<span class="number">60</span>))</span><br><span class="line">rdd1： org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;：<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.mapPartitionsWithIndex( (index，it) =&gt; it.map((index, _)) )</span><br><span class="line">res8： org.apache.spark.rdd.<span class="type">RDD</span>[（<span class="type">Int</span>，<span class="type">Int</span>）] = <span class="type">MapPartitionsRDD</span>[<span class="number">3</span>] at mapPartitionsWithIndex at &lt;console&gt;：<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res8.collect</span><br><span class="line">res9： <span class="type">Array</span>[(<span class="type">Int</span>，<span class="type">Int</span>)] = <span class="type">Array</span>( (<span class="number">0</span>,<span class="number">10</span>)，(<span class="number">0</span>,<span class="number">20</span>)，(<span class="number">0</span>,<span class="number">30</span>)，(<span class="number">1</span>,<span class="number">40</span>)，(<span class="number">1</span>,<span class="number">50</span>)，(<span class="number">1</span>,<span class="number">60</span>) )</span><br></pre></td></tr></table></figure>



<p><strong>分区数的确定，和对数组中的元素如何进行分区</strong></p>
<ol>
<li><p><strong>确定分区数：</strong></p>
<p> 读取配置文件中的 <code>spark.default.parallelism</code> 属性，如果未读取到该属性，就使用 <code>totalCores</code>，这个值是在初始化 <code>SparkContext</code> 时确定的核心数。</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1、先读取 spark.default.parallelism 属性</span></span><br><span class="line"><span class="comment">// 2、若未读取到，则使用 totalCores</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">defaultParallelism</span></span>(): <span class="type">Int</span> = scheduler.conf.getInt(<span class="string">&quot;spark.default.parallelism&quot;</span>, totalCores)</span><br></pre></td></tr></table></figure>

</li>
<li><p>  <strong>对元素进行分区</strong></p>
</li>
</ol>
<pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">	length： RDD 中数据的长度 </span></span><br><span class="line"><span class="comment">	numSlices： 分区数</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">positions</span></span>(length: <span class="type">Long</span>, numSlices: <span class="type">Int</span>)： <span class="type">Iterator</span>[(<span class="type">Int</span>，<span class="type">Int</span>)] = &#123;</span><br><span class="line">    (<span class="number">0</span> until numSlices).iterator.map &#123; i =&gt;</span><br><span class="line">        <span class="keyword">val</span> start = ((i * length) / numSlices).toInt</span><br><span class="line">        <span class="keyword">val</span> end = (((i + <span class="number">1</span>) * length) / numSlices).toInt</span><br><span class="line">        (start，end)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">seq <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> r： <span class="type">Range</span> =&gt;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> nr： <span class="type">NumericRange</span>[_] =&gt;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> _ =&gt;</span><br><span class="line">    <span class="keyword">val</span> array = seq.toArray <span class="comment">// To prevent O（n^2） operations for List etc</span></span><br><span class="line">    positions(array.length，numSlices).map &#123; <span class="keyword">case</span> (start，end) =&gt;</span><br><span class="line">        array.slice(start，end).toSeq</span><br><span class="line">    &#125;.toSeq</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</code></pre>
<hr>
<h4 id="5-flatMap-func"><a href="#5-flatMap-func" class="headerlink" title="5   flatMap(func)"></a>5   <code>flatMap(func)</code></h4><p><strong>源码：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">	flatMap 方法的参数需要是一个外层集合嵌套内层集合。</span></span><br><span class="line"><span class="comment">	参数1：f: T =&gt; TraversableOnce[U]，T 就表示某一个内层集合，返回值一定也要是一个集合</span></span><br><span class="line"><span class="comment">	最终会把外层集合里的内层集合扁平化</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">TraversableOnce</span>[<span class="type">U</span>]): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">    <span class="keyword">val</span> cleanF = sc.clean(f)</span><br><span class="line">    <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>[<span class="type">U</span>, <span class="type">T</span>](<span class="keyword">this</span>, (context, pid, iter) =&gt; iter.flatMap(cleanF))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>作用</strong>：类似于 <code>map</code>，但是每一个输入元素可以被映射为 0 或多个输出元素（所以 <code>func</code> 应该返回一个序列，而不是单一元素 <code>T =&gt; TraversableOnce[U]</code>）</p>
<p><strong>案例：</strong></p>
<p>创建一个元素为 <code>1~5</code> 的 RDD，运用 <code>flatMap</code> 创建一个新的 RDD，新的 RDD 为原 RDD 每个元素的平方和三次方来组成。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">5</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.flatMap(x =&gt; <span class="type">Array</span>(x * x, x * x * x))</span><br><span class="line">res13: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">6</span>] at flatMap at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res13.collect</span><br><span class="line">res14: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">27</span>, <span class="number">16</span>, <span class="number">64</span>, <span class="number">25</span>, <span class="number">125</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<hr>
<h4 id="6-glom"><a href="#6-glom" class="headerlink" title="6    glom()"></a>6    <code>glom()</code></h4><p><strong>作用：</strong>将每一个分区内的所有元素合并成一个数组，形成新的 RDD 类型是 <code>RDD[Array[T]]</code></p>
<p><strong>案例：</strong>创建一个 4 个分区的 RDD，并将每个分区的数据放到一个数组</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>,<span class="number">50</span>,<span class="number">60</span>), <span class="number">4</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.glom.collect</span><br><span class="line">res2: <span class="type">Array</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = <span class="type">Array</span>(<span class="type">Array</span>(<span class="number">10</span>), <span class="type">Array</span>(<span class="number">20</span>, <span class="number">30</span>), <span class="type">Array</span>(<span class="number">40</span>), <span class="type">Array</span>(<span class="number">50</span>, <span class="number">60</span>))</span><br></pre></td></tr></table></figure>



<hr>
<h4 id="7-groupBy-func"><a href="#7-groupBy-func" class="headerlink" title="7   groupBy(func)"></a>7   <code>groupBy(func)</code></h4><p><strong>作用：</strong><code>func</code> 会对集合中的每个元素进行运算，按照 <code>func</code> 的返回值对元素进行分组。</p>
<p>分组时按照 <code>func</code> 的返回值作为 key，对应的值放入一个迭代器（集合）中。</p>
<p>返回的 RDD 类型：<code>RDD[(K，Iterable[T])]</code></p>
<p>每组内元素的顺序不能保证，并且甚至每次调用得到的顺序也有可能不同。</p>
<p><strong>案例：</strong>创建一个 RDD，按照元素的奇偶性进行分组</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">20</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">8</span>))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">2</span>] at makeRDD at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.groupBy(x =&gt; <span class="keyword">if</span>(x % <span class="number">2</span> == <span class="number">1</span>) <span class="string">&quot;odd&quot;</span> <span class="keyword">else</span> <span class="string">&quot;even&quot;</span>)</span><br><span class="line">res4: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">Int</span>])] = <span class="type">ShuffledRDD</span>[<span class="number">4</span>] at groupBy at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res4.collect</span><br><span class="line">res5: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">Int</span>])] = <span class="type">Array</span>((even,<span class="type">CompactBuffer</span>(<span class="number">4</span>, <span class="number">20</span>, <span class="number">4</span>, <span class="number">8</span>))，(odd,<span class="type">CompactBuffer</span>(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<hr>
<h4 id="8-filter-func"><a href="#8-filter-func" class="headerlink" title="8    filter(func)"></a>8    <code>filter(func)</code></h4><p><strong>作用：</strong>过滤。 返回一个新的 RDD 是由 <code>func</code> 的返回值为 true 的那些元素组成。</p>
<p><strong>案例</strong>：创建一个 RDD（由字符串组成），过滤出一个新 RDD（包含“xiao”子串）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> names = sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;xiaoli&quot;</span>，<span class="string">&quot;laoli&quot;</span>，<span class="string">&quot;laowang&quot;</span>，<span class="string">&quot;xiaocang&quot;</span>，<span class="string">&quot;xiaojing&quot;</span>，<span class="string">&quot;xiaokong&quot;</span>))</span><br><span class="line">names: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; names.filter(_.contains(<span class="string">&quot;xiao&quot;</span>))</span><br><span class="line">res3: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">1</span>] at filter at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res3.collect</span><br><span class="line">res4: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(xiaoli, xiaocang, xiaojing, xiaokong) </span><br></pre></td></tr></table></figure>



<hr>
<h4 id="9-sample-withReplacement-fraction-seed"><a href="#9-sample-withReplacement-fraction-seed" class="headerlink" title="9    sample(withReplacement, fraction, seed)"></a>9    <code>sample(withReplacement, fraction, seed)</code></h4><p><code>sample(withReplacement, fraction, seed)</code></p>
<p><strong>作用：</strong></p>
<ol>
<li>   以指定的随机种子随机抽样出比例为 <code>fraction</code> 的数据，<strong>抽取到的数量在 <code>size * fraction</code> 附近</strong>，需要注意的是得到的结果并不能保证准确的比例。</li>
<li>   <code>withReplacement</code> 表示是抽出的数据是否放回。true 表示有放回的抽样，false 表示无放回的抽样。放回表示数据有可能会被重复抽取到，false 则不可能重复抽取到。如果是 false，则 <code>fraction</code> 的范围必须是 <code>[0,1]</code>，是 true 则 <code>fraction &gt;= 0</code> 就可以了。</li>
<li>   <code>seed</code> 用于指定随机数生成器种子。一般用默认的，或者传入当前的时间戳。</li>
</ol>
<ul>
<li>  <strong>不放回抽样</strong></li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">15</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.sample(<span class="literal">false</span>, <span class="number">0.5</span>).collect</span><br><span class="line">res15: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">7</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>  <strong>放回抽样</strong></li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd1.sample(<span class="literal">true</span>, <span class="number">2</span>).collect</span><br><span class="line">res25: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br></pre></td></tr></table></figure>



<hr>
<h4 id="10-distinct-numTasks"><a href="#10-distinct-numTasks" class="headerlink" title="10    distinct([numTasks]))"></a>10    <code>distinct([numTasks]))</code></h4><p><strong>作用：</strong>对 RDD 中元素执行去重操作。参数 <code>numTasks</code> 表示任务的数量，默认值和分区数保持一致。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="number">10</span>,<span class="number">10</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">1</span>))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">28</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.distinct().collect</span><br><span class="line">res29: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">6</span>, <span class="number">10</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>对于自定义类型的对象，如果想要去重，则需要重写对应的 <code>hashCode()</code> 和 <code>equals()</code> 方法。</p>
<hr>
<h4 id="11-coalesce-numPartitions"><a href="#11-coalesce-numPartitions" class="headerlink" title="11    coalesce(numPartitions)"></a>11    <code>coalesce(numPartitions)</code></h4><p><strong>作用：</strong>缩减分区数量。多用于大数据集过滤后，提高小数据集的执行效率。【大数据集过滤后，留下的数据集可以用更少的分区就能够存储了，所以可以缩减分区的数量】</p>
<p><strong>分析：</strong>假如我们从 HDFS 中取出的数据保存在 3 个分区中，这些数据经过数据清洗后，分区1剩余了 100W 条数据，分区2和分区3各剩5W条数据，如果不缩减分区继续进行运算的话，根据木桶效应，整个程序的运算速度一定会被运算速度最慢的分区所拖累，所以我们经常需要适当的缩减分区，来保证各个分区的运算效率尽量相近。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="number">0</span> to <span class="number">100</span>, <span class="number">5</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">45</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看当前RDD的分区数</span></span><br><span class="line">scala&gt; rdd1.partitions.length	</span><br><span class="line">res39: <span class="type">Int</span> = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 减少分区的数量至 2 </span></span><br><span class="line">scala&gt; rdd1.coalesce(<span class="number">2</span>)</span><br><span class="line">res40: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">CoalescedRDD</span>[<span class="number">46</span>] at coalesce at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res40.partitions.length</span><br><span class="line">res41: <span class="type">Int</span> = <span class="number">2</span></span><br></pre></td></tr></table></figure>



<p><strong>注意：</strong></p>
<ul>
<li>  第二个参数表示是否 <code>shuffle</code>，如果不传或者传入的为 false，则表示不进行 <code>shuffer</code>，此时分区数减少有效，增加分区数无效。</li>
<li>  如果想要增加分区，那么就必须设置 <code>shuffle</code> 为 <code>true</code></li>
</ul>
<hr>
<h4 id="12-repartition-numPartitions"><a href="#12-repartition-numPartitions" class="headerlink" title="12  repartition(numPartitions)"></a>12  <code>repartition(numPartitions)</code></h4><p><strong>作用：</strong>根据新的分区数，重新 <code>shuffle</code> 所有的数据，这个操作总会通过网络。</p>
<p>新的分区数相比以前可以多，也可以少</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="number">0</span> to <span class="number">100</span>, <span class="number">5</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">45</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.repartition(<span class="number">3</span>)</span><br><span class="line">res44: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">51</span>] at repartition at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res44.partitions.length</span><br><span class="line">res45: <span class="type">Int</span> = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.repartition(<span class="number">10</span>)</span><br><span class="line">res46: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">55</span>] at repartition at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res46.partitions.length</span><br><span class="line">res47: <span class="type">Int</span> = <span class="number">10</span></span><br></pre></td></tr></table></figure>





<hr>
<h4 id="13-coalasce-和-repartition-的区别"><a href="#13-coalasce-和-repartition-的区别" class="headerlink" title="13  coalasce 和 repartition 的区别"></a>13  coalasce 和 repartition 的区别</h4><ol>
<li><p>   <code>coalesce</code> 重新分区，可以选择是否进行 <code>shuffle</code> 过程，由参数 <code>shuffle: Boolean = false/true</code> 决定。</p>
</li>
<li><p><code>repartition</code> 底层调用的还是 <code>coalesce</code> 进行 <code>shuffle</code>。源码如下：</p>
   <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">repartition</span></span>(numPartitions: <span class="type">Int</span>)(<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">T</span>] = <span class="literal">null</span>): <span class="type">RDD</span>[<span class="type">T</span>] = withScope &#123;</span><br><span class="line">    coalesce(numPartitions, shuffle = <span class="literal">true</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>   如果是减少分区，尽量避免 <code>shuffle</code></p>
</li>
</ol>
<hr>
<h4 id="14-sortBy-func-ascending-，-numTasks"><a href="#14-sortBy-func-ascending-，-numTasks" class="headerlink" title="14  sortBy(func,[ascending]，[numTasks])"></a>14  <code>sortBy(func,[ascending]，[numTasks])</code></h4><p><strong>作用：</strong>使用 <code>func</code> 先对数据进行处理，按照处理后结果排序，默认为正序。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">10</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">16</span>))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">46</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.sortBy(x =&gt; x).collect</span><br><span class="line">res17: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">16</span>, <span class="number">20</span>, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.sortBy(x =&gt; x, <span class="literal">true</span>).collect</span><br><span class="line">res18: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">16</span>, <span class="number">20</span>, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 不用正序</span></span><br><span class="line">scala&gt; rdd1.sortBy(x =&gt; x, <span class="literal">false</span>).collect</span><br><span class="line">res19: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">30</span>, <span class="number">20</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">9</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>





<hr>
<h4 id="15-pipe-command-envVars"><a href="#15-pipe-command-envVars" class="headerlink" title="15  pipe(command, [envVars])"></a>15  <code>pipe(command, [envVars])</code></h4><p><strong>作用：</strong>管道，针对每个分区，把 RDD 中的每个数据通过管道传递给 shell 命令或脚本，返回输出的 RDD。一个分区执行一次这个命令。 如果只有一个分区，则执行一次命令。</p>
<p><strong>注意：</strong>脚本要放在 worker 节点可以访问到的位置</p>
<ol>
<li><p>步骤1：创建一个脚本文件 <code>pipe.sh</code>，文件内容如下：</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;hello&quot;</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">read</span> line;<span class="keyword">do</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">&quot;&gt;&gt;&gt;&quot;</span><span class="variable">$line</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

</li>
<li><p>步骤2： 创建只有 1 个分区的RDD</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>)，<span class="number">1</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.pipe(<span class="string">&quot;。/pipe.sh&quot;</span>).collect</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(hello, &gt;&gt;&gt;<span class="number">10</span>, &gt;&gt;&gt;<span class="number">20</span>, &gt;&gt;&gt;<span class="number">30</span>, &gt;&gt;&gt;<span class="number">40</span>)</span><br></pre></td></tr></table></figure>

</li>
<li><p>步骤3： 创建有 2 个分区的 RDD</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>)，<span class="number">2</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">3</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.pipe(<span class="string">&quot;。/pipe.sh&quot;</span>).collect</span><br><span class="line">res2: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(hello, &gt;&gt;&gt;<span class="number">10</span>, &gt;&gt;&gt;<span class="number">20</span>, hello, &gt;&gt;&gt;<span class="number">30</span>, &gt;&gt;&gt;<span class="number">40</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>总结： 每个分区执行一次脚本，但是每个元素算是标准输入中的一行</strong></p>
<hr>
<h3 id="2-3-2-双-Value-类型交互"><a href="#2-3-2-双-Value-类型交互" class="headerlink" title="2.3.2  双 Value 类型交互"></a>2.3.2  双 Value 类型交互</h3><p>这里的<strong>“双 Value 类型交互”</strong>指的是两个 <code>RDD[V]</code> 进行交互。</p>
<h4 id="1-union-otherDataset"><a href="#1-union-otherDataset" class="headerlink" title="1   union(otherDataset)"></a>1   <code>union(otherDataset)</code></h4><p><strong>作用：</strong>求并集。对源 RDD 和参数 RDD 求并集后返回一个新的 RDD</p>
<p><strong>案例</strong>：创建两个 RDD，求并集</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="number">1</span> to <span class="number">6</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">2</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = sc.parallelize(<span class="number">4</span> to <span class="number">10</span>)</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">3</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.union(rdd2)</span><br><span class="line">res0: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">UnionRDD</span>[<span class="number">4</span>] at union at &lt;console&gt;:<span class="number">29</span></span><br><span class="line"></span><br><span class="line">scala&gt; res0.collect</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>,  <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong><code>union</code> 和 <code>++</code> 是等价的</p>
<hr>
<h5 id="2-subtract-otherDataset"><a href="#2-subtract-otherDataset" class="headerlink" title="2    subtract (otherDataset)"></a>2    <code>subtract (otherDataset)</code></h5><p><strong>作用：</strong>计算差集。从原 RDD 中减去原 RDD 和 <code>otherDataset</code> 中的共同的部分。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd1.subtract(rdd2).collect</span><br><span class="line">res4: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; rdd2.subtract(rdd1).collect</span><br><span class="line">res5: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">8</span>, <span class="number">10</span>, <span class="number">7</span>, <span class="number">9</span>)</span><br></pre></td></tr></table></figure>



<h4 id="3-intersection-otherDataset"><a href="#3-intersection-otherDataset" class="headerlink" title="3    intersection(otherDataset)"></a>3    <code>intersection(otherDataset)</code></h4><p><strong>作用：</strong>计算交集。对源 RDD 和参数 RDD 求交集后返回一个新的 RDD</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd1.intersection(rdd2).collect</span><br><span class="line">res8: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">4</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>



<hr>
<h5 id="4-cartesian-otherDataset"><a href="#4-cartesian-otherDataset" class="headerlink" title="4    cartesian(otherDataset)"></a>4    <code>cartesian(otherDataset)</code></h5><p><strong>作用：</strong>计算 2 个 RDD 的笛卡尔积。尽量避免使用</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd1.cartesian(rdd2).collect</span><br><span class="line">res11: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="number">1</span>,<span class="number">4</span>)，(<span class="number">1</span>,<span class="number">5</span>)，(<span class="number">1</span>,<span class="number">6</span>)，(<span class="number">2</span>,<span class="number">4</span>)，(<span class="number">2</span>,<span class="number">5</span>)，(<span class="number">2</span>,<span class="number">6</span>)，(<span class="number">3</span>,<span class="number">4</span>)，(<span class="number">3</span>,<span class="number">5</span>)，(<span class="number">3</span>,<span class="number">6</span>)，(<span class="number">1</span>,<span class="number">7</span>)，(<span class="number">1</span>,<span class="number">8</span>)，(<span class="number">1</span>,<span class="number">9</span>)，(<span class="number">1</span>,<span class="number">10</span>)，(<span class="number">2</span>,<span class="number">7</span>)，(<span class="number">2</span>,<span class="number">8</span>)，(<span class="number">2</span>,<span class="number">9</span>)，(<span class="number">2</span>,<span class="number">10</span>)，(<span class="number">3</span>,<span class="number">7</span>)，(<span class="number">3</span>,<span class="number">8</span>)，(<span class="number">3</span>,<span class="number">9</span>)，(<span class="number">3</span>,<span class="number">10</span>)，(<span class="number">4</span>,<span class="number">4</span>)，(<span class="number">4</span>,<span class="number">5</span>)，(<span class="number">4</span>,<span class="number">6</span>)，(<span class="number">5</span>,<span class="number">4</span>)，(<span class="number">5</span>,<span class="number">5</span>)，(<span class="number">5</span>,<span class="number">6</span>)，(<span class="number">6</span>,<span class="number">4</span>)，(<span class="number">6</span>,<span class="number">5</span>)，(<span class="number">6</span>,<span class="number">6</span>)，(<span class="number">4</span>,<span class="number">7</span>)，(<span class="number">4</span>,<span class="number">8</span>)，(<span class="number">4</span>,<span class="number">9</span>)，(<span class="number">4</span>,<span class="number">10</span>)，(<span class="number">5</span>,<span class="number">7</span>)，(<span class="number">5</span>,<span class="number">8</span>)，(<span class="number">5</span>,<span class="number">9</span>)，(<span class="number">5</span>,<span class="number">10</span>)，(<span class="number">6</span>,<span class="number">7</span>)，(<span class="number">6</span>,<span class="number">8</span>)，(<span class="number">6</span>,<span class="number">9</span>)，(<span class="number">6</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>





<hr>
<h5 id="5-zip-otherDataset"><a href="#5-zip-otherDataset" class="headerlink" title="5    zip(otherDataset)"></a>5    <code>zip(otherDataset)</code></h5><p><strong>作用：</strong>拉链操作。</p>
<p><strong>使用的前提条件：</strong></p>
<ol>
<li> 两个 RDD 需要拥有相同的分区数；</li>
<li> 要求每个分区的元素数量相同。</li>
</ol>
<p>在 Spark 中，执行拉链操作时要求两个 RDD 中的分区数和分区内元素的数量和都必须相同，否则会抛出异常（在 scala 中，两个集合的长度可以不同）。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="number">1</span> to <span class="number">5</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">34</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = sc.parallelize(<span class="number">11</span> to <span class="number">15</span>)</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">35</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.zip(rdd2).collect</span><br><span class="line">res17: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="number">1</span>,<span class="number">11</span>)，(<span class="number">2</span>,<span class="number">12</span>)，(<span class="number">3</span>,<span class="number">13</span>)，(<span class="number">4</span>,<span class="number">14</span>)，(<span class="number">5</span>,<span class="number">15</span>))</span><br></pre></td></tr></table></figure>

<p><strong>类似算子：</strong><code>zipWithIndex，zipPartitions</code></p>
<hr>
<h3 id="2-3-3-Key-Value-类型"><a href="#2-3-3-Key-Value-类型" class="headerlink" title="2.3.3    Key-Value 类型"></a>2.3.3    Key-Value 类型</h3><p>大多数的 Spark 操作可以用在任意类型的 RDD 上，但是有一些特殊的操作只能用在 <code>key-value</code> 类型的 RDD 上。</p>
<p>这些特殊操作大多都涉及到 <code>shuffle</code> 操作，比如：按照 key 分组<code>(group)</code>，聚集<code>(aggregate)</code>等。</p>
<p>在 Spark 中，这些操作在 <code>K-V</code> 类型的 RDD 上自动可用(通过隐式转换)。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">RDD</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 通过隐式转换，对于 K-V 类型的 RDD 进行增强</span></span><br><span class="line">    <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">rddToPairRDDFunctions</span></span>[<span class="type">K</span>, <span class="type">V</span>](rdd: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)])</span><br><span class="line">    (<span class="keyword">implicit</span> kt: <span class="type">ClassTag</span>[<span class="type">K</span>], vt: <span class="type">ClassTag</span>[<span class="type">V</span>], ord: <span class="type">Ordering</span>[<span class="type">K</span>] = <span class="literal">null</span>): <span class="type">PairRDDFunctions</span>[<span class="type">K</span>, <span class="type">V</span>] = &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">PairRDDFunctions</span>(rdd)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>键值对的操作是定义在 <code>PairRDDFunctions</code> 类上，这个类是对 <code>RDD[(K, V)]</code> 的装饰。</p>
<hr>
<h4 id="1-partitionBy"><a href="#1-partitionBy" class="headerlink" title="1    partitionBy"></a>1    <code>partitionBy</code></h4><p><strong>作用：</strong>根据传入的分区器 <code>Partitioner</code>，对 <code>&lt;K,V&gt;</code> 类型的 RDD 数据重新进行分区。</p>
<p><strong>源码</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Partitioner 是一个分区器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partitionBy</span></span>(partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)] = self.withScope &#123;</span><br><span class="line">    <span class="keyword">if</span> (self.partitioner == <span class="type">Some</span>(partitioner)) &#123;</span><br><span class="line">        self</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">ShuffledRDD</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">V</span>](self, partitioner)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>  <code>Partitioner</code> 类是分区器的基类，我们自定义的分区器必须继承这个类</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Partitioner</span> <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numPartitions</span></span>: <span class="type">Int</span>	<span class="comment">// 分区数量</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span>	<span class="comment">// 通过 key 计算出对应的 &lt;K,V&gt; 数据保存在哪一个分区中</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<p><strong>测试</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">2</span>, <span class="string">&quot;b&quot;</span>), (<span class="number">3</span>, <span class="string">&quot;c&quot;</span>), (<span class="number">4</span>, <span class="string">&quot;d&quot;</span>)))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.partitions.length</span><br><span class="line">res1: <span class="type">Int</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 显式指定分区器</span></span><br><span class="line">scala&gt; rdd1.partitionBy(<span class="keyword">new</span> org.apache.spark.<span class="type">HashPartitioner</span>(<span class="number">3</span>)).partitions.length</span><br><span class="line">res3: <span class="type">Int</span> = <span class="number">3</span></span><br></pre></td></tr></table></figure>







<hr>
<h4 id="2-groupByKey"><a href="#2-groupByKey" class="headerlink" title="2    groupByKey()"></a>2    <code>groupByKey()</code></h4><p><strong>作用：</strong>按照 key 进行分组。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>, <span class="string">&quot;atguigu&quot;</span>, <span class="string">&quot;hello&quot;</span>, <span class="string">&quot;are&quot;</span>, <span class="string">&quot;go&quot;</span>))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">2</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = rdd1.map((_, <span class="number">1</span>))</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">MapPartitionsRDD</span>[<span class="number">3</span>] at map at &lt;console&gt;:<span class="number">26</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd2.groupByKey()</span><br><span class="line">res3: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">Int</span>])] = <span class="type">ShuffledRDD</span>[<span class="number">4</span>] at groupByKey at &lt;console&gt;:<span class="number">29</span></span><br><span class="line"></span><br><span class="line">scala&gt; res3.collect</span><br><span class="line">res4: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">Int</span>])] = <span class="type">Array</span>((are,<span class="type">CompactBuffer</span>(<span class="number">1</span>)), (hello,<span class="type">CompactBuffer</span>(<span class="number">1</span>, <span class="number">1</span>)), (go,<span class="type">CompactBuffer</span>(<span class="number">1</span>)), (atguigu,<span class="type">CompactBuffer</span>(<span class="number">1</span>)), (world,<span class="type">CompactBuffer</span>(<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">scala&gt; res3.map(t =&gt; (t._1, t._2.sum))</span><br><span class="line">res5: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">MapPartitionsRDD</span>[<span class="number">5</span>] at map at &lt;console&gt;:<span class="number">31</span></span><br><span class="line">                </span><br><span class="line">scala&gt; res5.collect</span><br><span class="line">res7: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((are,<span class="number">1</span>), (hello,<span class="number">2</span>), (go,<span class="number">1</span>), (atguigu,<span class="number">1</span>), (world,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong></p>
<ol>
<li>   基于当前的实现，<code>groupByKey</code> 必须在内存中持有所有的键值对，如果一个 key 有太多的 value，则会导致内存溢出(OutOfMemoryError)。</li>
<li>   所以这个操作非常耗资源，如果分组的目的是为了在每个 key 上执行聚合操作（比如 <code>sum</code> 和 <code>average</code>），则应该使用<code>PairRDDFunctions.aggregateByKey</code> 或者 <code>PairRDDFunctions.reduceByKey</code>，因为它们有更好的性能(会先在分区进行预聚合)</li>
</ol>
<hr>
<h4 id="3-reduceByKey-func-numTasks"><a href="#3-reduceByKey-func-numTasks" class="headerlink" title="3    reduceByKey(func, [numTasks])"></a>3    <code>reduceByKey(func, [numTasks])</code></h4><p><strong>作用：</strong>在 <code>&lt;K, V&gt;</code> 格式的 RDD 上调用，返回一个 <code>&lt;K,V&gt;</code> 的 RDD，使用指定的 <code>reduce</code> 函数，将相同 key 的 value 聚合到一起。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">List</span>((<span class="string">&quot;female&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;male&quot;</span>,<span class="number">5</span>),(<span class="string">&quot;female&quot;</span>,<span class="number">5</span>),(<span class="string">&quot;male&quot;</span>,<span class="number">2</span>)))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.reduceByKey(_ + _)</span><br><span class="line">res1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ShuffledRDD</span>[<span class="number">1</span>] at reduceByKey at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res1.collect</span><br><span class="line">res2: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((female,<span class="number">6</span>), (male,<span class="number">7</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="4-reduceByKey-和-groupByKey-的区别"><a href="#4-reduceByKey-和-groupByKey-的区别" class="headerlink" title="4    reduceByKey 和 groupByKey 的区别"></a>4    <code>reduceByKey</code> 和 <code>groupByKey</code> 的区别</h4><ol>
<li>   <code>reduceByKey</code>：按照 key 进行聚合，在 <code>shuffle</code> 之前有 <code>combine</code>（<strong>预聚合</strong>）操作，返回结果是 <code>RDD[k,v]</code>。【预聚合==分区内聚合】</li>
<li>   <code>groupByKey</code>：按照 key 进行分组，直接进行 <code>shuffle</code>。</li>
<li>   开发指导：<code>reduceByKey</code> 比 <code>groupByKey</code> 性能更好，因为 <code>reduceByKey</code> 有预聚合的过程，建议使用。但是需要注意是否会影响业务逻辑。</li>
</ol>
<hr>
<h4 id="5-foldByKey"><a href="#5-foldByKey" class="headerlink" title="5    foldByKey"></a>5    <code>foldByKey</code></h4><p><strong>参数：</strong> <code>(zeroValue: V)(func: (V, V) =&gt; V): RDD[(K, V)]</code></p>
<p><strong>作用：</strong>类似于 <code>reduceByKey</code> ，有预聚合，用于聚合操作，但是多了一个零值的功能。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>,<span class="number">3</span>)，(<span class="string">&quot;a&quot;</span>,<span class="number">2</span>)，(<span class="string">&quot;c&quot;</span>,<span class="number">4</span>)，(<span class="string">&quot;b&quot;</span>,<span class="number">3</span>)，(<span class="string">&quot;c&quot;</span>,<span class="number">6</span>)，(<span class="string">&quot;c&quot;</span>,<span class="number">8</span>)))</span><br><span class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">2</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd.foldByKey(<span class="number">0</span>)(_ + _).collect</span><br><span class="line">res5: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((b,<span class="number">3</span>)，(a,<span class="number">5</span>)，(c,<span class="number">18</span>))</span><br></pre></td></tr></table></figure>







<hr>
<h4 id="6-aggregateByKey-zeroValue-seqOp-combOp-numTasks"><a href="#6-aggregateByKey-zeroValue-seqOp-combOp-numTasks" class="headerlink" title="6   aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])"></a>6   <code>aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])</code></h4><p><strong>思考：</strong><code>reduceByKey，aggregateByKey，foldByKey</code> 的区别和联系？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1、reduceByKey、foldByKey 都有预聚合，且分区内聚合和分区间聚合的逻辑是一样的。</span><br><span class="line">2、aggregateByKey 也有预聚合，但是区内聚合和分区间聚合的逻辑可以不一样。</span><br><span class="line">3、零值只在分区内聚合的时候使用</span><br></pre></td></tr></table></figure>

<p><img src="/2022/05/31/Spark-Core/image-20211215213010832.png" alt="image-20211215213010832"></p>
<p><strong>函数声明：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">	1. zeroValue：零值，分区内使用。给每一个分区中的每一个key一个初始值；</span></span><br><span class="line"><span class="comment">	2. seqOp：分区内的聚合逻辑。函数用于在每一个分区中用初始值逐步迭代value；</span></span><br><span class="line"><span class="comment">	3. combOp：分区间的聚合逻辑。函数用于合并每个分区中的结果。</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">aggregateByKey</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](zeroValue: <span class="type">U</span>)(seqOp: (<span class="type">U</span>, <span class="type">V</span>) =&gt; <span class="type">U</span>,</span><br><span class="line">                                              combOp: (<span class="type">U</span>, <span class="type">U</span>) =&gt; <span class="type">U</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">U</span>)] = self.withScope &#123;</span><br><span class="line">    aggregateByKey(zeroValue, defaultPartitioner(self))(seqOp, combOp)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用给定的 <code>combine</code> 函数和一个初始化的 <code>zeroValue</code>，对每个 key 的 value 进行聚合。</p>
<p>这个函数返回的类型 U 不同于源 RDD 中的 V 类型。U 的类型是由初始化的 <code>zeroValue</code> 来决定的。所以我们需要两个操作：</p>
<ul>
<li>  一个操作 <code>seqOp</code> 用于把 1 个 V 变成 1 个U </li>
<li>  另外一个操作 <code>combOp</code> 用于合并 2 个 U</li>
</ul>
<p>第一个操作用于在一个分区内进行合并，第二个操作用在两个分区间进行合并。</p>
<p>为了避免内存分配，这两个操作函数都允许返回第一个参数，而不用创建一个新的 U</p>
<p><strong>案例：</strong>计算每个分区相同 key 对应 value 的最大值，然后让多个分区间的最大值相加</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">3</span>),(<span class="string">&quot;a&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">4</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">3</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">6</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">8</span>)),<span class="number">2</span>)</span><br><span class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 1、分区内计算最大值	2、分区间求和</span></span><br><span class="line">scala&gt; rdd.aggregateByKey(<span class="type">Int</span>.<span class="type">MinValue</span>)(math.max(_, _), _ +_)</span><br><span class="line">res0: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ShuffledRDD</span>[<span class="number">1</span>] at aggregateByKey at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res0.collect</span><br><span class="line">res1: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((b,<span class="number">3</span>), (a,<span class="number">3</span>), (c,<span class="number">12</span>)) </span><br></pre></td></tr></table></figure>





<hr>
<h4 id="7-combineByKey-C"><a href="#7-combineByKey-C" class="headerlink" title="7   combineByKey[C]"></a>7   <code>combineByKey[C]</code></h4><p><strong>描述：</strong></p>
<ul>
<li>  用于聚合</li>
<li>  分区内聚合和分区间聚合逻辑可以不同</li>
<li>  零值不是写死的，零值是根据每个 key 的第一个 value 来动态生成</li>
</ul>
<p><strong>函数声明：</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  1.createCombiner: 创建一个零值。combineByKey会遍历分区中的每个key-value对，</span></span><br><span class="line"><span class="comment">  如果第一次碰到这个key, 则调用createCombiner函数，传入value，得到一个C类型的值。</span></span><br><span class="line"><span class="comment">  (如果不是第一次碰到这个 key, 则不会调用这个方法)</span></span><br><span class="line"><span class="comment">  </span></span><br><span class="line"><span class="comment">  2.mergeValue：分区内的聚合函数。如果不是第一个遇到这个key, 则调用这个函数进行合并操作。</span></span><br><span class="line"><span class="comment">  </span></span><br><span class="line"><span class="comment">  3.mergeCombiners：分区间的聚合函数。跨分区合并相同的key的值(C)。 </span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combineByKey</span></span>[<span class="type">C</span>](</span><br><span class="line">    createCombiner: <span class="type">V</span> =&gt; <span class="type">C</span>,</span><br><span class="line">    mergeValue: (<span class="type">C</span>, <span class="type">V</span>) =&gt; <span class="type">C</span>,</span><br><span class="line">    mergeCombiners: (<span class="type">C</span>, <span class="type">C</span>) =&gt; <span class="type">C</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">C</span>)] = self.withScope &#123;</span><br><span class="line">    combineByKeyWithClassTag(createCombiner, mergeValue, mergeCombiners,</span><br><span class="line">                             partitioner, mapSideCombine, serializer)(<span class="literal">null</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>作用：</strong>针对每个 K，将 V 进行合并成 C，得到 <code>RDD[(K,C)]</code></p>
<p><strong>案例：</strong>workcount</p>
<p>需求1: 创建一个 pairRDD，根据 key 计算每种 key 的value的平均值。（先计算每个key出现的次数以及可以对应值的总和，再相除得到结果）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> input = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>，<span class="number">88</span>)，(<span class="string">&quot;b&quot;</span>，<span class="number">95</span>)，(<span class="string">&quot;a&quot;</span>，<span class="number">91</span>)，(<span class="string">&quot;b&quot;</span>，<span class="number">93</span>)，(<span class="string">&quot;a&quot;</span>，<span class="number">95</span>)，(<span class="string">&quot;b&quot;</span>，<span class="number">98</span>)),<span class="number">2</span>)</span><br><span class="line">input: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">5</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// acc 累加器, 用来记录分区内的值的和这个 key 出现的次数</span></span><br><span class="line"><span class="comment">// acc1, acc2 跨分区的累加器</span></span><br><span class="line">scala&gt; input.combineByKey((, <span class="number">1</span>)，(acc:(<span class="type">Int</span>, <span class="type">Int</span>), v) =&gt; (acc<span class="number">.1</span> + v, acc<span class="number">.2</span> + <span class="number">1</span>)，(acc1:(<span class="type">Int</span>, <span class="type">Int</span>), acc2: (<span class="type">Int</span>, <span class="type">Int</span>))=&gt; (acc1<span class="number">.1</span> + acc2<span class="number">.1</span>, acc1<span class="number">.2</span> + acc2<span class="number">.2</span>))</span><br><span class="line">res10: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = <span class="type">ShuffledRDD</span>[<span class="number">7</span>] at combineByKey at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res10.collect</span><br><span class="line">res11: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = <span class="type">Array</span>((b,(<span class="number">286</span>,<span class="number">3</span>))，(a,(<span class="number">274</span>,<span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line">scala&gt; res10.map(t =&gt; (t<span class="number">.1</span>, t<span class="number">.2</span><span class="number">.1</span>.toDouble / t<span class="number">.2</span><span class="number">.2</span>)).collect</span><br><span class="line">res12: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Double</span>)] = <span class="type">Array</span>((b,<span class="number">95.33333333333333</span>)，(a,<span class="number">91.33333333333333</span>))</span><br></pre></td></tr></table></figure>



<hr>
<h4 id="8-sortByKey"><a href="#8-sortByKey" class="headerlink" title="8   sortByKey"></a>8   <code>sortByKey</code></h4><p><strong>作用：</strong>在一个 <code>(K,V)</code> 的 RDD 上调用，K 必须实现 <code>Ordered[K]</code> 接口或者有一个隐式值：<code>Ordering[K]</code>，返回一个按照 key 进行排序的<code>(K,V)</code> 的 RDD。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>)，(<span class="number">10</span>, <span class="string">&quot;b&quot;</span>)，(<span class="number">11</span>, <span class="string">&quot;c&quot;</span>)，(<span class="number">4</span>, <span class="string">&quot;d&quot;</span>)，(<span class="number">20</span>, <span class="string">&quot;d&quot;</span>)，(<span class="number">10</span>, <span class="string">&quot;e&quot;</span>)))</span><br><span class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">11</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd.sortByKey()</span><br><span class="line">res25: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">ShuffledRDD</span>[<span class="number">14</span>] at sortByKey at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; res25.collect</span><br><span class="line">res26: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">1</span>,a)，(<span class="number">4</span>,d)，(<span class="number">10</span>,b)，(<span class="number">10</span>,e)，(<span class="number">11</span>,c)，(<span class="number">20</span>,d))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.sortByKey(<span class="literal">true</span>).collect</span><br><span class="line">res27: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">1</span>,a)，(<span class="number">4</span>,d)，(<span class="number">10</span>,b)，(<span class="number">10</span>,e)，(<span class="number">11</span>,c)，(<span class="number">20</span>,d))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 倒序</span></span><br><span class="line">scala&gt; rdd.sortByKey(<span class="literal">false</span>).collect</span><br><span class="line">res28: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">20</span>,d)，(<span class="number">11</span>,c)，(<span class="number">10</span>,b)，(<span class="number">10</span>,e)，(<span class="number">4</span>,d)，(<span class="number">1</span>,a))</span><br></pre></td></tr></table></figure>





<hr>
<h4 id="9-mapValues"><a href="#9-mapValues" class="headerlink" title="9   mapValues"></a>9   <code>mapValues</code></h4><p><strong>作用：</strong>针对 <code>(K,V)</code> 形式的类型只对 V 进行操作</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>)，(<span class="number">10</span>, <span class="string">&quot;b&quot;</span>)，(<span class="number">11</span>, <span class="string">&quot;c&quot;</span>)，(<span class="number">4</span>, <span class="string">&quot;d&quot;</span>)，(<span class="number">20</span>, <span class="string">&quot;d&quot;</span>)，(<span class="number">10</span>, <span class="string">&quot;e&quot;</span>)))</span><br><span class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">21</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd.mapValues(<span class="string">&quot;&lt;&quot;</span> + _ + <span class="string">&quot;&gt;&quot;</span>).collect</span><br><span class="line">res29: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">1</span>,&lt;a&gt;)，(<span class="number">10</span>,&lt;b&gt;)，(<span class="number">11</span>,&lt;c&gt;)，(<span class="number">4</span>,&lt;d&gt;)，(<span class="number">20</span>,&lt;d&gt;)，(<span class="number">10</span>,&lt;e&gt;))</span><br></pre></td></tr></table></figure>





<hr>
<h4 id="10-join-otherDataset-numTasks"><a href="#10-join-otherDataset-numTasks" class="headerlink" title="10  join(otherDataset, [numTasks])"></a>10  <code>join(otherDataset, [numTasks])</code></h4><ol>
<li> 含义和 SQL 差不多，用来连接两个 RDD</li>
<li> 连接肯定需要连接条件，在 SQL 中是 <code>tb_a.id = tb_b.id</code>，对应在 RDD 中就是 <code>rdd1.id = rdd2.id</code>，把 key 相等的连在一起</li>
<li> 也支持外连接：<code>leftOuterJoin, rightOuterJoin, and fullOuterJoin</code>。</li>
<li> 如果某一个 RDD 有重复的 Key, 则会分别与另外一个 RDD 的相同的 Key 进行组合。</li>
</ol>
<p><strong>内连接</strong>：在类型为 <code>(K,V)</code> 和 <code>(K,W)</code> 的 RDD 上调用，返回一个相同 key 对应的所有元素对在一起的 <code>(K,(V,W))</code> 的 RDD</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> rdd1 = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>)，(<span class="number">1</span>, <span class="string">&quot;b&quot;</span>)，(<span class="number">2</span>, <span class="string">&quot;c&quot;</span>)))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">6</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> rdd2 = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="string">&quot;aa&quot;</span>)，(<span class="number">3</span>, <span class="string">&quot;bb&quot;</span>)，(<span class="number">2</span>, <span class="string">&quot;cc&quot;</span>)))</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">7</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.join(rdd2).collect</span><br><span class="line">res2: <span class="type">Array</span>[(<span class="type">Int</span>, (<span class="type">String</span>, <span class="type">String</span>))] = <span class="type">Array</span>((<span class="number">2</span>,(c,cc))，(<span class="number">1</span>,(a,aa))，(<span class="number">1</span>,(b,aa)))</span><br></pre></td></tr></table></figure>





<hr>
<h4 id="11-cogroup-otherDataset-numTasks"><a href="#11-cogroup-otherDataset-numTasks" class="headerlink" title="11  cogroup(otherDataset, [numTasks])"></a>11  <code>cogroup(otherDataset, [numTasks])</code></h4><p><strong>作用：</strong>在类型为 <code>(K,V)</code> 和 <code>(K,W)</code> 的 RDD 上调用，返回一个 <code>(K,(Iterable&lt;V&gt;, Iterable&lt;W&gt;))</code> 类型的 RDD</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="number">10</span>),(<span class="number">2</span>, <span class="number">20</span>),(<span class="number">1</span>, <span class="number">100</span>),(<span class="number">3</span>, <span class="number">30</span>)),<span class="number">1</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">23</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>),(<span class="number">2</span>, <span class="string">&quot;b&quot;</span>),(<span class="number">1</span>, <span class="string">&quot;aa&quot;</span>),(<span class="number">3</span>, <span class="string">&quot;c&quot;</span>)),<span class="number">1</span>)</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">24</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.cogroup(rdd2).collect</span><br><span class="line">res9: <span class="type">Array</span>[(<span class="type">Int</span>, (<span class="type">Iterable</span>[<span class="type">Int</span>], <span class="type">Iterable</span>[<span class="type">String</span>]))] = <span class="type">Array</span>((<span class="number">1</span>,(<span class="type">CompactBuffer</span>(<span class="number">10</span>, <span class="number">100</span>),<span class="type">CompactBuffer</span>(a, aa)))，(<span class="number">3</span>,(<span class="type">CompactBuffer</span>(<span class="number">30</span>),<span class="type">CompactBuffer</span>(c)))，(<span class="number">2</span>,(<span class="type">CompactBuffer</span>(<span class="number">20</span>),<span class="type">CompactBuffer</span>(b))))</span><br></pre></td></tr></table></figure>







<hr>
<h3 id="2-3-4-案例实操"><a href="#2-3-4-案例实操" class="headerlink" title="2.3.4  案例实操"></a>2.3.4  案例实操</h3><h4 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h4><ol>
<li><p><strong>数据结构：</strong>时间戳，省份，城市，用户，广告，字段使用空格分割。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">时间戳	|	省份	|	城市	|	用户	|	广告</span><br><span class="line">1516609143867	6	7	64	16</span><br><span class="line">1516609143869	9	4	75	18</span><br><span class="line">1516609143869	1	7	87	12</span><br></pre></td></tr></table></figure>

<p> 每点击一次就会产生一条记录</p>
</li>
<li><p> <strong>需求：</strong>统计出每一个省份广告被点击次数的 TOP3</p>
</li>
<li><p><strong>分析：</strong>使用倒推法</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">==&gt; <span class="type">RDD</span>[(省份, (广告, <span class="number">10</span>))]	<span class="comment">// groupByKey，把相同省份的集合划分到一起</span></span><br><span class="line">==&gt; <span class="type">RDD</span>[(省份, list(广告<span class="number">1</span>信息， 广告<span class="number">2</span>信息， 广告<span class="number">3</span>信息, ...))]	<span class="comment">// 对list进行排序，取前三</span></span><br><span class="line">==&gt; 最终结果：<span class="type">RDD</span>[(省份, list(广告<span class="number">1</span>信息， 广告<span class="number">2</span>信息， 广告<span class="number">3</span>信息))]</span><br><span class="line"></span><br><span class="line"> =&gt; [((pid, cid)，<span class="number">1</span>)，((pid, cid)，<span class="number">1</span>)]  reuceByKey</span><br><span class="line"> =&gt; [(pid, cid), count)，(pid, cid), count] map</span><br><span class="line"> =&gt; [pid, (cid, count)，(cid, count)] groupByKey</span><br><span class="line"> =&gt; [pid, <span class="type">Iterable</span>((cid, count)，(cid, count)，。。。)]</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><ol>
<li><p> 步骤1：把文件放入到 resources 目录下</p>
</li>
<li><p>步骤2：具体代码</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> demo01</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @Author lnd</span></span><br><span class="line"><span class="comment"> * @Date 2021/12/16 18:05</span></span><br><span class="line"><span class="comment"> * @Version 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">// 时间戳，省份，城市，用户，广告</span></span><br><span class="line"><span class="comment">// 1516609143867 6 7 64 16</span></span><br><span class="line"><span class="comment">// 统计出每一个省份广告被点击次数的 TOP3</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Practice</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 1. 初始化spark配置信息，并建立到spark的连接</span></span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Practice&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2、从文件中读取数据得到 RDD</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;E:\\workspace_bigData\\spark\\spark-core\\src\\main\\resources\\agent.log&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3、((province, ad), 1)</span></span><br><span class="line">    <span class="keyword">val</span> provinceADAndOne: <span class="type">RDD</span>[((<span class="type">String</span>, <span class="type">String</span>), <span class="type">Int</span>)] = lines.map(line =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> splits: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">      ((splits(<span class="number">1</span>), splits(<span class="number">4</span>)), <span class="number">1</span>)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4、计算每个省份每个广告被点击的总次数</span></span><br><span class="line">    <span class="keyword">val</span> provinceADSum: <span class="type">RDD</span>[((<span class="type">String</span>, <span class="type">String</span>), <span class="type">Int</span>)] = provinceADAndOne.reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5、将省份作为key，广告加点击数为value：(province, (ad, sum))</span></span><br><span class="line">    <span class="keyword">val</span> provinceToAdSum: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>))] = provinceADSum.map(x =&gt; (x._1._1, (x._1._2, x._2)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 6、按照省份进行分组</span></span><br><span class="line">    <span class="keyword">val</span> provinceGroup: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Iterable</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = provinceToAdSum.groupByKey()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 7、对同一个省份的广告进行排序，按照点击数降序</span></span><br><span class="line">    <span class="keyword">val</span> result: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = provinceGroup.map(&#123;</span><br><span class="line">      <span class="keyword">case</span> (province, adSumIt) =&gt; &#123;</span><br><span class="line">        <span class="comment">// Iterable没有实现排序，需要先转换成容器式集合才能排序</span></span><br><span class="line">        <span class="keyword">val</span> tuples: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = adSumIt.toList.sortBy(-_._2) <span class="comment">//降序排</span></span><br><span class="line">          .take(<span class="number">3</span>) <span class="comment">// 取前三</span></span><br><span class="line"></span><br><span class="line">        (province, tuples)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 8、展示最终结果</span></span><br><span class="line">    result.collect().foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 9、关闭连接</span></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  结果展示：</span></span><br><span class="line"><span class="comment">  </span></span><br><span class="line"><span class="comment">  (4,List((12,25), (2,22), (16,22)))</span></span><br><span class="line"><span class="comment">  (8,List((2,27), (20,23), (11,22)))</span></span><br><span class="line"><span class="comment">  (6,List((16,23), (24,21), (22,20)))</span></span><br><span class="line"><span class="comment">  (0,List((2,29), (24,25), (26,24)))</span></span><br><span class="line"><span class="comment">  (2,List((6,24), (21,23), (29,20)))</span></span><br><span class="line"><span class="comment">  (7,List((16,26), (26,25), (1,23)))</span></span><br><span class="line"><span class="comment">  (5,List((14,26), (21,21), (12,21)))</span></span><br><span class="line"><span class="comment">  (9,List((1,31), (28,21), (0,20)))</span></span><br><span class="line"><span class="comment">  (3,List((14,28), (28,27), (22,25)))</span></span><br><span class="line"><span class="comment">  (1,List((3,25), (6,23), (5,22)))</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="2-4-RDD-的-Action-操作"><a href="#2-4-RDD-的-Action-操作" class="headerlink" title="2.4    RDD 的 Action 操作"></a>2.4    RDD 的 Action 操作</h2><h3 id="2-4-1-reduce-func"><a href="#2-4-1-reduce-func" class="headerlink" title="2.4.1  reduce(func)"></a>2.4.1  <code>reduce(func)</code></h3><p>通过 <code>func</code> 函数聚集 RDD 中的所有元素，先聚合分区内数据，再聚合分区间数据。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="number">1</span> to <span class="number">100</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.reduce(_ + _)</span><br><span class="line">res0: <span class="type">Int</span> = <span class="number">5050</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;c&quot;</span>, <span class="number">3</span>)))</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd2.reduce((x, y) =&gt; (x._1 + y._1, x._2 + y._2))</span><br><span class="line">res2: (<span class="type">String</span>, <span class="type">Int</span>) = (abc,<span class="number">6</span>)</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="2-4-2-collect"><a href="#2-4-2-collect" class="headerlink" title="2.4.2  collect"></a>2.4.2  <code>collect</code></h3><ul>
<li>  以数组的形式返回 RDD 中的所有元素。 </li>
<li>  所有的数据都会被拉到 Driver 端，所以要慎用。</li>
</ul>
<hr>
<h3 id="2-4-3-count"><a href="#2-4-3-count" class="headerlink" title="2.4.3  count()"></a>2.4.3  <code>count()</code></h3><ul>
<li>  返回 RDD 中元素的个数。</li>
</ul>
<hr>
<h3 id="2-4-4-take-n"><a href="#2-4-4-take-n" class="headerlink" title="2.4.4  take(n)"></a>2.4.4  <code>take(n)</code></h3><ul>
<li>  返回 RDD 中前 n 个元素组成的数组。 </li>
<li>  <code>take()</code> 的数据也会拉到 Driver 端，应该只对小数据集使用</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">Array</span>(<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">50</span>, <span class="number">60</span>))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">2</span>] at makeRDD at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.take(<span class="number">2</span>)</span><br><span class="line">res3: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">10</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>





<hr>
<h3 id="2-4-5-first"><a href="#2-4-5-first" class="headerlink" title="2.4.5  first"></a>2.4.5  <code>first</code></h3><p>返回 RDD 中的第一个元素。类似于 <code>take(1)</code>。</p>
<hr>
<h3 id="2-4-6-takeOrdered-n-ordering"><a href="#2-4-6-takeOrdered-n-ordering" class="headerlink" title="2.4.6  takeOrdered(n, [ordering])"></a>2.4.6  <code>takeOrdered(n, [ordering])</code></h3><ul>
<li>  返回排序后的前 n 个元素，默认是升序排列。</li>
<li>  数据也会拉到 Driver 端</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">Array</span>(<span class="number">100</span>, <span class="number">20</span>, <span class="number">130</span>, <span class="number">500</span>, <span class="number">60</span>))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">4</span>] at makeRDD at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.takeOrdered(<span class="number">2</span>)</span><br><span class="line">res6: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">20</span>, <span class="number">60</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.takeOrdered(<span class="number">2</span>)(<span class="type">Ordering</span>.<span class="type">Int</span>.reverse)</span><br><span class="line">res7: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">500</span>, <span class="number">130</span>)</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="2-4-7-aggregate"><a href="#2-4-7-aggregate" class="headerlink" title="2.4.7    aggregate"></a>2.4.7    <code>aggregate</code></h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">aggregate</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](zeroValue: <span class="type">U</span>)(seqOp: (<span class="type">U</span>, <span class="type">T</span>) =&gt; <span class="type">U</span>, combOp: (<span class="type">U</span>, <span class="type">U</span>) =&gt; <span class="type">U</span>): <span class="type">U</span></span><br></pre></td></tr></table></figure>

<p><strong>作用：</strong><code>aggregate</code> 函数将每个分区里面的元素通过 <code>seqOp</code> 和初始值进行聚合，然后用 <code>combine</code> 函数将每个分区的结果和初始值 <code>zeroValue</code> 进行 <code>combine</code> 操作。这个函数最终返回的类型不需要和 RDD 中元素类型一致</p>
<p><strong>注意：<code>zeroValue</code> 分区内聚合和分区间聚合的时候各会使用一次</strong>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">Array</span>(<span class="number">100</span>, <span class="number">30</span>, <span class="number">10</span>, <span class="number">30</span>, <span class="number">1</span>, <span class="number">50</span>, <span class="number">1</span>, <span class="number">60</span>, <span class="number">1</span>), <span class="number">2</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">8</span>] at makeRDD at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.aggregate(<span class="number">0</span>)(_ + _, _ + _)</span><br><span class="line">res12: <span class="type">Int</span> = <span class="number">283</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>), <span class="number">2</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">9</span>] at makeRDD at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.aggregate(<span class="string">&quot;x&quot;</span>)(_ + _, _ + _)</span><br><span class="line">res13: <span class="type">String</span> = xxabxcd</span><br></pre></td></tr></table></figure>





<hr>
<h3 id="2-4-8-fold"><a href="#2-4-8-fold" class="headerlink" title="2.4.8  fold"></a>2.4.8  <code>fold</code></h3><p>折叠操作，<code>aggregate</code> 的简化操作，<code>seqop</code> 和 <code>combop</code> 一样的时候，可以使用 <code>fold</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">Array</span>(<span class="number">100</span>, <span class="number">30</span>, <span class="number">10</span>, <span class="number">30</span>, <span class="number">1</span>, <span class="number">50</span>, <span class="number">1</span>, <span class="number">60</span>, <span class="number">1</span>), <span class="number">2</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">10</span>] at makeRDD at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.fold(<span class="number">0</span>)(_ + _)</span><br><span class="line">res16: <span class="type">Int</span> = <span class="number">283</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>), <span class="number">2</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">11</span>] at makeRDD at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.fold(<span class="string">&quot;x&quot;</span>)(_ + _)</span><br><span class="line">res17: <span class="type">String</span> = xxabxcd</span><br></pre></td></tr></table></figure>





<hr>
<h3 id="2-4-9-saveAsTextFile-path"><a href="#2-4-9-saveAsTextFile-path" class="headerlink" title="2.4.9    saveAsTextFile(path)"></a>2.4.9    <code>saveAsTextFile(path)</code></h3><p><strong>作用：</strong>将数据集的元素以 <code>textfile</code> 的形式保存到 HDFS 文件系统或者其它支持的文件系统，对于每个元素，Spark 将会调用 <code>toString</code> 方法，将它装换为文件中的文本。</p>
<hr>
<h3 id="2-4-10-saveAsSequenceFile-path"><a href="#2-4-10-saveAsSequenceFile-path" class="headerlink" title="2.4.10    saveAsSequenceFile(path)"></a>2.4.10    <code>saveAsSequenceFile(path)</code></h3><p><strong>作用：</strong>将数据集中的元素以 <code>Hadoop sequencefile</code> 的格式保存到指定的目录下，可以使 HDFS 或者其它 Hadoop 支持的文件系统。</p>
<hr>
<h3 id="2-4-11-saveAsObjectFile-path"><a href="#2-4-11-saveAsObjectFile-path" class="headerlink" title="2.4.11    saveAsObjectFile(path)"></a>2.4.11    <code>saveAsObjectFile(path)</code></h3><p><strong>作用：</strong>用于将 RDD 中的元素序列化成对象，存储到文件中。</p>
<hr>
<h3 id="2-4-12-countByKey"><a href="#2-4-12-countByKey" class="headerlink" title="2.4.12    countByKey()"></a>2.4.12    <code>countByKey()</code></h3><p><strong>作用：</strong>针对 <code>(K,V)</code> 类型的 RDD，返回一个 <code>(K,Int)</code> 的 <code>map</code>，表示每一个 key 对应的元素个数。</p>
<p><strong>应用：</strong>可以用来查看数据是否倾斜。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">10</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">20</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">100</span>), (<span class="string">&quot;c&quot;</span>, <span class="number">200</span>)))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">15</span>] at parallelize at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.countByKey()</span><br><span class="line">res19: scala.collection.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Long</span>] = <span class="type">Map</span>(b -&gt; <span class="number">1</span>, a -&gt; <span class="number">2</span>, c -&gt; <span class="number">1</span>)</span><br></pre></td></tr></table></figure>





<hr>
<h3 id="2-4-13-foreach-func"><a href="#2-4-13-foreach-func" class="headerlink" title="2.4.13    foreach(func)"></a>2.4.13    <code>foreach(func)</code></h3><p><strong>作用：</strong>针对 RDD 中的每个元素都执行一次 <code>func</code>。每个函数是在 <code>Executor</code> 上执行的，不是在 <code>Driver</code> 端执行的。</p>
<hr>
<h2 id="2-5-RDD-中函数的传递"><a href="#2-5-RDD-中函数的传递" class="headerlink" title="2.5    RDD 中函数的传递"></a>2.5    RDD 中函数的传递</h2><p>我们在使用 Spark 进行编程的时候，初始化工作是在 <code>Driver</code> 端完成的，而实际的运行程序是在 <code>Executor</code> 端进行的，所以就涉及到了进程间的通讯，数据是需要序列化的。</p>
<h3 id="2-5-1-传递函数"><a href="#2-5-1-传递函数" class="headerlink" title="2.5.1  传递函数"></a>2.5.1  传递函数</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SerDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;SerDemo&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;hello world&quot;</span>, <span class="string">&quot;hello atguigu&quot;</span>, <span class="string">&quot;atguigu&quot;</span>, <span class="string">&quot;hahah&quot;</span>), <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 需求: 在 RDD 中查找出来包含 &quot;hello&quot; 子字符串的元素</span></span><br><span class="line">        <span class="keyword">val</span> searcher = <span class="keyword">new</span> <span class="type">Searcher</span>(<span class="string">&quot;hello&quot;</span>)	<span class="comment">// 用来查找RDD中包含hello的字符串组成的子RDD</span></span><br><span class="line">        <span class="keyword">val</span> result: <span class="type">RDD</span>[<span class="type">String</span>] = searcher.getMatchedRDD1(rdd)</span><br><span class="line">        result.collect.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//需求: 在 RDD 中查找出来包含 query 子字符串的元素</span></span><br><span class="line"><span class="comment">// query 为需要查找的子字符串</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Searcher</span>(<span class="params">val query: <span class="type">String</span></span>)</span>&#123;</span><br><span class="line">    <span class="comment">// 判断 s 中是否包括子字符串 query</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isMatch</span></span>(s : <span class="type">String</span>) =&#123;</span><br><span class="line">        s.contains(query)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 过滤出包含 query 字符串的字符串组成的新的 RDD</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getMatchedRDD1</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]) =&#123;</span><br><span class="line">        rdd.filter(isMatch) </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 过滤出包含 query字符串的字符串组成的新的 RDD</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getMatchedRDD2</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]) =&#123;</span><br><span class="line">        rdd.filter(_.contains(query))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>说明：</strong>直接运行程序会发现报错，没有序列化化。因为 <code>rdd.filter(isMatch)</code> 是在 <code>Executor</code> 上执行的，而且用到了对象 <code>this</code> 的方法 <code>isMatch</code>，但是 <code>Executor</code> 上并没有 <code>Searcher</code> 对象，所以对象 <code>this</code> 需要序列化，才能把对象从 <code>driver</code> 发送到 <code>executor</code>。</p>
<p><img src="/2022/05/31/Spark-Core/image-20211217102243803.png" alt="image-20211217102243803"></p>
<p><strong>解决方案：</strong>让 <code>Searcher</code> 类实现序列化接口 <code>Serializable</code></p>
<p> <img src="/2022/05/31/Spark-Core/image-20211217102251217.png" alt="image-20211217102251217"></p>
<hr>
<h3 id="2-5-2-传递变量"><a href="#2-5-2-传递变量" class="headerlink" title="2.5.2  传递变量"></a>2.5.2  传递变量</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SerDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;SerDemo&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;hello world&quot;</span>, <span class="string">&quot;hello atguigu&quot;</span>, <span class="string">&quot;atguigu&quot;</span>, <span class="string">&quot;hahah&quot;</span>), <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">val</span> searcher = <span class="keyword">new</span> <span class="type">Searcher</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> result: <span class="type">RDD</span>[<span class="type">String</span>] = searcher.getMatchedRDD2(rdd)</span><br><span class="line">        result.collect.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>说明：</strong>这次没有传递函数，而是传递了一个属性过去，仍然会报错没有序列化，因为 <code>query</code> 变量是 <code>Searcher</code> 对象的一个属性，所以 <code>this</code> 仍然需要序列化。</p>
<p><strong>解决方案有 2 种：</strong></p>
<ul>
<li><p>  让类实现序列化接口：Serializable</p>
</li>
<li><p>传递局部变量而不是属性。</p>
<p>   <img src="/2022/05/31/Spark-Core/image-20211217102320709.png" alt="image-20211217102320709"></p>
<p>  如果使用 <code>val q = query</code> 把 <code>query</code> 变量赋值给常量 <code>q</code>，因为 <code>q</code> 是 String 类型的常量，这一系统类型已经默认实现了序列化接口，现在 <code>rdd.filter(_.contains(q))</code> 与 <code>Seacher</code> 对象没有了任何关系，所以 <code>Searcher</code> 对象可以无需序列化。</p>
</li>
</ul>
<hr>
<h3 id="2-5-3-kryo-序列化框架"><a href="#2-5-3-kryo-序列化框架" class="headerlink" title="2.5.3  kryo 序列化框架"></a>2.5.3  kryo 序列化框架</h3><p>参考地址：<a target="_blank" rel="noopener" href="https://github.com/EsotericSoftware/kryo">https://github.com/EsotericSoftware/kryo</a></p>
<p>Java 的序列化比较重，能够序列化任何的类，比较灵活，但是相当的慢，并且序列化后对象的体积也比较大。</p>
<p>Spark 出于性能的考虑，支持另外一种序列化机制 <code>kryo (2.0开始支持)</code>。kryo 比较快和简洁(速度是Serializable的10倍)，想获取更好的性能应该使用 kryo 来序列化。</p>
<p>从 2.0 开始，Spark 内部已经在使用 kryo 序列化机制：当 RDD 在 Shuffle数据的时候，简单数据类型，简单数据类型的数组和字符串类型已经在使用 kryo 来序列化。</p>
<p>有一点需要注意的是：<strong>即使使用 kryo 序列化，自定义类也要继承 Serializable 接口。</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day03</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SerDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">        .setAppName(<span class="string">&quot;SerDemo&quot;</span>)</span><br><span class="line">        .setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">        <span class="comment">// 替换默认的序列化机制 可以省(如果调用registerKryoClasses)</span></span><br><span class="line">        .set(<span class="string">&quot;spark.serializer&quot;</span>, <span class="string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span>)</span><br><span class="line">        <span class="comment">// 注册需要使用 kryo 序列化的自定义类</span></span><br><span class="line">        .registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">Searcher</span>]))</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;hello world&quot;</span>, <span class="string">&quot;hello atguigu&quot;</span>, <span class="string">&quot;atguigu&quot;</span>, <span class="string">&quot;hahah&quot;</span>), <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">val</span> searcher = <span class="keyword">new</span> <span class="type">Searcher</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> result: <span class="type">RDD</span>[<span class="type">String</span>] = searcher.getMatchedRDD1(rdd)</span><br><span class="line">        result.collect.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Searcher</span>(<span class="params">val query: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 判断 s 中是否包括子字符串 query</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isMatch</span></span>(s: <span class="type">String</span>) = &#123;</span><br><span class="line">        s.contains(query)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 过滤出包含 query字符串的字符串组成的新的 RDD</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getMatchedRDD1</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]) = &#123;</span><br><span class="line">        rdd.filter(isMatch) <span class="comment">//</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 过滤出包含 query字符串的字符串组成的新的 RDD</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getMatchedRDD2</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]) = &#123;</span><br><span class="line">        <span class="keyword">val</span> q = query</span><br><span class="line">        rdd.filter(_.contains(q))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<hr>
<h2 id="2-6-RDD-的依赖关系"><a href="#2-6-RDD-的依赖关系" class="headerlink" title="2.6    RDD 的依赖关系"></a>2.6    RDD 的依赖关系</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> rdd1 = sc.textFile(<span class="string">&quot;./words.txt&quot;</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = ./words.txt <span class="type">MapPartitionsRDD</span>[<span class="number">16</span>] at textFile at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = rdd1.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">17</span>] at flatMap at &lt;console&gt;:<span class="number">26</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd3 = rdd2.map((_, <span class="number">1</span>))</span><br><span class="line">rdd3: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">MapPartitionsRDD</span>[<span class="number">18</span>] at map at &lt;console&gt;:<span class="number">28</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd4 = rdd3.reduceByKey(_ + _)</span><br><span class="line">rdd4: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ShuffledRDD</span>[<span class="number">19</span>] at reduceByKey at &lt;console&gt;:<span class="number">30</span></span><br></pre></td></tr></table></figure>

<h3 id="2-6-1-查看-RDD-的血缘关系"><a href="#2-6-1-查看-RDD-的血缘关系" class="headerlink" title="2.6.1  查看 RDD 的血缘关系"></a>2.6.1  查看 RDD 的血缘关系</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd1.toDebugString</span><br><span class="line">res1: <span class="type">String</span> =</span><br><span class="line">(<span class="number">2</span>) ./words.txt <span class="type">MapPartitionsRDD</span>[<span class="number">1</span>] at textFile at &lt;console&gt;:<span class="number">24</span> []</span><br><span class="line">| ./words.txt <span class="type">HadoopRDD</span>[<span class="number">0</span>] at textFile at &lt;console&gt;:<span class="number">24</span> []</span><br><span class="line"></span><br><span class="line">scala&gt; rdd2.toDebugString</span><br><span class="line">res2: <span class="type">String</span> =</span><br><span class="line">(<span class="number">2</span>) <span class="type">MapPartitionsRDD</span>[<span class="number">2</span>] at flatMap at &lt;console&gt;:<span class="number">26</span> []</span><br><span class="line">| ./words.txt <span class="type">MapPartitionsRDD</span>[<span class="number">1</span>] at textFile at &lt;console&gt;:<span class="number">24</span> []</span><br><span class="line">| ./words.txt <span class="type">HadoopRDD</span>[<span class="number">0</span>] at textFile at &lt;console&gt;:<span class="number">24</span> []</span><br><span class="line"></span><br><span class="line">scala&gt; rdd3.toDebugString</span><br><span class="line">res3: <span class="type">String</span> =</span><br><span class="line">(<span class="number">2</span>) <span class="type">MapPartitionsRDD</span>[<span class="number">3</span>] at map at &lt;console&gt;:<span class="number">28</span> []</span><br><span class="line">| <span class="type">MapPartitionsRDD</span>[<span class="number">2</span>] at flatMap at &lt;console&gt;:<span class="number">26</span> []</span><br><span class="line">| ./words.txt <span class="type">MapPartitionsRDD</span>[<span class="number">1</span>] at textFile at &lt;console&gt;:<span class="number">24</span> []</span><br><span class="line">| ./words.txt <span class="type">HadoopRDD</span>[<span class="number">0</span>] at textFile at &lt;console&gt;:<span class="number">24</span> []</span><br><span class="line"></span><br><span class="line">scala&gt; rdd4.toDebugString</span><br><span class="line">res4: <span class="type">String</span> =</span><br><span class="line">(<span class="number">2</span>) <span class="type">ShuffledRDD</span>[<span class="number">4</span>] at reduceByKey at &lt;console&gt;:<span class="number">30</span> []</span><br><span class="line">+-(<span class="number">2</span>) <span class="type">MapPartitionsRDD</span>[<span class="number">3</span>] at map at &lt;console&gt;:<span class="number">28</span> []</span><br><span class="line">    | <span class="type">MapPartitionsRDD</span>[<span class="number">2</span>] at flatMap at &lt;console&gt;:<span class="number">26</span> []</span><br><span class="line">    | ./words.txt <span class="type">MapPartitionsRDD</span>[<span class="number">1</span>] at textFile at &lt;console&gt;:<span class="number">24</span> []</span><br><span class="line">    | ./words.txt <span class="type">HadoopRDD</span>[<span class="number">0</span>] at textFile at &lt;console&gt;:<span class="number">24</span> []</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>说明：</strong>圆括号中的数字表示 RDD 的并行度，也就是有几个分区。</p>
<hr>
<h3 id="2-6-2-查看-RDD-的依赖关系"><a href="#2-6-2-查看-RDD-的依赖关系" class="headerlink" title="2.6.2  查看 RDD 的依赖关系"></a>2.6.2  查看 RDD 的依赖关系</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd1.dependencies</span><br><span class="line">res28: <span class="type">Seq</span>[org.apache.spark.<span class="type">Dependency</span>[_]] = <span class="type">List</span>(org.apache.spark.<span class="type">OneToOneDependency</span>@<span class="number">70</span>dbde75)</span><br><span class="line"></span><br><span class="line">scala&gt; rdd2.dependencies</span><br><span class="line">res29: <span class="type">Seq</span>[org.apache.spark.<span class="type">Dependency</span>[_]] = <span class="type">List</span>(org.apache.spark.<span class="type">OneToOneDependency</span>@<span class="number">21</span>a87972)</span><br><span class="line"></span><br><span class="line">scala&gt; rdd3.dependencies</span><br><span class="line">res30: <span class="type">Seq</span>[org.apache.spark.<span class="type">Dependency</span>[_]] = <span class="type">List</span>(org.apache.spark.<span class="type">OneToOneDependency</span>@<span class="number">4776</span>f6af)</span><br><span class="line"></span><br><span class="line">scala&gt; rdd4.dependencies</span><br><span class="line">res31: <span class="type">Seq</span>[org.apache.spark.<span class="type">Dependency</span>[_]] = <span class="type">List</span>(org.apache.spark.<span class="type">ShuffleDependency</span>@<span class="number">4809035</span>f)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>想理解 RDDs 是如何工作的，最重要的事情就是了解 <code>transformations</code>。</p>
<p>RDD 之间的关系可以从两个维度来理解：一个是 RDD 是从哪些 RDD 转换而来，也就是 RDD 的 parent RDD(s) 是什么；另一个就是 RDD 依赖于 parent RDD(s) 的哪些 Partition(s)。这种关系就是 RDD 之间的依赖。</p>
<p>依赖有 2 种策略:</p>
<ol>
<li> 窄依赖(transformations with narrow dependencies)</li>
<li> 宽依赖(transformations with wide dependencies)</li>
</ol>
<p>宽依赖对 Spark 去评估一个 transformations 有更加重要的影响，比如对性能的影响。</p>
<hr>
<h3 id="2-6-3-窄依赖"><a href="#2-6-3-窄依赖" class="headerlink" title="2.6.3  窄依赖"></a>2.6.3  窄依赖</h3><p>如果 <code>B RDD</code> 是由 <code>A RDD</code> 计算得到的，则 <code>B RDD</code> 就是 <code>Child RDD</code>， <code>A RDD</code> 就是 <code>parent RDD</code>。</p>
<p>如果依赖关系在设计的时候就可以确定，而不需要考虑父 RDD 分区中的记录，并且如果父 RDD 中的每个分区最多只有一个子分区，这样的依赖就叫窄依赖。</p>
<p>一句话总结：<strong>父RDD 的每个分区最多被一个 RDD 的分区使用</strong>。</p>
<p><img src="/2022/05/31/Spark-Core/image-20211217104250450.png" alt="image-20211217104250450"></p>
<p>​                               </p>
<p>具体来说，窄依赖的时候，子 RDD 中的分区要么只依赖一个父 RDD 中的一个分区(比如map, filter操作)，要么在设计时候就能确定子 RDD 是父 RDD 的一个子集(比如: coalesce)。</p>
<p>所以，窄依赖的转换可以在任何的的一个分区上单独执行，而不需要其它分区的任何信息。</p>
<hr>
<h3 id="2-6-4-宽依赖"><a href="#2-6-4-宽依赖" class="headerlink" title="2.6.4  宽依赖"></a>2.6.4  宽依赖</h3><p>如果父 RDD 的分区被不止一个子 RDD 的分区依赖，就是宽依赖。</p>
<p><img src="/2022/05/31/Spark-Core/image-20211217104447823.png" alt="image-20211217104447823"></p>
<p>宽依赖工作的时候，不能随意在某些记录上运行，而是需要使用特殊的方式(比如按照 key)来获取分区中的所有数据。</p>
<p>例如：在排序(sort)的时候，数据必须被分区，同样范围的 key 必须在同一个分区内。具有宽依赖的 <code>transformations</code> 包括：sort， reduceByKey，groupByKey，join 和调用 <code>rePartition</code> 函数的任何操作。</p>
<hr>
<h2 id="2-7-Spark-Job-的划分"><a href="#2-7-Spark-Job-的划分" class="headerlink" title="2.7    Spark Job 的划分"></a>2.7    Spark Job 的划分</h2><p>由于 Spark 的懒执行，在驱动程序调用一个 <code>action</code> 算子之前，Spark 应用不会做任何事情。</p>
<p>针对每个 <code>action</code>，Spark 调度器就创建一个 <code>执行图(execution graph)</code> 和启动一个 <code>Spark job</code>。</p>
<p>每个 job 由多个 <code>stages</code> 组成，这些 <code>stages</code> 就是实现最终的 RDD 所需的数据转换的步骤，一个宽依赖划分一个 <code>stage</code>。</p>
<p>每个 <code>stage</code> 由多个 <code>tasks</code> 来组成，这些 <code>tasks</code> 就表示每个并行计算，并且会在多个执行器上执行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Application	应用</span><br><span class="line"></span><br><span class="line">Job：</span><br><span class="line">	一个应用中，每碰到一个 action ，就会启动一个 Job</span><br><span class="line">	一个应用可以有多个 Job</span><br><span class="line"></span><br><span class="line">stage：	阶段</span><br><span class="line">	每碰到一个宽依赖，就会在这个Job内创建一个新的 stage</span><br><span class="line">	一个 job 至少有一个 stage</span><br><span class="line"></span><br><span class="line">task：	并行度</span><br><span class="line">	每个stage执行任务时的并行度</span><br><span class="line">	task是一个线程，是执行代码的最小单位</span><br></pre></td></tr></table></figure>



<p><img src="/2022/05/31/Spark-Core/image-20211217121753477.png" alt="image-20211217121753477"></p>
<hr>
<h3 id="2-7-1-DAG-Directed-Acyclic-Graph-有向无环图"><a href="#2-7-1-DAG-Directed-Acyclic-Graph-有向无环图" class="headerlink" title="2.7.1    DAG(Directed Acyclic Graph) 有向无环图"></a>2.7.1    DAG(Directed Acyclic Graph) 有向无环图</h3><p>Spark 的顶层调度层使用 RDD 的依赖为每个 job 创建一个由 stages 组成的 DAG(有向无环图)。 在 Spark API 中，这被称作 DAG 调度器(DAG Scheduler)。</p>
<p>我们已经注意到，有些错误，比如：连接集群的错误，配置参数错误，启动一个 Spark job 的错误，这些错误必须处理，并且都表现为 DAG Scheduler 错误。这是因为一个 Spark job 的执行是被 DAG 来处理。</p>
<p>DAG 为每个 job 构建一个 stages 组成的图表，从而确定运行每个 task 的位置，然后传递这些信息给 TaskSheduler。TaskSheduler 负责在集群中运行任务。</p>
<hr>
<h3 id="2-7-2-Jobs"><a href="#2-7-2-Jobs" class="headerlink" title="2.7.2    Jobs"></a>2.7.2    Jobs</h3><p>Spark job 处于 Spark 执行层级结构中的最高层。每个 Spark job 对应一个 action，每个 action 被 Spark 应用中的驱动所程序调用。</p>
<p>可以把 Action 理解成把数据从 RDD 的数据带到其它存储系统的组件(通常是带到驱动程序所在的位置或者写到稳定的存储系统中)。</p>
<p>只要一个 action 被调用，Spark 就不会再向这个 job 增加新的东西。</p>
<hr>
<h3 id="2-7-3-stages"><a href="#2-7-3-stages" class="headerlink" title="2.7.3    stages"></a>2.7.3    stages</h3><p>前面说过，RDD 的转换是懒执行的，直到调用一个 action 才开始执行 RDD 的转换。</p>
<p>正如前面所提到的，一个 job 是由调用一个 action 来定义的。一个 action 可能会包含一个或多个转换( transformation )，Spark 根据宽依赖把 job 分解成 stage。</p>
<p>从整体来看，一个 stage 可以任务是“计算(task)”的集合，这些每个“计算”在各自的 Executor 中进行运算，而不需要同其它的执行器或者驱动进行网络通讯。换句话说，当任何两个 workers 之间开始需要网络通讯的时候，这时候一个新的 stage 就产生了。例如：shuffle 的时候。</p>
<p>这些创建 stage 边界的依赖称为 <code>ShuffleDependencies</code>。shuffle 是由宽依赖所引起的，比如：sort，groupBy，因为它们需要在分区中重新分发数据，那些窄依赖的转换会被分到同一个 stage 中。</p>
<p>想想我们以前学习的 “worldcount 案例”</p>
<p> <img src="/2022/05/31/Spark-Core/image-20211217124958363.png" alt="image-20211217124958363"></p>
<p>Spark 会把 flatMap，map 合并到一个 stage 中，因为这些转换不需要 shuffle。所以，数据只需要传递一次，每个执行器就可以顺序的执行这些操作。</p>
<p>因为边界 stage 需要同驱动进行通讯，所以与 job 有关的 stage 通常必须顺序执行而不能并行执行。</p>
<p>如果这个 stage 是用来计算不同的 RDDs，被用来合并成一个下游的转换(比如: join)，也是有可能并行执行的。但是仅需要计算一个 RDD 的宽依赖转换必须顺序计算。</p>
<p>所以, 设计程序的时候, 尽量少用 shuffle。</p>
<hr>
<h3 id="2-7-4-Tasks"><a href="#2-7-4-Tasks" class="headerlink" title="2.7.4  Tasks"></a>2.7.4  Tasks</h3><p>stage 由 tasks 组成。在执行层级中，task 是最小的执行单位，每一个 task 表现为一个本地计算。</p>
<p>一个 stage 中的所有 tasks 会对不同的数据执行相同的代码。(程序代码一样, 只是作用在了不同的数据上)</p>
<p>一个 task 不能被多个执行器来执行，但是，每个执行器会动态的分配多个 slots 来执行 tasks，并且在整个生命周期内会并行的运行多个 task，每个 stage 的 task 的数量对应着分区的数量，即每个 Partition 都被分配一个 Task。 </p>
<p>在大多数情况下，每个 stage 的所有 task 在下一个 stage 开启之前必须全部完成。</p>
<hr>
<h2 id="2-8-RDD-的持久化"><a href="#2-8-RDD-的持久化" class="headerlink" title="2.8    RDD 的持久化"></a>2.8    RDD 的持久化</h2><p>每碰到一个 Action 就会产生一个 job，每个 job 开始计算的时候总是从这个 job 最开始的 RDD 开始计算。</p>
<h3 id="2-8-1-先看一段代码"><a href="#2-8-1-先看一段代码" class="headerlink" title="2.8.1  先看一段代码"></a>2.8.1  先看一段代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">CacheDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Practice&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;ab&quot;</span>, <span class="string">&quot;bc&quot;</span>))</span><br><span class="line">        <span class="keyword">val</span> rdd2 = rdd1.flatMap(x =&gt; &#123;</span><br><span class="line">            println(<span class="string">&quot;flatMap...&quot;</span>)</span><br><span class="line">            x.split(<span class="string">&quot;&quot;</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">        <span class="keyword">val</span> rdd3: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = rdd2.map(x =&gt; &#123;</span><br><span class="line">            (x, <span class="number">1</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">        </span><br><span class="line">        rdd3.collect.foreach(println)</span><br><span class="line">        println(<span class="string">&quot;-----------&quot;</span>)</span><br><span class="line">        rdd3.collect.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>执行结果：</strong></p>
<p> <img src="/2022/05/31/Spark-Core/image-20211217125526721.png" alt="image-20211217125526721"></p>
<p><strong>说明：</strong></p>
<ol>
<li> 每调用一次 <code>collect</code>，都会创建一个新的 <code>job</code>，每个 <code>job</code> 总是从它血缘的起始开始计算。所以，会发现中间的这些计算过程都会重复的执行。</li>
<li> 原因是因为 <code>rdd</code> 记录了整个计算过程，如果计算的过程中出现哪个分区的数据损坏或丢失，则可以从头开始计算来达到容错的目的。</li>
</ol>
<hr>
<h3 id="2-8-2-RDD-数据的持久化"><a href="#2-8-2-RDD-数据的持久化" class="headerlink" title="2.8.2    RDD 数据的持久化"></a>2.8.2    RDD 数据的持久化</h3><p>每个 <code>job</code> 都会重新进行计算，在有些情况下是没有必要的，如何解决这个问题呢?</p>
<p>Spark 一个重要的能力就是可以持久化数据集在内存中。当我们持久化一个 RDD 时，每个节点都会存储它在内存中计算的那些分区，然后在其它的 <code>action</code> 中可以重用这些数据。这个特性会让将来的 <code>action</code> 计算起来更快(通常块 10 倍)。对于迭代算法和快速交互式查询来说，缓存(Caching)是一个关键工具。</p>
<p>可以使用方法 <code>persist()</code> 或者 <code>cache()</code> 来持久化一个 RDD，持久化的操作会在第一个 <code>action</code> 执行之后才真正执行。<code>action</code> 算子会计算这个 RDD，然后把结果的存储到它的节点的内存中。Spark 的 <code>Cache</code> 也是容错：如果 RDD 的任何一个分区的数据丢失了，Spark 会自动的重新计算。</p>
<p>RDD 的各个 <code>Partition</code> 是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部 <code>Partition</code>。</p>
<p>另外，允许我们对持久化的 RDD 使用不同的存储级别。</p>
<p>例如：可以存在磁盘上，存储在内存中(堆内存中)，跨节点做副本。</p>
<p>可以给 <code>persist()</code> 来传递存储级别。<code>cache()</code> 方法是使用默认存储级别( <code>StorageLevel.MEMORY_ONLY</code> )的简写方法。</p>
<table>
<thead>
<tr>
<th>Storage Level</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td>MEMORY_ONLY</td>
<td>Store RDD as  deserialized Java objects in the JVM. If the RDD does not fit in memory, some  partitions will not be cached and will be recomputed on the fly each time  they’re needed. This is the default level.</td>
</tr>
<tr>
<td>MEMORY_AND_DISK</td>
<td>Store RDD as  deserialized Java objects in the JVM. If the RDD does not fit in memory,  store the partitions that don’t fit on disk, and read them from there when  they’re needed.</td>
</tr>
<tr>
<td>MEMORY_ONLY_SER  (Java and Scala)</td>
<td>Store RDD as <em>serialized</em> Java objects (one byte  array per partition). This is generally more space-efficient than  deserialized objects, especially when using a <a target="_blank" rel="noopener" href="http://spark.apache.org/docs/2.1.1/tuning.html">fast serializer</a>,  but more CPU-intensive to read.</td>
</tr>
<tr>
<td>MEMORY_AND_DISK_SER  (Java and Scala)</td>
<td>Similar to  MEMORY_ONLY_SER, but spill partitions that don’t fit in memory to disk  instead of recomputing them on the fly each time they’re needed.</td>
</tr>
<tr>
<td>DISK_ONLY</td>
<td>Store the RDD  partitions only on disk.</td>
</tr>
<tr>
<td>MEMORY_ONLY_2,  MEMORY_AND_DISK_2, etc.</td>
<td>Same as the  levels above, but replicate each partition on two cluster nodes.</td>
</tr>
<tr>
<td>OFF_HEAP  (experimental)</td>
<td>Similar to  MEMORY_ONLY_SER, but store the data in <a target="_blank" rel="noopener" href="http://spark.apache.org/docs/2.1.1/configuration.html#memory-management">off-heap   memory</a>. This requires off-heap memory to be enabled.</td>
</tr>
</tbody></table>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rdd2.cache() // 等价于 rdd2.persist(StorageLevel.MEMORY_ONLY)	对rdd2进行持久化</span></span><br><span class="line">rdd2.persist(<span class="type">StorageLevel</span>.<span class="type">MEMORY_ONLY</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/05/31/Spark-Core/image-20211217170539985.png" alt="image-20211217170539985"></p>
<p><strong>说明：</strong></p>
<ol>
<li> 第一个 job 会计算 RDD2，以后的 job 就不用再计算了。</li>
<li> 有一点需要说明的是，即使我们不手动设置持久化，Spark 也会自动的对一些 <code>shuffle</code> 操作的中间数据做持久化操作（比如: <code>reduceByKey</code>）。这样做的目的是为了当一个节点 <code>shuffle</code> 失败后避免重新计算整个输入。当然，在实际使用的时候，如果想重用数据，仍然建议调用 <code>persist</code> 或 <code>cache</code>。</li>
</ol>
<hr>
<h2 id="2-9-设置检查点"><a href="#2-9-设置检查点" class="headerlink" title="2.9    设置检查点"></a>2.9    设置检查点</h2><p>Spark 中对于数据的保存除了持久化操作之外，还提供了一种检查点的机制，检查点（本质是通过将 RDD 写入 Disk 做检查点）是为了通过 Lineage 做容错的辅助。</p>
<p>Lineage 过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果之后有节点出现问题而丢失分区，从做检查点的 RDD 开始重做 Lineage，就会减少开销。</p>
<p>检查点通过将数据写入到 HDFS 文件系统实现了 RDD 的检查点功能。</p>
<p>为当前 RDD 设置检查点。该函数将会创建一个二进制的文件，并存储到 checkpoint 目录中，该目录是用 <code>SparkContext.setCheckpointDir()</code> 设置的。在 checkpoint 的过程中，该 RDD 的所有依赖于父 RDD 中的信息将全部被移除。</p>
<p>对 RDD 进行 <code>checkpoint</code> 操作并不会马上被执行，必须执行 <code>action</code> 操作才能触发，在触发的时候需要对这个 RDD 重新计算。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">CheckPointDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 要在SparkContext初始化之前设置, 都在无效</span></span><br><span class="line">        <span class="type">System</span>.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>, <span class="string">&quot;atguigu&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Practice&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">// 设置 checkpoint的目录. 如果spark运行在集群上, 则必须是 hdfs 目录</span></span><br><span class="line">        sc.setCheckpointDir(<span class="string">&quot;hdfs://hadoop201:9000/checkpoint&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;abc&quot;</span>))</span><br><span class="line">        <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[<span class="type">String</span>] = rdd1.map(_ + <span class="string">&quot; : &quot;</span> + <span class="type">System</span>.currentTimeMillis())</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">     标记 RDD2的 checkpoint.</span></span><br><span class="line"><span class="comment">     RDD2会被保存到文件中(文件位于前面设置的目录中), 并且会切断到父RDD的引用, 也就是切断了它向上的血缘关系</span></span><br><span class="line"><span class="comment">     该函数必须在job被执行之前调用.</span></span><br><span class="line"><span class="comment">     强烈建议把这个RDD序列化到内存中, 否则, 把它保存到文件的时候需要重新计算.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">        rdd2.checkpoint()</span><br><span class="line">        rdd2.collect().foreach(println)</span><br><span class="line">        rdd2.collect().foreach(println)</span><br><span class="line">        rdd2.collect().foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<hr>
<h3 id="持久化和checkpoint的区别"><a href="#持久化和checkpoint的区别" class="headerlink" title="持久化和checkpoint的区别"></a>持久化和checkpoint的区别</h3><ol>
<li>   持久化只是将数据保存在 BlockManager 中，而 RDD 的 Lineage 是不变的。但是 <code>checkpoint</code> 执行完后，RDD 已经没有之前所谓的依赖 RDD 了，而只有一个强行为其设置的 <code>checkpointRDD</code>，RDD 的 Lineage 改变了。</li>
<li>   持久化的数据丢失可能性更大，磁盘、内存都可能会存在数据丢失的情况。但是 <code>checkpoint</code> 的数据通常是存储在如 HDFS 等容错、高可用的文件系统，数据丢失可能性较小。</li>
<li>   <strong>注意：</strong>默认情况下，如果某个 RDD 没有持久化，但是设置了checkpoint，会存在问题。本来这个 job 都执行结束了，但是由于中间 RDD 没有持久化，checkpoint job 想要将 RDD 的数据写入外部文件系统的话，需要全部重新计算一次，再将计算出来的 RDD 数据 checkpoint 到外部文件系统。所以，建议对 <code>checkpoint()</code> 的 RDD 使用持久化，这样 RDD 只需要计算一次就可以了。</li>
</ol>
<hr>
<h1 id="第-3-章-Key-Value-类型-RDD-的数据分区器"><a href="#第-3-章-Key-Value-类型-RDD-的数据分区器" class="headerlink" title="第 3 章 Key-Value 类型 RDD 的数据分区器"></a>第 3 章 Key-Value 类型 RDD 的数据分区器</h1><ul>
<li>  对于只存储 value 的 RDD，是不需要分区器的。只有存储 <code>Key-Value</code> 类型的数据才会需要分区器。</li>
<li>  Spark 目前支持 Hash 分区器和 Range 分区器，用户也可以实现自定义的分区器。</li>
<li>  Hash 分区为器为 Spark 默认的分区器，Spark 中分区器直接决定了 RDD 分区的个数、RDD 中每条数据经过 <code>shuffle</code> 过程后属于哪个分区和 <code>Reduce</code> 的个数。</li>
</ul>
<hr>
<h2 id="3-1-查看-RDD-的分区"><a href="#3-1-查看-RDD-的分区" class="headerlink" title="3.1 查看 RDD 的分区"></a>3.1 查看 RDD 的分区</h2><h3 id="1-value-RDD-的分区器"><a href="#1-value-RDD-的分区器" class="headerlink" title="1.   value RDD 的分区器"></a>1.   value RDD 的分区器</h3><ul>
<li>  对于只存储 value 的 RDD，是没有分区器的。</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>(<span class="number">10</span>))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">2</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.partitioner</span><br><span class="line">res8: <span class="type">Option</span>[org.apache.spark.<span class="type">Partitioner</span>] = <span class="type">None</span></span><br></pre></td></tr></table></figure>



<hr>
<h3 id="2-key-value-RDD-的分区器"><a href="#2-key-value-RDD-的分区器" class="headerlink" title="2.   key-value RDD 的分区器"></a>2.   key-value RDD 的分区器</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;hello&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;world&quot;</span>, <span class="number">1</span>)))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">3</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.partitioner</span><br><span class="line">res11: <span class="type">Option</span>[org.apache.spark.<span class="type">Partitioner</span>] = <span class="type">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 导入HashPartitioner</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">HashPartitioner</span></span><br><span class="line"><span class="comment">// 使用 HashPartitioner 分区器对 rdd1 重新分区, 得到分区后的 RDD </span></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = rdd1.partitionBy(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">3</span>))</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ShuffledRDD</span>[<span class="number">5</span>] at partitionBy at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd2.partitioner</span><br><span class="line">res14: <span class="type">Option</span>[org.apache.spark.<span class="type">Partitioner</span>] = <span class="type">Some</span>(org.apache.spark.<span class="type">HashPartitioner</span>@<span class="number">3</span>)</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="3-2-HashPartitioner"><a href="#3-2-HashPartitioner" class="headerlink" title="3.2 HashPartitioner"></a>3.2 HashPartitioner</h2><p><code>HashPartitioner</code> 分区器的原理：对于给定的 <code>key</code>，计算其 <code>hashCode</code>，并除以分区的个数取余，如果余数小于 0，则用 <code>余数+分区的个数（否则加0）</code>，最后返回的值就是这个 key 所属的分区 ID。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day01</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">HashPartitioner</span>, <span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Practice&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>((<span class="number">10</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">20</span>, <span class="string">&quot;b&quot;</span>), (<span class="number">30</span>, <span class="string">&quot;c&quot;</span>), (<span class="number">40</span>, <span class="string">&quot;d&quot;</span>), (<span class="number">50</span>, <span class="string">&quot;e&quot;</span>), (<span class="number">60</span>, <span class="string">&quot;f&quot;</span>)))</span><br><span class="line">        <span class="comment">// 把分区号取出来, 检查元素的分区情况</span></span><br><span class="line">        <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = rdd1.mapPartitionsWithIndex((index, it) =&gt; it.map(x =&gt; (index, x<span class="number">.1</span> + <span class="string">&quot; : &quot;</span> + x<span class="number">.2</span>)))</span><br><span class="line"></span><br><span class="line">        println(rdd2.collect.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 把 RDD1使用 HashPartitioner重新分区</span></span><br><span class="line">        <span class="keyword">val</span> rdd3 = rdd1.partitionBy(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">5</span>))</span><br><span class="line">        <span class="comment">// 检测RDD3的分区情况</span></span><br><span class="line">        <span class="keyword">val</span> rdd4: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = rdd3.mapPartitionsWithIndex((index, it) =&gt; it.map(x =&gt; (index, x<span class="number">.1</span> + <span class="string">&quot; : &quot;</span> + x<span class="number">.2</span>)))</span><br><span class="line">        println(rdd4.collect.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="3-3-RangePartitioner"><a href="#3-3-RangePartitioner" class="headerlink" title="3.3 RangePartitioner"></a>3.3 RangePartitioner</h2><p><code>HashPartitioner</code> 分区的弊端：可能导致每个分区中数据量的不均匀，极端情况下会导致某些分区拥有 RDD 的全部数据。比如我们前面的例子就是一个极端，它们都进入了 0 分区。</p>
<p><code>RangePartitioner</code> 作用：将一定范围内的数映射到某一个分区内，尽量保证每个分区中数据量的均匀，而且分区与分区之间是有序的，一个分区中的元素肯定都是比另一个分区内的元素小或者大，但是分区内的元素是不能保证顺序的。简单的说就是将一定范围内的数映射到某一个分区内。实现过程为：</p>
<ol>
<li> 第一步：先从整个 RDD 中抽取出样本数据，将样本数据排序，计算出每个分区的最大 key 值，形成一个 <code>Array[KEY]</code> 类型的数组变量 <code>rangeBounds</code>（边界数组）。</li>
<li> 第二步：判断 <code>key</code> 在 <code>rangeBounds</code> 中所处的范围，给出该 <code>key</code> 值在下一个 RDD 中的分区 id 下标；该分区器要求 RDD 中的 KEY 类型必须是可以排序的。比如 <code>[1,100,200,300,400]</code>，然后对比传进来的 <code>key</code>，返回对应的 <code>分区id</code>。</li>
</ol>
<hr>
<h2 id="3-4-自定义分区器"><a href="#3-4-自定义分区器" class="headerlink" title="3.4 自定义分区器"></a>3.4 自定义分区器</h2><p>要实现自定义的分区器，你需要继承 <code>org.apache.spark.Partitioner</code>，并且需要实现下面的方法：</p>
<ol>
<li>   <code>numPartitions</code>：该方法需要返回分区数，必须要大于 0。</li>
<li>   <code>getPartition(key)</code>：返回指定键的分区编号(0 到 <code>numPartitions-1</code>)。</li>
<li>   <code>equals</code>：Java 判断相等性的标准方法。这个方法的实现非常重要，Spark 需要用这个方法来检查你的分区器对象是否和其他分区器实例相同，这样 Spark 才可以判断两个 RDD 的分区方式是否相同</li>
<li>   <code>hashCode</code>：如果你重写了 <code>equals</code>，则也应该重写这个方法。</li>
</ol>
<h3 id="MyPartitioner"><a href="#MyPartitioner" class="headerlink" title="MyPartitioner"></a>MyPartitioner</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">Partitioner</span>, <span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">使用自定义的 Partitioner 是很容易的 :只要把它传给 partitionBy() 方法即可。</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Spark 中有许多依赖于数据混洗的方法，比如 join() 和 groupByKey()，</span></span><br><span class="line"><span class="comment">它们也可以接收一个可选的 Partitioner 对象来控制输出数据的分区方式。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyPartitionerDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Practice&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> rdd1 = sc.parallelize(</span><br><span class="line">            <span class="type">Array</span>((<span class="number">10</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">20</span>, <span class="string">&quot;b&quot;</span>), (<span class="number">30</span>, <span class="string">&quot;c&quot;</span>), (<span class="number">40</span>, <span class="string">&quot;d&quot;</span>), (<span class="number">50</span>, <span class="string">&quot;e&quot;</span>), (<span class="number">60</span>, <span class="string">&quot;f&quot;</span>)),</span><br><span class="line">            <span class="number">3</span>)</span><br><span class="line">        <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = rdd1.partitionBy(<span class="keyword">new</span> <span class="type">MyPartitioner</span>(<span class="number">4</span>))</span><br><span class="line">        <span class="keyword">val</span> rdd3: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = rdd2.mapPartitionsWithIndex((index, items) =&gt; items.map(x =&gt; (index, x._1 + <span class="string">&quot; : &quot;</span> + x._2)))</span><br><span class="line">        println(rdd3.collect.mkString(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyPartitioner</span>(<span class="params">numPars: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">numPartitions</span></span>: <span class="type">Int</span> = numPars</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">        <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<hr>
<h1 id="第-4-章-文件中数据的读取和保存"><a href="#第-4-章-文件中数据的读取和保存" class="headerlink" title="第 4 章    文件中数据的读取和保存"></a>第 4 章    文件中数据的读取和保存</h1><p>本章专门学习如何<strong>从文件中读取数据</strong>和<strong>保存数据到文件中</strong>。</p>
<p>从文件中读取数据是创建 RDD 的一种方式。</p>
<p>把数据保存到文件中的操作是一种 Action。</p>
<p>Spark 的数据读取及数据保存可以从两个维度来作区分：<strong>文件格式</strong>以及<strong>文件系统</strong>。</p>
<ul>
<li>  文件格式分为：Text 文件、Json 文件、csv 文件、Sequence 文件以及 Object 文件；</li>
<li>  文件系统分为：本地文件系统、HDFS、Hbase 以及 数据库。</li>
</ul>
<p>平时用的比较多的就是：从 HDFS 读取和保存 Text 文件。</p>
<hr>
<h2 id="4-1-读写-Text-文件"><a href="#4-1-读写-Text-文件" class="headerlink" title="4.1    读写 Text 文件"></a>4.1    读写 Text 文件</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 读取本地文件</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.textFile(<span class="string">&quot;./words.txt&quot;</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = ./words.txt <span class="type">MapPartitionsRDD</span>[<span class="number">5</span>] at textFile at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = rdd1.flatMap(.split(<span class="string">&quot; &quot;</span>)).map((, <span class="number">1</span>)).reduceByKey(_ +_)</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ShuffledRDD</span>[<span class="number">8</span>] at reduceByKey at &lt;console&gt;:<span class="number">26</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 保存数据到 hdfs 上.    </span></span><br><span class="line">scala&gt; rdd2.saveAsTextFile(<span class="string">&quot;hdfs://hadoop201:9000/words_output&quot;</span>)</span><br></pre></td></tr></table></figure>





<hr>
<h2 id="4-2-读取-Json-文件"><a href="#4-2-读取-Json-文件" class="headerlink" title="4.2    读取 Json 文件"></a>4.2    读取 Json 文件</h2><p>如果 JSON 文件中每一行就是一个 JSON 记录，那么可以通过将 JSON 文件当做文本文件来读取，然后利用相关的 JSON 库对每一条数据进行 JSON 解析。</p>
<p><strong>注意：</strong>使用 RDD 读取 JSON 文件处理很复杂，同时 SparkSQL 集成了很好的处理 JSON 文件的方式，所以实际应用中多是采用 SparkSQL 处理 JSON 文件。</p>
<p>关于 SparkSQL 后面的章节专门去讲</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 读取 json 数据的文件, 每行是一个 json 对象</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.textFile(<span class="string">&quot;/opt/module/spark-local/examples/src/main/resources/people.json&quot;</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = /opt/module/spark-local/examples/src/main/resources/people.json <span class="type">MapPartitionsRDD</span>[<span class="number">11</span>] at textFile at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 导入 scala 提供的可以解析 json 的工具类</span></span><br><span class="line">scala&gt; <span class="keyword">import</span> scala.util.parsing.json.<span class="type">JSON</span></span><br><span class="line"><span class="keyword">import</span> scala.util.parsing.json.<span class="type">JSON</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 map 来解析 Json, 需要传入 JSON.parseFull</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd2 = rdd1.map(<span class="type">JSON</span>.parseFull)</span><br><span class="line">rdd2: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Option</span>[<span class="type">Any</span>]] = <span class="type">MapPartitionsRDD</span>[<span class="number">12</span>] at map at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 解析到的结果其实就是 Option 组成的数组, Option 存储的就是 Map 对象</span></span><br><span class="line">scala&gt; rdd2.collect</span><br><span class="line">res2: <span class="type">Array</span>[<span class="type">Option</span>[<span class="type">Any</span>]] = <span class="type">Array</span>(<span class="type">Some</span>(<span class="type">Map</span>(name -&gt; <span class="type">Michael</span>)), <span class="type">Some</span>(<span class="type">Map</span>(name -&gt; <span class="type">Andy</span>, age -&gt; <span class="number">30.0</span>)), <span class="type">Some</span>(<span class="type">Map</span>(name -&gt; <span class="type">Justin</span>, age -&gt; <span class="number">19.0</span>)))</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="4-3-读写-SequenceFile-文件"><a href="#4-3-读写-SequenceFile-文件" class="headerlink" title="4.3    读写 SequenceFile 文件"></a>4.3    读写 SequenceFile 文件</h2><p> SequenceFile 文件是 Hadoop 用来存储二进制形式的 <code>key-value</code> 对而设计的一种平面文件(Flat File)。</p>
<p>Spark 有专门用来读取 SequenceFile 的接口。在 SparkContext 中，可以调用 <code>sequenceFile[ keyClass, valueClass](path)</code>。</p>
<p>注意：SequenceFile 文件只针对 PairRDD</p>
<ol>
<li><p>先保存一个 SequenceFile 文件</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;b&quot;</span>, <span class="number">2</span>),(<span class="string">&quot;c&quot;</span>, <span class="number">3</span>)))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">13</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.saveAsSequenceFile(<span class="string">&quot;hdfs://hadoop201:9000/seqFiles&quot;</span>)</span><br></pre></td></tr></table></figure>

</li>
<li><p>读取 SequenceFile 文件</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.sequenceFile[<span class="type">String</span>, <span class="type">Int</span>](<span class="string">&quot;hdfs://hadoop201:9000/seqFiles&quot;</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">MapPartitionsRDD</span>[<span class="number">18</span>] at sequenceFile at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.collect</span><br><span class="line">res4: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((a,<span class="number">1</span>), (b,<span class="number">2</span>), (c,<span class="number">3</span>))</span><br></pre></td></tr></table></figure>

<p> 注意：需要指定泛型的类型 <code>sc.sequenceFile[String, Int]</code></p>
</li>
</ol>
<hr>
<h2 id="4-4-读写-objectFile-文件"><a href="#4-4-读写-objectFile-文件" class="headerlink" title="4.4    读写 objectFile 文件"></a>4.4    读写 objectFile 文件</h2><p>对象文件是将对象序列化后保存的文件，采用 Java 的序列化机制。</p>
<p>可以通过 <code>objectFile[k,v](path)</code> 函数接收一个路径，读取对象文件，返回对应的 RDD，也可以通过调用 <code>saveAsObjectFile()</code> 实现对对象文件的输出</p>
<ol>
<li><p>把 RDD 保存为 <code>objectFile</code></p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),(<span class="string">&quot;b&quot;</span>, <span class="number">2</span>),(<span class="string">&quot;c&quot;</span>, <span class="number">3</span>)))</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">19</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.saveAsObjectFile(<span class="string">&quot;hdfs://hadoop201:9000/obj_file&quot;</span>)</span><br></pre></td></tr></table></figure>

</li>
<li><p>读取 <code>objectFile</code></p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd1 = sc.objectFile(<span class="type">String</span>, <span class="type">Int</span>)</span><br><span class="line">rdd1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">MapPartitionsRDD</span>[<span class="number">25</span>] at objectFile at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.collect</span><br><span class="line">res8: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((a,<span class="number">1</span>), (b,<span class="number">2</span>), (c,<span class="number">3</span>))</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h2 id="4-5-从-HDFS-读写文件"><a href="#4-5-从-HDFS-读写文件" class="headerlink" title="4.5    从 HDFS 读写文件"></a>4.5    从 HDFS 读写文件</h2><p>Spark 的整个生态系统与 Hadoop 完全兼容的，所以对于 Hadoop 所支持的文件类型或者数据库类型，Spark 也同样支持。</p>
<p>另外，由于 Hadoop 的 API 有新旧两个版本，所以 Spark 为了能够兼容 Hadoop 所有的版本，也提供了两套创建操作接口。</p>
<p>对于外部存储创建操作而言，<code>HadoopRDD</code> 和 <code>newHadoopRDD</code> 是最为抽象的两个函数接口，主要包含以下四个参数：</p>
<ol>
<li> <strong>输入格式（InputFormat）</strong>：制定数据输入的类型，如 TextInputFormat 等，新旧两个版本所引用的版本分别是 <code>org.apache.hadoop.mapred.InputFormat</code> 和 <code>org.apache.hadoop.mapreduce.InputFormat(NewInputFormat)</code></li>
<li> <strong>键类型</strong>：指定 <code>[K,V]</code> 键值对中 K 的类型</li>
<li> <strong>值类型</strong>：指定 <code>[K,V]</code> 键值对中 V 的类型</li>
<li> <strong>分区值</strong>：指定由外部存储生成的 RDD 的 partition 数量的最小值，如果没有指定，系统会使用默认值 <code>defaultMinSplits</code></li>
</ol>
<p>注意：其它创建操作的 API 接口都是为了方便最终的 Spark 程序开发者而设置的，是这两个接口的高效实现版本。例如，对于 <code>textFile</code> 而言，只有 <code>path</code> 这个指定文件路径的参数，其它参数在系统内部指定了默认值。</p>
<ol>
<li> 在 Hadoop 中以压缩形式存储的数据，不需要指定解压方式就能够进行读取，因为 Hadoop 本身有一个解压器会根据压缩文件的后缀推断解压算法进行解压。</li>
<li> 如果用 Spark 从 Hadoop 中读取某种类型的数据不知道怎么读取的时候，上网查找一个使用 <code>map-reduce</code> 的时候是怎么读取这种这种数据的，然后再将对应的读取方式改写成上面的 hadoopRDD 和 newAPIHadoopRDD 两个类就行了。</li>
</ol>
<hr>
<h2 id="4-6-从-Mysql-数据读写文件"><a href="#4-6-从-Mysql-数据读写文件" class="headerlink" title="4.6    从 Mysql 数据读写文件"></a>4.6    从 Mysql 数据读写文件</h2><h3 id="1、引入-MySQL-依赖"><a href="#1、引入-MySQL-依赖" class="headerlink" title="1、引入 MySQL 依赖"></a>1、引入 MySQL 依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.27<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>





<h3 id="2、从-Mysql-读取数据"><a href="#2、从-Mysql-读取数据" class="headerlink" title="2、从 Mysql 读取数据"></a>2、从 Mysql 读取数据</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day04</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.<span class="type">DriverManager</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">JdbcRDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">JDBCDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Practice&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">//定义连接mysql的参数</span></span><br><span class="line">        <span class="keyword">val</span> driver = <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span></span><br><span class="line">        <span class="keyword">val</span> url = <span class="string">&quot;jdbc:mysql://hadoop201:3306/rdd&quot;</span></span><br><span class="line">        <span class="keyword">val</span> userName = <span class="string">&quot;root&quot;</span></span><br><span class="line">        <span class="keyword">val</span> passWd = <span class="string">&quot;aaa&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> rdd = <span class="keyword">new</span> <span class="type">JdbcRDD</span>(</span><br><span class="line">            sc,</span><br><span class="line">            () =&gt; &#123;</span><br><span class="line">                <span class="type">Class</span>.forName(driver)</span><br><span class="line">                <span class="type">DriverManager</span>.getConnection(url, userName, passWd)</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;select id, name from user where id &gt;= ? and id &lt;= ?&quot;</span>,</span><br><span class="line">            <span class="number">1</span>,</span><br><span class="line">            <span class="number">20</span>,</span><br><span class="line">            <span class="number">2</span>,</span><br><span class="line">            result =&gt; (result.getInt(<span class="number">1</span>), result.getString(<span class="number">2</span>))</span><br><span class="line">        )</span><br><span class="line">        rdd.collect.foreach(println)</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="3、向-Mysql-写入数据"><a href="#3、向-Mysql-写入数据" class="headerlink" title="3、向 Mysql 写入数据"></a>3、向 Mysql 写入数据</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day04</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">Connection</span>, <span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">JDBCDemo2</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Practice&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">//定义连接mysql的参数</span></span><br><span class="line">        <span class="keyword">val</span> driver = <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span></span><br><span class="line">        <span class="keyword">val</span> url = <span class="string">&quot;jdbc:mysql://hadoop201:3306/rdd&quot;</span></span><br><span class="line">        <span class="keyword">val</span> userName = <span class="string">&quot;root&quot;</span></span><br><span class="line">        <span class="keyword">val</span> passWd = <span class="string">&quot;aaa&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = sc.parallelize(<span class="type">Array</span>((<span class="number">110</span>, <span class="string">&quot;police&quot;</span>), (<span class="number">119</span>, <span class="string">&quot;fire&quot;</span>)))</span><br><span class="line">        <span class="comment">// 对每个分区执行 参数函数</span></span><br><span class="line">        rdd.foreachPartition(it =&gt; &#123;</span><br><span class="line">            <span class="type">Class</span>.forName(driver)</span><br><span class="line">            <span class="keyword">val</span> conn: <span class="type">Connection</span> = <span class="type">DriverManager</span>.getConnection(url, userName, passWd)</span><br><span class="line">            it.foreach(x =&gt; &#123;</span><br><span class="line">                <span class="keyword">val</span> statement: <span class="type">PreparedStatement</span> = conn.prepareStatement(<span class="string">&quot;insert into user values(?, ?)&quot;</span>)</span><br><span class="line">                statement.setInt(<span class="number">1</span>, x<span class="number">.1</span>)</span><br><span class="line">                statement.setString(<span class="number">2</span>, x<span class="number">.2</span>)</span><br><span class="line">                statement.executeUpdate()</span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h2 id="4-7-从-Hbase-读写文件"><a href="#4-7-从-Hbase-读写文件" class="headerlink" title="4.7    从 Hbase 读写文件"></a>4.7    从 Hbase 读写文件</h2><p>由于 <code>org.apache.hadoop.hbase.mapreduce.TableInputFormat</code> 类的实现，Spark 可以通过 Hadoop 输入格式访问 HBase。这个输入格式会返回键值对数据，其中键的类型为 <code>org. apache.hadoop.hbase.io.ImmutableBytesWritable</code>，而值的类型为 <code>org.apache.hadoop.hbase.client.Result</code>。</p>
<h3 id="1、导入依赖"><a href="#1、导入依赖" class="headerlink" title="1、导入依赖"></a>1、导入依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mortbay.jetty<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>servlet-api-2.5<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>javax.servlet<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>servlet-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mortbay.jetty<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>servlet-api-2.5<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>javax.servlet<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>servlet-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="2、从-HBase-读取数据"><a href="#2、从-HBase-读取数据" class="headerlink" title="2、从 HBase 读取数据"></a>2、从 HBase 读取数据</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day04</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.<span class="type">HBaseConfiguration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Result</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.<span class="type">TableInputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HBaseDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Practice&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> hbaseConf: <span class="type">Configuration</span> = <span class="type">HBaseConfiguration</span>.create()</span><br><span class="line">        hbaseConf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop201,hadoop202,hadoop203&quot;</span>)</span><br><span class="line">        hbaseConf.set(<span class="type">TableInputFormat</span>.<span class="type">INPUT_TABLE</span>, <span class="string">&quot;student&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">ImmutableBytesWritable</span>, <span class="type">Result</span>)] = sc.newAPIHadoopRDD(</span><br><span class="line">            hbaseConf,</span><br><span class="line">            classOf[<span class="type">TableInputFormat</span>],</span><br><span class="line">            classOf[<span class="type">ImmutableBytesWritable</span>],</span><br><span class="line">            classOf[<span class="type">Result</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[<span class="type">String</span>] = rdd.map &#123;</span><br><span class="line">            <span class="keyword">case</span> (_, result) =&gt; <span class="type">Bytes</span>.toString(result.getRow)</span><br><span class="line">        &#125;</span><br><span class="line">        rdd2.collect.foreach(println)</span><br><span class="line">        sc.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3、向-HBase-写入数据"><a href="#3、向-HBase-写入数据" class="headerlink" title="3、向 HBase 写入数据"></a>3、向 HBase 写入数据</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day04</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.<span class="type">HBaseConfiguration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Put</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.<span class="type">TableOutputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.<span class="type">Job</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HBaseDemo2</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Practice&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> hbaseConf = <span class="type">HBaseConfiguration</span>.create()</span><br><span class="line">        hbaseConf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop201,hadoop202,hadoop203&quot;</span>)</span><br><span class="line">        hbaseConf.set(<span class="type">TableOutputFormat</span>.<span class="type">OUTPUT_TABLE</span>, <span class="string">&quot;student&quot;</span>)</span><br><span class="line">        <span class="comment">// 通过job来设置输出的格式的类</span></span><br><span class="line">        <span class="keyword">val</span> job = <span class="type">Job</span>.getInstance(hbaseConf)</span><br><span class="line">        job.setOutputFormatClass(classOf[<span class="type">TableOutputFormat</span>[<span class="type">ImmutableBytesWritable</span>]])</span><br><span class="line">        job.setOutputKeyClass(classOf[<span class="type">ImmutableBytesWritable</span>])</span><br><span class="line">        job.setOutputValueClass(classOf[<span class="type">Put</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> initialRDD = sc.parallelize(<span class="type">List</span>((<span class="string">&quot;100&quot;</span>, <span class="string">&quot;apple&quot;</span>, <span class="string">&quot;11&quot;</span>), (<span class="string">&quot;200&quot;</span>, <span class="string">&quot;banana&quot;</span>, <span class="string">&quot;12&quot;</span>), (<span class="string">&quot;300&quot;</span>, <span class="string">&quot;pear&quot;</span>, <span class="string">&quot;13&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> hbaseRDD = initialRDD.map(x =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> put = <span class="keyword">new</span> <span class="type">Put</span>(<span class="type">Bytes</span>.toBytes(x<span class="number">.1</span>))</span><br><span class="line">            put.addColumn(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;name&quot;</span>), <span class="type">Bytes</span>.toBytes(x<span class="number">.2</span>))</span><br><span class="line">            put.addColumn(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;weight&quot;</span>), <span class="type">Bytes</span>.toBytes(x._3))</span><br><span class="line">            (<span class="keyword">new</span> <span class="type">ImmutableBytesWritable</span>(), put)</span><br><span class="line">        &#125;)</span><br><span class="line">        hbaseRDD.saveAsNewAPIHadoopDataset(job.getConfiguration)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<hr>
<h1 id="第-5-章-RDD-编程进阶"><a href="#第-5-章-RDD-编程进阶" class="headerlink" title="第 5 章 RDD 编程进阶"></a>第 5 章 RDD 编程进阶</h1><h2 id="5-1共享变量问题"><a href="#5-1共享变量问题" class="headerlink" title="5.1共享变量问题"></a>5.1共享变量问题</h2><p>看下面的代码:</p>
<p>package day04</p>
<p> import org.apache.spark.rdd.RDD<br> import org.apache.spark.{SparkConf, SparkContext}</p>
<p> object AccDemo1 {<br>   def main(args: Array[String]): Unit = {<br>     val conf = new SparkConf().setAppName(“Practice”).setMaster(“local[2]”)<br>     val sc = new SparkContext(conf)<br>     val p1 = Person(10)<br>     // 将来会把对象序列化之后传递到每个节点上<br>     val rdd1 = sc.parallelize(Array(p1))<br>     val rdd2: RDD[Person] = rdd1.map(p =&gt; {p.age = 100; p})</p>
<pre><code> rdd2.count()
 // 仍然是 10
 println(p1.age)
</code></pre>
<p>   }<br> }</p>
<p> case class Person(var age:Int)</p>
<p>正常情况下, 传递给 Spark 算子(比如: map, reduce 等)的函数都是在远程的集群节点上执行, 函数中用到的所有变量都是独立的拷贝.</p>
<p>这些变量被拷贝到集群上的每个节点上, 都这些变量的更改不会传递回驱动程序.</p>
<p>支持跨 task 之间共享变量通常是低效的, 但是 Spark 对共享变量也提供了两种支持:</p>
<p>\1.    累加器</p>
<p>\2.    广播变量</p>
<h3 id="5-2累加器-Accumulator"><a href="#5-2累加器-Accumulator" class="headerlink" title="5.2累加器(Accumulator)"></a>5.2累加器(Accumulator)</h3><p>累加器用来对信息进行聚合，通常在向 Spark 传递函数时，比如使用 map() 函数或者用 filter() 传条件时，可以使用驱动器程序中定义的变量，但是集群中运行的每个任务都会得到这些变量的一份新的副本，所以更新这些副本的值不会影响驱动器中的对应变量。</p>
<p>如果我们想实现所有分片处理时更新共享变量的功能，那么累加器可以实现我们想要的效果。</p>
<p>累加器是一种变量, 仅仅支持“add”, 支持并发. 累加器用于去实现计数器或者求和. Spark 内部已经支持数字类型的累加器, 开发者可以添加其他类型的支持.</p>
<h4 id="内置累加器"><a href="#内置累加器" class="headerlink" title="内置累加器"></a>内置累加器</h4><p>需求:计算文件中空行的数量</p>
<p>package day04</p>
<p> import org.apache.spark.rdd.RDD<br> import org.apache.spark.util.LongAccumulator<br> import org.apache.spark.{SparkConf, SparkContext}</p>
<p> object AccDemo1 {<br>   def main(args: Array[String]): Unit = {<br>     val conf = new SparkConf().setAppName(“Practice”).setMaster(“local[2]”)<br>     val sc = new SparkContext(conf)<br>     val rdd: RDD[String] = sc.textFile(“file://“ + ClassLoader.getSystemResource(“words.txt”).getPath)<br>     // 得到一个 Long 类型的累加器. 将从 0 开始累加<br>     val emptyLineCount: LongAccumulator = sc.longAccumulator<br>     rdd.foreach(s =&gt; if (s.trim.length == 0) emptyLineCount.add(1))<br>     println(emptyLineCount.value)<br>   }<br> }</p>
<p>说明:</p>
<p>\1.    在驱动程序中通过sc.longAccumulator得到Long类型的累加器, 还有Double类型的</p>
<p>\2.    可以通过value来访问累加器的值.(与sum等价). avg得到平均值</p>
<p>\3.    只能通过add来添加值.</p>
<p>\4.    累加器的更新操作最好放在action中, Spark 可以保证每个 task 只执行一次. 如果放在 transformations 操作中则不能保证只更新一次.有可能会被重复执行.</p>
<h4 id="自定义累加器"><a href="#自定义累加器" class="headerlink" title="自定义累加器"></a>自定义累加器</h4><p>通过继承类AccumulatorV2来自定义累加器.</p>
<p>下面这个累加器可以用于在程序运行过程中收集一些文本类信息，最终以List[String]的形式返回。</p>
<p>package day04</p>
<p> import java.util<br> import java.util.{ArrayList, Collections}</p>
<p> import org.apache.spark.util.AccumulatorV2</p>
<p> object MyAccDemo {<br>   def main(args: Array[String]): Unit = {</p>
<p>   }<br> }</p>
<p> class MyAcc extends AccumulatorV2[String, java.util.List[String]] {<br>   private val _list: java.util.List[String] = Collections.synchronizedList(new ArrayList<a href>String</a>)<br>   override def isZero: Boolean = _list.isEmpty</p>
<p>   override def copy(): AccumulatorV2[String, util.List[String]] = {<br>     val newAcc = new MyAcc<br>     _list.synchronized {<br>       newAcc._list.addAll(_list)<br>     }<br>     newAcc<br>   }</p>
<p>   override def reset(): Unit = _list.clear()</p>
<p>   override def add(v: String): Unit = _list.add(v)</p>
<p>   override def merge(other: AccumulatorV2[String, util.List[String]]): Unit =other match {<br>     case o: MyAcc =&gt; _list.addAll(o.value)<br>     case _ =&gt; throw new UnsupportedOperationException(<br>       s”Cannot merge ${this.getClass.getName} with ${other.getClass.getName}”)<br>   }</p>
<p>   override def value: util.List[String] = java.util.Collections.unmodifiableList(new util.ArrayList<a href="_list">String</a>)<br> }</p>
<p>测试:</p>
<p>object MyAccDemo {<br>   def main(args: Array[String]): Unit = {<br>     val pattern = “””^\d+$”””<br>     val conf = new SparkConf().setAppName(“Practice”).setMaster(“local[2]”)<br>     val sc = new SparkContext(conf)<br>     // 统计出来非纯数字, 并计算纯数字元素的和<br>     val rdd1 = sc.parallelize(Array(“abc”, “a30b”, “aaabb2”, “60”, “20”))</p>
<pre><code> val acc = new MyAcc
 sc.register(acc)
 val rdd2: RDD[Int] = rdd1.filter(x =&gt; &#123;
   val flag: Boolean = x.matches(pattern)
   if (!flag) acc.add(x)
   flag
 &#125;).map(_.toInt)
 println(rdd2.reduce(_ + _))
 println(acc.value)
</code></pre>
<p>   }<br> }</p>
<p>注意:</p>
<p>在使用自定义累加器的不要忘记注册sc.register(acc)</p>
<p>​                               </p>
<h3 id="5-3广播变量"><a href="#5-3广播变量" class="headerlink" title="5.3广播变量"></a>5.3广播变量</h3><p>广播变量在每个节点上保存一个只读的变量的缓存, 而不用给每个 task 来传送一个 copy.</p>
<p>例如, 给每个节点一个比较大的输入数据集是一个比较高效的方法. Spark 也会用该对象的广播逻辑去分发广播变量来降低通讯的成本.</p>
<p>广播变量通过调用SparkContext.broadcast(v)来创建. 广播变量是对v的包装, 通过调用广播变量的 value方法可以访问.</p>
<p>scala&gt; val broadcastVar = sc.broadcast(Array(1, 2, 3))<br> broadcastVar: org.apache.spark.broadcast.Broadcast[Array[Int]] = Broadcast(0)</p>
<p> scala&gt; broadcastVar.value<br> res0: Array[Int] = Array(1, 2, 3)</p>
<p>说明:</p>
<p>\1.     通过对一个类型T的对象调用SparkContext.broadcast创建出一个Broadcast[T]对象。任何可序列化的类型都可以这么实现。</p>
<p>\2.     通过value属性访问该对象的值(在Java中为value()方法)。</p>
<p>\3.     变量只会被发到各个节点一次，应作为只读值处理(修改这个值不会影响到别的节点)。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/31/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/31/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-31 12:06:46" itemprop="dateCreated datePublished" datetime="2022-05-31T12:06:46+08:00">2022-05-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-30 22:10:37" itemprop="dateModified" datetime="2022-05-30T22:10:37+08:00">2022-05-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/09/MQ%E6%A6%82%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/09/MQ%E6%A6%82%E8%BF%B0/" class="post-title-link" itemprop="url">MQ概述</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-09 18:20:33" itemprop="dateCreated datePublished" datetime="2022-05-09T18:20:33+08:00">2022-05-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-11 08:22:27" itemprop="dateModified" datetime="2022-05-11T08:22:27+08:00">2022-05-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/MQ/" itemprop="url" rel="index"><span itemprop="name">MQ</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="MQ概述"><a href="#MQ概述" class="headerlink" title="MQ概述"></a>MQ概述</h1><h2 id="MQ简介"><a href="#MQ简介" class="headerlink" title="MQ简介"></a>MQ简介</h2><blockquote>
<p>  MQ；Message Queue；消息队列</p>
</blockquote>
<p>MQ 是一种提供<strong>消息队列服务</strong>的中间件，简称为消息中间件。是一套提供了<strong>消息生产、存储、消费全过程</strong> API 的软件系统。</p>
<p>消息即数据。一般单条消息的体量不会很大，但消息总是会持续产生。</p>
<hr>
<h2 id="MQ用途"><a href="#MQ用途" class="headerlink" title="MQ用途"></a>MQ用途</h2><p>MQ 的使用场景有很多，但大多数场景都是基于以下三个方向衍生出来的。分别是：</p>
<h3 id="限流削峰"><a href="#限流削峰" class="headerlink" title="限流削峰"></a>限流削峰</h3><p>MQ 可以将系统的<strong>超量</strong>请求暂存起来，以便系统后期空闲时可以慢慢处理，从而避免了请求的丢失或系统被压垮。</p>
<p><img src="/2022/05/09/MQ%E6%A6%82%E8%BF%B0/MQ%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9A%E9%99%90%E6%B5%81%E5%89%8A%E5%B3%B0.svg" alt="MQ使用场景：限流削峰"></p>
<p>如图所示，系统 A 可处理的请求峰值是 2000/s，超量的请求就会被系统丢掉或者压垮系统。这显然会造成业务上的重大损失。</p>
<p>引入 MQ 后，可将请求先保存在 MQ 中，由 MQ 向系统 A 发送 2000/s 的请求。既能保证系统的正常运行，又不会造成请求的丢失。</p>
<h3 id="异步解耦"><a href="#异步解耦" class="headerlink" title="异步解耦"></a>异步解耦</h3><p>上游系统对下游系统的调用若为同步调用，则会大大降低系统的吞吐量和并发度，且系统耦合度太高。</p>
<blockquote>
<p>  在同步调用状态下，上游系统调用下游系统处理请求，上游系统向下游系统发出请求后，在下游系统没有处理完毕请求的情况下，上游系统会一直处于阻塞状态。</p>
</blockquote>
<p>而异步调用则可以解决这些问题。所以两层之间若要实现由同步到异步的转化，一般的做法就是，在这两层之间添加一个 MQ 层。</p>
<p><img src="/2022/05/09/MQ%E6%A6%82%E8%BF%B0/MQ%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9A%E5%BC%82%E6%AD%A5%E8%A7%A3%E8%80%A6.svg" alt="MQ使用场景：异步解耦"></p>
<h3 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h3><p>现代系统会产生海量的数据流，如：业务日志数据、监控数据、用户行为数据等。针对这些数据流进行实时或批量采集汇总，然后对这些数据进行大数据分析，这是互联网平台的必备技术。通过 MQ 完成此类数据收集是最好的选择。大数据收集场景最常用的框架就是 Kafka。</p>
<hr>
<h2 id="常见的MQ产品"><a href="#常见的MQ产品" class="headerlink" title="常见的MQ产品"></a>常见的MQ产品</h2><h3 id="ActiveMQ"><a href="#ActiveMQ" class="headerlink" title="ActiveMQ"></a>ActiveMQ</h3><p>ActiveMQ 是使用 Java 语言开发的一款 MQ 产品。早期很多公司与项目都在使用，但是现在社区活跃度已经很低，现在的项目中已经很少使用了。优点是使用 Java 开发，对于 Java 开发人员来说源码更容易看懂。</p>
<h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><p>RabbitMQ 是使用 ErLang 语言开发的一款 MQ 产品。其吞吐量较 Kafka 和 RocketMQ 要低。且由于 ErLang 语言的使用人数较少，所以公司内部对其实现定制化开发的难度较大。</p>
<h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p>Kafka 是使用 Scala/Java 语言开发的一款 MQ 产品。其最大的特点就是高吞吐率，常用于大数据领域的实时计算、日志采集等场景。</p>
<p>但是 Kafka 没有遵循任何常见的 MQ 协议，而是使用自研协议。</p>
<p>对于 Spring Cloud Netflix 来说，其仅支持 RabbitMQ 和 Kafka。</p>
<h3 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h3><p>RocketMQ 是使用 Java 语言开发的一款 MQ 产品。经过数年阿里“双十一”的考验，性能与稳定性非常高。</p>
<p>其没有遵循任何常见的 MQ 协议，而是使用自研协议。</p>
<p>对于 Spring Cloud Alibaba，其支持 RabbitMQ、Kafka 和 RocketMQ，但提倡使用 RocketMQ。</p>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><table>
<thead>
<tr>
<th>关键词</th>
<th>ActiveMQ</th>
<th>RabbitMQ</th>
<th>Kafka</th>
<th>RocketMQ</th>
</tr>
</thead>
<tbody><tr>
<td>开发语言</td>
<td>Java</td>
<td>ErLang</td>
<td>Java/Scala</td>
<td>Java</td>
</tr>
<tr>
<td>单机吞吐量</td>
<td>万级</td>
<td>万级</td>
<td>十万级</td>
<td>十万级</td>
</tr>
<tr>
<td>Topic</td>
<td>-</td>
<td>-</td>
<td>百级Topic时会影响系统吞吐量</td>
<td>千级Topic时会影响系统吞吐量</td>
</tr>
<tr>
<td>社区活跃度</td>
<td>低</td>
<td>高</td>
<td>高</td>
<td>高</td>
</tr>
</tbody></table>
<ul>
<li>  ActiveMQ 和 RabbitMQ 中没有 Topic 这一概念。</li>
</ul>
<h2 id="MQ常见协议"><a href="#MQ常见协议" class="headerlink" title="MQ常见协议"></a>MQ常见协议</h2><p>一般情况下，MQ 的实现是要遵循一些常规性协议的。</p>
<blockquote>
<p>  <strong>Tip：</strong></p>
<p>  虽然官方规定了 MQ 产品需要遵循的一些常见协议，但无论是 RocketMQ 还是 Kafka，都没有遵循官方规定的协议，而是使用了自研的协议。</p>
</blockquote>
<p>常见的协议如下：</p>
<h3 id="JMS"><a href="#JMS" class="headerlink" title="JMS"></a>JMS</h3><p>JMS，Java Message Service（Java 消息服务）。是 Java 平台上有关 MOM（Message Oriented Middleware，面向消息的中间件）的技术规范。</p>
<p>它便于消息系统中的 Java 应用程序进行消息交换，并且通过提供标准的产生、发送、接收消息的接口，简化企业级应用的开发。</p>
<p>ActiveMQ 是该协议的典型实现。</p>
<h3 id="STOMP"><a href="#STOMP" class="headerlink" title="STOMP"></a>STOMP</h3><p>STOMP，Streaming Text Oriented Message Protocol（面向流文本的消息协议）。</p>
<p>STOMP 是一种 MOM 设计的简单文本协议。提供一个可互操作的连接格式，允许客户端与任意 STOMP 消息代理（Broker）进行交互。</p>
<p>ActiveMQ 是该协议的典型实现，RabbitMQ 通过插件可以支持该协议。</p>
<h3 id="AMQP"><a href="#AMQP" class="headerlink" title="AMQP"></a>AMQP</h3><p>AMQP，Advanced Message Queuing Protocol（高级消息队列协议）。</p>
<p>AMQP 是一个提供统一消息服务的应用层标准，是应用层协议的一个开发标准，是一种 MOM 设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品、不同开发语言等条件的限制。</p>
<p>RabbitMQ 是该协议的典型实现。</p>
<h3 id="MQTT"><a href="#MQTT" class="headerlink" title="MQTT"></a>MQTT</h3><p>MQTT，Message Queuing Telemetry Transport（消息队列遥测传输）。</p>
<p>MQTT 是 IBM 开发的一个即时通讯协议，是一种二进制协议，主要用于服务器和低功耗 IoT（物联网）设备间的通信。该协议支持所有平台，几乎可以把所有联网的物品和外部连接起来，被用来当做传感器和制动器的通信协议。</p>
<p>RabbitMQ 通过插件可以支持该协议。</p>
<hr>
<h1 id="RocketMQ-1"><a href="#RocketMQ-1" class="headerlink" title="RocketMQ"></a>RocketMQ</h1><ul>
<li>  <a href>RocketMQ概述</a></li>
<li>  <a href>RocketMQ理论基础</a></li>
<li></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/09/RocketMQ/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/09/RocketMQ/" class="post-title-link" itemprop="url">RocketMQ</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-09 14:19:15" itemprop="dateCreated datePublished" datetime="2022-05-09T14:19:15+08:00">2022-05-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-11 20:32:24" itemprop="dateModified" datetime="2022-05-11T20:32:24+08:00">2022-05-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/MQ/" itemprop="url" rel="index"><span itemprop="name">MQ</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/MQ/RocketMQ/" itemprop="url" rel="index"><span itemprop="name">RocketMQ</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="RocketMQ概述"><a href="#RocketMQ概述" class="headerlink" title="RocketMQ概述"></a>RocketMQ概述</h1><h2 id="RocketMQ简介"><a href="#RocketMQ简介" class="headerlink" title="RocketMQ简介"></a>RocketMQ简介</h2><p><img src="/2022/05/09/RocketMQ/image-20220511082821184.png" alt="image-20220511082821184"></p>
<ul>
<li>  官网地址：<a target="_blank" rel="noopener" href="https://rocketmq.apache.org/">https://rocketmq.apache.org/</a></li>
<li>  RocketMQ 是一个统一消息引擎、轻量级数据处理平台。</li>
<li>  RocketMQ 是一款阿里巴巴开源的消息中间件。2016年11月28日，阿里巴巴向 Apache 基金会捐赠了 RocketMQ，成为 Apache 孵化项目。2017年9月25日，Apache 宣布 RocketMQ 孵化成为 Apache 顶级项目（TLP），成为国内首个互联网中间件在 Apache 上的顶级项目。</li>
</ul>
<h2 id="RocketMQ发展历程"><a href="#RocketMQ发展历程" class="headerlink" title="RocketMQ发展历程"></a>RocketMQ发展历程</h2><img src="/2022/05/09/RocketMQ/image-20220509183545154.png" alt="image-20220509183545154">

<ul>
<li>  2007年，阿里开启“五彩石项目”，Notify 作为项目中的<strong>交易核心消息流转系统</strong>应运而生。Notify 系统是 RocketMQ 的雏形。</li>
<li>  2010年，B2B 大规模使用 ActiveMQ 作为阿里的消息内核，阿里急需一个具有<strong>海量堆积能力</strong>的消息系统。</li>
<li>  2011年初，Kafka 开源。淘宝中间件团队在对 Kafka 进行了深入研究后，开发出了一款新的 MQ——MetaQ。</li>
<li>  2012年，MetaQ 发展到了 v3.0 版本，并在它的基础上进行了进一步的抽象，形成了 RocketMQ，然后对其进行了开源。</li>
<li>  2015年，阿里在 RocketMQ 的基础上，又推出了一款专门针对阿里云上用户的消息系统 Aliware MQ。</li>
<li>  2016年双十一，RocketMQ 承载了<strong>万亿级</strong>消息的流转，跨越了一个新的里程碑。11月28日，阿里巴巴向 Apache 基金会捐赠了 RocketMQ，成为 Apache 孵化项目。</li>
<li>  2017年9月25日，Apache 宣布 RocketMQ 孵化称为 Apache 顶级项目（TLP），成为国内首个互联网中间件在 Apache 上的顶级项目。</li>
</ul>
<hr>
<h1 id="RocketMQ理论基础"><a href="#RocketMQ理论基础" class="headerlink" title="RocketMQ理论基础"></a>RocketMQ理论基础</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="1、消息（Message）"><a href="#1、消息（Message）" class="headerlink" title="1、消息（Message）"></a>1、消息（Message）</h3><p>消息（Message）是指：消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。</p>
<h3 id="2、主题（Topic）"><a href="#2、主题（Topic）" class="headerlink" title="2、主题（Topic）"></a>2、主题（Topic）</h3><p>主题（Topic）表示一类消息的集合。每个主题包含若干条消息，每条消息只能属于一个主题。主题是 RocketMQ 中进行消息订阅的基本单位。</p>
<ul>
<li>  topic：message =&gt; 1：n</li>
<li>  message：topic =&gt; 1：1</li>
</ul>
<p>一个生产者可以同时向 MQ 发送多种 Topic 的消息；而一个消费者只对某种特定的 Topic 感兴趣，即只可以订阅和消费一种 Topic 的消息。</p>
<ul>
<li>  producer：topic =&gt; 1：n</li>
<li>  consumer：topic =&gt; 1：1</li>
</ul>
<h3 id="3、标签（Tag）"><a href="#3、标签（Tag）" class="headerlink" title="3、标签（Tag）"></a>3、标签（Tag）</h3><p>为消息设置的标签，用于同一主题下区分不同类型的消息。</p>
<p>来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同的标签。标签能够有效地保持代码的清晰度和连贯性，并优化 RocketMQ 提供的查询系统。消费者可以根据 Tag 实现对不同子主题的不同消费逻辑，实现更好的扩展性。</p>
<p><strong>例子：</strong></p>
<p>Topic 是消息的一级分类，Tag 是消息的二级分类。</p>
<p>生产者：</p>
<ul>
<li>Topic=货物<ul>
<li>  Tag=上海</li>
<li>  Tag=江苏</li>
<li>  Tag=南京</li>
</ul>
</li>
</ul>
<p>消费者：</p>
<ul>
<li>  Topic=货物，Tag=上海</li>
<li>  Topic=货物，Tag=上海|浙江</li>
<li>  Topic=货物，Tag=*</li>
</ul>
<h3 id="4、队列（Queue）"><a href="#4、队列（Queue）" class="headerlink" title="4、队列（Queue）"></a>4、队列（Queue）</h3><p>MQ 中存储消息的物理实体。一个 Topic 中的消息可以存放在多个 Queue 中，每个 Queue 中存放的就是该 Topic 的消息。</p>
<blockquote>
<p>  <strong>Tip</strong></p>
<p>  RocketMQ 中的 Queue 又被称为 Partition（分区）。</p>
<p>  分区（Partition）的概念源自于 Kafka。Kafka 中没有 Queue（队列）的概念，只有 Partition。</p>
</blockquote>
<h4 id="为什么划分Partition？"><a href="#为什么划分Partition？" class="headerlink" title="为什么划分Partition？"></a>为什么划分Partition？</h4><p>一个 Topic 的 Queue 中的消息同一时间只允许一个消费者组中的一个消费者消费，不允许一个消费者组中的多个消费者同时消费。但是不同消费者组中的消费者可以同时消费一条消息。</p>
<table>
<thead>
<tr>
<th>场景</th>
<th>是否可行</th>
</tr>
</thead>
<tbody><tr>
<td>一条消息同时被一个消费者组中的一个消费者消费。</td>
<td>✔</td>
</tr>
<tr>
<td>一条消息同时被一个消费者组中的多个消费者消费。</td>
<td>✖</td>
</tr>
<tr>
<td>一条消息同时被不同消费者组中的多个消费者消费。</td>
<td>✔</td>
</tr>
<tr>
<td>一个消费者组中的一个消费者同时消费多条消息。</td>
<td>✔</td>
</tr>
</tbody></table>
<p><img src="/2022/05/09/RocketMQ/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%88%86%E5%8C%BA.svg" alt="为什么分区"></p>
<p>举个例子就是：</p>
<ul>
<li>  如果不划分分区（即可视为只有一个分区），且生产者生产消息的速度大于消费者，那么就会有大量的待处理消息滞留在唯一的一个分区中。而且一个分区同时只能被一个消费者消费，这就会造成大量的请求消息得不到处理。</li>
<li>  为了解决这个问题，RocketMQ/Kafka 引入了“分区”的概念。如上图所示，将一个 Topic 中的消息保存在 3 个分区中，每个消费者消费一个分区，同时最多可支持 3 个消费者消费，大大加快了消息的消费速度，解决了消息堆积的问题。</li>
</ul>
<p>从 MQ 的角度来看，一个消费者组只代表一个消费者。建立消费者组的目的是提高消费速度。</p>
<h4 id="分片（Sharing）"><a href="#分片（Sharing）" class="headerlink" title="分片（Sharing）"></a>分片（Sharing）</h4><p>在 RocketMQ 中还有一个概念就是<strong>分片（Sharding）</strong>。分片不同于分区，在 RocketMQ 中，分片指的是存放相应 Topic 的 Broker。每个分片中会创建相应数量的分区（即 Queue），每个 Queue 的大小都是相同的。</p>
<p><img src="/2022/05/09/RocketMQ/image-20220511094229752.png" alt="image-20220511094229752"></p>
<p>Broker 可以简单理解为“物理主机”。</p>
<p>如上图所示，就可以简单理解为：TopicA 中的消息保存在三台服务器上，每台服务器上的所有消息被称为一个分片，每个分片又划分了多个分区（Queue/Partition）来保存消息。</p>
<h3 id="5、消息标识（MessageId-Key）"><a href="#5、消息标识（MessageId-Key）" class="headerlink" title="5、消息标识（MessageId/Key）"></a>5、消息标识（MessageId/Key）</h3><p>RocketMQ 中每个消息拥有“唯一”的 MessageId，且可以携带具有业务标识的 Key，以方便对消息的查询。不过需要注意的是，MessageId 有两个：在生产者 send() 消息时会自动生成一个 MessageId（msgId）；当消息到达 Broker 后，Broker 也会自动生成一个 MessageId（offsetMsgId）。msgId、offsetMsgId 与 Key 都被称为消息标识。</p>
<blockquote>
<p>  “唯一”其实会发生重复。</p>
</blockquote>
<ul>
<li><p>msgId：由 producer 端生成，其生成规则为：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">producerIp + 进程pid + MessageClientIDSetter类的ClassLoader的hashCode + 当前时间 + AutomicInteger自增计数器</span><br></pre></td></tr></table></figure></li>
<li><p>offsetMsgId：由 broker 端生成，其生成规则为：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brokerIp + 物理分区的offset（Queue中的偏移量）</span><br></pre></td></tr></table></figure></li>
<li><p>  key：由用户指定的业务相关的唯一标识。</p>
</li>
</ul>
<hr>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p><img src="/2022/05/09/RocketMQ/image-20220511101230750.png" alt="image-20220511101230750"></p>
<p>RocketMQ 的架构分为四部分构成。</p>
<h3 id="1、Producer"><a href="#1、Producer" class="headerlink" title="1、Producer"></a>1、Producer</h3><p>消息生产者，负责生产消息。</p>
<p>Producer 通过 MQ 的负载均衡模块选择相应的 Broker 集群队列进行消息投递。投递的过程支持快速失败并且低延迟。</p>
<blockquote>
<p>  <em>例如：</em></p>
<ul>
<li>  <em>业务系统产生的日志写入到 MQ 的过程，就是消息生产的过程。</em></li>
<li>  <em>电商平台中用户提交的秒杀请求写入到 MQ 的过程，也是消息生产的过程。</em></li>
</ul>
</blockquote>
<p>RocketMQ 中的消息生产者都是以生产者组（Producer Group）的形式出现的。生产者组是同一类生产者的集合，这类 Producer 发送相同的 Topic 类型的消息。一个生产者组可以同时发送多个主题的消息。</p>
<h3 id="2、Consumer"><a href="#2、Consumer" class="headerlink" title="2、Consumer"></a>2、Consumer</h3><p>消息消费者，负责消费消息。</p>
<p>一个消息消费者会从 Broker 服务器中获取到消息，并对消息进行相关业务处理。</p>
<blockquote>
<p>  <em>例如：</em></p>
<ul>
<li>  Qos 系统从 MQ 中读取日志，并对日志进行解析处理的过程就是消息消费的过程。</li>
<li>  电商平台的业务系统从 MQ 中读取到秒杀请求，并对请求进行处理的过程也是消息消费的过程。</li>
</ul>
</blockquote>
<p>RocketMQ 中的消息消费者都是以消费者组（Consumer Group）的形式出现的。消费者组是同一类消费者的集合，这类 Consumer 消费的是同一个 Topic 类型的消息。消费者组使得在消息消费方面，实现<strong>负载均衡</strong>和<strong>容错</strong>的目标变得非常容易。</p>
<blockquote>
<ul>
<li>  <strong>负载均衡</strong>：将一个 Topic 中的不同 Queue 平均分配给同一个 Consumer Group 的不同 Consumer。注意：并不是将消息负载均衡，而是将 Queue 负责均衡。</li>
<li>  <strong>容错</strong>：一个 Consumer 挂了，该 Consumer Group 中的其它 Consumer 可以接着消费原 Consumer 消费的 Queue。</li>
</ul>
</blockquote>
<p><img src="/2022/05/09/RocketMQ/image-20220511111742454.png" alt="image-20220511111742454"></p>
<p>消费者组中的 Consumer 的数量应该小于等于订阅 Topic 的 Queue 的数量。如果超出 Queue 的数量，则多出的 Consumer 将不能消费消息。</p>
<p><img src="/2022/05/09/RocketMQ/image-20220511112033543.png" alt="image-20220511112033543"></p>
<p>不过，一个 Topic 类型的消息可以被多个消费者组同时消费。</p>
<blockquote>
<p>  Tip</p>
<ul>
<li>  一个消费者组同时只能消费一个 Topic 中的消息，不能同时消费多个 Topic 中的消息。</li>
<li>  一个消费者组中的消费者必须订阅完全相同的 Topic。</li>
</ul>
</blockquote>
<h3 id="3、Name-Server"><a href="#3、Name-Server" class="headerlink" title="3、Name Server"></a>3、Name Server</h3><h4 id="功能介绍"><a href="#功能介绍" class="headerlink" title="功能介绍"></a>功能介绍</h4><p>NameServer 是一个 Broker 与 Topic 路由的注册中心，支持 Broker 的动态注册与发现。</p>
<p>RocketMQ 的思想来源于 Kafka，而 Kafka 是依赖了 ZooKeeper 的。所以，在 RocketMQ 的早期版本（即 MetaQ v1.0 和 v2.0 版本）中，也是依赖于 ZooKeeper 的。从 MetaQ v3.0（即 RocketMQ）开始去掉了 ZooKeeper 依赖，而是使用了自己的 NameServer。</p>
<p>NameServer 主要包括两个功能：</p>
<ul>
<li><strong>Broker 管理</strong>：<ul>
<li>  接收 Broker 集群的注册信息并且保存下来作为路由信息的基本数据；</li>
<li>  提供心跳检测机制，检查 Broker 是否还存活。</li>
</ul>
</li>
<li>  <strong>路由信息管理</strong>：每个 NameServer 中都保存着 Broker 集群的整个路由信息和用于客户端查询的队列（Queue）信息。Producer 和 Consumer 通过 NameServer 可以获取整个 Broker 集群的路由信息，从而进行消息的投递和消费。</li>
</ul>
<h4 id="路由注册"><a href="#路由注册" class="headerlink" title="路由注册"></a>路由注册</h4><p>NameServer 通常也是以集群的方式部署。不过，NameServer 是<code>无状态</code>的，即 NameServer 集群中的各个节点间是无差异的，各节点间相互不进行信息通讯。</p>
<p><strong>那各节点是如何进行数据同步的呢？</strong></p>
<p>在 Broker 节点启动时，轮询 NameServer 列表，与每个 NameServer 建立长连接，发起注册请求。在 NameServer 内部维护着一个 Broker 列表，用来动态存储 Broker 的信息。</p>
<blockquote>
<p>  <strong>Tip</strong></p>
<p>  这是 NameServer 与 ZooKeeper、Eureka、Nacos 等其它注册中心不同的地方。</p>
</blockquote>
<p>这种 NameServer 无状态的方式，有什么优缺点：</p>
<ul>
<li>  优点：NameServer 集群搭建简单、扩容简单。</li>
<li>  缺点：对于 Broker，必须明确指出所有 NameServer 的地址，否则未指出的将不会去注册。也正因为如此，NameServer 并不能随便扩容。因为每次新增 NameServer 节点必须将该节点的地址在所有的 Broker 上配置一遍。</li>
</ul>
<p><strong>为什么建立长连接？</strong></p>
<p>Broker 节点为了证明自己是活着的，为了维护与 NameServer 之间的长连接，会将最新的信息以<code>心跳包</code>的方式上报给 Server，每 30 秒发送一次心跳。</p>
<p>心跳包中包含 BrokerId、Broker地址（IP+Port）、Broker 名称、Broker 所属集群名称等等。NameServer 在收到心跳包后，会更新心跳时间戳、记录这个 Broker 的最新存活时间。</p>
<h4 id="路由剔除"><a href="#路由剔除" class="headerlink" title="路由剔除"></a>路由剔除</h4><p>由于 Broker 关机、宕机或网络抖动等原因，NameServer 长时间没有收到某个 Broker 的心跳后，就可能会将其从 Broker 列表中剔除。</p>
<p>NameServer 中有一个定时任务，每隔 10 秒就会扫描一次 Broker 列表，查看每个 Broker 的最新心跳时间戳距离当前时间是否超过 120 秒，如果超过，则会判定 Broker 失效，并将其从 Broker 列表中剔除。</p>
<blockquote>
<p>  扩展</p>
<p>  问：对于 RocketMQ 日常运维工作，如 Broker 升级，需要停掉 Broker 的工作，OP（运维工程师）需要怎么做？</p>
<p>  答：OP 需要将 Broker 的读写权限禁掉，一旦 Client（Consumer 或 Producer）向 Broker 发送请求，都会收到 NO_PERMISSION 响应，然后 Client 会进行其它 Broker 的重试。当 OP 观察到这个 Broker 没有流量后，再关闭它，就可以实现 Broker 从 NameServer 中移除。</p>
</blockquote>
<h4 id="路由发现"><a href="#路由发现" class="headerlink" title="路由发现"></a>路由发现</h4><p>RocketMQ 的路由发现采用的是 Pull 模型。</p>
<p>当 Topic 路由信息发生变化时，NameServer 不会主动推送给客户端，而是客户端定时拉取 Topic 最新的路由，默认客户端每 30 秒会拉取一次最新的路由。</p>
<blockquote>
<p>  扩展</p>
<ul>
<li>Push 模型：推送模型。其实时性较好，是一个“发布-订阅”模型，需要维护一个长连接，而长连接的维护是需要资源成本的。该模型适用于以下场景：<ul>
<li>  实时性要求较高。</li>
<li>  Client 数量不多，Server 数据变化较频繁。</li>
</ul>
</li>
<li>  Pull 模型：拉取模型。存在的问题是——实时性较差。</li>
<li>  Long Polling 模型：长轮询模型。是对 Push 和 Pull 模型的整合，充分利用了这两种模型的优势，屏蔽了它们的劣势。</li>
</ul>
</blockquote>
<h4 id="客户端NameServer选择策略"><a href="#客户端NameServer选择策略" class="headerlink" title="客户端NameServer选择策略"></a>客户端NameServer选择策略</h4><p>这里的客户端指定的是 Producer 和 Consumer。</p>
<p>客户端在配置时必须要写上 NameServer 集群的地址，那么客户端到底连接的是哪个 NameServer 节点呢？客户端首先会产生一个随机数，然后再与 NameServer 的节点数量取模，此时得到的就是要连接的节点索引，然后就会进行连接。如果连接失败，则会采用 round-robin 策略，逐个尝试去连接其它节点。</p>
<p>总结：首先采取<strong>随机策略</strong>进行选择，失败后选择<strong>轮询策略</strong>。</p>
<blockquote>
<p>  扩展：ZooKeeper Client 是如何选择 ZooKeeper Server 的？</p>
<ul>
<li>  简单来说：就是经过两次 Shuffle，然后选择第一台 ZooKeeper Server。</li>
<li>  展开讲就是：将配置文件中的 ZooKeeper Server 地址进行第一次 shuffle，然后随机选择一个。这次选择出的一般都是一个 hostname。然后获取到该 hostname 对应的所有 ip，再对这些 ip 进行二次 shuffle，从 shuffle 过的结果中选择第一个 Server 的地址进行连接。</li>
</ul>
</blockquote>
<h3 id="4、Broker"><a href="#4、Broker" class="headerlink" title="4、Broker"></a>4、Broker</h3><p>Broker 充当着消息中转的角色，负责存储消息、转发消息。</p>
<p>Broker 在 RocketMQ 系统中负责接收并存储从生产者发送来的消息，同时为消费者的拉取请求做准备。Broker 同时也存储着消息相关的元数据，包括消费者组消费进度偏移 offset、主题 Topic、队列 Queue等。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/04/%E4%BC%9A%E8%AF%9D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/04/%E4%BC%9A%E8%AF%9D/" class="post-title-link" itemprop="url">会话</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-04 23:21:06" itemprop="dateCreated datePublished" datetime="2022-05-04T23:21:06+08:00">2022-05-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-05 11:17:51" itemprop="dateModified" datetime="2022-05-05T11:17:51+08:00">2022-05-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/JavaWeb/" itemprop="url" rel="index"><span itemprop="name">JavaWeb</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h2><ul>
<li>  <strong>一次会话</strong>：浏览器第一次成功给服务器发送请求时，会话建立，直到有一方断开连接时，会话结束。</li>
<li>  一次会话中可以包含多次请求和响应。</li>
</ul>
<h2 id="会话技术"><a href="#会话技术" class="headerlink" title="会话技术"></a>会话技术</h2><ul>
<li>  <strong>会话技术</strong>：在一次会话的多次请求间，共享数据的技术。</li>
<li>会话技术实现方式：<ul>
<li>  客户端会话技术：<code>Cookie</code></li>
<li>  服务器端会话技术：<code>Session</code></li>
</ul>
</li>
<li>  <code>Cookie</code>：把共享的数据存到客户端，就叫客户端会话技术。</li>
<li>  <code>Session</code>：把共享的数据存到服务器端，就叫服务器端会话技术。</li>
</ul>
<h1 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h1><p><code>Cookie</code> 是一种<strong>客户端会话技术</strong>，将共享域数据保存到客户端。</p>
<h2 id="Cookie的实现原理"><a href="#Cookie的实现原理" class="headerlink" title="Cookie的实现原理"></a>Cookie的实现原理</h2><ol>
<li> 客户端首次访问服务器；</li>
<li> 服务器的响应消息中携带 cookie，客户端将 cookie 保存到本地缓存中；</li>
<li> 在当前次会话中，当客户端再次访问服务器时，请求消息中会携带 cookie 数据；</li>
<li> 服务器解析客户端的请求消息，如果客户端需要的资源在 cookie 中存在，就不再重新分配该数据给客户端。</li>
</ol>
<p><img src="/2022/05/04/%E4%BC%9A%E8%AF%9D/Cookie%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png" alt="Cookie实现原理"></p>
<p>客户端<strong>首次</strong>访问一个服务器时，服务器会在响应消息中携带 Cookie 数据并将 Cookie 数据保存在客户端缓存中。</p>
<ul>
<li><p>  Cookie 数据被封装在响应头中（响应头中的数据都是以键值对的形式存在的）。</p>
</li>
<li><p>Cookie 数据在 HTTP 响应头中的格式：</p>
  <figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">set-cookie</span><span class="punctuation">: </span>key=value</span><br></pre></td></tr></table></figure></li>
</ul>
<p>HTTP 协议中规定：若客户端收到的响应头信息中含有 <code>set-cookie</code>，就将该键对应的信息 <code>key=value</code> 保存在客户端浏览器的缓存中。</p>
<p>在当前次会话中，当客户端<strong>再次</strong>访问服务器时，请求消息中就会携带 cookie 信息。</p>
<ul>
<li><p>  Cookie 信息被封装在请求头中（请求头中的数据都是以键值对的形式存在的）。</p>
</li>
<li><p>Cookie 数据在 HTTP 请求头中的格式：</p>
  <figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cookie:key=value</span><br></pre></td></tr></table></figure></li>
</ul>
<p>服务器拿到 Cookie 数据后，就不再重新分配 cookie 中的数据给客户端浏览器了。</p>
<ul>
<li><p>Servlet 服务获取 cookie 的两种方法。</p>
<ul>
<li><p>在服务器中可以使用  getHeader(cookie)  来获取请求头中cookie数据</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">req.getHeader(cookie)</span><br></pre></td></tr></table></figure></li>
<li><p>也可以使用已经封装好的API  getCookies()  来获取请求头中的cookie数据，简化我们的开发步骤。</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">req.getCookies()</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2 id="Cookie-入门"><a href="#Cookie-入门" class="headerlink" title="Cookie 入门"></a>Cookie 入门</h2><h3 id="1、基础案例"><a href="#1、基础案例" class="headerlink" title="1、基础案例"></a>1、基础案例</h3><ul>
<li>  服务器 –&gt; 客户端</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebServlet(&quot;/demo01cookie&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo01_Cookie</span> <span class="keyword">extends</span> <span class="title class_">HttpServlet</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException &#123;</span><br><span class="line">        <span class="comment">// 1. 创建Cookie对象，并绑定数据。</span></span><br><span class="line">        <span class="type">Cookie</span> <span class="variable">cookie</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cookie</span>(<span class="string">&quot;name&quot;</span>,<span class="string">&quot;zhangsan&quot;</span>);</span><br><span class="line">        <span class="comment">// 2. 服务器把Cookie对象封装到Response对象中发送给客户端。</span></span><br><span class="line">        resp.addCookie(cookie);</span><br><span class="line">        System.out.println(<span class="string">&quot;cookie数据成功传递给浏览器&quot;</span>);</span><br><span class="line">        <span class="comment">// 3. 当前次会话中，客户端浏览器再次访问（请求）服务器时，服务器端获取Cookie对象，拿到数据。</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>  客户端 –&gt; 服务器</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebServlet(&quot;/demo02cookie&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo02_Cookie</span> <span class="keyword">extends</span> <span class="title class_">HttpServlet</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException &#123;</span><br><span class="line">        <span class="comment">// 4. 客户端浏览器再次访问（请求）服务器时，服务器端获取Cookie对象，拿到数据。</span></span><br><span class="line">        Cookie[] usernames = req.getCookies();  <span class="comment">// 返回的cookies数据以Map的结构存储</span></span><br><span class="line">        <span class="comment">// 5.获取数据[遍历cookies]</span></span><br><span class="line">        <span class="keyword">if</span> (usernames!=<span class="literal">null</span>)&#123;</span><br><span class="line">            <span class="keyword">for</span> (Cookie username : usernames) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> username.getName();</span><br><span class="line">                <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> username.getValue();</span><br><span class="line">                System.out.println(name+<span class="string">&quot;:&quot;</span>+value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="2、Cookie的细节"><a href="#2、Cookie的细节" class="headerlink" title="2、Cookie的细节"></a>2、Cookie的细节</h3><h4 id="Q1：服务器端一次可不可以发送多个cookie给客户端？"><a href="#Q1：服务器端一次可不可以发送多个cookie给客户端？" class="headerlink" title="Q1：服务器端一次可不可以发送多个cookie给客户端？"></a>Q1：服务器端一次可不可以发送多个cookie给客户端？</h4><ul>
<li>  答：可以。</li>
</ul>
<p>服务器创建多个 cookie 对象，使用 response 对象多次调用 <code>addcookie()</code> 方法将 cookie 信息封装到响应头中；</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebServlet(&quot;/demo03cookie&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo03_Cookie</span> <span class="keyword">extends</span> <span class="title class_">HttpServlet</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException &#123;</span><br><span class="line">        <span class="comment">// 1.创建多个cookie对象</span></span><br><span class="line">        <span class="type">Cookie</span> <span class="variable">cookie1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cookie</span>(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;zhangsan&quot;</span>);</span><br><span class="line">        <span class="type">Cookie</span> <span class="variable">cookie2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cookie</span>(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123&quot;</span>);</span><br><span class="line">        <span class="comment">// 2.使用response对象调用多次`addcookie()`方法</span></span><br><span class="line">        resp.addCookie(cookie1);</span><br><span class="line">        resp.addCookie(cookie2);</span><br><span class="line">        System.out.println(<span class="string">&quot;成功&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ul>
<li><p>客户端接收 cookie 信息。（传输过程要符合HTTP协议规范）</p>
<ul>
<li><p>response 响应消息的响应头中封装了多个 cookie 信息，发送给客户端：</p>
  <figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">set-cookie</span><span class="punctuation">: </span>name=zhangsan</span><br><span class="line"><span class="attribute">set-cookie</span><span class="punctuation">: </span>password=123</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>客户端浏览器如何将这多个cookie再次发送给服务器？</p>
<ul>
<li><p>客户端将这多个cookie信息封装在一起，保存到<code>request请求的请求头中</code>发送给服务器：</p>
  <figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">cookie</span><span class="punctuation">: </span>name=zhangsan;password=123;...</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h4 id="Q2：cookie能在浏览器中保存多长时间？"><a href="#Q2：cookie能在浏览器中保存多长时间？" class="headerlink" title="Q2：cookie能在浏览器中保存多长时间？"></a>Q2：cookie能在浏览器中保存多长时间？</h4><p>默认情况下，当浏览器关闭后，cookie 数据被销毁。[一次会话结束]</p>
<ul>
<li>  相当于 cookie 数据保存在浏览器的缓存中，当浏览器关闭后，浏览器内存被释放，cookie 数据也就被释放掉了</li>
</ul>
<p>但是可以设置 cookie 的生命周期，让 cookie 持久化存储。</p>
<p>cookie 的生命周期由服务器端决定。</p>
<blockquote>
<p>  Cookie#setMaxAge 源码：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Cookie</span> <span class="keyword">implements</span> <span class="title class_">Cloneable</span>, Serializable &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">maxAge</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 设置 cookie 的最大存活时间，以秒为单位</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     * cookie 的存活时间取决于入参 expiry。</span></span><br><span class="line"><span class="comment">     * 当 expiry 为正数时，cookie 数据会被写入到硬盘中持久化存储，存储时间取决于 expiry 的值，单位是 s；</span></span><br><span class="line"><span class="comment">     * 当 expiry 为负数（默认值）时，cookie 的生命周期与浏览器相同；</span></span><br><span class="line"><span class="comment">     * 当 expiry 为 0 时，表示删除 cookie 信息。</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setMaxAge</span><span class="params">(<span class="type">int</span> expiry)</span> &#123;</span><br><span class="line">        maxAge = expiry;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>测试：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebServlet(&quot;/demo04cookie&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo04_Cookie</span> <span class="keyword">extends</span> <span class="title class_">HttpServlet</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException &#123;</span><br><span class="line">        <span class="comment">// 1.创建cookie对象</span></span><br><span class="line">        <span class="type">Cookie</span> <span class="variable">cookie</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cookie</span>(<span class="string">&quot;lisi&quot;</span>,<span class="string">&quot;24&quot;</span>);</span><br><span class="line">        <span class="comment">// 2.设置cookie的存活时间</span></span><br><span class="line">        cookie.setMaxAge(<span class="number">60</span>);   <span class="comment">// 将cookie持久化存储到硬盘文件中，60s后会自动删除cookie文件</span></span><br><span class="line">        <span class="comment">// 3.将cookie数据封装到Response对象的响应头中，并响应给客户端浏览器</span></span><br><span class="line">        resp.addCookie(cookie);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="Q3：cookie中能不能存储中文？"><a href="#Q3：cookie中能不能存储中文？" class="headerlink" title="Q3：cookie中能不能存储中文？"></a>Q3：cookie中能不能存储中文？</h4><ul>
<li>  在 Tomcat8 之前，cookie 中不能直接存储中文数据。如果需要存储中文，需要先将中文数据转码（一般采用 URL 编码）</li>
<li>在 Tomcat8+ 之后，cookie 支持中文数据的存储。<ul>
<li>  但是还是不支持特殊字符的存储。特殊字符需要在服务器使用 URL 编码存储，浏览器使用 URL 解码。</li>
</ul>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * cookie不支持特殊字符的存储【如：空格...】，需要使用URL编码将中文数据编码</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 1、服务器端发送含有特殊字符的 cookie 给客户端</span></span><br><span class="line"><span class="type">String</span> <span class="variable">str_data</span> <span class="operator">=</span> <span class="string">&quot;[含有 特殊字符]&quot;</span></span><br><span class="line"><span class="comment">// 2、使用URL编码处理含有特殊字符的数据</span></span><br><span class="line"><span class="type">String</span> <span class="variable">url_date</span> <span class="operator">=</span> URLEncoder.encode(str_date,<span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line"><span class="comment">// 3、将URL编码过的数据存储到cookie中</span></span><br><span class="line">cookie.setValue(url_date);</span><br><span class="line"><span class="comment">// 4、将cookie放入响应消息的响应头中回传给客户端浏览器</span></span><br><span class="line">resp.addCookie(cookie);</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 客户端携带cookie给服务器端解析</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">// 1、获取请求消息中请求头中的cookie集合，</span></span><br><span class="line">Cookie[] cookies = req.getCookies();</span><br><span class="line"><span class="keyword">for</span> (Cookie cookie : cookies) &#123;</span><br><span class="line">    <span class="comment">// 2、获取值(URL类型数据)</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">url_value</span> <span class="operator">=</span> cookie.getValue();</span><br><span class="line">    <span class="comment">// 3、获取的值要经过URL解码</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> URLDecoder.decode(url_value, <span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">    <span class="comment">// 4、处理值</span></span><br><span class="line">    resp.getWriter().write(value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h4 id="Q4：cookie的获取-共享-范围有多大？"><a href="#Q4：cookie的获取-共享-范围有多大？" class="headerlink" title="Q4：cookie的获取(共享)范围有多大？"></a>Q4：cookie的获取(共享)范围有多大？</h4><p>在一个TomCat服务器中，部署了多个WEB项目，那么这些WEB项目（工程项目）中的cookie能不能共享？</p>
<ol>
<li> 默认情况下，cookie的获取(共享)范围仅限于当前的工程项目中。不能共享到多个工程项目中。</li>
<li>但是Cookie类中提供了一个<code>setPath()</code>方法，可以设置cookie的共享域范围：<ul>
<li><code>setPath(String path)</code>：设置cookie的获取范围，默认情况下，该值为当前WEB项目的路径：<ul>
<li>  如：<code>setPath(&quot;/D6&quot;)</code></li>
</ul>
</li>
<li>如果想要扩大cookie的获取范围到整个TomCat服务器，可以设置获取范围为：<ul>
<li>  <code>setPath(&quot;/&quot;)</code></li>
</ul>
</li>
</ul>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebServlet(&quot;/demo05cookie&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo05_Cookie</span> <span class="keyword">extends</span> <span class="title class_">HttpServlet</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException &#123;</span><br><span class="line">        <span class="comment">// 1.创建cookie对象</span></span><br><span class="line">        <span class="type">Cookie</span> <span class="variable">cookie</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cookie</span>(<span class="string">&quot;wangwu&quot;</span>,<span class="string">&quot;25&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.1 默认情况下，cookie的获取(共享)范围仅限于当前的工程项目中。不能共享到多个工程项目中。</span></span><br><span class="line">        <span class="comment">// 2.2 扩大cookie的获取范围到整个TomCat服务器</span></span><br><span class="line">        cookie.setPath(<span class="string">&quot;/&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.响应cookie给客户端浏览器</span></span><br><span class="line">        resp.addCookie(cookie);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>不同TomCat服务器间cookie的共享问题？</p>
<ol>
<li>概念：<ul>
<li>  假设百度贴吧 和 百度新闻 分别部署在2个不同的服务器上，那么如何使这两个服务器上的cookie可以共享呢？</li>
</ul>
</li>
<li>方法：<ul>
<li><code>setDomain(String path)</code>：如果设置一级域名相同，那么多个服务器之间的cookie就可以共享了<ul>
<li>  如：<code>setDomain(&quot;baidu.com&quot;)</code>，那么百度贴吧(<code>tieba.baidu.com</code>)和百度新闻(<code>news.baidu.com</code>)之间的cookie就可以共享了。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="3、Cookie的特点-amp-使用场景"><a href="#3、Cookie的特点-amp-使用场景" class="headerlink" title="3、Cookie的特点&amp;使用场景"></a>3、Cookie的特点&amp;使用场景</h3><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul>
<li>  cookie 数据存储在客户端浏览器，安全级别低。</li>
<li>  浏览器对于单个 cookie 的存储大小有限制（4kb以内）</li>
<li>  浏览器对于同一域名下的 cookie 数量也有限制（20个以内）</li>
</ul>
<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><ul>
<li>  cookie一般用于存储少量的、不太敏感的数据。</li>
<li>  比如：在不登录的情况下，完成服务器对客户端的身份识别。</li>
</ul>
<h4 id="案例：记住上一次访问时间"><a href="#案例：记住上一次访问时间" class="headerlink" title="案例：记住上一次访问时间"></a>案例：记住上一次访问时间</h4><p><strong>需求：</strong></p>
<ul>
<li>  访问一个接口，如果是第一次访问，则提示：宁好，欢迎宁首次访问XSYU</li>
<li>  如果不是第一次访问，则提示：欢迎回来，宁上次的访问时间为：2020-06-10 11:46:36</li>
</ul>
<p><img src="/2022/05/04/%E4%BC%9A%E8%AF%9D/%E6%A1%88%E4%BE%8B%EF%BC%9A%E8%AE%B0%E4%BD%8F%E4%B8%8A%E4%B8%80%E6%AC%A1%E8%AE%BF%E9%97%AE%E6%97%B6%E9%97%B4.png" alt="案例：记住上一次访问时间"></p>
<p><strong>分析：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">当客户端（浏览器）请求服务器时，服务器判断请求头中是否含有『cookie: lastTime=Xxx』</span><br><span class="line">    <span class="keyword">if</span>(没有)&#123;</span><br><span class="line">        <span class="number">1.</span>证明浏览器是第一次访问服务器</span><br><span class="line">        <span class="number">2.</span>响应数据：您好，欢迎首次访问！</span><br><span class="line">        <span class="number">3.</span>响应：将一个键值对『lastTime=$&#123;currentTime&#125;』作为cookie响应给浏览器，</span><br><span class="line">        <span class="number">4.</span>并设置 cookie 持久化存储。</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123; <span class="comment">// 有</span></span><br><span class="line">        <span class="number">1.</span>证明浏览器不是第一次访问该服务器</span><br><span class="line">        <span class="number">2.</span>获取请求消息中请求头中的『cookie: lastTime=Xxx』</span><br><span class="line">        <span class="number">3.</span>响应数据：将时间值显示在客户端浏览器页面上：欢迎回来，您上次的访问时间为：...</span><br><span class="line">        <span class="number">4.</span>更新 cookie ，设置『lastTime=$&#123;最新时间&#125;』</span><br><span class="line">        <span class="number">5.</span>响应给浏览器，并持久化存储。</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>代码实现</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebServlet(&quot;/cookietest&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CookieTest</span> <span class="keyword">extends</span> <span class="title class_">HttpServlet</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置响应头的数据格式及编码</span></span><br><span class="line">        resp.setContentType(<span class="string">&quot;text/html;charset=utf-8&quot;</span>);</span><br><span class="line">        <span class="comment">// 设置一个flag用来表示是否有key为lastTime的缓存</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">flag</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 获取请求消息中请求头中的cookie集合，</span></span><br><span class="line">        Cookie[] cookies = req.getCookies();</span><br><span class="line">        <span class="keyword">if</span> (cookies!=<span class="literal">null</span> &amp;&amp; cookies.length&gt;<span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 2. 遍历cookie集合</span></span><br><span class="line">            <span class="keyword">for</span> (Cookie cookie : cookies) &#123;</span><br><span class="line">                <span class="comment">// 3.1 cookie对象中存在lastTime键值对：则证明浏览器不是第一次访问该服务器</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="string">&quot;lastTime&quot;</span>.equals(cookie.getName())) &#123;</span><br><span class="line">                    <span class="comment">// 3.2 有lastTime的Cookie，不是第一次访问</span></span><br><span class="line">                    flag = <span class="literal">true</span>;</span><br><span class="line">                    <span class="comment">// 3.3 获取值，并响应数据：</span></span><br><span class="line">                    <span class="type">String</span> <span class="variable">url_value</span> <span class="operator">=</span> cookie.getValue();</span><br><span class="line">                    <span class="comment">// 获取的值要经过URL解码</span></span><br><span class="line">                    <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> URLDecoder.decode(url_value, <span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">                    resp.getWriter().write(<span class="string">&quot;&lt;h1&gt;欢迎回来，宁上次的访问时间为：&quot;</span> + value + <span class="string">&quot;&lt;/h1&gt;&quot;</span>);</span><br><span class="line">                    <span class="comment">// 3.4 更新cookie键值对`lastTime=具体时间`,响应给浏览器，并持久化存储。</span></span><br><span class="line">                    <span class="type">Date</span> <span class="variable">date</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Date</span>();</span><br><span class="line">                    <span class="type">SimpleDateFormat</span> <span class="variable">sdf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SimpleDateFormat</span>(<span class="string">&quot;yyyy年MM月dd日 HH：mm：ss&quot;</span>);</span><br><span class="line">                    <span class="type">String</span> <span class="variable">str_date</span> <span class="operator">=</span> sdf.format(date);</span><br><span class="line">                    <span class="comment">// 3.5 cookie不支持特殊字符的存储【空格...】，需要使用URL编码将中文数据编码</span></span><br><span class="line">                    <span class="type">String</span> <span class="variable">str_url_date</span> <span class="operator">=</span> URLEncoder.encode(str_date,<span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">                    cookie.setValue(str_url_date);</span><br><span class="line">                    cookie.setMaxAge(<span class="number">30</span> * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span>);</span><br><span class="line">                    resp.addCookie(cookie);</span><br><span class="line">                    <span class="keyword">break</span>;   <span class="comment">// 找到了就不用继续查找cookies集合了</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 4.1 cookie对象中不存在lastTime键值对：则证明浏览器是第一次访问该服务器</span></span><br><span class="line">        <span class="keyword">if</span>(cookies==<span class="literal">null</span> || cookies.length==<span class="number">0</span> || flag == <span class="literal">false</span>)&#123;</span><br><span class="line">            <span class="comment">// 4.2 响应数据：</span></span><br><span class="line">            resp.getWriter().write(<span class="string">&quot;宁好，欢迎宁首次访问XSYU&quot;</span>);</span><br><span class="line">            <span class="comment">// 4.3 创建cookie键值对`lastTime=具体时间`,响应给浏览器，并持久化存储。</span></span><br><span class="line">            <span class="type">Date</span> <span class="variable">date</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Date</span>();</span><br><span class="line">            <span class="type">SimpleDateFormat</span> <span class="variable">sdf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SimpleDateFormat</span>(<span class="string">&quot;yyyy年MM月dd日 HH：mm：ss&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">str_date</span> <span class="operator">=</span> sdf.format(date);</span><br><span class="line">            <span class="comment">// 4.4 URL编码</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">url_str_date</span> <span class="operator">=</span> URLEncoder.encode(str_date, <span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">            <span class="type">Cookie</span> <span class="variable">cookie</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cookie</span>(<span class="string">&quot;lastTime&quot;</span>,url_str_date);</span><br><span class="line">            cookie.setValue(url_str_date);</span><br><span class="line">            <span class="comment">// 设置cookie存活时间</span></span><br><span class="line">            cookie.setMaxAge(<span class="number">30</span> * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span>);</span><br><span class="line">            resp.addCookie(cookie);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h1 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h1><p><strong>服务器端会话技术</strong>：在一次会话的多次请求间共享数据，将数据保存在服务器的 <code>HttpSession </code>对象中。</p>
<h2 id="Session快速入门"><a href="#Session快速入门" class="headerlink" title="Session快速入门"></a>Session快速入门</h2><ul>
<li><p>获取 <code>HttpSession</code> 对象：</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">HttpSession</span> <span class="variable">session</span> <span class="operator">=</span> req.getSession()</span><br><span class="line"><span class="comment">// 通过请求消息头中Session的ID来获取Session对象。</span></span><br></pre></td></tr></table></figure>

</li>
<li><p>使用<code>HttpSession</code>对象：[是一个域对象，域对象中有的方法它都有]</p>
<ul>
<li>  <code>Object getAttribute(String name)</code></li>
<li>  <code>void setAttribute(String name, Object value)</code></li>
<li>  <code>void removeAttribute(String name)</code></li>
</ul>
</li>
</ul>
<h2 id="Session原理"><a href="#Session原理" class="headerlink" title="Session原理"></a>Session原理</h2><h3 id="Q：服务器如何确保在一次会话中，多次获取到的Session是同一个？"><a href="#Q：服务器如何确保在一次会话中，多次获取到的Session是同一个？" class="headerlink" title="Q：服务器如何确保在一次会话中，多次获取到的Session是同一个？"></a>Q：服务器如何确保在一次会话中，多次获取到的Session是同一个？</h3><p>Session的实现是依赖于Cookie的。</p>
<p><img src="/2022/05/04/%E4%BC%9A%E8%AF%9D/Session%E5%8E%9F%E7%90%86.png" alt="Session原理"></p>
<p><strong>客户端首次访问服务器时：</strong></p>
<ul>
<li><p>  客户端首次访问服务器时，请求消息中是没有 cookie 数据的；</p>
</li>
<li><p>  服务器发现请求消息中没有 cookie 时，就会在内存中创建一个新的 Session 对象，并给这个 Session 对象分配唯一的ID。</p>
</li>
<li><p>服务器向客户端发送响应消息时，就会在响应头中额外添加一组 <code>set-cookie</code> 键值对，保存 Session 对象的地址ID。</p>
  <figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">set-cookie</span><span class="punctuation">: </span>......</span><br><span class="line"><span class="attribute">set-cookie</span><span class="punctuation">: </span>JSESSION=Session对象的ID值</span><br></pre></td></tr></table></figure></li>
<li><p>  客户端收到响应消息后，就会把『JSESSION=Session对象的ID值』也存储到浏览器 cookie 信息中。</p>
</li>
</ul>
<p><strong>在一次会话中，当客户端再次访问服务器时：</strong></p>
<ul>
<li>  请求头中就会携带<code>cookie:JSESSION=Session对象的ID</code>信息；</li>
<li>  服务器获取到该cookie信息后，根据该信息自动查找内存中是否存在对应ID的Session对象；</li>
<li>  所以，接口 B 中通过 <code>request.getSession()</code> 得到的 Session 对象与接口 A 中创建的 Session 对象是同一个。</li>
</ul>
<h2 id="Session的细节"><a href="#Session的细节" class="headerlink" title="Session的细节"></a>Session的细节</h2><h3 id="Q1：客户端关闭，服务器端不关闭，两次获取的session是否为同一个？"><a href="#Q1：客户端关闭，服务器端不关闭，两次获取的session是否为同一个？" class="headerlink" title="Q1：客户端关闭，服务器端不关闭，两次获取的session是否为同一个？"></a>Q1：客户端关闭，服务器端不关闭，两次获取的session是否为同一个？</h3><p>默认情况下，两次访问获得的session不是同一个。</p>
<ul>
<li>  默认情况下，会话结束后，cookie 资源会被释放掉，客户端浏览器关闭后重新访问，服务器会重新分配一个 session 对象保存到<code>set-cookie</code> 响应头中返回给客户端浏览器。显然两次获取的session不是同一个。</li>
</ul>
<p>如果需要两次访问获取的session对象是同一个，该如何做？</p>
<ul>
<li>  可以设置cookie的最大存活时间，让cookie持久化存储。</li>
<li>  在最大存活时间内，cookie中的<code>JSESSIONID</code>不会改变，所以每次访问的session对象也就是同一个。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebServlet(&quot;/sessionDemo03&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SessionDemo03</span> <span class="keyword">extends</span> <span class="title class_">HttpServlet</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException &#123;</span><br><span class="line">        <span class="comment">// 1.获取Session对象</span></span><br><span class="line">        <span class="type">HttpSession</span> <span class="variable">session</span> <span class="operator">=</span> req.getSession();</span><br><span class="line">        System.out.println(session);</span><br><span class="line">        <span class="comment">// 2.获取Cookie对象,并将Cookie持久化存储</span></span><br><span class="line">        <span class="type">Cookie</span> <span class="variable">cookie</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cookie</span>(<span class="string">&quot;JSESSIONID&quot;</span>,session.getId());</span><br><span class="line">        cookie.setMaxAge(<span class="number">3600</span>);</span><br><span class="line">        resp.addCookie(cookie);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="Q2：客户端不关闭，服务器关闭后再打开，两次获取的session是否为同一个？"><a href="#Q2：客户端不关闭，服务器关闭后再打开，两次获取的session是否为同一个？" class="headerlink" title="Q2：客户端不关闭，服务器关闭后再打开，两次获取的session是否为同一个？"></a>Q2：客户端不关闭，服务器关闭后再打开，两次获取的session是否为同一个？</h3><p>不是同一个。</p>
<ul>
<li>  服务器关闭后，内存中的Session对象肯定会被全部销毁。服务器重启后，获取到的Session对象显然不是同一个</li>
</ul>
<p>虽然session对象不是同一个，但是如果想要保证Session中的数据不丢失，可以采用：</p>
<ul>
<li>  在服务器正常关闭之前，将session对象序列化到硬盘上。</li>
<li>  在服务器启动后，将session文件反序列化为内存中的session对象即可。</li>
</ul>
<h3 id="Q3：session什么时候被销毁？"><a href="#Q3：session什么时候被销毁？" class="headerlink" title="Q3：session什么时候被销毁？"></a>Q3：session什么时候被销毁？</h3><ol>
<li><p> 服务器关闭</p>
</li>
<li><p>session对象调用自杀方法</p>
<ul>
<li>  <code>session.invalidate()</code></li>
</ul>
</li>
<li><p>session 默认的失效时间是30分钟</p>
<ul>
<li>  在 web.xml 文件中修改默认失效时间：</li>
</ul>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">session-config</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">session-timeout</span>&gt;</span>30<span class="tag">&lt;/<span class="name">session-timeout</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">session-config</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Session的特点"><a href="#Session的特点" class="headerlink" title="Session的特点"></a>Session的特点</h2><ul>
<li>  session用于存储一次会话中的多次请求数据，存储在服务器端</li>
<li>  session可以存储任意类型、任意大小的数据</li>
</ul>
<h2 id="Session-vs-Cookie"><a href="#Session-vs-Cookie" class="headerlink" title="Session vs. Cookie"></a>Session vs. Cookie</h2><ul>
<li>  Session存储在服务器端，Cookie存储在客户端</li>
<li>  Session没有数据大小的限制，Cookie有数据大小的限制</li>
<li>  Session存储的数据较为安全，Cookie存储的数据相对不太安全</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
