<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/17/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/17/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/17/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hexo</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">224</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">61</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/02/19/MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/02/19/MapReduce/" class="post-title-link" itemprop="url">MapReduce</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-02-19 15:10:17" itemprop="dateCreated datePublished" datetime="2021-02-19T15:10:17+08:00">2021-02-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-12-14 19:23:26" itemprop="dateModified" datetime="2021-12-14T19:23:26+08:00">2021-12-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="MapReduce-理论基础"><a href="#MapReduce-理论基础" class="headerlink" title="MapReduce 理论基础"></a>MapReduce 理论基础</h1><h2 id="MapReduce-定义"><a href="#MapReduce-定义" class="headerlink" title="MapReduce 定义"></a>MapReduce 定义</h2><p>MapReduce 是一个分布式运算程序的编程框架，是用户开发“基于Hadoop的数据分析应用”的核心框架。</p>
<p>MapReduce 核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，可以运行在一个Hadoop集群上。</p>
<hr>
<h2 id="MapReduce优缺点"><a href="#MapReduce优缺点" class="headerlink" title="MapReduce优缺点"></a>MapReduce优缺点</h2><h3 id="优点——简单"><a href="#优点——简单" class="headerlink" title="优点——简单"></a>优点——简单</h3><h3 id="缺点——慢"><a href="#缺点——慢" class="headerlink" title="缺点——慢"></a>缺点——慢</h3><hr>
<h2 id="MapReduce-组件"><a href="#MapReduce-组件" class="headerlink" title="MapReduce 组件"></a>MapReduce 组件</h2><p>MapReduce 是一种编程思想，符合这种编程思想的程序就可以叫做 MapReduce 程序。</p>
<h3 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h3><p><strong>Job</strong>（作业）：一个符合 MapReduce 编程规范的程序就是一个 Job，Job 其实就是一段可以运行的静态代码。</p>
<hr>
<h3 id="MrAppMaster"><a href="#MrAppMaster" class="headerlink" title="MrAppMaster"></a>MrAppMaster</h3><p><strong>MrAppMaster</strong>：MrAppMaster 是一个进程。在分布式环境下运行 Job 时，会先启动一个 MRAppMaster 进程，这个进程就主要负责 Job 中程序运行过程中执行状态的监控，容错，和 ResourceManager 申请资源，提交 Task 等。</p>
<hr>
<h3 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h3><p><strong>Task</strong>：Task 也是一个进程，负责 Job 任务的计算。</p>
<ul>
<li>  MapTask：负责 Map 阶段程序计算的 Task 称为 MapTask。</li>
<li>  ReduceTask：负责 Reduce 阶段程序计算的 Task 称为 ReduceTask。</li>
</ul>
<hr>
<h3 id="Partitioner（分区）"><a href="#Partitioner（分区）" class="headerlink" title="Partitioner（分区）"></a>Partitioner（分区）</h3><p>Partitioner（分区器）负责在 Mapper 将数据写出时，为每组 <code>&lt;keyout-valueout&gt;</code> 打上标记，保存在不同的分区中。</p>
<p>如果 Map 阶段的数据保存在多个分区中，在 Reduce 阶段，一个 ReduceTask 只需处理一个分区的数据即可。</p>
<hr>
<h3 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h3><p>Map 阶段是 MapReduce 程序运行的第一个阶段。</p>
<p>Map 阶段会将输入的数据进行切分，将一份大数据切分为若干小部分，切分后每个部分称为一<strong>片（split）</strong>，每片数据会交给一个MapTask 进程进行计算。</p>
<p>在一个 MapReduce 程序的 Map 阶段，会启动 N 个 MapTask 进程并行运算。</p>
<ul>
<li>  N 取决于切片（split）数，一般会为每一个 split 都分配一个 Task。</li>
</ul>
<hr>
<h3 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h3><p>Reduce 阶段是 MapReduce 程序运行的第二个阶段。</p>
<p>Reduce 阶段的目的是将 Map 阶段每个 MapTask 计算后的结果进行合并汇总，得到最终结果。</p>
<p>Reduce 阶段是可选的，也就是说一个 MapReduce 程序运行时可以没有 Reduce 阶段。</p>
<p>一个 Job 可以通过设置，启动 N 个 ReduceTask，这些 ReduceTask 也是并行运行的，每个 ReduceTask 最终都会产生一个结果。</p>
<hr>
<h2 id="MapReduce-常用API"><a href="#MapReduce-常用API" class="headerlink" title="MapReduce 常用API"></a>MapReduce 常用API</h2><p>Hadoop 是用 Java 实现的，在 MapReduce 程序运行过程中，会创建一些实例对象，其中一些重要的<strong>基类</strong>对象如下：</p>
<h3 id="Map-阶段"><a href="#Map-阶段" class="headerlink" title="Map 阶段"></a>Map 阶段</h3><ol>
<li><p> <strong>Mapper</strong>：map阶段的核心对象</p>
</li>
<li><p><strong>InputFormat</strong>：用于处理指定格式的输入数据</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MapReduce 规范规定程序运行时必须指定一个输入目录，一个输出目录。</span><br><span class="line">InputFormat 限定了输入目录中文件的格式。</span><br><span class="line">	1、如果是普通文件，可以使用 FileInputFormat 实现类；</span><br><span class="line">	2、如果是SequeceFile文件（hadoop提供的一种文件格式），可以使用 SequnceFileInputFormat 实现类；</span><br><span class="line">	3、如果处理的数据在数据库中，需要使用 DBInputFormat 实现类</span><br></pre></td></tr></table></figure></li>
<li><p><strong>RecordReader</strong>：记录读取器</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RecordReader 负责从输入目录文件中，读取数据，读取后封装为一组键值对记录。</span><br><span class="line">因为 MapReduce 只能处理&lt;K,V&gt;数据</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="Reduce阶段"><a href="#Reduce阶段" class="headerlink" title="Reduce阶段"></a>Reduce阶段</h3><ol>
<li><p> <strong>Reducer</strong>：reduce 阶段的核心对象</p>
</li>
<li><p><strong>OutPutFormat</strong>：用于处理输出数据的格式</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">OutPutFormat 用于指定 MapReduce 处理后的结果，要以什么样的文件格式写出。</span><br><span class="line">	1、如果想将结果写出到一个普通文件中，可以使用 FileOutputFormat；</span><br><span class="line">	2、如果想将结果写出到数据库中，可以使用 DBOutPutFormat；</span><br><span class="line">	4、如果想将结果写出到 SequeceFile 中，可以使用 SequnceFileOutputFormat</span><br></pre></td></tr></table></figure></li>
<li><p><strong>RecordWriter</strong>：记录写出器</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RecordWriter 将处理的结果以什么样的格式，写出到输出文件中。</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="MapReduce-处理数据的流程："><a href="#MapReduce-处理数据的流程：" class="headerlink" title="MapReduce 处理数据的流程："></a>MapReduce 处理数据的流程：</h3><ol>
<li> <code>InputFormat</code> 调用 <code>RecordReader</code>，读取输入目录下的文件中的数据，并将数据封装为 <code>&lt;keyin, valuein&gt;</code> 对象；</li>
<li> 将封装好的 <code>&lt;keyin, valuein&gt;</code> 对象，交给 <code>Mapper.map()</code>处理 <code>--&gt;</code> 将处理的结果写出到 <code>&lt;keyout, valueout&gt;</code> 对象中；</li>
<li> 将<code>&lt;keyout, valueout&gt;</code> 对象序列化到磁盘中存储；</li>
<li> <code>ReduceTask</code> 进程创建 <code>Reducer</code> 对象，使用 <code>Reducer.reduce()</code> 处理 Mapper 写出的 <code>&lt;keyout, valueout&gt;</code> 对象；</li>
<li> <code>OutPutFormat</code> 调用 <code>RecordWriter</code>，将 <code>Reducer</code> 处理后的 <code>&lt;keyout, valueout&gt;</code> 对象写出到文件中。</li>
</ol>
<hr>
<h1 id="MapReduce-编程规范"><a href="#MapReduce-编程规范" class="headerlink" title="MapReduce 编程规范"></a>MapReduce 编程规范</h1><p>用户编写的程序分成三个部分：Mapper、Reducer 和 Driver</p>
<h2 id="一、Mapper-阶段"><a href="#一、Mapper-阶段" class="headerlink" title="一、Mapper 阶段"></a>一、Mapper 阶段</h2><ol>
<li><p>用户自定义的 Mapper 要继承 <code>org.apache.hadoop.mapreduce.Mapper</code></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Mapper</span>&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt; &#123;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p> Mapper 的输入数据是 KV 对的形式（KV 的类型可自定义）</p>
</li>
<li><p> Mapper 的业务逻辑写在 <code>map()</code> 方法中</p>
</li>
<li><p> Mapper 的输出数据是 KV 对的形式（KV 的类型可自定义）</p>
</li>
<li><p> <code>map()</code> 方法（MapTask 进程）会对每个 <code>&lt;K, V&gt;</code> 都调用一次。</p>
</li>
</ol>
<hr>
<h2 id="二、Reducer-阶段"><a href="#二、Reducer-阶段" class="headerlink" title="二、Reducer 阶段"></a>二、Reducer 阶段</h2><ol>
<li><p>用户自定义的 Reducer 要继承 <code>org.apache.hadoop.mapreduce.Reducer</code></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Reducer</span>&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt; &#123;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p> Reducer 的输入数据类型对应 Mapper 的输出数据类型，也是 KV</p>
</li>
<li><p> Reducer 的输出数据是 KV 对的形式（KV 的类型可自定义）</p>
</li>
<li><p> Reducer 的业务逻辑写在 <code>reduce()</code> 方法中</p>
</li>
<li><p> ReduceTask 进程对每一组相同 K 的 <code>&lt;K, V&gt;</code> 组调用一次 <code>reduce()</code> 方法。</p>
</li>
</ol>
<hr>
<h2 id="三、Driver"><a href="#三、Driver" class="headerlink" title="三、Driver"></a>三、Driver</h2><p><strong>Driver 就相当于 Yarn 的客户端，用于提交 Job 到 Yarn 中。</strong></p>
<hr>
<h1 id="WordCount-案例"><a href="#WordCount-案例" class="headerlink" title="WordCount 案例"></a>WordCount 案例</h1><h2 id="WordCount-案例分析"><a href="#WordCount-案例分析" class="headerlink" title="WordCount 案例分析"></a>WordCount 案例分析</h2><p><img src="/2021/02/19/MapReduce/image-20211126202235883.png" alt="image-20211126202235883"></p>
<p><img src="/2021/02/19/MapReduce/image-20211202113216507.png" alt="image-20211202113216507"></p>
<h3 id="需求："><a href="#需求：" class="headerlink" title="需求："></a>需求：</h3><p>在 HDFS 的 <code>/hello</code> 目录下存在两个文件，现在要求统计两个文件中不同单词的数量，并要求将 <code>a-p</code> 开头的单词放入到一个结果文件中，<code>q-z</code> 开头的单词放入到另一个结果文件中。    </p>
<ul>
<li><p><code>/hello/a.txt    200M</code></p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hello,hi,hadoop</span><br><span class="line">hive,hadoop,hive,</span><br><span class="line">zoo,spark,wow</span><br><span class="line">zoo,spark,wow</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
<li><p><code>/hello/b.txt    100M</code></p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hello,hi,hadoop</span><br><span class="line">zoo,spark,wow</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Map-阶段-1"><a href="#Map-阶段-1" class="headerlink" title="Map 阶段"></a>Map 阶段</h3><p>Map 阶段：运行多个 MapTask 进程，将大数据切分成若干份小数据，每个 MapTask 进程处理一部分数据，并输出阶段性的结果。</p>
<ol>
<li><p>数据切片（split）：默认的切分策略是以文件为单位，以 block 的大小为单个片的大小进行切片。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/hello/a.txt	200M</span><br><span class="line">/hello/b.txt	100M</span><br><span class="line"></span><br><span class="line">现在我们有2个文件，默认块的大小是128M，所以split的大小也为128M。</span><br><span class="line">所以我们需要对文件 a.txt 进行切片，切分后的结果为：</span><br><span class="line">	split0: /hello/a.txt,0-128M</span><br><span class="line">	split1: /hello/a.txt,128M-200M</span><br><span class="line">对于文件 b.txt，其大小小于128M，所以不需要再进行切片了，直接保存在一个单独的split上；</span><br><span class="line">	split2: /hello/b.txt,0M-100M</span><br></pre></td></tr></table></figure></li>
<li><p>由于目前我们有 3 个 split，所以启动 3 个 MapTask 进程执行任务，每个 MapTask 进程负责处理一个 split 上的数据</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">split0: /hello/a.txt,0-128M--------MapTask1</span><br><span class="line">split1: /hello/a.txt,128M-200M--------MapTask2</span><br><span class="line">split2: /hello/b.txt,0M-100M--------MapTask3</span><br></pre></td></tr></table></figure></li>
<li><p>读取数据阶段。</p>
<p> 在 MapReduce 中，所有的数据必须封装为 <code>&lt;K, V&gt;</code> 形式，所以 MapTask1、2、3 分别都会创建一个 <code>InputFormat</code> 对象（默认实现类为 <code>TextInputFormat</code>），每个 <code>InputFormat</code> 对象再创建一个依赖对象 <code>RecordReader</code>（默认实现类为 <code>LineRecordReader</code>），<code>RecordReader</code> 负责读取 split 中的数据，并封装成 <code>&lt;K, V&gt;</code> 格式。</p>
<p> <code>LineRecordReader</code>：以文件中的当前行的偏移量（offset ）为 key，当前行的内容为 value，将文件内容封装成一个个<code>&lt;K,V&gt;</code>对象。</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">举例：a.txt</span><br><span class="line"><span class="comment"># (k，v) &lt;---&gt; (偏移量，内容)</span></span><br><span class="line">hello,hi,hadoop-----&gt;(<span class="number">0</span>, (hello,hi,hadoop))</span><br><span class="line">hive,hadoop,hive-----&gt;(<span class="number">20</span>, (hive,hadoop,hive))</span><br><span class="line">zoo,spark,wow-----&gt;(<span class="number">30</span>, (zoo,spark,wow))</span><br><span class="line">zoo,spark,wow-----&gt;(<span class="number">40</span>, (zoo,spark,wow))</span><br></pre></td></tr></table></figure></li>
<li><p><code>map()</code>方法</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">map() 是 Map 阶段的核心处理逻辑。 </span><br><span class="line">在单词统计中，map() 会被循环调用，对输入的每个&lt;K,V&gt;对象都进行处理！</span><br><span class="line">    输入：(0, (hello,hi,hadoop))</span><br><span class="line">    输出：(hello,1),(hi,1),(hadoop,1)</span><br><span class="line"></span><br><span class="line">    输入：(20, (hive,hadoop,hive))</span><br><span class="line">    输出：(hive,1),(hadoop,1),(hive,1)  </span><br><span class="line"></span><br><span class="line">    输入：(30, (zoo,spark,wow))</span><br><span class="line">    输出：(zoo,1),(spark,1),(wow,1)  </span><br><span class="line"></span><br><span class="line">    输入：(40, (zoo,spark,wow))</span><br><span class="line">    输出：(zoo,1),(spark,1),(wow,1) </span><br></pre></td></tr></table></figure></li>
<li><p>根据需求，我们需要生成两个结果文件，将 <code>a-p</code> 开头的单词放入到一个结果文件中，<code>q-z</code> 开头的单词放入到另一个结果文件中。所以，我们需要将 MapTask 输出的记录进行<strong>分区</strong>，将 <code>a-p</code> 开头的单词放入到一个区，<code>q-z</code> 开头的单词放入到另一个区，这就需要在Mapper 输出结果后，调用 Partitioner，对 Mapper 输出的 <code>key-value</code> 进行分区，在分区过程中默认会将结果按照字典顺序排序。为了分别处理这两个区的数据，我们也会启动两个 ReduceTask ，每个 ReduceTask 负责处理一个分区中的数据。</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">分区规则： </span><br><span class="line">	a-p开头的单词放入到一个区；q-z开头的单词放入到另一个区</span><br><span class="line"></span><br><span class="line">MapTask1：	<span class="comment">// MapTask1 的处理结果分别放入两个区，同理，MapTask2、3也一样，将处理结果输出到两个区中 </span></span><br><span class="line"><span class="number">0</span>号区：  (hadoop,<span class="number">1</span>)，(hadoop,<span class="number">1</span>)，(hello,<span class="number">1</span>),(hi,<span class="number">1</span>),(hive,<span class="number">1</span>),(hive,<span class="number">1</span>)</span><br><span class="line"><span class="number">1</span>号区：  (spark,<span class="number">1</span>),(spark,<span class="number">1</span>),(wow,<span class="number">1</span>) ，(wow,<span class="number">1</span>),(zoo,<span class="number">1</span>)(zoo,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">MapTask2:		   </span><br><span class="line"><span class="number">0</span>号区： ...</span><br><span class="line"><span class="number">1</span>号区： ...</span><br><span class="line"></span><br><span class="line">MapTask3:		   </span><br><span class="line"><span class="number">0</span>号区： (hadoop,<span class="number">1</span>),(hello,<span class="number">1</span>),(hi,<span class="number">1</span>),	<span class="comment">// 分区后的数据按key的字典顺序排列</span></span><br><span class="line"><span class="number">1</span>号区： (spark,<span class="number">1</span>),(wow,<span class="number">1</span>),(zoo,<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="Reduce-阶段"><a href="#Reduce-阶段" class="headerlink" title="Reduce 阶段"></a>Reduce 阶段</h3><ol>
<li><p><strong>copy</strong>：<code>ReduceTask</code> 进程启动后，会启动 <strong>shuffle</strong> 进程，从 MapTask 进程中拷贝相应分区的数据。比如：</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ReduceTask1: 只负责0号区</span><br><span class="line">	将3个MapTask生成的保存在0号区数据全部拷贝到ReduceTask1所在的机器！</span><br><span class="line">        (hadoop,1)，(hadoop,1)，(hello,1),(hi,1),(hive,1),(hive,1)</span><br><span class="line">        (hadoop,1),(hello,1),(hi,1),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ReduceTask2: 只负责1号区</span><br><span class="line">	将3个MapTask生成的保存在1号区数据全部拷贝到ReduceTask2所在的机器！</span><br><span class="line">        (spark,1),(spark,1),(wow,1) ，(wow,1),(zoo,1)(zoo,1)</span><br><span class="line">        (spark,1),(wow,1),(zoo,1)</span><br></pre></td></tr></table></figure>

</li>
<li><p><strong>sort</strong>：排序</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ReduceTask1: 将从0号区拷贝到本地机器上的数据进行排序：</span><br><span class="line">	(hadoop,1)，(hadoop,1)，(hadoop,1),(hello,1),(hello,1),(hi,1),(hi,1),(hive,1),(hive,1)</span><br><span class="line">ReduceTask2: 将从1号区拷贝到本地机器上的数据进行排序：</span><br><span class="line">	(spark,1),(spark,1),(spark,1),(wow,1) ，(wow,1),(wow,1),(zoo,1),(zoo,1)(zoo,1)</span><br></pre></td></tr></table></figure></li>
<li><p><strong>reduce</strong></p>
<p> <code>ReduceTask进程 --&gt; 创建Reducer对象 --&gt; 调用reduce()方法(一次读入一组数据)</code></p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">何为一组数据: key相同的为一组数据</span><br><span class="line">ReduceTask1----&gt;Reducer-----&gt;reduce(一次读入一组数据)</span><br><span class="line">	输入： (hadoop,1)，(hadoop,1)，(hadoop,1)</span><br><span class="line">	输出： (hadoop,3)</span><br><span class="line"></span><br><span class="line">	输入： (hello,1),(hello,1)</span><br><span class="line">	输出： (hello,2)</span><br><span class="line">	</span><br><span class="line">	输入： (hi,1),(hi,1)</span><br><span class="line">	输出： (hi,2)</span><br><span class="line">	</span><br><span class="line">	输入：(hive,1),(hive,1)</span><br><span class="line">	输出：(hive,2)</span><br><span class="line">	</span><br><span class="line">ReduceTask2----&gt;Reducer-----&gt;reduce(一次读入一组数据)</span><br><span class="line">	输入： (spark,1),(spark,1),(spark,1)</span><br><span class="line">	输出： (spark,3)</span><br><span class="line">	</span><br><span class="line">	输入： (wow,1) ，(wow,1),(wow,1)</span><br><span class="line">	输出： (wow,3)</span><br><span class="line"></span><br><span class="line">	输入：(zoo,1),(zoo,1)(zoo,1)</span><br><span class="line">	输出：(zoo,3)</span><br></pre></td></tr></table></figure>

</li>
<li><p>调用 <code>OutPutFormat</code> 中的 <code>RecordWriter</code> 将 <code>Reducer</code> 输出的记录落盘</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ReduceTask1----&gt;OutPutFormat（默认使用TextOutPutFormat）------&gt;RecordWriter（默认使用LineRecoreWriter）</span><br><span class="line">    LineRecoreWriter会将一个&lt;K,V&gt;写出为一行，key和alue之间使用\t分割</span><br><span class="line">    在输出目录中，生成文件part-r-0000</span><br><span class="line">        hadoop	3</span><br><span class="line">        hello	2</span><br><span class="line">        hi	2</span><br><span class="line">        hive	2</span><br><span class="line"></span><br><span class="line">ReduceTask2----&gt;OutPutFormat（默认TextOutPutFormat）------&gt;RecordWriter（LineRecoreWriter）</span><br><span class="line">    LineRecoreWriter会将一个&lt;K,V&gt;写出为一行，key和alue之间使用\t分割</span><br><span class="line">    在输出目录中，生成文件part-r-0001</span><br><span class="line">        spark	3</span><br><span class="line">        wow	3</span><br><span class="line">        zoo	3</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="MapReduce总结"><a href="#MapReduce总结" class="headerlink" title="MapReduce总结"></a>MapReduce总结</h3><ul>
<li><p>Map阶段(MapTask)</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">切片(Split)-----读取数据(Read)-------交给Mapper处理(Map)------分区和排序(sort)</span><br></pre></td></tr></table></figure>

</li>
<li><p>Reduce阶段(ReduceTask)</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">拷贝数据(copy)------排序(sort)-----合并(reduce)-----写出(write)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<hr>
<h2 id="WordCount案例实战"><a href="#WordCount案例实战" class="headerlink" title="WordCount案例实战"></a>WordCount案例实战</h2><h3 id="一、准备数据"><a href="#一、准备数据" class="headerlink" title="一、准备数据"></a>一、准备数据</h3><p><strong>注意：</strong></p>
<ul>
<li>  准备的数据的格式必须是文本</li>
<li>  编码必须是<code>utf-8无bom</code></li>
</ul>
<p><img src="/2021/02/19/MapReduce/image-20211202141842801.png" alt="image-20211202141842801"></p>
<hr>
<h1 id="Hadoop-序列化"><a href="#Hadoop-序列化" class="headerlink" title="Hadoop 序列化"></a>Hadoop 序列化</h1><h2 id="什么是序列化"><a href="#什么是序列化" class="headerlink" title="什么是序列化"></a>什么是序列化</h2><ul>
<li>  <strong>序列化</strong>就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储（持久化）和网络传输。</li>
<li>  <strong>反序列化</strong>就是将收到字节序列（或其他数据传输协议）或者是硬盘的持久化数据，转换成内存中的对象。</li>
</ul>
<hr>
<h2 id="为什么要序列化"><a href="#为什么要序列化" class="headerlink" title="为什么要序列化"></a>为什么要序列化</h2><p>一般来说，“活的”对象只存在于内存中，关机断电就没有了。而且“活的”对象只能由本地的进程使用，不能被发送到网络上的另外一台计算机。然而序列化可以存储“活的”对象，可以将“活的”对象发送到远程计算机。</p>
<hr>
<h2 id="为什么不用Java的序列化"><a href="#为什么不用Java的序列化" class="headerlink" title="为什么不用Java的序列化"></a>为什么不用Java的序列化</h2><p>Java 的序列化是一个重量级的序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以，Hadoop 自己开发了一套轻量级的序列化机制（Writable）。</p>
<p><strong>Hadoop 序列化特点：</strong></p>
<ol>
<li> 紧凑：高效使用存储空间。</li>
<li> 快速：读写数据的额外开销小。</li>
<li> 可扩展：随着通信协议的升级而可升级</li>
<li> 互操作：支持多语言的交互</li>
</ol>
<hr>
<h2 id="常用数据序列化类型"><a href="#常用数据序列化类型" class="headerlink" title="常用数据序列化类型"></a>常用数据序列化类型</h2><blockquote>
<p>  常用的数据类型对应的 Hadoop 数据序列化类型</p>
</blockquote>
<table>
<thead>
<tr>
<th>Java类型</th>
<th>Hadoop Writable类型</th>
</tr>
</thead>
<tbody><tr>
<td>boolean</td>
<td>BooleanWritable</td>
</tr>
<tr>
<td>byte</td>
<td>ByteWritable</td>
</tr>
<tr>
<td>int</td>
<td>IntWritable</td>
</tr>
<tr>
<td>float</td>
<td>FloatWritable</td>
</tr>
<tr>
<td>long</td>
<td>LongWritable</td>
</tr>
<tr>
<td>double</td>
<td>DoubleWritable</td>
</tr>
<tr>
<td>String</td>
<td>Text</td>
</tr>
<tr>
<td>map</td>
<td>MapWritable</td>
</tr>
<tr>
<td>array</td>
<td>ArrayWritable</td>
</tr>
</tbody></table>
<hr>
<h2 id="自定义-bean-对象事件序列化接口（Writable）"><a href="#自定义-bean-对象事件序列化接口（Writable）" class="headerlink" title="自定义 bean 对象事件序列化接口（Writable）"></a>自定义 bean 对象事件序列化接口（Writable）</h2><p>自定义的 bean 对象如果想要序列化传输，就必须实现序列化接口。具体的操作步骤如下 7 步：</p>
<ol>
<li><p> 实现 <code>Writable</code> 接口</p>
</li>
<li><p>反序列化时，需要反射调用 bean 对象的空参构造函数，所以自定义的 bean 对象必须提供空参构造函数。</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="built_in">super</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>重写序列化方法</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">	out.writeLong(upFlow);</span><br><span class="line">	out.writeLong(downFlow);</span><br><span class="line">	out.writeLong(sumFlow);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
<li><p>重写反序列化方法</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">	upFlow = in.readLong();</span><br><span class="line">	downFlow = in.readLong();</span><br><span class="line">	sumFlow = in.readLong();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p> 注意反序列化方法中参数的顺序要与序列化方法中参数的顺序完全一致</p>
</li>
<li><p> 要想把结果显示在文件中，需要重写 <code>toString()</code> 方法</p>
</li>
<li><p>如果需要将自定义的 bean 对象作为 key 传输，则还需要实现 Comparable 接口，因为 MapReduce 中的 Shuffle 过程要求 key 必须能排序。</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line">    <span class="comment">// 倒序排列，从大到小</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.sumFlow &gt; o.getSumFlow() ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="序列化案例实操"><a href="#序列化案例实操" class="headerlink" title="序列化案例实操"></a>序列化案例实操</h2><p><strong>一、需求</strong></p>
<p>统计每一个手机号耗费的总上行流量、下行流量、总流量</p>
<p>（1）输入数据</p>
<p>（2）输入数据格式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">7	13560436666		120.196.100.99		1116	954		 200  </span><br><span class="line">id   手机号码     	 网络ip             上行流量  下行流量   网络状态码  </span><br></pre></td></tr></table></figure>

<p>（3）期望输出数据格式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">13560436666      1116         954            2070  </span><br><span class="line">手机号码        上行流量     下行流量         总流量  </span><br></pre></td></tr></table></figure>

<p><img src="/2021/02/19/MapReduce/image-20211202150116535.png" alt="image-20211202150116535"></p>
<hr>
<h1 id="MapReduce-框架原理"><a href="#MapReduce-框架原理" class="headerlink" title="MapReduce 框架原理"></a>MapReduce 框架原理</h1><p><img src="/2021/02/19/MapReduce/image-20211127120148703.png" alt="image-20211127120148703"></p>
<hr>
<h1 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h1><h2 id="FileInputFormat切片源码解析-input-getSplits-job"><a href="#FileInputFormat切片源码解析-input-getSplits-job" class="headerlink" title="FileInputFormat切片源码解析(input.getSplits(job))"></a>FileInputFormat切片源码解析(input.getSplits(job))</h2><p><img src="/2021/02/19/MapReduce/image-20211202172418064.png" alt="image-20211202172418064"></p>
<h2 id="FileInputFormat-的切片策略（默认切片策略）"><a href="#FileInputFormat-的切片策略（默认切片策略）" class="headerlink" title="FileInputFormat 的切片策略（默认切片策略）"></a>FileInputFormat 的切片策略（默认切片策略）</h2><ul>
<li><strong>切片策略</strong><ol>
<li> 首先获取当前输入目录中的所有文件；</li>
<li> 以文件为单位进行切片，如果文件是空文件，默认创建一个空的切片（split）。</li>
<li> 如果文件不为空，要先判断文件是否可切片（非压缩文件都可切，压缩文件只有Bzip2格式可切）。</li>
<li> 如果文件不可切，将整个文件作为一片</li>
<li>如果文件可切，先获取事先设置的每片的大小（默认等于 Block 的大小），再按照文件的内容长度进行循环切片。<ul>
<li>  如果 <code>待切片内容长度/每片大小 &gt; 1.1</code>，则先切去一片，再用剩余的文件大小作为待切片内容，循环判断；</li>
<li>  如果 <code>待切片内容长度/每片大小 &lt;= 1.1</code>，将剩余的所有内容整个作为 1 片。</li>
</ul>
</li>
</ol>
</li>
</ul>
<ul>
<li><p><strong>案例分析</strong></p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">（1）输入目录中共有两个文件</span><br><span class="line">	file1.txt	320M</span><br><span class="line">	file2.txt	130M</span><br><span class="line">	</span><br><span class="line">（2）经过 FileInputFormat 切片后，形成的切片信息如下：</span><br><span class="line">	file1.txt.split1 --- 0~128M</span><br><span class="line">	file1.txt.split2 --- 128~256M</span><br><span class="line">	file1.txt.split3 --- 256~320M</span><br><span class="line">	file2.txt.split1 --- 0~130M</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="片和块的关系"><a href="#片和块的关系" class="headerlink" title="片和块的关系"></a><strong>片和块的关系</strong></h2><ul>
<li>  片（Split）：切片（Split）的过程发生在内存中，在运算 MapReduce 程序时，由于每个 MapTask 会负责一个 split 的运算，所以会临时的将某个目录下的所有文件划分为若干 split。但是实际上每个 split 中的数据还是以 block 的形式存储在 HDFS 中的。</li>
<li>  块（Block）：在向 HDFS 中写文件时，文件中的内容以 block 为单位存储。块是实际的物理存在。</li>
<li>  MapTask 在读取切片的内容时，需要根据切片的 metainfo ，获取到当前切片属于文件的哪部分，再根据此信息去寻找对应的块，读取数据。</li>
</ul>
<p><strong>建议：</strong></p>
<p><img src="/2021/02/19/MapReduce/image-20211202170551898.png" alt="image-20211202170551898"></p>
<ul>
<li><p>片大小最好等于块大小。</p>
<blockquote>
<p>  因为每个片都会启动一个对应的 MapTask 进程，每个 MapTask 进程只能运行在一台服务器上，如果片大小不等于块大小，比如片大小为100M，块大小为128M，那么一个 MapTask 进程就可能要跨节点加载数据，这时产生的网络IO和磁盘IO代价是非常大的。如果片大小等于块大小，就不会出现跨节点加载数据的过程，可以节省网络IO的时间。</p>
</blockquote>
</li>
<li><p>  MapReduce 程序速度慢的原因在于执行时，会频繁发生磁盘 IO 和网络 IO。比如在 map 阶段，需要先将磁盘中的文件读取到内存中进行运算，运算结束后还需要将阶段性的运算结果写出到磁盘上；这个运算结果还可能需要通过网络传输到集群中的其它节点上进行 reduce 阶段的运算，reduce 阶段同样需要把磁盘上的文件（map 阶段的运算结果文件）加载到内存中运算，运算结束后再将运算结果写出到磁盘上。</p>
</li>
<li><p>  将片大小设置为和块大小一致，可以最大限度减少因为切片带来的磁盘 IO 和网络 IO。</p>
</li>
</ul>
<hr>
<p><img src="/2021/02/19/MapReduce/image-20211202173603095.png" alt="image-20211202173603095"></p>
<hr>
<h2 id="CombineTextInputFormat切片机制"><a href="#CombineTextInputFormat切片机制" class="headerlink" title="CombineTextInputFormat切片机制"></a>CombineTextInputFormat切片机制</h2><p>框架默认的TextInputformat切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个MapTask，这样如果有大量小文件，就会产生大量的MapTask，处理效率极其低下。</p>
<p><strong>一、应用场景：</strong></p>
<p><code>CombineTextInputFormat</code> 用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p>
<p><strong>二、虚拟存储切片最大值设置</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);	<span class="comment">// 4m</span></span><br></pre></td></tr></table></figure>

<ul>
<li>  虚拟存储切片最大值设置可以根据实际的小文件大小情况来设置具体的值。</li>
</ul>
<p><strong>三、切片机制</strong></p>
<p>生成切片过程包括：<strong>虚拟存储过程</strong>和<strong>切片过程</strong>两部分。</p>
<ol>
<li><p><strong>虚拟存储过程：</strong></p>
<ul>
<li>  （a）将输入目录下所有文件按照文件名称字典顺序一次读入，记录文件大小，并累加计算所有文件的总长度。</li>
<li>  （b）根据是否设置 <code>setMaxInputSplitSize</code> 值，将每个文件划分成一个一个 <code>setMaxInputSplitSize</code> 值大小的文件。</li>
<li>  （c）注意：当剩余数据大小超过 <code>setMaxInputSplitSize</code> 值且不大于2倍 <code>setMaxInputSplitSize</code> 值，此时将文件均分成2个虚拟存储块（防止出现太小切片）。</li>
<li>  例如 <code>setMaxInputSplitSize</code> 值为4M，最后文件剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。</li>
</ul>
</li>
<li><p><strong>切片过程：</strong></p>
<ul>
<li><p>  （a）判断虚拟存储的文件大小是否大于 <code>setMaxInputSplitSize</code> 值，大于等于则单独形成一个切片。</p>
</li>
<li><p>  （b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</p>
</li>
<li><p>（c）测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）</span><br><span class="line"></span><br><span class="line">最终会形成3个切片，大小分别为：</span><br><span class="line"></span><br><span class="line">（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<hr>
<h2 id="CombineTextInputFormat-案例实操"><a href="#CombineTextInputFormat-案例实操" class="headerlink" title="CombineTextInputFormat 案例实操"></a>CombineTextInputFormat 案例实操</h2><ol>
<li><p>需求</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">将输入的大量小文件合并成一个切片统一处理。</span><br><span class="line"></span><br><span class="line">（1）输入数据</span><br><span class="line">	准备4个小文件</span><br><span class="line">（2）期望</span><br><span class="line">	期望一个切片处理4个文件</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h1 id="InputFormat-数据输入"><a href="#InputFormat-数据输入" class="headerlink" title="InputFormat 数据输入"></a>InputFormat 数据输入</h1><h2 id="FileInputFormat-接口"><a href="#FileInputFormat-接口" class="headerlink" title="FileInputFormat 接口"></a>FileInputFormat 接口</h2><p>MapReduce 任务的输入文件一般都存储在 HDFS 里面。常见的输入文件格式包括：<strong>基于行的日志文件、二进制格式文件等</strong>。这些文件一般会很大，达到数十GB，甚至更大。那么MapReduce是如何读取这些数据的呢？下面我们首先学习 FileInputFormat 接口。</p>
<p>FileInputFormat 常见的接口实现类包括：</p>
<ul>
<li>  TextInputFormat</li>
<li>  KeyValueTextInputFormat</li>
<li>  NLineInputFormat</li>
<li>  CombineTextInputFormat</li>
<li>  自定义 InputFormat </li>
</ul>
<hr>
<h2 id="FileInputFormat-实现类"><a href="#FileInputFormat-实现类" class="headerlink" title="FileInputFormat 实现类"></a>FileInputFormat 实现类</h2><h3 id="TextInputFormat"><a href="#TextInputFormat" class="headerlink" title="TextInputFormat"></a>TextInputFormat</h3><ul>
<li><p>  使用场景：TextInputFormat 是默认的 InputFormat，常用于输入目录中全是文本文件的场景。</p>
</li>
<li><p>  切片策略：使用默认的切片策略。</p>
</li>
<li><p>RecordReader：使用的实现类是<code>LineRecordReader</code>，一次处理一行数据，以行头的偏移量为 key，该行内容作为 value。</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LineRecordReader</span><br><span class="line">	LongWritable key	<span class="comment">// 存储该行在整个文件中的起始字节偏移量	</span></span><br><span class="line">	Text value	<span class="comment">// 该行的内容</span></span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h3 id="NLineInputFormat"><a href="#NLineInputFormat" class="headerlink" title="NLineInputFormat"></a>NLineInputFormat</h3><ul>
<li><p>  使用场景：常用于输入目录中全是文本文件的场景。适合一行的内容特别多，在 Map 阶段 map() 的处理逻辑非常负责，可以根据行数自定义切片的大小。</p>
</li>
<li><p>  切片策略：以文件为单位，每 N 行作为一个切片。</p>
</li>
<li><p>RecordReader：使用的实现类是<code>LineRecordReader</code>，一次处理一行数据，以行头的偏移量为 key，该行内容作为 value。</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LineRecordReader</span><br><span class="line">	LongWritable key</span><br><span class="line">	Text value</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h3 id="KeyValueTextInputFormat"><a href="#KeyValueTextInputFormat" class="headerlink" title="KeyValueTextInputFormat"></a>KeyValueTextInputFormat</h3><ul>
<li><p>  使用场景：常用于输入目录中全是文本文件的场景。使用分隔字符，将每一行的内容分割为 key 和 value。如果没有找到分隔符，则以当前行的内容作为 key，value 为空串。默认的分隔符为 <code>\t</code>，可以通过参数<code>mapreduce.input.keyvaluelinerecordreader.key.value.separator</code> 显式指定分隔符。</p>
</li>
<li><p>  切片策略：使用默认的切片策略。</p>
</li>
<li><p>RecordReader：使用的实现类是 <code>KeyValueLineRecordReader</code></p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">KeyValueLineRecordReader</span><br><span class="line">    Text key	分隔符之前的内容</span><br><span class="line">    Text value	分隔符之后的内容</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h3 id="CombineTextInputFormat"><a href="#CombineTextInputFormat" class="headerlink" title="CombineTextInputFormat"></a>CombineTextInputFormat</h3><p>框架默认的 <code>TextInputformat</code> 切片机制是以文件为单位，在文件内按照块大小对文件进行切片。也就是说不管文件多小，都会是一个单独的切片，都会交给一个 MapTask，这样如果有大量小文件，就会产生大量的 MapTask，处理效率极其低下。</p>
<ul>
<li><p>  应用场景：<code>CombineTextInputFormat</code> 改变了传统的切片方式，它将多个小文件划分到一个切片中，这样多个小文件就可以交给一个 MapTask 处理，适合小文件较多的场景。</p>
</li>
<li><p>  切片策略：多个小文件划分到一个切片中。根据 maxSize 对每个文件进行逻辑切片，切分为若干 part，将多个 part 组合，直到超过 maxSize，这些 part 作为一个切片。1hu</p>
</li>
<li><p>RecordReader：使用的实现类是<code>LineRecordReader</code>，一次处理一行数据，以行头的偏移量为 key，该行内容作为 value。</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LineRecordReader</span><br><span class="line">	LongWritable key</span><br><span class="line">	Text value</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h3 id="自定义-InputFormat-实现类"><a href="#自定义-InputFormat-实现类" class="headerlink" title="自定义 InputFormat 实现类"></a>自定义 InputFormat 实现类</h3><p>在开发中，Hadoop 框架自带的 InputFormat 类型并不能满足所有的应用场景，有时还需要通过自定义 InputFormat 来解决实际问题。</p>
<p>无论是 HDFS 还是 MapReduce，在处理小文件时效率都非常低，但又难免面临处理大量小文件的场景，此时，就需要有相应解决方案。可以自定义 InputFormat 实现小文件的合并。</p>
<p><strong>一、需求</strong></p>
<p>将多个小文件合并成一个 <code>SequenceFile</code> 文件（SequenceFile 文件是 Hadoop 用来存储二进制形式的 <code>key-value</code> 对的文件格式），SequenceFile 里面存储着多个文件，存储的形式为：<code>文件路径+文件名 = key</code>，<code>文件内容=value</code>。</p>
<p><img src="/2021/02/19/MapReduce/image-20211202202010080.png" alt="image-20211202202010080"></p>
<p><strong>二、需求分析</strong></p>
<ol>
<li>自定义一个类继承 FileInputFormat<ul>
<li>  （1）重写 <code>isSplitable()</code> 方法，返回 false 表示单个文件不可被切片</li>
<li>  （2）重写 <code>createRecordReader()</code> 方法，返回自定义的 RecordReader 对象。</li>
</ul>
</li>
<li>重写 RecordReader，实现一次读取一个完整的文件并按照一定的规则封装为<code>&lt;K,V&gt;</code>对象<ul>
<li>  （1）采用 IO 流一次读取一个完整的文件输出到 value 中。（因为设置了文件不可被切片，所以每次都会读取一整个文件封装到 value 中）</li>
<li>  （2）获取 <code>文件路径信息+名称</code>，作为 key </li>
</ul>
</li>
<li> 默认的输出格式是 <code>TextOutputFormat</code>（文本的输出格式），由于我们要将文件输出为 <code>SequenceFile</code> 文件，所以需要将最终的输出格式设置为<code>SequnceFileOutputFormat</code></li>
</ol>
<p><strong>三、程序实现</strong></p>
<hr>
<h2 id="关键设置"><a href="#关键设置" class="headerlink" title="关键设置"></a>关键设置</h2><p>如何设置 MapTask 的数量？</p>
<ul>
<li>  MapTask 的数量，人为设置是无效的，只能由切片数来决定。</li>
</ul>
<h1 id="Job-提交流程阶段总结"><a href="#Job-提交流程阶段总结" class="headerlink" title="Job 提交流程阶段总结"></a>Job 提交流程阶段总结</h1><h2 id="Job提交流程源码"><a href="#Job提交流程源码" class="headerlink" title="Job提交流程源码"></a>Job提交流程源码</h2><blockquote>
<p>  Job提交流程源码详解</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 提交job</span></span><br><span class="line">waitForCompletion()</span><br><span class="line"></span><br><span class="line"><span class="comment">// --&gt;</span></span><br><span class="line">submit();</span><br><span class="line"></span><br><span class="line"><span class="comment">// --&gt;</span></span><br><span class="line"><span class="comment">// 1、建立连接</span></span><br><span class="line">connect();  </span><br><span class="line">    <span class="comment">// （1）加载配置，创建提交Job的代理</span></span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Cluster</span>(getConfiguration());</span><br><span class="line">    <span class="comment">// （2）判断是本地yarn还是远程</span></span><br><span class="line">    initialize(jobTrackAddr, conf); </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2、提交job</span></span><br><span class="line">submitter.submitJobInternal(Job.<span class="built_in">this</span>, cluster)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// （1）创建给集群提交数据的Stag路径</span></span><br><span class="line">  <span class="type">Path</span> <span class="variable">jobStagingArea</span> <span class="operator">=</span> JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line">  <span class="comment">// （2）获取jobId ，并创建Job路径</span></span><br><span class="line">  <span class="type">JobID</span> <span class="variable">jobId</span> <span class="operator">=</span> submitClient.getNewJobID();</span><br><span class="line">  <span class="comment">// （3）拷贝jar包到集群</span></span><br><span class="line">  copyAndConfigureFiles(job, submitJobDir);  </span><br><span class="line">  rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line">  <span class="comment">// （4）计算切片，生成切片规划文件</span></span><br><span class="line">  writeSplits(job, submitJobDir);</span><br><span class="line">  maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line">  input.getSplits(job);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// （5）向Stag路径写XML配置文件</span></span><br><span class="line">  writeConf(conf, submitJobFile);</span><br><span class="line">  conf.writeXml(out);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// （6）提交Job,返回提交状态</span></span><br><span class="line">  status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h2><p>一、准备阶段</p>
<p>运行 <code>Job.waitForCompletion()</code>，先使用 JobSubmitter 提交 Job，在提交之前，会在 Job 的作业目录中生成以下信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">job.split: 当前Job的切片信息，有几个切片对象</span><br><span class="line">job.splitmetainfo: 切片对象的属性信息</span><br><span class="line">job.xml: job所有的属性配置</span><br></pre></td></tr></table></figure>



<p>二、提交阶段</p>
<ol>
<li><p>LocalJobRunner 进行提交</p>
<ul>
<li>  创建一个 LocalJobRunner.job()</li>
<li>  <code>Job.start()</code>   启动线程</li>
</ul>
</li>
<li><p>Map 阶段</p>
<ul>
<li>  采用线程池提交多个MapTaskRunable线程！</li>
<li>  每个MapTaskRunable线程上，实例化一个MapTask对象！</li>
<li>  每个MapTask对象，实例化一个Mapper!</li>
<li>  Mapper.run()</li>
<li>  线程运行结束，会在线程的作业目录中生成 file.out文件，保存MapTask输出的所有的key-value!</li>
</ul>
</li>
<li><p>Reduce 阶段</p>
<ul>
<li>  采用线程池提交多个ReduceTaskRunable线程！</li>
<li>  每个ReduceTaskRunable线程上，实例化一个ReduceTask对象！</li>
<li>  每个ReduceTask对象，实例化一个Reduce!</li>
<li>  reducer.run()</li>
<li>  线程运行结束，会在输出目录中生成 part-r-000x 文件，保存 ReduceTask 输出的所有的key-value!</li>
</ul>
<p>  阶段定义： </p>
<ul>
<li>  copy：使用 shuffle 线程拷贝 MapTask 对应分区中的数据！</li>
<li>  sort: 将拷贝的所有的分区的数据汇总后，排序</li>
<li>  reduce：对排好序的数据，进行合并！</li>
</ul>
</li>
</ol>
<hr>
<h1 id="Shuffle-机制"><a href="#Shuffle-机制" class="headerlink" title="Shuffle 机制"></a>Shuffle 机制</h1><p>MapReduce 为了确保 Reducer 阶段每个输入数据都是按 key 排序的，会执行多次排序的过程，这个阶段被称为 Shuffle 阶段。</p>
<p>从 Mapper 出去到 Reducer 接收之前全部都是 Shuffle 的范围。</p>
<h2 id="MapTask-工作机制"><a href="#MapTask-工作机制" class="headerlink" title="MapTask 工作机制"></a>MapTask 工作机制</h2><p><img src="/2021/02/19/MapReduce/image-20211203123841956.png" alt="image-20211203123841956"></p>
<p><strong>一、MapTask 的两个阶段（官方定义）</strong></p>
<p>MapTask 的执行过程大致可分为两个阶段：</p>
<ol>
<li> map 阶段：<code>Mapper.map()</code> 方法中在执行 <code>context.write(keyout, valueout)</code> 之前都属于 map 阶段；</li>
<li> sort 阶段：只有当存在 ReduceTask 时才会有 sort 阶段</li>
</ol>
<p><code>Mapper#map()</code> 方法是一个会循环执行的方法，在该方法中会调用 <code>context.write(keyout, valueout)</code> 方法将当前次处理的 <code>&lt;keyout. valueout&gt;</code> 写出到磁盘上。当然写出到磁盘上是最终目的，在真正执行的时候，肯定是先把一个个键值对对象先保存到一个缓冲区中，等到缓冲区快满的时候再写出到磁盘上。</p>
<p>每条记录在写入缓冲区时，会先调用<strong>分区器（Partitioner）</strong>为当前记录分配一个区号。</p>
<p>缓冲区中记录的顺序是按照进入缓冲区的先后时间来排序的，也就是说进入的越早，分配到的索引（index）就越小，第一个进入缓冲区的记录分配到的 index 就是 0，之后依次自增。</p>
<p>缓冲区也是一块内存，对于其中的每条记录，寻址方式就是偏移量。从缓冲区内存的开始位置起（偏移量从0开始），每条记录 key 的偏移量记为 <code>keystart</code>，值的偏移量记为 <code>valuestart</code>。</p>
<p>缓冲区中每条记录的数据格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">索引（序号）	分区号		 key偏移量		value偏移量	key的值	  value的值</span><br><span class="line">index		partition	keystart	  valuestart	  key		  value 		unsued</span><br></pre></td></tr></table></figure>

<p>缓冲区有两个线程，一个为收集线程，收集线程负责将Mapper写出的<code>&lt;K,V&gt;</code> 记录收集到缓冲区。另一个为溢写线程，溢写线程会在缓冲区已经占满了80%时被唤醒，唤醒后负责将缓冲区收集的数据溢写到磁盘。</p>
<p>一旦缓冲区满足了溢写条件后，会先对缓冲区中的所有数据进行一次排序。排序是按照 key 进行升序排序（数字大小升序或字典升序）。排序时，只对索引进行排序，而不会真实移动数据的位置。</p>
<p>排序完成之后，接下来就需要对数据进行溢写，溢写数据的时候会按照分区将数据写出到不同的区。每次溢写都会生成一个临时文件 <code>spillx.out</code>，在一次 MapReduce 中，可能会发生多次溢写（因为每次缓冲区快满的时候就会溢写一次），生成多个临时文件。当 map 阶段执行结束时，缓冲区中的最后一批数据会执行一次 flush（即使缓冲区没有达到要溢写的阈值）。</p>
<p>溢写结束后，会对生成的所有临时文件 <code>spillx.out</code> 执行一次 merge，将多个临时文件合并成一个最终结果。合并时，会将同一个分区的临时文件进行汇总，汇总后再进行排序，由于此时单个临时文件已经是有序的了，所以汇总之后的排序算法采用的是归并排序。在最终结果中，每个分区中的 <code>&lt;K,V&gt;</code> 记录都是有序的，并且会将最终文件写到 MapTask 所在机器磁盘上的某个文件中。等待 ReduceTask 的 Shuffle 线程来拷贝数据。</p>
<blockquote>
<p>  <strong>细节部分</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">① 先分区</span><br><span class="line"></span><br><span class="line">② 每次溢写前，都需要对缓冲区中的数据进行排序。</span><br><span class="line">	排序时，只排索引，不移动数据</span><br><span class="line">	使用的排序算法是快速排序</span><br><span class="line"></span><br><span class="line">③ 合并多个溢写临时文件为最终的文件时，先汇总后排序，排序算法使用归并排序</span><br></pre></td></tr></table></figure>





<hr>
<h2 id="Partition-分区"><a href="#Partition-分区" class="headerlink" title="Partition 分区"></a>Partition 分区</h2><p><strong>一、问题引出</strong></p>
<p>要求<strong>将统计结果按照条件输出到不同的文件中</strong>（分区），比如：将统计结果按照手机归属地不同省份输出到不同文件中。</p>
<p>二、默认 Partition 分区</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HashPartitioner</span>&lt;K2, V2&gt; <span class="keyword">implements</span> <span class="title class_">Partitioner</span>&lt;K2, V2&gt; &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(K2 key, V2 value, <span class="type">int</span> numReduceTasks)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (key.hashCode() &amp; <span class="number">2147483647</span>) % numReduceTasks;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>  默认分区是根据 key 的 hashCode 对 ReduceTasks 个数取模得到的。</li>
</ul>
<p><strong>三、自定义 Partition 步骤</strong></p>
<ol>
<li><p>自定义实现类继承 Partitioner，重写 <code>getPartition</code> 方法</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text text, FlowBean flowBean, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">        <span class="comment">// TODO 控制分区的代码</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
<li><p>在 Job 驱动中，将分区器置换为自定义的 Partitioner</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setPartitionerClass(MyPartitioner.class);</span><br></pre></td></tr></table></figure>

</li>
<li><p>自定义 Partition 后，要根据自定义 Partitioner 的逻辑设置相应数量的 ReduceTask</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p><strong>四、小总结</strong></p>
<ol>
<li> 如果 <code>ReduceTask的数量 &gt; getPartition的结果数</code>，则会多产生几个空的输出文件 <code>part-r-000xx</code>；</li>
<li> 如果 <code>1 &lt; ReduceTask的数量 &lt; getPartitioner的结果数</code>，则会有一部分数据无处安放，会抛出 Exception；</li>
<li> 如果 <code>ReduceTask的数量=1</code>，则不管 MapTask 端输出多少个分区文件，最终结果都会交给这一个 ReduceTask，最终也就只会产生一个结果文件 <code>part-r-0000</code>。</li>
</ol>
<hr>
<h3 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h3><hr>
<h2 id="WriteComparable-排序"><a href="#WriteComparable-排序" class="headerlink" title="WriteComparable 排序"></a>WriteComparable 排序</h2><h3 id="排序概述"><a href="#排序概述" class="headerlink" title="排序概述"></a>排序概述</h3><p>排序是 MapReduce 框架中最重要的操作之一。</p>
<p>MapTask 和 ReduceTask 均会对数据按照 key 进行排序。该操作属于 Hadoop 的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。</p>
<p>默认排序方式是按照字典顺序排序，且实现该排序的方法是快速排序。</p>
<p>对于 MapTask，它会将处理的结果暂时放到一个缓冲区中，当缓冲区使用率达到一定阈值后（溢写阈值），再对缓冲区中的数据进行一次排序，并将这些有序数据写到磁盘上，而当数据处理完毕后，它会对磁盘上所有文件进行一次合并，以将这些文件合并成一个大的有序文件。</p>
<p>对于 ReduceTask，它从每个 MapTask 所在的服务器上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则放到磁盘上，否则放到内存中。如果磁盘上文件数目达到一定阈值，则进行一次合并以生成一个更大的文件；如果内存中文件大小或数目超过一定阈值，则进行一次合并后将数据写到磁盘上。当所有数据拷贝完毕后，ReduceTask 统一对内存和磁盘上的所有数据进行一次归并排序。</p>
<hr>
<h3 id="排序分类"><a href="#排序分类" class="headerlink" title="排序分类"></a>排序分类</h3><p>一、部分排序</p>
<p>MapReduce 根据输入记录的键对数据集排序，保证输出的每个文件内部有序。</p>
<p>二、全排序</p>
<p>最终输出结果只有一个文件，且文件内部有序。实现方式是只设置一个 ReduceTask。但该方法在处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了 MapReduce 所提供的并行架构。</p>
<p>三、辅助排序</p>
<p>四、二次排序</p>
<hr>
<h3 id="自定义排序"><a href="#自定义排序" class="headerlink" title="自定义排序"></a>自定义排序</h3><p><strong>一、原理</strong></p>
<p>bean 对象实现 <code>WritableComparable</code> 接口，重写接口中的 <code>compareTo</code> 方法，就可以实现自定义排序</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line">	<span class="comment">// 倒序排列，从大到小</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">this</span>.sumFlow &gt; o.getSumFlow() ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="Combiner-合并"><a href="#Combiner-合并" class="headerlink" title="Combiner 合并"></a>Combiner 合并</h2><ol>
<li> Combiner 是 MR 程序中 Mapper 和 Reducer 之外的另一种组件；</li>
<li> Combiner 组件的父类就是 Reducer；</li>
<li>Combiner 和 Reducer 的区别在于运行的位置：<ul>
<li>  Reducer 是在 reduce 阶段调用，Combiner 是在 shuffle 阶段调用；</li>
<li>  Combiner 是在每一个 MapTask 所在的节点运行；</li>
<li>  Reducer 是接收全局所有 Mapper 的输出结果。</li>
<li>  Combiner 和 Reducer 本质上都是 Reducer 类，作用都是对有相同 key 的 <code>&lt;K,V&gt;</code> 进行合并。 </li>
</ul>
</li>
<li> Combiner 的意义就是对每一个 MapTask 的输出结果进行局部汇总，以减少网络传输量。</li>
<li> Combiner 能够应用的前提是不影响最终的业务逻辑，而且，Combiner 的输出 <code>&lt;K,V&gt;</code> 应该和 Reducer 的输入 <code>&lt;K,V&gt;</code> 类型对应起来。</li>
</ol>
<h3 id="自定义-Combiner-实现步骤"><a href="#自定义-Combiner-实现步骤" class="headerlink" title="自定义 Combiner 实现步骤"></a>自定义 Combiner 实现步骤</h3><ol>
<li><p>自定义一个 Combiner 继承 Reducer，重写 reduce 方法</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 汇总操作</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span>(IntWritable v :values)&#123;</span><br><span class="line">			count += v.get();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 写出</span></span><br><span class="line">        context.write(key, <span class="keyword">new</span> <span class="title class_">IntWritable</span>(count));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
<li><p>在 Job 驱动类中设置</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(MyCombiner.class);</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="GroupingComparator分组（辅助排序）"><a href="#GroupingComparator分组（辅助排序）" class="headerlink" title="GroupingComparator分组（辅助排序）"></a>GroupingComparator分组（辅助排序）</h2><p>对Reduce阶段的数据根据某一个或几个字段进行分组。</p>
<h3 id="GroupingComparator分组案例实操"><a href="#GroupingComparator分组案例实操" class="headerlink" title="GroupingComparator分组案例实操"></a>GroupingComparator分组案例实操</h3><hr>
<p>移动计算而不是移动数据【目的：减少磁盘IO和网络IO】</p>
<blockquote>
<p>  Shuffle 阶段数据发生了关键的变化：</p>
</blockquote>
<ol>
<li> 从 Mapper 出去的 &lt;K，V&gt; 值是无序的，而到了 Reducer 中数据则是有分组的。 也就是说，在 Shuffle 阶段会将数据整理、分组。</li>
<li> Mapper 出来的数据是无序的，在 Shuffle 阶段首先对数据进行排序，排完序之后，相等的数据就挨在一起了，再进行分组就相对容易了。</li>
<li>排序方法：快排 + 归并<ul>
<li>  对于快速排序来说，需要将所有的数据全部加载进内存中然后再进行比较；但是对于大数据而言，显然是不合理的。所以会先将大数据的切分，对每一块数据进行快排。</li>
<li>  然后再将多个有序块再进行归并排序。</li>
</ul>
</li>
<li> 数据会被分片（逻辑上），每一个片对应一个 MapTask 。每个 MapTask 都会进行排序，最终形成一个归并排序后的有序数据块，这些数据块最终又会汇总到一个 Reducer 中。Reducer 在拿到多个有序文件后，再进行一次归并让多个有序文件变成一个有序文件，最终输入到 Reducer 中。</li>
<li> 这就是 Shuffle 阶段如何把数据进行排序、分组的过程。</li>
</ol>
<ul>
<li>三次排序：<ol>
<li> 快排</li>
<li> 归并</li>
<li> 再次归并</li>
</ol>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/02/10/Hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/02/10/Hadoop/" class="post-title-link" itemprop="url">Hadoop理论基础</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-02-10 10:49:09" itemprop="dateCreated datePublished" datetime="2021-02-10T10:49:09+08:00">2021-02-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-12-14 16:52:33" itemprop="dateModified" datetime="2021-12-14T16:52:33+08:00">2021-12-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><blockquote>
<p>大数据（Big Data）：</p>
</blockquote>
<p>大数据指<strong>无法在一定时间范围内</strong>用常规软件工具进行捕捉、管理和处理的数据集合。是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的<strong>海量、高增长率和多样化的信息资产</strong>。</p>
<ul>
<li><strong>多样化</strong>：传统的数据库如 MySQL 只能处理结构化的数据类型，而大数据不仅可以处理结构化的数据，还可以处理非结构化、半结构化的数据。</li>
</ul>
<blockquote>
<p>大数据技术/大数据框架：</p>
</blockquote>
<p>主要解决，海量数据的<strong>存储</strong>和海量数据的<strong>分析计算</strong>问题。</p>
<blockquote>
<p>大数据特点：</p>
</blockquote>
<ol>
<li><p>Volume（大量）  </p>
</li>
<li><p>Velocity（高速）</p>
</li>
<li><p>Variety（多样）</p>
</li>
<li><p>Value（低价值密度）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">因为低价值密度的特点，所以需要：</span><br><span class="line">    （1）我们的计算机有足够好的算力；</span><br><span class="line">    （2）优良的算法。</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><blockquote>
<p>Hadoop 设计的初衷是采用大量廉价的机器，组成一个集群！完成大数据的存储和计算！[通过数量的堆叠来提高算力]</p>
</blockquote>
<h2 id="Hadoop-是什么"><a href="#Hadoop-是什么" class="headerlink" title="Hadoop 是什么"></a>Hadoop 是什么</h2><ul>
<li>Hadoop 是一个由 Apache 基金会所开发的<strong>分布式系统基础架构</strong>。【分布式 ==&gt; 多台机器】</li>
<li>主要解决，海量数据的<strong>存储</strong>和海量数据的<strong>分析计算</strong>问题。</li>
<li>狭义上来说，单指 Hadoop 技术。</li>
<li>广义上来说，Hadoop 通常是指一个更广泛的概念——<strong>Hadoop 生态圈</strong></li>
</ul>
<p><img src="/2021/02/10/Hadoop/image-20210210110619991.png" alt="image-20210210110619991"></p>
<hr>
<h2 id="Hadoop-的优点（4高）"><a href="#Hadoop-的优点（4高）" class="headerlink" title="Hadoop 的优点（4高）"></a>Hadoop 的优点（4高）</h2><ol>
<li><p><strong>高可靠性</strong></p>
<p> Hadoop 底层维护多个数据副本，所以即使某个存储节点出现故障（即使 Hadoop 集群中的某个数据副本所在的节点出现故障），也不会导致数据的丢失。</p>
<p> 而且 Hadoop 会实时动态的监测集群中的节点数量，如果集群中的某个节点发生故障导致副本数小于集群预设的副本数，那么 Hadoop 就会自动创建一个新的副本，维护副本数量等于预设的副本数量。</p>
</li>
<li><p><strong>高扩展性</strong></p>
<p> 在集群间分配任务数据，可方便的扩展数以千计的节点。</p>
<p> 在处理数据时如果发现集群中的节点不够使用了，可以很方便的增加一些节点扩展整个 Hadoop 集群。</p>
</li>
<li><p><strong>高效性</strong></p>
<p> 在 MapReduce 的思想下，Hadoop 是并行工作的，通过多台机器数量的堆叠来提高算力，以加快任务处理速度。</p>
</li>
<li><p><strong>高容错性</strong></p>
<p> 能够自动将失败的任务重新分配。</p>
<p> Hadoop 在 Map 阶段会将大的任务分成若干个小的任务进行运算，如果在运算过程中某个小的任务因某些不可抗力因素发生失败，那么 Hadoop  就会重新分配一个线程来运行未成功的任务，直至成功。</p>
</li>
</ol>
<hr>
<h2 id="Hadoop-组件"><a href="#Hadoop-组件" class="headerlink" title="Hadoop 组件"></a>Hadoop 组件</h2><p><img src="/2021/02/10/Hadoop/image-20210210111631179.png" alt="image-20210210111631179"></p>
<ul>
<li>在 Hadoop1.x 时代，Hadoop 中的 MapReduce 同时负责业务运算和资源调度，耦合性较大；</li>
<li><strong>在 Hadoop2.x 时代，增加了 Yarn 。Yarn 只负责资源的调度，MapReduce 只负责运算。</strong></li>
</ul>
<h3 id="Hadoop-1-0"><a href="#Hadoop-1-0" class="headerlink" title="Hadoop 1.0"></a>Hadoop 1.0</h3><ul>
<li><strong>HDFS</strong>：负责存储数据</li>
<li><strong>Common</strong>：Hadoop 中常用工具包的模块。</li>
<li><strong>MapReduce</strong>：1️⃣编程模型；2️⃣负责计算资源的申请和调度。</li>
</ul>
<h3 id="Hadoop-2-0"><a href="#Hadoop-2-0" class="headerlink" title="Hadoop 2.0"></a>Hadoop 2.0</h3><ul>
<li><strong>HDFS</strong>：负责存储数据</li>
<li><strong>Common</strong>：Hadoop 中常用工具包的模块。</li>
<li><strong>YARN</strong>：只负责资源调度。[只有在计算时才会用到 YRAN ，因为在计算时需要申请软、硬件资源，都是由 YARN 统一分配的]</li>
<li><strong>MapReduce</strong>（编程模型）：使用 Hadoop 制定的编程规范要求，来编写程序，完成大数据的计算。</li>
</ul>
<h3 id="Hadoop-1-x-和-Hadoop-2-x-的区别"><a href="#Hadoop-1-x-和-Hadoop-2-x-的区别" class="headerlink" title="Hadoop 1.x 和 Hadoop 2.x 的区别"></a>Hadoop 1.x 和 Hadoop 2.x 的区别</h3><ul>
<li>  在 1.x 版本中，MapReduce 模块既负责规定 MR 程序规范还负责为 MR 程序申请运算资源，<strong>运算和资源申请是硬绑定的</strong>，所以 Hadoop 只能为符合 MR 编程规范的程序提供服务！</li>
<li>  在 2.x 版本中，MR 只负责 MR 程序的计算，资源的调度和管理由 YARN 负责！Hadoop 集群不仅能为自身的 MR 程序提供服务，还可以集成第三方计算引擎，例如 TeZ，Spark，Flink 等提供计算资源的调度服务！</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">完成Java程序运行 vs. 完成大数据的计算</span><br><span class="line"></span><br><span class="line">1、写程序，程序需要符合计算框架的要求！</span><br><span class="line">		java----&gt;main-----&gt;运行</span><br><span class="line">		MapReduce(编程模型)-----&gt;Map--Reducer</span><br><span class="line">2、运行程序，申请计算资源（软、硬件资源）</span><br><span class="line">		java-----&gt;JVM------&gt;OS-----&gt;申请计算资源</span><br><span class="line">		1.0: MapReduce(编程模型)----&gt;JobTracker-----&gt;JVM-----&gt;申请计算资源</span><br><span class="line">		2.0: MapReduce(编程模型)----&gt;jar------&gt;运行时，将jar包中的任务，提交给YARN，和YARN进行通信，由YARN中的组件-----&gt;JVM------&gt;申请计算资源</span><br><span class="line">				</span><br><span class="line">	1.x和2.x的区别是将资源调度和管理进行分离！由统一的资源调度平台YARN进行大数据计算资源的调度！</span><br><span class="line">    提升了Hadoop的通用性！Hadoop搭建的集群中的计算资源，不仅可以运行 Hadoop 中的 MR 程序！</span><br><span class="line">    也可以运行其他计算框架的程序！</span><br><span class="line">	在hadoop不久之后，由于MR的低效性，出现了许多更为高效的计算框架！</span><br><span class="line">	例如： Tez，Storm,Spark，Flink</span><br></pre></td></tr></table></figure>



<ol>
<li> <strong>编写代码</strong>。MapReduce 是一种编程规范，是一种编写代码的标准，如果想要我们写的程序能在 Hadoop 上运行就需要让自己编写的程序符合 MR 规范。</li>
<li> <strong>打成 jar 包</strong>。我们编写好了符合 MapReduce 规范的程序后（其实也就是 Java 程序），就会把这个程序打成 jar 包。这个 jar 包就是需要执行的任务的描述，在执行任务时，需要把 jar 包提交给 Yarn 由 Yarn 中的 ResourceManager 调度资源来执行这个 jar 包中的程序。</li>
</ol>
<hr>
<h1 id="HDFS-概述"><a href="#HDFS-概述" class="headerlink" title="HDFS 概述"></a>HDFS 概述</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://lvnengdong.github.io/2021/02/08/HDFS/">HDFS 详情页链接</a></p>
</blockquote>
<p>HDFS（Hadoop Distribute File System）：负责存储数据。</p>
<p><img src="/2021/02/10/Hadoop/HDFS%20%E6%A0%B8%E5%BF%83%E8%BF%9B%E7%A8%8B.png" alt="HDFS 核心进程"></p>
<h2 id="1、NameNode"><a href="#1、NameNode" class="headerlink" title="1、NameNode"></a>1、NameNode</h2><p>HDFS 是一个分布式文件存储系统，所谓的分布式，就是多台机器。我们知道在大数据环境下数据量能轻易达到 TB、PB 级别，如果想要在单台机器上存储这么多的数据是不实际的，所以就衍生出了分布式文件存储系统，将非常大的数据切割成多份小的数据，分别保存在不同的服务器上。</p>
<p>举个例子就是说如果一个文件大小为 1TB，但是目前提供的所有机器最大存储量都是 500GB，那么如果想要对该大文件进行存储，就必须对大文件进行分割，比如使用 ABC 三台机器，A机器存第 0<del>300GB 的数据，B机器存第 300</del>600GB 的数据，C机器存第 600~1000GB 的数据，这样就成功解决了大文件的存储问题。</p>
<p>但是解决了存储问题后，我们还必须解决数据访问的问题。如果我们若想访问该文件中的某一部分数据，那么我们首先就要定位到这部分数据存储在哪台机器上，在分布式文件存储系统中，一定会有一个文件中保存了该系统中所有数据的分布情况信息，那么保存该文件的节点就叫做 <strong>NameNode</strong>，这个文件中保存的信息就叫做<strong>元数据</strong>。</p>
<p><strong>概念：</strong></p>
<ul>
<li>  NameNode（nn）：负责存储文件的<strong>元数据</strong>。</li>
<li>  <strong>元数据</strong>：文件的属性信息。如<strong>文件名、文件目录结构、文件属性</strong>（生成时间、副本数、文件权限），以及每个文件的<strong>块列表</strong>和<strong>块所在的DataNode</strong> 等。</li>
</ul>
<p><strong>职责：</strong></p>
<ol>
<li>接收客户端的请求，根据元数据信息将请求转发给对应的 DN。</li>
<li>接收 DN 的请求，实时更新元数据信息。[DN 会向 NN 上报当前节点中数据的变化情况]</li>
<li>向 DN 分配任务。</li>
</ol>
<hr>
<h2 id="2、DataNode"><a href="#2、DataNode" class="headerlink" title="2、DataNode"></a>2、DataNode</h2><p><strong>概念：</strong></p>
<ul>
<li>  DataNode（dn）：负责文件中数据的存储。</li>
<li>  在本地文件系统中<strong>存储文件块数据</strong>，以及<strong>块数据的校验和</strong>。</li>
</ul>
<p><strong>职责：</strong></p>
<ol>
<li>负责接收 NM 分配的任务。</li>
<li>负责数据块（block）的管理（读、写）</li>
</ol>
<hr>
<h2 id="3、SecondaryNameNode"><a href="#3、SecondaryNameNode" class="headerlink" title="3、SecondaryNameNode"></a>3、SecondaryNameNode</h2><p><strong>概念：</strong></p>
<ul>
<li>  SecondaryNameNode（2nn）：负责辅助 NameNode 工作！</li>
<li>  <strong>每隔一段时间对NameNode元数据备份</strong>。</li>
</ul>
<hr>
<h1 id="MapReduce-概述"><a href="#MapReduce-概述" class="headerlink" title="MapReduce 概述"></a>MapReduce 概述</h1><blockquote>
<p>  <a target="_blank" rel="noopener" href="https://lvnengdong.github.io/2021/02/19/MapReduce/">MapReduce详解</a></p>
</blockquote>
<p>MapReduce 是一种<strong>编程规范</strong>，将程序的运行划分成两个阶段，一个称为 Map 阶段，另一个称为 Reduce 阶段。在 Map 阶段和 Reduce 阶段分别启动多个进程负责程序的运算，这些进程称为 Task。在 Map 阶段启动的 Task 称为 MapTask，在 Reduce 阶段启动的 Task 称为 ReduceTask。</p>
<p><strong>一个符合 MapReduce 编程规范的程序被称为一个 Job，执行一个 Job 时会使用多个 Task。</strong>Job 就是一段任务代码，描述了任务应该怎么做，而 Task 则是一些线程，用于真正地执行 Job。</p>
<blockquote>
<p>  Job：任务</p>
<p>   Task：进程</p>
<p>  MRAppMaster：MapReduce 应用管理者，进程</p>
</blockquote>
<ul>
<li>遵循 MapReduce 编程规范编写的程序，打包后，被称为一个 <strong>Job</strong>。</li>
<li>Job 需要提交到 YARN 上，向 YARN 申请计算资源，分配 Task 执行 Job 。</li>
<li>在开始执行 Job 时，会先创建一个 MRAppMaster 进程，由这个进程和 ResourceManager 进行通信，为 Job 中的每个 Task 申请计算所需的资源。</li>
<li>Task 的请求，会被 ResourceManager 缓存到一个调度队列中，由 NodeManager 领取 Task，领取后 NodeManager 会根据 Task 的要求，提供计算资源；提供后，为了避免计算资源在当前 Task 使用时被其它的 Task 抢占，NodeManager 会将已分配的计算资源封装到一个容器（Container）中。Container 可以对计算资源进行隔离。</li>
<li>MrAppMaster 还负责监控 Job 中各个 Task 运行情况，进行容错管理！</li>
</ul>
<p>要求程序中有 Mapper（简单处理） 和 Reducer（合并）。</p>
<p>MapReduce将计算过程分为两个阶段：Map和Reduce</p>
<ul>
<li>Map阶段并行处理输入数据</li>
<li>Reduce阶段对Map结果进行汇总</li>
</ul>
<hr>
<h1 id="Yarn-架构概述"><a href="#Yarn-架构概述" class="headerlink" title="Yarn 架构概述"></a>Yarn 架构概述</h1><p>Yarn 负责集群中所有计算资源的管理和调度。</p>
<p>MapReduce 程序会被提交给 Yarn 中的 ResourceManager 上，相当于把一个计算任务交给 的 ResourceManager，ResourceManager 对于 MapReduce 而言就是一个黑盒，ResourceManager 怎么处理 MapReduce 不管</p>
<p>实际上 ResourceManager 在收到了 MapReduce 任务后，会把任务下发给 NodeManager 去执行，ResourceManager 自己是不会真正去执行这个任务的</p>
<p><strong>核心进程</strong></p>
<blockquote>
<ol>
<li>ResourceManager（1个）：负责整个集群上所有资源的管理调度</li>
</ol>
</blockquote>
<ul>
<li>职责<ol>
<li>接收客户端提交的 Job 任务，</li>
<li>向  NM 分配任务。</li>
<li>接收 NM 上报的资源信息。</li>
</ol>
</li>
</ul>
<blockquote>
<ol start="2">
<li>NodeManager（N个）：负责单台计算机上所有资源的管理调度</li>
</ol>
</blockquote>
<ul>
<li>职责：<ol>
<li>负责和 RM 进行通信，上报本机中的可用资源</li>
<li>负责领取 RM 分配的任务！</li>
<li>负责为 Job 中的每个 Task 分配计算资源！</li>
</ol>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">计算资源：内存、CPU、硬盘等等。</span><br><span class="line"></span><br><span class="line">1、NM 负责单台计算机所有计算资源的管理调度。	</span><br><span class="line">	* 即 NM 会统计出当前计算机已经使用了多少计算资源，还剩多少资源。</span><br><span class="line">2、RM 负责整个集群所有计算资源的管理调度。	</span><br><span class="line">	* 即每台 NM 统计出自己已使用和可使用的计算资源后，都会上报给 RM 。</span><br><span class="line">	* RM 接收并统计集群中所有已使用和可使用计算资源。	</span><br><span class="line">	* 这样当客户端提交 Job 请求时，RM 就可宏观调控根据需求分配具体的计算资源到每台机器上。 </span><br></pre></td></tr></table></figure>



<p><strong>概念</strong>：</p>
<blockquote>
<p>Container（容器）：</p>
</blockquote>
<p>比如：NodeManager 为 Job 的某个 Task 分配了 2 个 CPU 和 2G 内存的计算资源！</p>
<p>为了防止当前 Task 在使用这些资源期间，被其它的 Task 抢占资源。 NodeManager 就会将这些计算资源，封装到一个 Container 中，在 Container 中的资源，会被暂时隔离，无法被其它进程所抢占。</p>
<p>当前 Task 运行结束后，当前 Container 中的资源才会被释放！允许其它 task 来 使用！</p>
<p><img src="/2021/02/10/Hadoop/image-20210210113413297.png" alt="image-20210210113413297"></p>
<blockquote>
<ol>
<li>ResourceManager（RM）</li>
</ol>
</blockquote>
<ol>
<li>处理客户端请求</li>
<li>监控NodeManager</li>
<li>启动或监控ApplicationMaster</li>
<li>资源的分配与调度</li>
</ol>
<blockquote>
<ol start="2">
<li>NodeManager（NM）</li>
</ol>
</blockquote>
<ol>
<li>管理单个节点上的资源</li>
<li>处理来自ResourceManager的命令</li>
<li>处理来自ApplicationMaster的命令</li>
</ol>
<blockquote>
<ol start="3">
<li>ApplicationMaster（AM）</li>
</ol>
</blockquote>
<ol>
<li>负责数据的切分</li>
<li>为应用程序申请资源并分配给内部的任务</li>
<li>任务的监控与容错</li>
</ol>
<blockquote>
<ol start="4">
<li>Container</li>
</ol>
</blockquote>
<p>Container 是YARN中的资源抽象，它封装了某个节点上的多维度资源，<strong>如内存、CPU、磁盘、网络等</strong>。</p>
<hr>
<h1 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h1><p><img src="/2021/02/10/Hadoop/image-20210210114157414.png" alt="image-20210210114157414"></p>
<p>图中涉及的技术名词解释如下：</p>
<ol>
<li>Sqoop：Sqoop 是一款开源的工具，主要用于在 Hadoop、Hive 与传统的数据库（MySql）间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进到 Hadoop 的 HDFS 中，也可以将 HDFS 的数据导进到关系型数据库中。</li>
<li>Flume：Flume 是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume 支持在日志系统中定制各类数据发送方，用于收集数据； </li>
<li>Kafka：Kafka 是一种高吞吐量的分布式发布订阅消息系统； </li>
<li>Storm：Storm 用于“连续计算”，对数据流做连续查询，在计算时就将结果以流的形式输出给用户。</li>
<li>Spark：Spark 是当前最流行的开源大数据内存计算框架。可以基于 Hadoop 上存储的大数据进行计算。</li>
<li>Flink：Flink 是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。</li>
<li>Oozie：Oozie 是一个管理 Hdoop 作业（job）的工作流程调度管理系统。</li>
<li>Hbase：HBase 是一个分布式的、面向列的开源数据库。HBase 不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</li>
<li>Hive：Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的 SQL 查询功能，可以将 SQL 语句转换为 MapReduce 任务进行运行。 其优点是学习成本低，可以通过类 SQL 语句快速实现简单的 MapReduce 统计，不必开发专门的 MapReduce 应用，十分适合数据仓库的统计分析。</li>
<li>ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/02/08/HDFS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/02/08/HDFS/" class="post-title-link" itemprop="url">HDFS</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-02-08 19:48:38" itemprop="dateCreated datePublished" datetime="2021-02-08T19:48:38+08:00">2021-02-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-12-14 17:17:41" itemprop="dateModified" datetime="2021-12-14T17:17:41+08:00">2021-12-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="HDFS-概述"><a href="#HDFS-概述" class="headerlink" title="HDFS 概述"></a>HDFS 概述</h1><h2 id="分布式文件管理系统"><a href="#分布式文件管理系统" class="headerlink" title="分布式文件管理系统"></a>分布式文件管理系统</h2><p>随着数据量越来越大，在一个机器上存不下所有的数据，就需要把数据分配到更多的机器中，但是这样又不方便管理和维护，所以我们迫切需要<strong>一种系统来管理多台机器上的文件</strong>，这就是分布式文件管理系统。HDFS 是分布式文件管理系统中的一种落地实现。</p>
<hr>
<h2 id="HDFS-定义"><a href="#HDFS-定义" class="headerlink" title="HDFS 定义"></a>HDFS 定义</h2><p><strong>HDFS（Hadoop Distribute FileSystem）</strong></p>
<ul>
<li>  Hadoop 分布式文件系统，本质上还是一个<strong>文件系统</strong>，即用来存储文件的系统。</li>
<li>  其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的每个服务器有各自的角色。</li>
<li>  HDFS 通过目录树来定位文件；</li>
</ul>
<hr>
<h2 id="HDFS-的使用场景"><a href="#HDFS-的使用场景" class="headerlink" title="HDFS 的使用场景"></a>HDFS 的使用场景</h2><p><strong>适合一次写入，多次读出的场景，且不支持文件的修改</strong>。适合用来做数据分析。</p>
<ul>
<li>  不支持对文件的随机写，即可以追加写，但是不能修改已写入的数据。</li>
</ul>
<hr>
<h2 id="HDFS-的优缺点"><a href="#HDFS-的优缺点" class="headerlink" title="HDFS 的优缺点"></a>HDFS 的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol>
<li><p><strong>高容错性</strong></p>
<ul>
<li>  （1）数据自动创建多个副本中。它通过增加副本的形式，提高容错性。</li>
</ul>
<p><img src="/2021/02/08/HDFS/image-20210219125213030.png" alt="image-20210219125213030"></p>
<ul>
<li>  （2）某一个副本丢失以后 ，它可以自动恢复，使副本数量维持预设置的数量。</li>
</ul>
<p><img src="/2021/02/08/HDFS/image-20210219125238273.png" alt="image-20210219125238273"></p>
<blockquote>
<p>  HDFS 的副本自动恢复机制：</p>
<ul>
<li>  如果 HDFS 集群中某个 DataNode 节点宕机，导致副本数据丢失，HDFS 会在集群中剩余的未保存该副本的机器中随机挑选一台机器保存该副本，维护副本数量与用户设定的副本数量一致或与节点数量一致。</li>
<li>  每个副本在每个节点上只能保存一份。如果用户预设置了保存10个副本，但是集群中只有 3 个 DataNode，那么当前集群中就只会有 3 个副本，但是当集群扩展到10台时，NameNode 就会自动在新的 DataNode 节点上创建新的副本，维护副本数量到10个。</li>
</ul>
</blockquote>
</li>
<li><p><strong>适合处理大数据</strong></p>
<p>（1）数据规模：能够处理的数据规模达到 GB、TB、甚至 PB 级别；</p>
<p>（2）文件规模：能够处理百万规模以上的文件数量，数量相当之大。</p>
</li>
<li><p>可构建在廉价机器上，通过多副本机制，提高可靠性。</p>
</li>
</ol>
<hr>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><h4 id="1、HDFS-不支持对文件的随机写"><a href="#1、HDFS-不支持对文件的随机写" class="headerlink" title="1、HDFS 不支持对文件的随机写"></a>1、HDFS 不支持对文件的随机写</h4><p>HDFS 仅支持对数据的追加写（append），不支持文件的随机修改。</p>
<p><strong>原因</strong>：</p>
<ol>
<li><p> HDFS 没有提供对文件的在线寻址（在线打开）功能，无法在线直接修改。如果想要修改就必须将文件下载到本地修改，修改完毕之后再上传到 HDFS 上，IO 代价很大。</p>
</li>
<li><p>文件在 HDFS 上存储时，以 block 为基本单位存储，如果修改了一个块中的内容，就会影响当前 block 之后的所有 block，效率很低。</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">假设有一文件 A.txt ，共 100W 行，200M。</span><br><span class="line">文件A在存储到 HDFS 上时按 block 分开存储，每块 128M 。</span><br><span class="line">200M 可分为2块存储，block1 存储0~128M，block2 存储128~200M。</span><br><span class="line">假设 block1 在 DataNode1 来存储，block2 在 DataNode2 存储，即这两块数据位于不同的磁盘上。</span><br><span class="line"></span><br><span class="line">现在有一需求需要修改第5W行的内容：</span><br><span class="line"><span class="code">	1、首先我们要找到第5W行在哪个位置，但是 HDFS 没有寻址的功能，HDFS 不支持在线打开，只支持</span></span><br><span class="line"><span class="code">	下载到本地之后再打开。所以压根就找不到第5W行在哪个位置。</span></span><br><span class="line"><span class="code">	2、即使 HDFS 能找到第5W行在哪个位置。 假设第5W行在第60M的位置，我们据此找到了 block1，现</span></span><br><span class="line"><span class="code">	在需求是删除4W~5W行内容，并在后面追加20W行数据。这时我们就会发现 block1 中的数据已经超过了</span></span><br><span class="line"><span class="code">	128M，就需要将block1中超过128M的内容顺延存储到 block2 中，那么 block2 中数据的存储位置需要</span></span><br><span class="line"><span class="code">	全部重写一遍。而且本例中只使用了2个block，如果涉及到了更多的block，那么当前block之后的所有block</span></span><br><span class="line"><span class="code">	都有可能需要重写，这一代价是非常高的。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="quote">&gt; 所以 HDFS 在设计之初就不支持对文件的随机写。</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="2、不适合低延时数据的访问"><a href="#2、不适合低延时数据的访问" class="headerlink" title="2、不适合低延时数据的访问"></a>2、不适合低延时数据的访问</h4><p>意思就是：如果我们想要能尽可能快的读写数据（即数据访问时延较低），使用 HDFS 是不合适的。比如毫秒级的读写数据，HDFS 是做不到的。一般处理少量的数据时，要求时延要尽可能地小，那么使用 HDFS 就是不适合的。</p>
<ul>
<li><p>比如你在本机打开一个文件，打开的速度是很快的；（不涉及到网络IO，只涉及到磁盘IO）</p>
</li>
<li><p>但是如果想要访问 HDFS 上存储的文件，它的速度是慢于本地打开的。（不仅涉及到网络IO，还涉及到磁盘IO）</p>
<blockquote>
<ul>
<li><p>  因为 HDFS 是分布式存储的，假设现在有一个 1G 的文件分为了8个block存储在 HDFS 上。</p>
</li>
<li><p>因为这 8 个 block 可能存储在集群的多个节点上（假设为[节点1：2个块]，[节点2：3个块]，[节点3：3个块]）：</p>
<p>  假设我们要下载这个文件，就需要请求这 3 台服务器将这 8 个 block 都下载下来。如果这三台机器所在的三个机房分为位于美国、上海、南极，那么客户端在请求这三台机器时首先就会涉及到网络 IO，客户端在打开时又要涉及到磁盘 IO。时效性较差，不适合低延时数据的访问。</p>
</li>
</ul>
</blockquote>
</li>
</ul>
<h4 id="3、不适合存储大量的小文件。"><a href="#3、不适合存储大量的小文件。" class="headerlink" title="3、不适合存储大量的小文件。"></a>3、不适合存储大量的小文件。</h4><p><strong>原因</strong>：</p>
<ol>
<li> 如果 HDFS 存储了大量的小文件，就会降低 NameNode 的服务能力！</li>
<li> 小文件存储的寻址时间会超过读取时间，它违反了 HDFS 的设计目标。</li>
</ol>
<p><strong>.eg</strong></p>
<p>NameNode 负责管理文件元数据信息，NameNode 在运行时，当有请求想要访问某个文件时，NameNode 必须将当前集群中存储的所有文件的元数据加载到内存进行检索，如果 NameNode 中存储了大量小文件的话，在加载时它会占用 NameNode 中部分内存来存储小文件的元数据信息。</p>
<p>例如：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">NameNode 的内存是有限的，假设 NameNode 内存中最大可以存储 1亿条元数据信息，</span><br><span class="line"><span class="code">	如果集群中全部存储 1k 的小文件的话，那么这个集群最大的存储能力是 1亿 * 1k ；</span></span><br><span class="line"><span class="code">	如果集群中全部存储 1G 的大文件的话，那么这个集群最大的存储能力是 1亿 * 1G ；</span></span><br><span class="line"><span class="code">	显然，存大文件时集群的存储能力呈指数级上升！</span></span><br></pre></td></tr></table></figure>





<h4 id="4、不支持并发写入、文件随机修改"><a href="#4、不支持并发写入、文件随机修改" class="headerlink" title="4、不支持并发写入、文件随机修改"></a>4、不支持并发写入、文件随机修改</h4><p>同一文件在同一时刻只能由一个线程写入，不允许多个线程同时写。假设线程 A 正在上传<code>ss.txt</code>文件，那么在线程 A 开始上传到结束之间，其它线程不能再上传<code>ss.txt</code>文件</p>
<p><img src="/2021/02/08/HDFS/image-20210225211305080.png" alt="image-20210225211305080"></p>
<hr>
<h2 id="HDFS-块大小"><a href="#HDFS-块大小" class="headerlink" title="HDFS 块大小"></a>HDFS 块大小</h2><p>HDFS 中的文件在物理上是分块存储（Block），块的大小由 <code>hdfs-default.xml </code>配置文件中的参数 <code>dfs.blocksize</code> 来决定。</p>
<ul>
<li>  在 Hadoop 2.x 中，默认值是<code>134217728</code>（128M）；</li>
<li>  在 Hadoop 1.x 中，默认值是 64M 。</li>
</ul>
<blockquote>
<ol>
<li> <strong>Hadoop 2.x 块大小默认为 128M 的原因</strong>：基于最佳传输损耗理论！</li>
</ol>
</blockquote>
<p><strong>最佳传输损耗理论</strong>：在一次传输中，寻址时间占总传输时间1%时，本次传输的损耗最小，为最佳性价比传输！</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> 不论对磁盘中的文件进行读还是写，首先要进行寻址！（寻找数据在磁盘中的哪个位置）</span><br><span class="line"><span class="bullet">-</span> 目前硬件的发展条件，普通磁盘写的速率大约为 100M/s，寻址时间大约为 10ms/次。</span><br><span class="line"><span class="code">    </span></span><br><span class="line"><span class="code">    根据 最佳传输损耗理论 ，总传输时间约为： 10ms / 1% = 1s</span></span><br><span class="line"><span class="code">    普通磁盘的传输容量大小约为： 1 * 100M = 100M</span></span><br><span class="line"><span class="code">    又因为</span></span><br><span class="line"><span class="code">        - 块的大小必须是 2^N （文件在传输过程中，每64K就需要校验一次，因此块的大小必须为 2^N）</span></span><br><span class="line"><span class="code">        - 最接近 100M 的就是 128M</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">-</span> 所以 Hadoop 2.x 规定默认块的大小为 128M 。</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> 如果公司使用的固态硬盘写的速度是300M/S，那么就可以将块大小调整到 256M</span><br><span class="line"><span class="bullet">-</span> 如果公司使用的固态硬盘写的速度是500M/S，那么就可以将块大小调整到 512M</span><br></pre></td></tr></table></figure>

<blockquote>
<ol start="2">
<li> <strong>为什么块的大小不能设置太小，也不能设置太大？</strong></li>
</ol>
</blockquote>
<p>块大小需要适当的调节，既不能太大，也不能太小！</p>
<ul>
<li><p>不能太大：</p>
  <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1.</span> 在一些分块读取的场景，不够灵活，会带来额外的网络消耗。</span><br><span class="line"><span class="code">    假设当前有一文件A，大小为1G。</span></span><br><span class="line"><span class="code">        如果块大小为128M，可分8块。    [取第一块]</span></span><br><span class="line"><span class="code">        如果块大小为1G，可分1块。      [取第一块]</span></span><br><span class="line"><span class="code">    需求：需要读取A文件0~128M部分的内容。</span></span><br><span class="line"><span class="code">    完成：两种分块方式在完成需求是同样只需要取第一块，将第一块下载到本地。但块太大的时候会带来额外的网络传输消耗和本地磁盘资源的消耗。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">2.</span> 在上传文件时，一旦发生故障，会造成资源的浪费。</span><br><span class="line"><span class="code">    假设上文A文件，</span></span><br><span class="line"><span class="code">        按128M分块，在上传第5块时因网络原因传输中断了，在网络重新连接后，只需重新上传第5块即可。</span></span><br><span class="line"><span class="code">        但是如果按1G分块，在上传到999M时因网络原因传输中断了，在重新连接网络后还需要从头重写上传整个文件</span></span><br><span class="line"><span class="code">    </span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>​           </p>
<ul>
<li><p>不能太小：</p>
  <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1.</span> 块太小，同样大小的文件，会占用 NameNode 过多的的元数据空间。</span><br><span class="line"><span class="code">    假设 有一文件B，大小为128M。</span></span><br><span class="line"><span class="code">        若 块大小为1M ，则保存文件需128块，需要生成128个块的映射信息。这些信息都属于元数据，都要存到NameNode中。</span></span><br><span class="line"><span class="code">        若 块大小为128M ，则保存文件只需1块， 只需要存储一个块的映射信息。</span></span><br><span class="line"><span class="code">2. 块太小，在进行读写操作时，会增加寻址时间，程序一直在找块的开始位置；</span></span><br><span class="line"><span class="code">    下载B文件，</span></span><br><span class="line"><span class="code">        若 块大小为1M，共128块，需要下载全部的128个块，寻址128次，每次寻址耗时 10ms；</span></span><br><span class="line"><span class="code">        若 块大小为128M ，共1块，只需下载1块，寻址1次</span></span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<ol start="3">
<li> 图示</li>
</ol>
</blockquote>
<p><img src="/2021/02/08/HDFS/image-20210219131335414.png?lastModify=1637670391" alt="image-20210219131335414"></p>
<p><strong>总结：HDFS块的大小设置主要取决于磁盘传输速率。</strong></p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><blockquote>
<ol>
<li> 副本数量</li>
</ol>
</blockquote>
<p>副本数的概念指的是最大副本数！</p>
<p>具体存放几个副本需要参考 DataNode 节点的数量，每个 DataNode 节点最多只能存储一个副本！</p>
<blockquote>
<ol>
<li> 默认块大小</li>
</ol>
</blockquote>
<p>默认 block 大小为 128M ，128M 指的是单个 block 的最大存储空间，如果当前块存储的数据不满 128M ，存了多少数据就占用多少磁盘空间。它也是一个独立的块！</p>
<blockquote>
<ol start="3">
<li> <strong>一个 block 只属于一个文件</strong></li>
</ol>
</blockquote>
<p> 意思是即使当前 block 只占用了几 kb，还有很大的剩余内存，但是也不能存储其它文件的内容。</p>
<hr>
<h1 id="HDFS-体系结构"><a href="#HDFS-体系结构" class="headerlink" title="HDFS 体系结构"></a>HDFS 体系结构</h1><p><img src="/2021/02/08/HDFS/image-20210219130216472.png" alt="image-20210219130216472"></p>
<p><strong>一、NameNode</strong>：就是Master，它是一个主管、管理者。</p>
<ol>
<li> 管理HDFS的名称空间；</li>
<li> 配置副本策略；</li>
<li> 管理数据块（Block）映射信息；</li>
<li> 处理客户端读写请求</li>
</ol>
<p><strong>二、DataNode</strong>：就是Slave。NameNode下达命令，DataNode执行实际的操作</p>
<ol>
<li> 存储文件的真实数据，基本存储单位是 Block。</li>
<li> 执行数据块的读/写操作。</li>
</ol>
<p><strong>三、Client</strong>：就是客户端。</p>
<ol>
<li> 文件切分。文件上传到 HDFS 前，Client 会按计划将文件切分成一个一个的 Block，然后再进行上传；</li>
<li> 与NameNode交互，获取文件的位置信息；</li>
<li> 与DataNode交互，读取或者写入数据；</li>
<li> Client提供一些命令来管理HDFS，比如NameNode格式化；</li>
<li> Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作；</li>
</ol>
<p><strong>四、Secondary NameNode（2nn）</strong>：并非 NameNode 的热备。当 NameNode 挂掉的时候，它并不能马上替换NameNode并提供服务。</p>
<ol>
<li> 辅助 NameNode，分担其工作量，比如定期合并 Fsimage 和 Edits ，并推送给 NameNode；</li>
<li> 在紧急情况下，可辅助恢复 NameNode。</li>
</ol>
<hr>
<h1 id="HDFS-的-Shell-操作"><a href="#HDFS-的-Shell-操作" class="headerlink" title="HDFS 的 Shell 操作"></a>HDFS 的 Shell 操作</h1><h2 id="hadoop-命令"><a href="#hadoop-命令" class="headerlink" title="hadoop 命令"></a>hadoop 命令</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[lvnengdong@hadoop102 hadoop]$ hadoop</span><br><span class="line">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  <span class="built_in">where</span> COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client	<span class="comment"># 运行一个通用的文件系统客户端</span></span><br><span class="line">  version              <span class="built_in">print</span> the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file	<span class="comment"># 运行一个jar包</span></span><br><span class="line">                       note: please use <span class="string">&quot;yarn jar&quot;</span> to launch</span><br><span class="line">                             YARN applications, not this <span class="built_in">command</span>.</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  daemonlog            get/set the <span class="built_in">log</span> level <span class="keyword">for</span> each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"></span><br><span class="line">Most commands <span class="built_in">print</span> <span class="built_in">help</span> when invoked w/o parameters.</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="hadoop-fs-命令"><a href="#hadoop-fs-命令" class="headerlink" title="hadoop fs 命令"></a>hadoop fs 命令</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[lvnengdong@hadoop102 hadoop]$ hadoop fs</span><br><span class="line">Usage: hadoop fs [generic options]</span><br><span class="line">	[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]	<span class="comment"># 追加</span></span><br><span class="line">	[-<span class="built_in">cat</span> [-ignoreCrc] &lt;src&gt; ...]	<span class="comment"># 查看文件内容</span></span><br><span class="line">	[-checksum &lt;src&gt; ...]	<span class="comment"># 检查校验和</span></span><br><span class="line">	[-<span class="built_in">chgrp</span> [-R] GROUP PATH...]	<span class="comment"># 改变所属组</span></span><br><span class="line">	[-<span class="built_in">chmod</span> [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]	<span class="comment"># 改变权限</span></span><br><span class="line">	[-<span class="built_in">chown</span> [-R] [OWNER][:[GROUP]] PATH...]	<span class="comment"># 改变所属主</span></span><br><span class="line">	[-copyFromLocal [-f] [-p] [-l] &lt;localsrc&gt; ... &lt;dst&gt;]	<span class="comment"># 上传文件（到HDFS）</span></span><br><span class="line">	[-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]	<span class="comment"># （从HDFS）下载文件</span></span><br><span class="line">	[-count [-q] [-h] &lt;path&gt; ...]	</span><br><span class="line">	[-<span class="built_in">cp</span> [-f] [-p | -p[topax]] &lt;src&gt; ... &lt;dst&gt;]	<span class="comment"># 复制</span></span><br><span class="line">	[-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]	<span class="comment"># 创建快照</span></span><br><span class="line">	[-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]	<span class="comment"># 删除快照</span></span><br><span class="line">	[-<span class="built_in">df</span> [-h] [&lt;path&gt; ...]]	</span><br><span class="line">	[-<span class="built_in">du</span> [-s] [-h] &lt;path&gt; ...]</span><br><span class="line">	[-expunge]	<span class="comment"># 清空回收站</span></span><br><span class="line">	[-find &lt;path&gt; ... &lt;expression&gt; ...]	<span class="comment"># 查找</span></span><br><span class="line">	[-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]	<span class="comment"># 下载</span></span><br><span class="line">	[-getfacl [-R] &lt;path&gt;]	</span><br><span class="line">	[-getfattr [-R] &#123;-n name | -d&#125; [-e en] &lt;path&gt;]</span><br><span class="line">	[-getmerge [-<span class="built_in">nl</span>] &lt;src&gt; &lt;localdst&gt;]	<span class="comment"># 下载并合并</span></span><br><span class="line">	[-<span class="built_in">help</span> [cmd ...]]	<span class="comment"># 查看命令的说明文档</span></span><br><span class="line">	[-<span class="built_in">ls</span> [-d] [-h] [-R] [&lt;path&gt; ...]]	<span class="comment"># 列出目录中的内容</span></span><br><span class="line">	[-<span class="built_in">mkdir</span> [-p] &lt;path&gt; ...]	<span class="comment"># 创建目录</span></span><br><span class="line">	[-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]	<span class="comment"># 从本地上传到HDFS（上传完毕后删除本地文件）</span></span><br><span class="line">	[-moveToLocal &lt;src&gt; &lt;localdst&gt;]	<span class="comment"># 从HDFS下载到本地（下载完毕后删除HDFS中的文件）</span></span><br><span class="line">	[-<span class="built_in">mv</span> &lt;src&gt; ... &lt;dst&gt;]	<span class="comment"># 移动或重命名</span></span><br><span class="line">	[-put [-f] [-p] [-l] &lt;localsrc&gt; ... &lt;dst&gt;]	<span class="comment"># 上传</span></span><br><span class="line">	[-renameSnapshot &lt;snapshotDir&gt; &lt;olDataNodeame&gt; &lt;newName&gt;]	<span class="comment"># 重命名快照</span></span><br><span class="line">	[-<span class="built_in">rm</span> [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]	<span class="comment"># 删除</span></span><br><span class="line">	[-<span class="built_in">rmdir</span> [--ignore-fail-on-non-empty] &lt;<span class="built_in">dir</span>&gt; ...]	<span class="comment"># 删除目录</span></span><br><span class="line">	[-setfacl [-R] [&#123;-b|-k&#125; &#123;-m|-x &lt;acl_spec&gt;&#125; &lt;path&gt;]|[--<span class="built_in">set</span> &lt;acl_spec&gt; &lt;path&gt;]]	<span class="comment"># 设置文件权限</span></span><br><span class="line">	[-setfattr &#123;-n name [-v value] | -x name&#125; &lt;path&gt;]	<span class="comment"># 设置文件属性</span></span><br><span class="line">	[-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]	<span class="comment"># 设置某个文件的副本数量</span></span><br><span class="line">	[-<span class="built_in">stat</span> [format] &lt;path&gt; ...]	<span class="comment"># </span></span><br><span class="line">	[-<span class="built_in">tail</span> [-f] &lt;file&gt;]</span><br><span class="line">	[-<span class="built_in">test</span> -[defsz] &lt;path&gt;]</span><br><span class="line">	[-text [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-touchz &lt;path&gt; ...]</span><br><span class="line">	[-<span class="built_in">truncate</span> [-w] &lt;length&gt; &lt;path&gt; ...]</span><br><span class="line">	[-usage [cmd ...]]</span><br><span class="line"></span><br><span class="line">Generic options supported are</span><br><span class="line">-conf &lt;configuration file&gt;     specify an application configuration file</span><br><span class="line">-D &lt;property=value&gt;            use value <span class="keyword">for</span> given property</span><br><span class="line">-fs &lt;<span class="built_in">local</span>|namenode:port&gt;      specify a namenode</span><br><span class="line">-jt &lt;<span class="built_in">local</span>|resourcemanager:port&gt;    specify a ResourceManager</span><br><span class="line">-files &lt;comma separated list of files&gt;    specify comma separated files to be copied to the map reduce cluster</span><br><span class="line">-libjars &lt;comma separated list of jars&gt;    specify comma separated jar files to include <span class="keyword">in</span> the classpath.</span><br><span class="line">-archives &lt;comma separated list of archives&gt;    specify comma separated archives to be unarchived on the compute machines.</span><br><span class="line"></span><br><span class="line">The general <span class="built_in">command</span> line syntax is</span><br><span class="line">bin/hadoop <span class="built_in">command</span> [genericOptions] [commandOptions]</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>-help 命令测试</strong></p>
<ul>
<li><p>查看 <code>-count</code> 命令的说明文档</p>
  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[lvnengdong@hadoop102 hadoop]$ hadoop fs -<span class="built_in">help</span> count</span><br><span class="line">-count [-q] [-h] &lt;path&gt; ... :</span><br><span class="line">	<span class="comment"># 统计目录中下的文件夹数量、文件数量、字节数</span></span><br><span class="line">  Count the number of directories, files and bytes under the paths</span><br><span class="line">  that match the specified file pattern.  The output columns are:</span><br><span class="line">  DIR_COUNT FILE_COUNT CONTENT_SIZE FILE_NAME or</span><br><span class="line">  QUOTA REMAINING_QUOTA SPACE_QUOTA REMAINING_SPACE_QUOTA </span><br><span class="line">        DIR_COUNT FILE_COUNT CONTENT_SIZE FILE_NAME</span><br><span class="line">  The -h option shows file sizes <span class="keyword">in</span> human readable format.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="hadoop-fs-和-hdfs-dfs"><a href="#hadoop-fs-和-hdfs-dfs" class="headerlink" title="hadoop fs 和 hdfs dfs"></a>hadoop fs 和 hdfs dfs</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs 具体命令 </span><br><span class="line"><span class="comment"># 和</span></span><br><span class="line">hdfs dfs 具体命令</span><br><span class="line"></span><br><span class="line"><span class="comment"># 的功能是类似的</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>Tip：</p>
</blockquote>
<p><code>hadoop fs</code> 命令既可以在本地模式在生效，也可以在分布式模式下生效；而 <code>hdfs dfs</code> 只能在分布式模式下生效！</p>
<p><strong>hdfs 命令</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[lvnengdong@hadoop102 hadoop]$ hdfs</span><br><span class="line">Usage: hdfs [--config confdir] [--loglevel loglevel] COMMAND</span><br><span class="line">       <span class="built_in">where</span> COMMAND is one of:</span><br><span class="line">  dfs                  run a filesystem <span class="built_in">command</span> on the file systems supported <span class="keyword">in</span> Hadoop.	<span class="comment"># 也是运行一个</span></span><br><span class="line">  classpath            prints the classpath</span><br><span class="line">  namenode -format     format the DFS filesystem</span><br><span class="line">  secondarynamenode    run the DFS secondary namenode</span><br><span class="line">  namenode             run the DFS namenode</span><br><span class="line">  journalnode          run the DFS journalnode</span><br><span class="line">  zkfc                 run the ZK Failover Controller daemon</span><br><span class="line">  datanode             run a DFS datanode</span><br><span class="line">  dfsadmin             run a DFS admin client</span><br><span class="line">  haadmin              run a DFS HA admin client</span><br><span class="line">  fsck                 run a DFS filesystem checking utility</span><br><span class="line">  balancer             run a cluster balancing utility</span><br><span class="line">  jmxget               get JMX exported values from NameNode or DataNode.</span><br><span class="line">  mover                run a utility to move block replicas across</span><br><span class="line">                       storage types</span><br><span class="line">  oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class="line">  oiv_legacy           apply the offline fsimage viewer to an legacy fsimage</span><br><span class="line">  oev                  apply the offline edits viewer to an edits file</span><br><span class="line">  fetchdt              fetch a delegation token from the NameNode</span><br><span class="line">  getconf              get config values from configuration</span><br><span class="line">  <span class="built_in">groups</span>               get the <span class="built_in">groups</span> <span class="built_in">which</span> <span class="built_in">users</span> belong to</span><br><span class="line">  snapshotDiff         diff two snapshots of a directory or diff the</span><br><span class="line">                       current directory contents with a snapshot</span><br><span class="line">  lsSnapshottableDir   list all snapshottable <span class="built_in">dirs</span> owned by the current user</span><br><span class="line">						Use -<span class="built_in">help</span> to see options</span><br><span class="line">  portmap              run a portmap service</span><br><span class="line">  nfs3                 run an NFS version 3 gateway</span><br><span class="line">  cacheadmin           configure the HDFS cache</span><br><span class="line">  crypto               configure HDFS encryption zones</span><br><span class="line">  storagepolicies      list/get/set block storage policies</span><br><span class="line">  version              <span class="built_in">print</span> the version</span><br><span class="line"></span><br><span class="line">Most commands <span class="built_in">print</span> <span class="built_in">help</span> when invoked w/o parameters.</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="命令分类"><a href="#命令分类" class="headerlink" title="命令分类"></a>命令分类</h3><blockquote>
<p>本地 –&gt;&gt; HDFS（上传）</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-put			# 拷贝</span><br><span class="line">-copyFromLocal	 # 可以进行多线程拷贝</span><br><span class="line">-moveFromLocal	 # 移动 </span><br><span class="line">-appendToFile	 # 追加</span><br></pre></td></tr></table></figure>

<blockquote>
<p>HDFS –&gt;&gt; HDFS </p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-<span class="built_in">cd</span></span><br><span class="line">-<span class="built_in">mv</span></span><br><span class="line">-<span class="built_in">chown</span></span><br><span class="line">-<span class="built_in">chmod</span></span><br><span class="line">-<span class="built_in">du</span></span><br><span class="line">-<span class="built_in">df</span></span><br><span class="line">-<span class="built_in">cat</span></span><br><span class="line">-<span class="built_in">rm</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>HDFS –&gt;&gt; 本地（下载）</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-get			<span class="comment"># 下载</span></span><br><span class="line">-copyToLocal	<span class="comment"># 下载（等价于 get）</span></span><br><span class="line">-getmerge		<span class="comment"># 合并下载。把 HDFS 上的一批可以用通配符匹配的文件先合并成一个文件，再下载到本地。合并的顺序是文件在 HDFS 上的排列顺序</span></span><br></pre></td></tr></table></figure>





<h3 id="常用命令实操"><a href="#常用命令实操" class="headerlink" title="常用命令实操"></a>常用命令实操</h3><h4 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h4><ol>
<li>启动Hadoop集群（方便后续的测试）</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>-help：输出这个命令参数</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -help rm</span><br></pre></td></tr></table></figure>

<h4 id="2、上传"><a href="#2、上传" class="headerlink" title="2、上传"></a>2、上传</h4><blockquote>
<ol>
<li><code>-moveFromLocal</code>：从本地剪切粘贴到HDFS</li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ touch kongming.txt</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -moveFromLocal ./kongming.txt /sanguo/shuguo</span><br></pre></td></tr></table></figure>



<blockquote>
<ol start="2">
<li>-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -copyFromLocal README.txt /</span><br></pre></td></tr></table></figure>



<blockquote>
<ol start="3">
<li>-appendToFile：追加一个文件到已经存在的文件末尾</li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ touch liubei.txt</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ vi liubei.txt</span><br><span class="line"></span><br><span class="line">输入</span><br><span class="line"></span><br><span class="line">san gu mao lu</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -appendToFile liubei.txt /sanguo/shuguo/kongming.txt</span><br></pre></td></tr></table></figure>





<blockquote>
<ol start="4">
<li>-put：等同于copyFromLocal</li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -put ./zaiyiqi.txt /user/atguigu/test/</span><br></pre></td></tr></table></figure>



<h3 id="2-3-3-下载"><a href="#2-3-3-下载" class="headerlink" title="2.3.3 下载"></a>2.3.3 下载</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">1）-copyToLocal：从HDFS拷贝到本地</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -copyToLocal /sanguo/shuguo/kongming.txt ./</span><br><span class="line"></span><br><span class="line">2）-get：等同于copyToLocal，就是从HDFS下载文件到本地</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -get /sanguo/shuguo/kongming.txt ./</span><br><span class="line"></span><br><span class="line">3）-getmerge：合并下载多个文件，比如HDFS的目录 /user/atguigu/test下有多个文件:log.1, log.2,log.3,...</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -getmerge /user/atguigu/test/* ./zaiyiqi.txt</span><br><span class="line"></span><br><span class="line">### 2.3.4 HDFS直接操作</span><br><span class="line"></span><br><span class="line">1）-ls: 显示目录信息</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -ls /</span><br><span class="line"></span><br><span class="line">2）-mkdir：在HDFS上创建目录</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -mkdir -p /sanguo/shuguo</span><br><span class="line"></span><br><span class="line">3）-cat：显示文件内容</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -cat /sanguo/shuguo/kongming.txt</span><br><span class="line"></span><br><span class="line">4）-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -chmod 666 /sanguo/shuguo/kongming.txt</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -chown atguigu:atguigu  /sanguo/shuguo/kongming.txt</span><br><span class="line"></span><br><span class="line">5）-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -cp /sanguo/shuguo/kongming.txt /zhuge.txt</span><br><span class="line"></span><br><span class="line">6）-mv：在HDFS目录中移动文件</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -mv /zhuge.txt /sanguo/shuguo/</span><br><span class="line"></span><br><span class="line">7）-tail：显示一个文件的末尾</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -tail /sanguo/shuguo/kongming.txt</span><br><span class="line"></span><br><span class="line">8）-rm：删除文件或文件夹</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -rm /user/atguigu/test/jinlian2.txt</span><br><span class="line"></span><br><span class="line">9）-rmdir：删除空目录</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -mkdir /test</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -rmdir /test</span><br><span class="line"></span><br><span class="line">10）-du统计文件夹的大小信息</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -du -s -h /user/atguigu/test</span><br><span class="line"></span><br><span class="line">2.7 K /user/atguigu/test</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -du -h /user/atguigu/test</span><br><span class="line"></span><br><span class="line">1.3 K /user/atguigu/test/README.txt</span><br><span class="line"></span><br><span class="line">15   /user/atguigu/test/jinlian.txt</span><br><span class="line"></span><br><span class="line">1.4 K /user/atguigu/test/zaiyiqi.txt</span><br><span class="line"></span><br><span class="line">11）-setrep：设置HDFS中文件的副本数量</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -setrep 10 /sanguo/shuguo/kongming.txt</span><br><span class="line"></span><br><span class="line">这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量。因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10。</span><br></pre></td></tr></table></figure>







<hr>
<h1 id="HDFS-客户端操作"><a href="#HDFS-客户端操作" class="headerlink" title="HDFS 客户端操作"></a>HDFS 客户端操作</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在对 HDFS（Hadoop 的分布式文件系统）进行操作时，又可分为<strong>服务端</strong>操作和<strong>客户端</strong>操作两部分。</p>
<p><strong>服务端：</strong></p>
<ul>
<li>  启动 NameNode，DataNode，2NN 等；</li>
</ul>
<p><strong>客户端（可以有多种形式）：</strong></p>
<ul>
<li>使用 Shell 客户端。    使用 <code>hadoop fs -命令</code> 对 HDFS 进行操作。</li>
<li>使用 Java 客户端。    使用 JavaAPI 和方法对 HDFS 进行操作。 </li>
<li>使用 Python 客户端。    使用 PythonAPI 和方法对 HDFS 进行操作。</li>
<li>……</li>
</ul>
<hr>
<h2 id="Java-客户端环境准备"><a href="#Java-客户端环境准备" class="headerlink" title="Java 客户端环境准备"></a>Java 客户端环境准备</h2><ol>
<li><p> 在 Windows 上安装 Hadoop 客户端。</p>
</li>
<li><p>配置 HADOOP_HOME 环境变量</p>
<p> <img src="/2021/02/08/HDFS/image-20211124095328168.png" alt="image-20211124095328168"></p>
</li>
<li><p>配置 PATH 环境变量。然后重启电脑。</p>
<p> <img src="/2021/02/08/HDFS/image-20211124095406232.png" alt="image-20211124095406232"></p>
</li>
<li><p>测试</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\admin&gt;hadoop version</span><br><span class="line">Hadoop <span class="number">2.7</span><span class="number">.2</span></span><br><span class="line">Subversion https:<span class="comment">//git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41</span></span><br><span class="line">Compiled by jenkins on <span class="number">2016</span>-<span class="number">01</span>-26T00:08Z</span><br><span class="line">Compiled with protoc <span class="number">2.5</span><span class="number">.0</span></span><br><span class="line">From source with checksum d0fda26633fa762bff87ec759ebe689c</span><br><span class="line">This command was run using /D:/Software/Dev/hadoop-<span class="number">2.7</span><span class="number">.2</span>/share/hadoop/common/hadoop-common-<span class="number">2.7</span><span class="number">.2</span>.jar</span><br></pre></td></tr></table></figure></li>
<li><p>创建一个Maven工程，并导入相关依赖</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 使用 Hadoop中Common工具类所需的依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- Hadoop 客户端依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- 使用 Hadoop hdfs 所需的依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="HDFS-的-API-操作"><a href="#HDFS-的-API-操作" class="headerlink" title="HDFS 的 API 操作"></a>HDFS 的 API 操作</h2><h3 id="FileSystem"><a href="#FileSystem" class="headerlink" title="FileSystem"></a>FileSystem</h3><blockquote>
<p><code>org.apache.hadoop.fs.FileSystem;</code></p>
</blockquote>
<p><strong>FileSystem</strong> 是分布式文件系统的<strong>基类</strong>，它是一个抽象类，常见的有两种实现：</p>
<ol>
<li>本地文件系统：<code>LocalFileSystem</code>，相当于设置了 <code>fs.defaultFS=file:///</code></li>
<li>分布式文件系统：<code>DistributeFileSystem</code>，相当于设置了`fs.defaultFS=hdfs://IP地址:端口号``</li>
<li><code>FileSystem</code> 对象到底是本地文件系统对象还是分布式文件系统对象取决于配置文件中 <code>fs.defaultFS</code> 的值</li>
</ol>
<p><code>FileSystem</code>是一个抽象类，不能直接 new ，但是可以通过静态方法 <code>FileSystem.get()</code> 方法来创建该类的实现类对象。<code>get()</code> 有3个重载方法，分别是：</p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>get(Configuration conf)</code></td>
<td>创建一个FileSystem实现类对象，不指定使用的文件协议，以当前计算机的用户身份登录</td>
</tr>
<tr>
<td align="left"><code>get(URI uri, Configuration conf)</code></td>
<td>创建一个FileSystem对象，指定使用的文件协议，以当前计算机的用户身份登录</td>
</tr>
<tr>
<td align="left"><code>get(final URI uri, final Configuration conf, final String user)</code></td>
<td>创建一个FileSystem对象，指定使用的文件协议，并以指定身份登录</td>
</tr>
</tbody></table>
<ul>
<li>  可以看到 <code>get</code> 方法会依赖于一个 <strong>Configuration</strong> 对象，这个对象在下一章节就会讲到。</li>
</ul>
<hr>
<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><blockquote>
<p><code>org.apache.hadoop.conf.Configuration</code></p>
</blockquote>
<p><strong>作用</strong>：读取配置文件中的参数。</p>
<p>Configuration 在读取配置文件时，会读取 4~8 个配置文件。</p>
<ol>
<li> Configuration 对象在加载时首先会读取 4 个默认配置文件 <code>xxx-default.xml</code>；</li>
<li> 如果类路径（classpath）下存在自定义配置文件 <code>xxx-site.xml</code>，Configuration 对象会继续读取这些自定义配置文件并使用自定义配置文件中的属性覆盖默认配置文件中的同名属性。 </li>
<li> 也就是说，Configuration 类一加载就会默认读取8个配置文件，将8个配置文件中所有属性读取到一个Map集合中；</li>
<li> 当然，该类也提供了 <code>set(name, value)</code> 方法，用于在代码中覆盖配置文件中的参数。</li>
</ol>
<p><strong>源码解读：</strong></p>
<p>Configuration 类的源码中有一段静态代码块。静态代码块中的代码在类加载到 JVM 中时就被执行。所以说该静态代码块中的内容一定是在创建 Configuration 对象前执行的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Configuration</span> <span class="keyword">implements</span> <span class="title class_">Iterable</span>&lt;Map.Entry&lt;String,String&gt;&gt;,</span><br><span class="line">Writable &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">static</span>&#123;</span><br><span class="line">        <span class="comment">//print deprecation warning if hadoop-site.xml is found in classpath</span></span><br><span class="line">        <span class="comment">// 1、获取类加载器</span></span><br><span class="line">        <span class="type">ClassLoader</span> <span class="variable">cL</span> <span class="operator">=</span> Thread.currentThread().getContextClassLoader();</span><br><span class="line">        <span class="keyword">if</span> (cL == <span class="literal">null</span>) &#123;</span><br><span class="line">            cL = Configuration.class.getClassLoader();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 2、如果在类路径下发现了 hadoop-site.xml 配置文件，打印警告</span></span><br><span class="line">        <span class="comment">//【因为 hadoop-site.xml 是 Hadoop 1.x 中使用的配置文件，在Hadoop2.x中已经过时了，</span></span><br><span class="line">        <span class="comment">// 它的作用是将所有配置信息配置到一个配置文件中】</span></span><br><span class="line">        <span class="keyword">if</span>(cL.getResource(<span class="string">&quot;hadoop-site.xml&quot;</span>)!=<span class="literal">null</span>) &#123;</span><br><span class="line">            LOG.warn(<span class="string">&quot;DEPRECATED: hadoop-site.xml found in the classpath. &quot;</span> +</span><br><span class="line">                     <span class="string">&quot;Usage of hadoop-site.xml is deprecated. Instead use core-site.xml, &quot;</span>	</span><br><span class="line">                     + <span class="string">&quot;mapred-site.xml and hdfs-site.xml to override properties of &quot;</span> +</span><br><span class="line">                     <span class="string">&quot;core-default.xml, mapred-default.xml and hdfs-default.xml &quot;</span> +</span><br><span class="line">                     <span class="string">&quot;respectively&quot;</span>);</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">        翻译：</span></span><br><span class="line"><span class="comment">        	hadoop-site.xml 已经被弃用了，应该用 core-site.xml, mapred-site.xml </span></span><br><span class="line"><span class="comment">        	和 hdfs-site.xml 去覆盖这个配置文件</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、加载默认和自定义配置文件。</span></span><br><span class="line">        addDefaultResource(<span class="string">&quot;core-default.xml&quot;</span>);</span><br><span class="line">        addDefaultResource(<span class="string">&quot;core-site.xml&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>配置文件</strong></p>
<p>在我们引入 Hadoop 相关的 Maven 依赖时，这些依赖中就已经包含了 Hadoop 四个常用的配置文件，所以在创建 <code>new Configuration()</code> 对象时首先会加载这四个配置文件得到 <code>configuration</code> 对象。如果想要得到加载自定义配置文件的 <code>configuration</code> 对象，就需要在类路径下创建对应的 <code>xxx-site.xml</code> 配置文件来重写默认配置文件中的属性。</p>
<p><img src="/2021/02/08/HDFS/image-20211124173109470.png" alt="image-20211124173109470"></p>
<ul>
<li><p>举例：</p>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在 core-default.xml 配置文件中使用的是本地文件系统，即</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">如果我们想要使用 HDFS 的分布式文件系统，就需要在类路径下创建一个 core-site.xml 文件，覆盖原先的配置。</span><br><span class="line">这时我们再通过 `new Configuration()` 得到的对象就是一个分布式文件系统的配置对象。</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><ol>
<li><p>创建 HDFSClient </p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">HDFSClient 测试：</span></span><br><span class="line"><span class="comment">	1、本地模式的 HDFSClient</span></span><br><span class="line"><span class="comment">	2、分布式模式的 HDFSClient</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">mkdir</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="comment">// 1、创建 fileSystem 对象，用于连接 HDFS 集群</span></span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">    <span class="comment">// 2、测试</span></span><br><span class="line">    System.out.println(fs);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">分析：</span></span><br><span class="line"><span class="comment">	1、当我们使用默认的配置文件创建 fs 对象时，得到的是一个`本地文件系统对象`，输出结果为：</span></span><br><span class="line"><span class="comment">		org.apache.hadoop.fs.LocalFileSystem@606e4010</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">	2、如果我们在类路径下自定义一个 `core-site.xml` 配置文件（配置文件见下文）并重写 </span></span><br><span class="line"><span class="comment">	fs.defaultFS=hdfs://hadoop102:9000，这时再创建 fs 对象，自定义的配置文件就会重写</span></span><br><span class="line"><span class="comment">	默认的配置文件中的同名属性，这时得到的 fs 对象就是一个`分布式文件系统对象`，输出的结果为：</span></span><br><span class="line"><span class="comment">		DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-53042264_1, ugi=admin (auth:SIMPLE)]]</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></li>
<li><p>调用 fs 对象的 <code>mkdirs</code>方法在 HDFS 文件系统的根目录下创建一个文件</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">mkdir</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="comment">// 1、创建客户端对象，用于连接 HDFS 集群</span></span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">Configuration</span>());</span><br><span class="line">    <span class="comment">// 2、调用 mkdirs() 方法在 HDFS 集群的根路径创建一个目录</span></span><br><span class="line">    fs.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/IDEA&quot;</span>));</span><br><span class="line">    <span class="comment">// 3、释放资源</span></span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">分析：</span></span><br><span class="line"><span class="comment">	程序运行失败，抛出异常。</span></span><br><span class="line"><span class="comment">	异常信息是： org.apache.hadoop.security.AccessControlException: Permission denied: user=admin, access=WRITE, inode=&quot;/&quot;:lvnengdong:supergroup:drwxr-xr-x</span></span><br><span class="line"><span class="comment">	我们可以看到这是一个访问控制异常，也就是说权限被拒绝。</span></span><br><span class="line"><span class="comment">	原因是：当前登录 HDFS 的用户是admin（这个是我Windows系统的用户名），而 Hadoop 集群所属的用户是 lvnengdong。</span></span><br><span class="line"><span class="comment">	根据权限控制信息 drwxr-xr-x 所示，非主非组用户所拥有的权限只有 r-x ，而没有写权限，所以 admin 用户不能在Hadoop集群上创建目录！</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">解决方法：</span></span><br><span class="line"><span class="comment">    1、修改 Hadoop 集群对游客的访问权限，赋予游客写的权限</span></span><br><span class="line"><span class="comment">    2、使用拥有写权限的用户（这里是 lvnengdong 用户）登录</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></li>
<li><p>修改代码（方式一）：以指定用户登录（这里是拥有写权限的 lvnengdong 用户）</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">mkdir</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="keyword">final</span> <span class="type">URI</span> <span class="variable">uri</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>);</span><br><span class="line">    <span class="keyword">final</span> <span class="type">String</span> <span class="variable">user</span> <span class="operator">=</span> <span class="string">&quot;lvnengdong&quot;</span>;</span><br><span class="line">    <span class="comment">// </span></span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(uri, configuration, user);</span><br><span class="line">    fs.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/IDEA &quot;</span>));</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">分析：</span></span><br><span class="line"><span class="comment">	* 使用 fs 对象的 get 方法，可以指定访问 HDFS 系统的用户身份（这里指定为 lvnengdong）。</span></span><br><span class="line"><span class="comment">	* 由于 Hadoop 采用一种弱权限验证，所以无需验证密码，可直接以 lvnengdong 这个身份登录。</span></span><br><span class="line"><span class="comment">	* 重载方法中的另一个参数是 URI 对象，该对象的介绍见下文。</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <strong>弱权限验证</strong></p>
<ul>
<li>Hadoop 的权限验证是一种弱权限验证</li>
<li><strong>弱权限验证</strong>：你告诉 Hadoop 你是谁，它就认为你是谁，它并不会检查你是谁！</li>
</ul>
</blockquote>
</li>
<li><p>不用修改代码（方式二）</p>
<p> （1）服务端操作</p>
<ul>
<li>  <strong>原理：</strong>为了使用方便，我们还可以将 HDFS 根目录的权限完全放开！即允许任何用户都能在 HDFS 的目录下执行任何操作！</li>
<li>  <strong>操作：</strong>在 HDFS 服务器中的任一节点上执行 ： <code>hadoop fs -chmod -R 777 /</code> 命令，开放所有用户对该目录的操作权限！</li>
</ul>
<p> （2）客户端操作</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这时我们再用 Windows 上的用户（或任意用户）在 HDFS 集群上进行创建目录操作时，也可以成功！</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">mkdir</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException &#123;</span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">URI</span> <span class="variable">uri</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:8020&quot;</span>);</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(uri, conf);</span><br><span class="line">    fs.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/IDEA3 &quot;</span>));</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h4 id="URI"><a href="#URI" class="headerlink" title="URI"></a>URI</h4><blockquote>
<p><code>java.net.URI</code></p>
</blockquote>
<ul>
<li><code>URI</code> 指的是如何连接到 HDFS 文件系统。（主要包括：1️⃣连接协议2️⃣连接地址）</li>
<li>可以是<strong>本地模式</strong>，使用 file文件系统协议：<code>file:/// </code></li>
<li>也可以是<strong>分布式模式</strong>，使用分布式文件系统协议：<code>hdfs://IP地址:端口号</code>（我的是    <code>hdfs://hadoop102:9000</code>）</li>
</ul>
<p><strong>Tip:</strong></p>
<ul>
<li>  如果使用 <code>FileSystem.get()</code> 的重载方法中包含 URI 这一参数，就相当于在代码中手动设置了 <code>fs.defaultFS=$uri</code>，这时就无需在自定义配置文件 <code>core-site.xml</code> 中重写 <code>fs.defaultFS</code>属性了，因为最终的 <code>fs.defaultFS</code> 的最终属性以代码中的 uri 为准。</li>
<li>  URI 这个参数对应的值实际就是<code>core-site.xml</code>配置文件中<code>fs.defaultFS</code> 的值，包含了连接 HDFS 使用的协议和 NameNode 的地址（如果是分布式文件系统）。</li>
</ul>
<hr>
<h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><ul>
<li>我们在搭建集群时会配置很多参数，</li>
<li>这些参数有些是由客户端来使用，有些是由服务端来使用，有些是客户端和服务端都来要使用。</li>
<li>对于仅在客户端使用的参数，在服务端可以无需配置，同理对于仅在服务端使用的参数，在客户端也可以不配置。而对于客户端和服务器端都需要使用的参数，则需要在客户端和服务器端都要配置。</li>
</ul>
<blockquote>
<p>  <strong>core-site.xml</strong></p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">        这个参数是 NameNode 的地址，客户端和服务端都需要使用！</span></span><br><span class="line"><span class="comment">        客户端需要知道 NameNode 的地址向 NameNode 发送请求。如上传文件时首先 NameNode 请求 分配资源；</span></span><br><span class="line"><span class="comment">        服务端上的 DataNode 节点也需要知道 NameNode 的地址与 NameNode 进行通信，如 DataNode 在启动时要加入到 Hadoop 集群中，也要知道 NameNode 的地址。</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- HDFS中NameNode的RPC地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 这个参数只在服务端使用，所以在客户端的配置文件中就可以省略！ --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定Hadoop运行时产生的文件保存的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>







<hr>
<h3 id="增删改查"><a href="#增删改查" class="headerlink" title="增删改查"></a>增删改查</h3><h4 id="1、创建目录"><a href="#1、创建目录" class="headerlink" title="1、创建目录"></a>1、创建目录</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSClient</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 声明一个全局变量 fs</span></span><br><span class="line">    <span class="keyword">private</span> FileSystem fs;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">     	<span class="comment">// 1、创建 fs 对象</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">URI</span> <span class="variable">uri</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">user</span> <span class="operator">=</span> <span class="string">&quot;lvnengdong&quot;</span>;</span><br><span class="line">        fs = FileSystem.get(uri,conf,user);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 3、释放资源</span></span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Shell命令：hadoop fs -mkdir /xxx</span></span><br><span class="line"><span class="comment">     * 分析：</span></span><br><span class="line"><span class="comment">     *  hadoop fs   运行一个客户端</span></span><br><span class="line"><span class="comment">     *  -mkdir  编译好的脚本</span></span><br><span class="line"><span class="comment">     *  /xxx    用户指定的参数</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *  Java 命令（面向对象）</span></span><br><span class="line"><span class="comment">     *  1、创建一个客户端对象</span></span><br><span class="line"><span class="comment">     *  2、调用创建目录的方法</span></span><br><span class="line"><span class="comment">     *  3、路径作为方法的参数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">mkdir</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 2、调用 mkdirs() 方法，创建一个文件夹</span></span><br><span class="line">        fs.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/IDEA3 &quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2、上传文件"><a href="#2、上传文件" class="headerlink" title="2、上传文件"></a>2、上传文件</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 上传文件</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">       <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;C:\\Users\\admin\\Desktop\\image\\demo01.jpg&quot;</span>);</span><br><span class="line">       <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>);</span><br><span class="line">       fs.copyFromLocalFile(src, dst);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<h4 id="3、下载文件"><a href="#3、下载文件" class="headerlink" title="3、下载文件"></a>3、下载文件</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 下载文件</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test02</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">       <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/README.txt&quot;</span>);</span><br><span class="line">       <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;d:/&quot;</span>);</span><br><span class="line">       fs.copyToLocalFile(src, dst);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h4 id="4、删除文件"><a href="#4、删除文件" class="headerlink" title="4、删除文件"></a>4、删除文件</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 删除文件</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">    */</span>	</span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test03</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">       <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/IDEA3&quot;</span>);</span><br><span class="line">       <span class="comment">// 参数1：要删除文件的路径     参数2：是否递归删除</span></span><br><span class="line">       fs.delete(path, <span class="literal">true</span>);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h4 id="5、重命名"><a href="#5、重命名" class="headerlink" title="5、重命名"></a>5、重命名</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 重命名</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test04</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">       <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/IDEA2&quot;</span>);</span><br><span class="line">       <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/newIDEA2&quot;</span>);</span><br><span class="line">       fs.rename(src, dst);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h4 id="6、判断当前路径是否存在"><a href="#6、判断当前路径是否存在" class="headerlink" title="6、判断当前路径是否存在"></a>6、判断当前路径是否存在</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 判断当前路径是否存在</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test05</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">       <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/IDEA&quot;</span>);</span><br><span class="line">       <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> fs.exists(path);</span><br><span class="line">       System.out.println(b);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h4 id="7、判断当前路径是目录还是文件"><a href="#7、判断当前路径是目录还是文件" class="headerlink" title="7、判断当前路径是目录还是文件"></a>7、判断当前路径是目录还是文件</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断当前路径是目录还是文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test06</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/IDEA&quot;</span>);</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b1</span> <span class="operator">=</span> fs.isFile(path);</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b2</span> <span class="operator">=</span> fs.isDirectory(path);</span><br><span class="line">        System.out.println(b1);</span><br><span class="line">        System.out.println(b2);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">	但是不建议使用这两个方法，这两个方法已经过期。建议使用 FileStatus</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>



<h5 id="重要：FileStatus"><a href="#重要：FileStatus" class="headerlink" title="重要：FileStatus"></a>重要：FileStatus</h5><p>当前文件的相关信息(文件/文件夹的属性信息)</p>
<blockquote>
<p>源码（部分）：<code>FileStatus</code> 中保存的属性信息。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FileStatus</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Path path;	<span class="comment">// 完整的路径（包括文件名）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> length;</span><br><span class="line">    <span class="keyword">private</span> Boolean isdir;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">short</span> block_replication;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> blocksize;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> modification_time;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> access_time;</span><br><span class="line">    <span class="keyword">private</span> FsPermission permission;</span><br><span class="line">    <span class="keyword">private</span> String owner;</span><br><span class="line">    <span class="keyword">private</span> String group;</span><br><span class="line">    <span class="keyword">private</span> Path symlink;</span><br><span class="line">    <span class="keyword">private</span> Set&lt;AttrFlags&gt; attr;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>测试1：判断当前路径是目录还是文件</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 判断当前路径是目录还是文件</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test07</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">       <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/IDEA&quot;</span>);</span><br><span class="line">       <span class="comment">// 1、得到 FileStatus 对象，保存了一个文件的属性信息</span></span><br><span class="line">       <span class="type">FileStatus</span> <span class="variable">info</span> <span class="operator">=</span> fs.getFileStatus(path);</span><br><span class="line">       <span class="comment">// 2、根据 status 对象判断当前路径是文件还是目录</span></span><br><span class="line">       <span class="type">boolean</span> <span class="variable">b1</span> <span class="operator">=</span> info.isDirectory();</span><br><span class="line">       <span class="type">boolean</span> <span class="variable">b2</span> <span class="operator">=</span> info.isFile();</span><br><span class="line">       System.out.println(b1);</span><br><span class="line">       System.out.println(b2);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<h5 id="重要：ListStatus"><a href="#重要：ListStatus" class="headerlink" title="重要：ListStatus"></a>重要：ListStatus</h5><p><code>ListStatus</code> 的作用与 <code>FileStatus</code> 相似，但是 <code>ListStatus</code> 可以列出当前路径及其子路径的所有文件/文件夹的属性信息。</p>
<blockquote>
<p>测试：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test08</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">      <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/output2&quot;</span>);</span><br><span class="line">      <span class="comment">// 1、得到 FileStatus[] 对象，保存了当前路径及其子路径的属性信息</span></span><br><span class="line">      FileStatus[] listInfo = fs.listStatus(path);</span><br><span class="line">      <span class="keyword">for</span> (FileStatus info : listInfo) &#123;</span><br><span class="line">          <span class="comment">// 2、获取文件路径。Path 是完整的路径：协议+文件名</span></span><br><span class="line">          <span class="type">Path</span> <span class="variable">filePath</span> <span class="operator">=</span> info.getPath();</span><br><span class="line">          <span class="comment">// 3、如果只想获取文件名，可以使用</span></span><br><span class="line">          <span class="type">String</span> <span class="variable">fileName</span> <span class="operator">=</span> filePath.getName();</span><br><span class="line">          System.out.println(fileName + <span class="string">&quot;是否是目录：&quot;</span> + status.isDirectory());</span><br><span class="line">          System.out.println(fileName + <span class="string">&quot;是否是文件：&quot;</span> + status.isFile());</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="8、获取文件的块信息"><a href="#8、获取文件的块信息" class="headerlink" title="8、获取文件的块信息"></a>8、获取文件的块信息</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">offset和length</span><br><span class="line">	offset是偏移量： 指块在文件中的起始位置</span><br><span class="line">	length是长度，指块中文件的大小</span><br><span class="line"></span><br><span class="line">    sts.zip 390M</span><br><span class="line">    length    offset</span><br><span class="line">    blk1:   0-128M      128M		0</span><br><span class="line">    blk2:    128M-256M  128M        128M</span><br><span class="line">    ...</span><br><span class="line">    blk4:    384M-390M  6M          384M</span><br><span class="line"></span><br><span class="line">LocatedFileStatus</span><br><span class="line">	LocatedFileStatus是FileStatus的子类，除了文件的属性，还有块的位置信息！</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取到文件的块信息</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testGetBlockInfomation</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/sts.zip&quot;</span>);</span><br><span class="line"></span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; status = fs.listLocatedStatus(path);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(status.hasNext()) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">LocatedFileStatus</span> <span class="variable">locatedFileStatus</span> <span class="operator">=</span> status.next();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;Ownner:&quot;</span>+locatedFileStatus.getOwner());</span><br><span class="line">        System.out.println(<span class="string">&quot;Group:&quot;</span>+locatedFileStatus.getGroup());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//---------------块的位置信息--------------------</span></span><br><span class="line">        BlockLocation[] blockLocations = locatedFileStatus.getBlockLocations();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (BlockLocation blockLocation : blockLocations) &#123;</span><br><span class="line"></span><br><span class="line">            System.out.println(blockLocation);</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;------------------------&quot;</span>);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="自定义上传和下载"><a href="#自定义上传和下载" class="headerlink" title="自定义上传和下载"></a>自定义上传和下载</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.junit.After;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 1. 上传文件时，只上传这个文件的一部分</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 2. 下载文件时，如何只下载这个文件的某一个块？ </span></span><br><span class="line"><span class="comment"> * 			或只下载文件的某一部分？</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestCustomUploadAndDownload</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> FileSystem fs;</span><br><span class="line">    <span class="keyword">private</span> FileSystem localFs;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException, URISyntaxException &#123;</span><br><span class="line">        <span class="comment">//创建一个客户端对象</span></span><br><span class="line">        fs=FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>),conf);</span><br><span class="line">        localFs=FileSystem.get(<span class="keyword">new</span> <span class="title class_">Configuration</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">if</span> (fs !=<span class="literal">null</span>) &#123;</span><br><span class="line">            fs.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 只上传文件的前10M</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * 官方的实现</span></span><br><span class="line"><span class="comment">	 * InputStream in=null;</span></span><br><span class="line"><span class="comment">      OutputStream out = null;</span></span><br><span class="line"><span class="comment">      try &#123;</span></span><br><span class="line"><span class="comment">        in = srcFS.open(src);</span></span><br><span class="line"><span class="comment">        out = dstFS.create(dst, overwrite);</span></span><br><span class="line"><span class="comment">        IOUtils.copyBytes(in, out, conf, true);</span></span><br><span class="line"><span class="comment">      &#125; catch (IOException e) &#123;</span></span><br><span class="line"><span class="comment">        IOUtils.closeStream(out);</span></span><br><span class="line"><span class="comment">        IOUtils.closeStream(in);</span></span><br><span class="line"><span class="comment">        throw e;</span></span><br><span class="line"><span class="comment">      &#125;</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testCustomUpload</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//提供两个Path，和两个FileSystem</span></span><br><span class="line">        Path src=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;e:/悲惨世界(英文版).txt&quot;</span>);</span><br><span class="line">        Path dest=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/悲惨世界(英文版)10M.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用本地文件系统中获取的输入流读取本地文件</span></span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">is</span> <span class="operator">=</span> localFs.open(src);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用HDFS的分布式文件系统中获取的输出流，向dest路径写入数据</span></span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">os</span> <span class="operator">=</span> fs.create(dest, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1k</span></span><br><span class="line">        <span class="type">byte</span> [] buffer=<span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 流中数据的拷贝</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">1024</span> * <span class="number">10</span>; i++) &#123;</span><br><span class="line">            is.read(buffer);</span><br><span class="line">            os.write(buffer);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关流</span></span><br><span class="line">        IOUtils.closeStream(is);</span><br><span class="line">        IOUtils.closeStream(os);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testFirstBlock</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//提供两个Path，和两个FileSystem</span></span><br><span class="line">        Path src=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/sts.zip&quot;</span>);</span><br><span class="line">        Path dest=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;e:/firstblock&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用HDFS的分布式文件系统中获取的输入流，读取HDFS上指定路径的数据</span></span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">is</span> <span class="operator">=</span> fs.open(src);</span><br><span class="line">        <span class="comment">// 使用本地文件系统中获取的输出流写入本地文件</span></span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">os</span> <span class="operator">=</span> localFs.create(dest, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1k</span></span><br><span class="line">        <span class="type">byte</span> [] buffer=<span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 流中数据的拷贝</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">1024</span> * <span class="number">128</span>; i++) &#123;</span><br><span class="line">            is.read(buffer);</span><br><span class="line">            os.write(buffer);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关流</span></span><br><span class="line">        IOUtils.closeStream(is);</span><br><span class="line">        IOUtils.closeStream(os);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testSecondBlock</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//提供两个Path，和两个FileSystem</span></span><br><span class="line">        Path src=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/sts.zip&quot;</span>);</span><br><span class="line">        <span class="comment">//Path dest=new Path(&quot;e:/secondblock&quot;);</span></span><br><span class="line">        Path dest=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;e:/thirdblock&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用HDFS的分布式文件系统中获取的输入流，读取HDFS上指定路径的数据</span></span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">is</span> <span class="operator">=</span> fs.open(src);</span><br><span class="line">        <span class="comment">// 使用本地文件系统中获取的输出流写入本地文件</span></span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">os</span> <span class="operator">=</span> localFs.create(dest, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定位到流的指定位置</span></span><br><span class="line">        is.seek(<span class="number">1024</span>*<span class="number">1024</span>*<span class="number">128</span>*<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1k</span></span><br><span class="line">        <span class="type">byte</span> [] buffer=<span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 流中数据的拷贝</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">1024</span> * <span class="number">128</span>; i++) &#123;</span><br><span class="line">            is.read(buffer);</span><br><span class="line">            os.write(buffer);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关流</span></span><br><span class="line">        IOUtils.closeStream(is);</span><br><span class="line">        IOUtils.closeStream(os);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testFinalBlock</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//提供两个Path，和两个FileSystem</span></span><br><span class="line">        Path src=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/sts.zip&quot;</span>);</span><br><span class="line">        <span class="comment">//Path dest=new Path(&quot;e:/secondblock&quot;);</span></span><br><span class="line">        Path dest=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;e:/fourthblock&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用HDFS的分布式文件系统中获取的输入流，读取HDFS上指定路径的数据</span></span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">is</span> <span class="operator">=</span> fs.open(src);</span><br><span class="line">        <span class="comment">// 使用本地文件系统中获取的输出流写入本地文件</span></span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">os</span> <span class="operator">=</span> localFs.create(dest, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定位到流的指定位置</span></span><br><span class="line">        is.seek(<span class="number">1024</span>*<span class="number">1024</span>*<span class="number">128</span>*<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//buffSize 默认不能超过4096</span></span><br><span class="line">        IOUtils.copyBytes(is, os, <span class="number">4096</span>, <span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h1 id="HDFS的数据流"><a href="#HDFS的数据流" class="headerlink" title="HDFS的数据流"></a>HDFS的数据流</h1><h2 id="HDFS-写数据流程"><a href="#HDFS-写数据流程" class="headerlink" title="HDFS 写数据流程"></a>HDFS 写数据流程</h2><p><img src="/2021/02/08/HDFS/image-20211124184155174.png" alt="image-20211124184155174"></p>
<ol>
<li><p> 服务端：启动 NameNode 和 DataNode；</p>
</li>
<li><p> 客户端：创建一个能够连接到 HDFS 的客户端对象 <code>DistributedFileSystem</code>。</p>
</li>
<li><p> 由客户端对象向 NameNode 发送上传文件请求；</p>
</li>
<li><p>NameNode 处理请求，校验客户端请求权限、路径等的合法性</p>
<ul>
<li>  权限校验：NameNode 会检查客户端用户是否有权限操作 HDFS 文件系统；</li>
<li>  路径校验：NameNode 会检查待上传的目标文件是否已存在，目标文件的父目录是否存在等；如果存在，通过 <code>overwrite=true/fasle</code> 属性来决定是否覆盖 HDFS 上现有的文件。</li>
</ul>
</li>
<li><p> 校验通过后，NameNode 响应客户端可以上传文件；</p>
</li>
<li><p>客户端根据 block 参数的大小，将文件切分为一个个 Block，并开始上传第一个块，默认第一块的范围是 0~128M；NameNode 根据客户端设置的文件副本数(默认为3)，通过机架感知策略选取 3 个 DataNode 节点返回，表示采用这三个节点存储数据；</p>
<ul>
<li>  根据机架感知策略，NameNode 返回的 DataNode 列表中，是按照网络拓扑距离离客户端从小到大的顺序排列的，也就是说，列表中的第一个 DataNode 节点距离客户端一定是最近的，之后的每个节点距离客户端越来越远。</li>
</ul>
</li>
<li><p>客户端根据返回的 DataNode 节点列表，请求建立传输通道。</p>
<ul>
<li>  客户端向最近（网络拓扑距离最近）的 DataNode 节点发起通道建立请求，再由这个 DataNode 节点依次向通道中的（距离当前DataNode 网络距离最近的）下一个节点发送建立通道请求，各个节点都响应成功后 ，通道建立成功。</li>
</ul>
</li>
<li><p>客户端每读取 64K 的数据，就会将数据封装成一个 <strong>packet</strong>（数据包，传输的基本单位），通过 <strong>FSDataOutputStream</strong> 对象将 packet 发送到通道的下一个节点，通道中的节点收到 packet 之后，首先落盘存储，然后再将 packet 发送到通道的下一个节点！</p>
<blockquote>
<p>  优点：如果由客户端一个人向所有的 DataNode 进行数据传输的话，有多少个副本，客户端就需要发送多少次数据，当副本数量很大时（比如达到了100），一个客户端就需要向100个客户端都发送数据，显然效率非常慢。在 HDFS 中采用人传人的方式传递数据，比如由客户端向一个 DataNode 发送数据，再由该 DataNode 向下一个 DataNode 继续发送数据，以此类推，达到负载均衡和加速数据传输的效果。</p>
</blockquote>
</li>
<li><p> 每个节点在收到 packet 后，都会向客户端发送 ack 确认消息。</p>
</li>
<li><p> 当一个 Block 传输完成之后（一个 Block 由多个 Packet 组成），Block 传输通道关闭，所有的 DataNode 都会向 NameNode 汇报当前 Block 已经传输完毕以及 Block 的其它相关信息，如 BlockId、offset 偏移量等等。</p>
</li>
<li><p> 第一个块传输完成后，第二个块开始传输，依次重复 3~9 步，直到最后一个块传输完成，NameNode 向客户端响应传输完成，客户端关闭输出流。</p>
</li>
</ol>
<hr>
<h3 id="异常写流程"><a href="#异常写流程" class="headerlink" title="异常写流程"></a>异常写流程</h3><ol>
<li> <code>1~6</code> 同上；</li>
<li> 客户端每读取 64K 的数据，封装成一个 packet，封装成功的 packet，放入到一个队列中，这个队列称为 <strong>dataQuene(待发送数据包队列)</strong></li>
<li>在发送时，会先将 dataQuene 中的 packet 按顺序发送，发送后再放入到**ackquene(已发送数据包等待ack确认消息队列)**。<ul>
<li>  每个 DataNode 节点在收到 packet 后，都会向客户端发送 ack 确认消息；</li>
<li>  如果一个 packet 在发送后，已经收到了所有 DataNode 返回的 ack 确认消息，这个 packet 会在 ackquene 中删除；</li>
<li>  假如一个 packet 在发送后，在等待 DataNode 的 ack 确认消息时超时，传输就会中止，ackquene 中的所有 packet 都会回滚到 dataQuene。</li>
</ul>
</li>
<li> 重新建立通道：剔除坏的 DataNode 节点，重新建立通道，建立完成之后，继续传输！</li>
<li> 只要有一个 DataNode 节点收到了数据，DataNode 上报 NameNode 已经收完此块，NameNode 就认为当前块已经传输成功了。至于其它的 DataNode 节点可能未收到完整数据，NameNode 会在之后空闲的时候自动维护副本数！</li>
</ol>
<hr>
<h2 id="HDFS-读数据流程"><a href="#HDFS-读数据流程" class="headerlink" title="HDFS 读数据流程"></a>HDFS 读数据流程</h2><p><img src="/2021/02/08/HDFS/image-20211124210327466.png" alt="image-20211124210327466"></p>
<ol>
<li> 服务端启动 HDFS 中的 NameNode 和 DataNode 进程；</li>
<li> 客户端创建一个分布式文件系统客户端 <code>DistributedFileSystem</code>，由客户端向 NameNode 发送请求，请求下载文件；</li>
<li>NameNode 处理请求，检查客户端是否有权限上传，路径是否合法等<ul>
<li>  权限校验：NameNode 会检查客户端用户是否有权限操作 HDFS 文件系统；</li>
<li>  路径校验：NameNode 会检查待上传的目标文件是否已存在，目标文件的父目录是否存在等；</li>
</ul>
</li>
<li>检查通过后，NameNode 通过查询元数据，找到文件块所在的 DataNode 的地址并响应给客户端。<ul>
<li>  根据机架感知策略，NameNode 返回的 DataNode 列表中，是按照网络拓扑距离离客户端从小到大的顺序排列的，也就是说，列表中的第一个 DataNode 节点距离客户端一定是最近的，之后的每个节点距离客户端越来越远。</li>
</ul>
</li>
<li> 客户端根据返回的 DataNode 节点，挑选一台最近的可以正常运行的 DataNode 服务器，建立连接，请求读取数据。</li>
<li> 客户端以 Packet 为单位接收数据，先将数据写在缓存中，缓存区满后再将数据写入目标文件。</li>
</ol>
<hr>
<h2 id="网络拓扑-节点距离计算"><a href="#网络拓扑-节点距离计算" class="headerlink" title="网络拓扑-节点距离计算"></a>网络拓扑-节点距离计算</h2><p>在 HDFS 写数据的过程中，NameNode 会选择距离待上传数据最近的 DataNode （也就是距离发起上传的客户端最近的 DataNode）接收数据。那么这个最近距离怎么计算呢？</p>
<p><strong>节点距离：两个节点到达最近的共同祖先的距离总和。</strong>  </p>
<p><img src="/2021/02/08/HDFS/image-20211125112723407.png" alt="image-20211125112723407"></p>
<h2 id="机架感知"><a href="#机架感知" class="headerlink" title="机架感知"></a>机架感知</h2><p><strong>Hadoop 2.7.2 默认的机架感知策略：</strong></p>
<ol>
<li> 第一个副本放在本地机架的一个 DN 节点；</li>
<li>第二个副本放在本地机架的另一个 DN 节点；<ul>
<li>  本地机架的网络拓扑距离最多为2，速度快！</li>
</ul>
</li>
<li>第三个副本放在其他机架的一个 DN 节点<ul>
<li>  为了安全性，防止本地机架挂掉。</li>
</ul>
</li>
</ol>
<hr>
<h1 id="NameNode-和-SecondaryNameNode"><a href="#NameNode-和-SecondaryNameNode" class="headerlink" title="NameNode 和 SecondaryNameNode"></a>NameNode 和 SecondaryNameNode</h1><h2 id="NameNode-中元数据的组成"><a href="#NameNode-中元数据的组成" class="headerlink" title="NameNode 中元数据的组成"></a>NameNode 中元数据的组成</h2><ul>
<li>  NameNode 中完整的元数据信息是由<strong>日志文件edits_xxx</strong>和<strong>快照文件fsimage</strong>共同组成的。</li>
</ul>
<p>元数据信息保存在 NameNode 服务器上的指定目录下（这个目录是根据配置文件信息创建的），我自己指定的目录是<code>/opt/module/hadoop-2.7.2/data/dfs/name/</code>，可以看到元数据信息由两部分组成，分别是日志文件 <code>edits_xxx</code> 和快照文件<code>fsimage_xxx</code>。也就是说 NameNode 服务在运行时会将这两部分数据都加载到内存中形成完整的元数据信息。</p>
<p>当客户端向 NameNode 发送读数据请求时，NameNode 会先将磁盘上的元数据信息加载到内存中，在内存中进行检索找到保存真实数据的 DataNode 节点地址返回给客户端。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[lvnengdong@hadoop102 dfs]$ tree /opt/module/hadoop-2.7.2/data/dfs/name/</span><br><span class="line">/opt/module/hadoop-2.7.2/data/dfs/name/</span><br><span class="line">├── current</span><br><span class="line">│   ├── edits_0000000000000000001-0000000000000000007</span><br><span class="line">│   ├── edits_inprogress_0000000000000000008</span><br><span class="line">│   ├── fsimage_0000000000000000000</span><br><span class="line">│   ├── fsimage_0000000000000000000.md5</span><br><span class="line">│   ├── fsimage_0000000000000000007</span><br><span class="line">│   ├── fsimage_0000000000000000007.md5</span><br><span class="line">│   ├── seen_txid</span><br><span class="line">│   └── VERSION</span><br><span class="line">└── in_use.lock</span><br></pre></td></tr></table></figure>

<p>为什么磁盘中的元数据信息要分成两部分呢？这一点其实和 Redis 很相似，首先日志文件中保存了所有对元数据的写操作（行为数据），但是日志文件会随着 NameNode 服务运行时间的增加而不断膨胀，当日志文件的数量（或大小）到达了一个阈值后，会对这些日志文件进行一个压缩，压缩后的日志文件就变成了一个快照文件<code>fsimage</code>，<code>fsimage</code> 是一个当前时刻元数据的一致性快照（快照文件保存的是状态数据），当生成快照文件后，就可以将当前快照之前的所有日志文件清空，重新开始记录新的日志文件。所以在运行 NameNode 进程时，需要加载两种类型的文件才能在内存中拼接成完整的元数据信息：1️⃣某一时刻的快照文件；2️⃣该时刻之后新生成的所有日志文件。</p>
<hr>
<h2 id="NN-和-2NN-工作机制"><a href="#NN-和-2NN-工作机制" class="headerlink" title="NN 和 2NN 工作机制"></a>NN 和 2NN 工作机制</h2><p><img src="/2021/02/08/HDFS/image-20211125115010253.png" alt="image-20211125115010253"></p>
<p><strong>第一阶段：NameNode启动</strong></p>
<ol>
<li><p> 如果是第一次启动 NameNode 的话，需要执行 NameNode 格式化指令，创建 Fsimage 和 Edits 文件。如果不是第一次启动 NameNode，会直接加载已存在的日志文件和镜像文件到内存中组成完成的元数据信息。</p>
</li>
<li><p> 客户端提交对元数据进行增删改查的请求。</p>
</li>
<li><p> NameNode 会先将写操作记录到日志文件中，更新滚动日志。</p>
</li>
<li><p>NameNode 在内存中对元数据进行增删改。【注意是先将写操作同步到日志文件中，再执行真正的写操作】</p>
<blockquote>
<p>  首先对元数据的写操作肯定是先发生在内存中的，为了防止突然断电导致内存中的数据丢失，NameNode 采用的策略是先将对每个对元数据执行的写操作都同步到日志文件中，然后再去更新内存中的元数据信息，这样在进行断电后数据恢复时，就可以根据日志文件来将元数据到断电前的状态。</p>
</blockquote>
</li>
</ol>
<p><strong>第二阶段：Secondary NameNode工作</strong></p>
<ol>
<li> Secondary NameNode询问 NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。</li>
<li> Secondary NameNode请求执行CheckPoint。</li>
<li> NameNode滚动正在写的Edits日志。</li>
<li> 将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。</li>
<li> Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</li>
<li> 生成新的镜像文件fsimage.chkpoint。</li>
<li> 拷贝fsimage.chkpoint到NameNode。</li>
<li> NameNode将fsimage.chkpoint重新命名成fsimage。</li>
</ol>
<hr>
<h2 id="NN和2NN工作机制详解"><a href="#NN和2NN工作机制详解" class="headerlink" title="NN和2NN工作机制详解"></a>NN和2NN工作机制详解</h2><ul>
<li>  Fsimage：NameNode 内存中元数据序列化后形成的文件。  </li>
<li>  Edits：记录客户端更新元数据信息的每一步操作。</li>
</ul>
<ol>
<li> NameNode 启动时，先滚动 Edits 并生成一个空的 <code>edits.inprogress</code>，然后加载 Edits 和 Fsimage 到内存中，此时 NameNode 内存就持有最新的元数据信息。</li>
<li> Client 开始对 NameNode 发送元数据的增删改的请求，这些请求的操作首先会被记录到 <code>edits.inprogress</code> 中（查询元数据的操作不会被记录在 Edits 中，因为查询操作不会更改元数据信息），如果此时 NameNode 挂掉，重启后会从 Edits 中读取元数据的信息。然后，NameNode 会在内存中执行元数据的增删改的操作。  </li>
<li> 由于 Edits 中记录的操作会越来越多，Edits 文件会越来越大，导致 NameNode 在启动加载 Edits 时会很慢，所以需要对 Edits 和Fsimage 进行合并（所谓合并，就是将 Edits 和 Fsimage 加载到内存中，照着 Edits 中的操作一步步执行，最终形成新 Fsimage）。</li>
<li> SecondaryNameNode 的作用就是帮助 NameNode 进行 Edits 和 Fsimage 的合并工作。SecondaryNameNode 首先会询 NameNode是否需要 CheckPoint（触发 CheckPoint 需要满足两个条件中的任意一个，定时时间到l了和 Edits 中数据写满了）。直接带 NameNode是否检查结果。</li>
<li> SecondaryNameNode 执行 CheckPoint 操作，首先会让 NameNode 滚动 Edits 并生成一个空的 <code>edits.inprogress</code>，【滚动 Edits 就是封闭当前的 <code>edits.inprogress</code>，重新生成一个新的  <code>edits.inprogress</code>】滚动 Edits 的目的是给 Edits 打个标记，以后所有新的操作都写入 <code>edits.inprogress</code>，其他未合并的 Edits 和 Fsimage 会拷贝到 SecondaryNameNode 的本地，然后将拷贝的 Edits 和 Fsimage 加载到内存中进行合并，生成 <code>fsimage.chkpoint</code>，然后将 <code>fsimage.chkpoint</code> 拷贝给 NameNode，重命名为 Fsimage 后替换掉原来的 Fsimage。NameNode 在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">启动加载就是在 fsimage 的基础上按照 edits 日志文件重新执行一遍写操作，就能将 NameNode 恢复到上一次停止时的状态。</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="fsimage-和-edits-解析"><a href="#fsimage-和-edits-解析" class="headerlink" title="fsimage 和 edits 解析"></a>fsimage 和 edits 解析</h2><p>第一次格式化NN时，此时会创建NN工作的目录，将在 <code>/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current</code> 目录中产生如下文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fsimage 0000000000000000000</span><br><span class="line">fsimage 0000000000000000000.md5</span><br><span class="line">seen_txid</span><br><span class="line">VERSION</span><br></pre></td></tr></table></figure>

<ol>
<li> <strong>fsimage</strong> 文件：HDFS 文件系统元数据的一个永久性的检查点，其中包含 HDFS 文件系统的所有目录和文件 <code>idnode</code> 的序列化信息。</li>
<li> edits文件：存放 HDFS 文件系统的所有更新操作的文件，文件系统客户端执行的所有写操作首先会被记录到Edits文件中。</li>
<li> <strong>seen_txid</strong>文件：保存的是一个数字，就是最后一个edits_的数字</li>
<li> 每次 NameNode 启动的时候都会将 <code>fsimage</code> 文件读入内存，加载 <code>edits</code> 里面的写操作，保证内存中的元数据信息是最新的、同步的。</li>
</ol>
<p><strong>fsimage文件的产生</strong>：</p>
<pre><code>②当NN在启动时，NN会将所有的edits文件和fsiamge文件加载到内存合并得到最新的元数据，将元数据持久化到磁盘生成新的fsimage文件。
【NameNode在运行期间是不允许将edits文件和fsiamge文件合并成一个新的fsiamge文件的，因为NameNode在HDFS中处于一个非常重要的地位，承担的流量非常大，而合并edits文件和fsiamge文件又是一个非常耗费性能的操作，所以在NameNode运行期间不允许合并这两个文件。只有在每次NameNode刚启动时的阶段，处于一个安全模式，这个模式下不允许客户端对NameNode进行读写操作，整个流量处于一个比较低的阶段，这时候才会进行将edits文件和fsiamge文件合并成一个新的fsiamge文件操作】

③如果启用了2nn,2nn也会辅助NN合并元数据，会将合并后的元数据发送到NN
</code></pre>
<p>edits：<br>NN在启动之后，每次接受的写操作请求，都会将写命令记录到edits文件中，edits文件每间隔一定的时间和大小滚动！</p>
<p>为合并过的Edits中的元数据信息已经被记录在Fsimage中。  </p>
<h3 id="注意点："><a href="#注意点：" class="headerlink" title="注意点："></a>注意点：</h3><blockquote>
<p>  <strong>Q：fsimage 中没有记录 block 所对应 DataNode，为什么？</strong></p>
</blockquote>
<p>A：在集群启动后，要求 DataNode 上报数据块信息，并间隔一段时间后再次上报。</p>
<hr>
<h2 id="CheckPoint-时间设置"><a href="#CheckPoint-时间设置" class="headerlink" title="CheckPoint 时间设置"></a>CheckPoint 时间设置</h2><ol>
<li><p>默认情况下，SecondaryNameNode每隔一小时执行一次。</p>
<ul>
<li>  hdfs-default.xml</li>
</ul>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">&lt;/property &gt;</span><br></pre></td></tr></table></figure>

</li>
<li><p>一分钟检查一次操作次数，当操作次数达到 100 万时，SecondaryNameNode执行一次。</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.txns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>操作动作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.check.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span> 1分钟检查一次操作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">&lt;/property &gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h1 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h1><h2 id="DataNode-工作机制"><a href="#DataNode-工作机制" class="headerlink" title="DataNode 工作机制"></a>DataNode 工作机制</h2><p><img src="/2021/02/08/HDFS/image-20211126180438535.png" alt="image-20211126180438535"></p>
<ol>
<li> 一个数据块在 DataNode 上以文件形式存储在磁盘上，每个 Block 包括两个文件，一个是数据本身，一个是元数据（包括数据块的长度，块数据的校验和，以及时间戳等）。</li>
<li> DataNode 启动需要先将自身的信息注册到 NameNode 上，注册完成后，还需要周期性（1小时）的向 NameNode 上报最新的块信息。</li>
<li> 心跳是每3秒一次，心跳返回结果中还带有 NameNode 发给该 DataNode 的命令，如复制块数据到另一台机器，或删除某个数据块。如果 NameNode 超过 10 分钟没有收到某个 DataNode 的心跳，则认为该 DataNode 节点不可用。</li>
<li> 集群运行中可以安全加入和退出一些机器。</li>
</ol>
<h2 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h2><p>当 DataNode 向 NameNode 上报自身的信息时，会先对当前节点内的所有数据进行一次数据完整性校验。校验流程如下：</p>
<ol>
<li> 当 DataNode 读取 Block 的时候，它会计算 CheckSum。</li>
<li> 如果计算后的 CheckSum，与 Block 创建时值不一样，说明 Block 已经损坏。</li>
<li> Block 损坏后，DataNode 会删除该损坏的 Block，并向 NameNode 上报该信息，这样当 Client 再来读取该 Block 时，NameNode 就会分配 Client 读取其他 DataNode 上的 Block。</li>
<li> 并且 DataNode 在运行时会周期性的验证磁盘上所有块的 CheckSum。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/02/07/%E5%8F%82%E8%80%83%E5%8D%9A%E5%AE%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/02/07/%E5%8F%82%E8%80%83%E5%8D%9A%E5%AE%A2/" class="post-title-link" itemprop="url">参考博客</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2021-02-07 18:53:08 / Modified: 21:05:58" itemprop="dateCreated datePublished" datetime="2021-02-07T18:53:08+08:00">2021-02-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%85%B6%E5%AE%83/" itemprop="url" rel="index"><span itemprop="name">其它</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h2><p>SSH：Secure SHell</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/diffx/p/9553587.html">https://www.cnblogs.com/diffx/p/9553587.html</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/30/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/01/30/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB/" class="post-title-link" itemprop="url">常用的工具类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-01-30 13:16:25" itemprop="dateCreated datePublished" datetime="2021-01-30T13:16:25+08:00">2021-01-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-04-11 23:29:57" itemprop="dateModified" datetime="2021-04-11T23:29:57+08:00">2021-04-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BC%80%E5%8F%91%E6%97%A5%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">开发日记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="数组工具类：Arrays"><a href="#数组工具类：Arrays" class="headerlink" title="数组工具类：Arrays"></a>数组工具类：Arrays</h1><blockquote>
<p><code>java.util.Arrays</code>：此类包含用来操作数组的各种方法。 该类中所有的方法均为静态方法。</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center"><code>public static String toString（int[] a）</code></td>
<td align="center">返回指定数组内容的字符串表示形式。</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center"><code>public static void sort（int[] a）</code></td>
<td align="center">对<code>int[] a</code>数组进行升序排序</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center"><code>public static &lt;T&gt; List&lt;T&gt; asList(T... a)</code></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<h1 id="Arrays-asList"><a href="#Arrays-asList" class="headerlink" title="Arrays.asList"></a>Arrays.asList</h1><blockquote>
<p>作用</p>
</blockquote>
<p>该方法是将<strong>数组</strong>转换成<strong>List集合</strong>的方法。</p>
<blockquote>
<p>源码</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Arrays</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; List&lt;T&gt; <span class="title function_">asList</span><span class="params">(T... a)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(a);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">	该方法是将 T 类型的数组转换成 List&lt;T&gt; 集合的方法。</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<ul>
<li>注意：此处返回的 ArrayList 对象不是 java.util 包下的 ArrayList 对象，而是 java.util.Arrays.ArrayList ， 它是 Arrays 类自己定义的一个静态内部类，该类继承自 AbstractList ，所以没有实现 <code>add()</code>、<code>remove()</code>等方法。而在 AbstractList 类中，调用<code>add()</code>、<code>remove()</code>方法是会直接抛出<code>java.lang.UnsupportedOperationException</code>异常的。</li>
</ul>
<blockquote>
<p>示例</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Employee</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Double salary;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> Integer age;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Employee</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Employee</span><span class="params">(Double salary, String name, Integer age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.salary = salary;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Double <span class="title function_">getSalary</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> salary;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSalary</span><span class="params">(Double salary)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.salary = salary;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">getAge</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAge</span><span class="params">(Integer age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Employee&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;salary=&quot;</span> + salary +</span><br><span class="line">                <span class="string">&quot;, name=&#x27;&quot;</span> + name + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, age=&quot;</span> + age +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">    List&lt;String&gt; list1 = Arrays.asList(<span class="string">&quot;aaa&quot;</span>, <span class="string">&quot;bbb&quot;</span>, <span class="string">&quot;ccc&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    List&lt;Integer&gt; list2 = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line">    </span><br><span class="line">    Employee[] employees = &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">3000.00</span>, <span class="string">&quot;张三&quot;</span>, <span class="number">23</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">5000.00</span>, <span class="string">&quot;李四&quot;</span>, <span class="number">24</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">8000.00</span>, <span class="string">&quot;王五&quot;</span>, <span class="number">27</span>)</span><br><span class="line">    &#125;;</span><br><span class="line">    List&lt;Employee&gt; list3 = Arrays.asList(employees);</span><br><span class="line">    System.out.println(list1);</span><br><span class="line">    System.out.println(list2);</span><br><span class="line">    System.out.println(list3);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">输出结果：</span></span><br><span class="line"><span class="comment">    [aaa, bbb, ccc]</span></span><br><span class="line"><span class="comment">    [1, 2, 3]</span></span><br><span class="line"><span class="comment">    [Employee&#123;salary=3000.0, name=&#x27;张三&#x27;, age=23&#125;, Employee&#123;salary=5000.0, name=&#x27;李四&#x27;, age=24&#125;, Employee&#123;salary=8000.0, name=&#x27;王五&#x27;, age=27&#125;]</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Tip</p>
</blockquote>
<ol>
<li><p>该方法适用于对象型数据的数组（如String、Integer、Employee等），不建议使用基本数据类型的数组（int、double等）。</p>
</li>
<li><p>该方法将数组与List列表连接起来；当更新其中一个时，另一个自动更新。</p>
</li>
<li><p>用此方法得到的List对象的长度是不可改变的，不支持写操作。如 add()、remove()、clear()等方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">add</span> <span class="operator">=</span> list2.add(<span class="number">7</span>);</span><br><span class="line"><span class="comment">// 如果使用得到的list对象进行add()操作，就会直接抛出 java.lang.UnsupportedOperationException 异常。</span></span><br></pre></td></tr></table></figure>

<p>如果使用该List对象只是用来进行读操作（遍历、读取集合中某个元素等），就可以放心的使用<code>asList()</code>方法，如果你还想进行写操作，还是要new一个<code>java.util.ArrayList</code>对象，然后进行写操作。</p>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/29/PageHelper/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/01/29/PageHelper/" class="post-title-link" itemprop="url">PageHelper</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2021-01-29 19:16:43 / Modified: 20:42:35" itemprop="dateCreated datePublished" datetime="2021-01-29T19:16:43+08:00">2021-01-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/MyBatis/" itemprop="url" rel="index"><span itemprop="name">MyBatis</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>官方文档：<a target="_blank" rel="noopener" href="https://pagehelper.github.io/docs/howtouse/">https://pagehelper.github.io/docs/howtouse/</a></p>
<h2 id="在SpringBoot中使用PageHelper"><a href="#在SpringBoot中使用PageHelper" class="headerlink" title="在SpringBoot中使用PageHelper"></a>在SpringBoot中使用PageHelper</h2><h3 id="1、引入分页插件"><a href="#1、引入分页插件" class="headerlink" title="1、引入分页插件"></a>1、引入分页插件</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.github.pagehelper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>pagehelper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>最新版本<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="2、在代码中使用"><a href="#2、在代码中使用" class="headerlink" title="2、在代码中使用"></a>2、在代码中使用</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/29/Java8%E6%96%B0%E7%89%B9%E6%80%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/01/29/Java8%E6%96%B0%E7%89%B9%E6%80%A7/" class="post-title-link" itemprop="url">Java8新特性</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-01-29 10:12:14" itemprop="dateCreated datePublished" datetime="2021-01-29T10:12:14+08:00">2021-01-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-11-18 15:17:20" itemprop="dateModified" datetime="2021-11-18T15:17:20+08:00">2021-11-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/JavaSE/" itemprop="url" rel="index"><span itemprop="name">JavaSE</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="函数式接口"><a href="#函数式接口" class="headerlink" title="函数式接口"></a>函数式接口</h1><ul>
<li>  包含且仅包含一个抽象方法的接口称为<strong>函数式接口</strong>。（不是规定接口中只能有一个方法，非抽象方法的个数是不加限制的，当然在 JDK8 中接口中只能有抽象方法和静态方法了，所以这里的非抽象方法在 JDK8 中就是指静态方法，在 JDK9 中接口中还可以声明 private 方法）</li>
<li>  <code>@FunctionalInterface</code>注解：我们可以通过在任意接口上使用<code>@FunctionalInterface</code>注解来检查当接口是否为函数式接口。如果某个接口是一个函数式接口，在 JavaDoc也会包含一条声明加以说明。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2021/11/18 9:51</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">MyFun</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">fun1</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">fun2</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;哈哈哈&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Java内置四大核心函数式接口"><a href="#Java内置四大核心函数式接口" class="headerlink" title="Java内置四大核心函数式接口"></a>Java内置四大核心函数式接口</h2><table>
<thead>
<tr>
<th align="left">函数式接口</th>
<th align="left">抽象方法</th>
<th align="center">参数类型</th>
<th align="center">返回值类型</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">消费型接口：<code>Consumer&lt;T&gt;</code></td>
<td align="left"><code>void accept(T t)</code></td>
<td align="center">T</td>
<td align="center">void</td>
<td align="left">对类型为T的对象进行操作。<strong>只进不出</strong></td>
</tr>
<tr>
<td align="left">供给型接口：<code>Supplier&lt;T&gt;</code></td>
<td align="left"><code>T get()</code></td>
<td align="center">-</td>
<td align="center">T</td>
<td align="left">返回类型为T的对象。<strong>只出不进</strong></td>
</tr>
<tr>
<td align="left">函数型接口：<code>Function&lt;T R&gt;</code></td>
<td align="left"><code>R apply(T t)</code></td>
<td align="center">T</td>
<td align="center">R</td>
<td align="left">对类型为T的对象进行操作，<br>并返回类型为R的结果对象</td>
</tr>
<tr>
<td align="left">断定型接口：<code>Predicate&lt;T&gt;</code></td>
<td align="left"><code>boolean test(T t)</code></td>
<td align="center">T</td>
<td align="center">Boolean</td>
<td align="left">确定类型为T的对象是否满足约束，<br>并返回Boolean值</td>
</tr>
</tbody></table>
<h2 id="其它函数式接口"><a href="#其它函数式接口" class="headerlink" title="其它函数式接口"></a>其它函数式接口</h2><table>
<thead>
<tr>
<th align="center">函数式接口</th>
<th align="center">抽象方法</th>
<th align="center">参数类型</th>
<th align="center">返回类型</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>BiFunction&lt;T, U, R&gt;</code></td>
<td align="center"><code>R apply(T t, U u);</code></td>
<td align="center">T，U</td>
<td align="center">R</td>
</tr>
<tr>
<td align="center"><code>UnaryOperator&lt;T&gt;</code><br>(Funtion子接口)</td>
<td align="center"><code>T apply(T t)</code></td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
<tr>
<td align="center"><code>BinaryOperator&lt;T&gt;</code><br>(BinFunction子接口)</td>
<td align="center"><code>T apply(T t1, T t2);</code></td>
<td align="center">T，T</td>
<td align="center">T</td>
</tr>
<tr>
<td align="center"><code>BiConsumer&lt;T, U&gt;</code></td>
<td align="center"><code>void accept(T t, U u);</code></td>
<td align="center">T，U</td>
<td align="center">void</td>
</tr>
<tr>
<td align="center"><code>ToIntFunction&lt;T&gt;</code><br><code>ToLongFunction&lt;T&gt;</code><br><code>ToDoubleFunction&lt;T&gt;</code></td>
<td align="center"><code>int applyAsInt(T value);</code><br><code>long applyAsLong(T value);</code><br><code>double applyAsDouble(T value);</code></td>
<td align="center">T</td>
<td align="center">int<br>long<br>double</td>
</tr>
<tr>
<td align="center"><code>IntFunction&lt;R&gt;</code><br><code>LongFunction&lt;R&gt;</code><br><code>DoubleFunction&lt;R&gt;</code></td>
<td align="center"><code>R apply(int value);</code><br><code>R apply(long value);</code><br><code>R apply(double value);</code></td>
<td align="center">int<br>long<br>double</td>
<td align="center">R</td>
</tr>
</tbody></table>
<hr>
<h1 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h1><p>所谓的 Lambda 表达式，就是对接口中抽象方法的实现。</p>
<p>Lambda是一个<strong>匿名函数</strong>，我们可以把Lambda表达式理解为<strong>一段可以传递的代码</strong>（将代码像变量一样进行传递）。可以写出更简洁、更灵活的代码。</p>
<p><strong>Lambda 表达式整体可以视为一个看起来很长的变量，可以作为方法中的参数传递</strong>。</p>
<p>Lambda表达式，也可以称为闭包，是 Java8 的新特性。</p>
<p>Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中）。</p>
<p>原来的匿名内部类 <code>--&gt;&gt;</code> Lambda表达式</p>
<p>Lambda 表达式要求接口是函数式接口，即接口中只有一个抽象方法，所以在重写接口中的抽象方法时不会产生歧义，方法名就可以省略。</p>
<blockquote>
<p>  <strong>实现方式口诀：</strong></p>
</blockquote>
<p><strong>拷贝小括号，写死右箭头，落地大括号</strong>。</p>
<ol>
<li> 拷贝小括号：将接口中抽象方法的参数列表全部拷贝过来；</li>
<li> 写死右箭头；</li>
<li> 落地大括号：具体的落地实现放在大括号中</li>
</ol>
<p><strong>Lambda 表达式就是解决了匿名内部类代码语法冗余的现象</strong></p>
<hr>
<h2 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h2><ul>
<li>  函数：<code>f(x) = kx + b</code>，<code>f(x)</code> 是要求得的计算结果， <code>kx+b</code> 是计算过程。</li>
<li>  函数式编程：就是让一个指定类型的变量表示 <code>f(x)</code>，用 Lambda 表达式表示计算过程的编程。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Fun fx = (x) -&gt; &#123;kx + b&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="从匿名内部类开始学习Lambda表达式"><a href="#从匿名内部类开始学习Lambda表达式" class="headerlink" title="从匿名内部类开始学习Lambda表达式"></a>从匿名内部类开始学习Lambda表达式</h2><h3 id="eg-1"><a href="#eg-1" class="headerlink" title="eg.1"></a>eg.1</h3><p>匿名内部类可以看做是 Lambda 表达式的下位替代。在没有 Lambda 表达式之前，我们可以使用匿名内部类来实现某个接口中的抽象方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    <span class="comment">// 匿名内部类</span></span><br><span class="line">    <span class="type">Runnable</span> <span class="variable">r1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Hello World&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    r1.run();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Lambda 表达式</span></span><br><span class="line">    <span class="type">Runnable</span> <span class="variable">r2</span> <span class="operator">=</span> () -&gt; System.out.println(<span class="string">&quot;Hello Lambda&quot;</span>);</span><br><span class="line">    r2.run();   </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">-----------------------------------------输出结果----------------------------------------------------------</span><br><span class="line">    Hello World</span><br><span class="line">    Hello Lambda</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">-----------------------------------------Runnable接口----------------------------------------------------------</span><br><span class="line"><span class="keyword">package</span> java.lang;</span><br><span class="line"></span><br><span class="line"><span class="meta">@FunctionalInterface</span>	<span class="comment">// 这是一个特殊的供给型函数式接口（不进也不出）</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Runnable</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>从上面的代码中我们可以看出，该匿名内部类中的功能性代码其实只有一句，即<code>System.out.println(&quot;Hello World&quot;);</code>，但是为了程序符合语法，能正常运行，我们添加了许多模式化的代码。</p>
<ul>
<li>  匿名内部类实现的细节：1、实现了 Runnable 接口，并重写了接口中的 run() 方法。    2、多态，用一个 Runnable 类型的变量接收重写后匿名对象；</li>
<li>  而在使用了 Lambda 表达式后，我们可以只写最核心的一句代码就可以实习想要的功能，使程序更为简洁、紧凑！</li>
</ul>
<hr>
<h3 id="eg-2"><a href="#eg-2" class="headerlink" title="eg.2"></a>eg.2</h3><p><code>Comparator&lt;T&gt;</code>是一个函数式接口，主要作用是比较两个同类型数据的大小，其内含有一个抽象方法 <code>compare()</code> 是用来自定义比较规则的，T 用来指定要比较的两个数据的数据类型。</p>
<p><code>TreeSet</code>是 Set 集合的一个实现类，它的一种构造方法可以直接在创建对象时指定<code>Comparator</code>对象，由于 Comparator 是一个接口，所以在 TreeSet 的构造函数中必须传递一个实现了 <code>compare()</code> 方法的子类实例对象，在 <code>compare()</code> 方法中自定义比较规则。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 匿名内部类</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span>&#123;</span><br><span class="line">       Comparator&lt;Integer&gt; comparator = <span class="keyword">new</span> <span class="title class_">Comparator</span>&lt;Integer&gt;() &#123;</span><br><span class="line">           <span class="meta">@Override</span></span><br><span class="line">           <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(Integer o1, Integer o2)</span> &#123;</span><br><span class="line">               <span class="keyword">return</span> Integer.compare(o1, o2);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;;</span><br><span class="line">       TreeSet&lt;Integer&gt; treeSet = <span class="keyword">new</span> <span class="title class_">TreeSet</span>&lt;&gt;(comparator);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Lambda 表达式</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test02</span><span class="params">()</span>&#123;</span><br><span class="line">       Comparator&lt;Integer&gt; comparator = (x, y) -&gt; Integer.compare(x, y);</span><br><span class="line">       TreeSet&lt;Integer&gt; treeSet = <span class="keyword">new</span> <span class="title class_">TreeSet</span>&lt;&gt;(comparator);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>可以看到用传统的匿名内部类实现<code>Comparator</code>接口中的比较规则时代码量非常多，但是其中的核心代码只有一行</li>
<li>而使用 Lambda 表达式则极大的减少了代码的书写。 </li>
</ul>
<hr>
<h3 id="eg-3"><a href="#eg-3" class="headerlink" title="eg.3"></a>eg.3</h3><ol>
<li>创建<code>Employee</code>员工类</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> pojo;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@ToString</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Employee</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Integer id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> Integer age;</span><br><span class="line">    <span class="keyword">private</span> Double salary;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Demo</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestLambda</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 创建一个 emps 集合</span></span><br><span class="line">    List&lt;Employee&gt; employees = Arrays.asList(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">1</span>, <span class="string">&quot;张三&quot;</span>, <span class="number">23</span>, <span class="number">3000.00</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">2</span>, <span class="string">&quot;李四&quot;</span>, <span class="number">25</span>, <span class="number">5000.00</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">3</span>, <span class="string">&quot;王五&quot;</span>, <span class="number">27</span>, <span class="number">8000.00</span>)</span><br><span class="line">    );</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 需求1：获取当前公司中员工年龄大于 24 的员工信息</span></span><br><span class="line"><span class="comment">     * 需求2：获取当前公司中员工工资大于 5000 的员工信息</span></span><br><span class="line"><span class="comment">     * 需求3：......</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test03</span><span class="params">()</span>&#123;</span><br><span class="line"></span><br><span class="line">        List&lt;Employee&gt; list1 = <span class="built_in">this</span>.filterEmployeesByAge(employees);</span><br><span class="line">        List&lt;Employee&gt; list2 = <span class="built_in">this</span>.filterEmployeesBySalary(employees);</span><br><span class="line">        System.out.println(list1);</span><br><span class="line">        System.out.println(list2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> List&lt;Employee&gt; <span class="title function_">filterEmployeesByAge</span><span class="params">(List&lt;Employee&gt; list)</span>&#123;</span><br><span class="line">        ArrayList&lt;Employee&gt; emps = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (Employee employee : list) &#123;</span><br><span class="line">            <span class="keyword">if</span> (employee.getAge()&gt;<span class="number">24</span>)&#123;</span><br><span class="line">                emps.add(employee);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> emps;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> List&lt;Employee&gt; <span class="title function_">filterEmployeesBySalary</span><span class="params">(List&lt;Employee&gt; list)</span>&#123;</span><br><span class="line">        ArrayList&lt;Employee&gt; emps = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (Employee employee : list) &#123;</span><br><span class="line">            <span class="keyword">if</span> (employee.getSalary() &gt; <span class="number">5000</span>)&#123;</span><br><span class="line">                emps.add(employee);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> emps;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们在完成需求1时，创建了一个<code>filterEmployeesByAge</code>方法用于筛选年龄；在完成需求2时，又创建了一个方法<code>filterEmployeesBySalary</code>用于筛选工资。但是我们可以发现，两个方法之间只有一句核心代码不同，其它都相同，存在冗余的代码。而且随着需求的不断增加，这样每新增一个需求就创建一个方法的形式显然是不可取的。</p>
<ol start="3">
<li> 优化方式一：<strong>策略设计模式</strong></li>
</ol>
<p>我们可以把<strong>抽象的比较规则</strong>封装到一个接口中，将<strong>具体的比较规则</strong>封装成该接口的一个个实现类。这时候只要在真正的比较方法中将待比较的字段和比较规则一起传入方法中，就可以完成比较的功能了。</p>
<ul>
<li>创建一个接口<code>MyPredicate&lt;T&gt;</code></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 该接口中包含一个抽象方法 test(T t)；</span></span><br><span class="line"><span class="comment"> * 该方法的作用是：如果 T 满足条件则返回 True，否则返回 False</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">MyPredicate</span>&lt;T&gt; &#123;</span><br><span class="line">    Boolean <span class="title function_">test</span><span class="params">(T t)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>创建接口的2个实现类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 根据年龄筛选员工信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterEmployeesByAge</span> <span class="keyword">implements</span> <span class="title class_">MyPredicate</span>&lt;Employee&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Boolean <span class="title function_">test</span><span class="params">(Employee employee)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> employee.getAge() &gt; <span class="number">25</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 根据工资筛选员工信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterEmployeesByAge</span> <span class="keyword">implements</span> <span class="title class_">MyPredicate</span>&lt;Employee&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Boolean <span class="title function_">test</span><span class="params">(Employee employee)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> employee.getSalary() &gt; <span class="number">5000</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>测试</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestLambda</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 需求1：获取当前公司中员工年龄大于 24 的员工信息</span></span><br><span class="line"><span class="comment">     * 需求2：获取当前公司中员工工资大于 5000 的员工信息</span></span><br><span class="line"><span class="comment">     * 需求3：......</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test04</span><span class="params">()</span>&#123;</span><br><span class="line">        </span><br><span class="line">        List&lt;Employee&gt; list1 = filterEmployees(employees, <span class="keyword">new</span> <span class="title class_">FilterEmployeesByAge</span>());</span><br><span class="line">        List&lt;Employee&gt; list2 = filterEmployees(employees, <span class="keyword">new</span> <span class="title class_">FilterEmployeesBySalary</span>());</span><br><span class="line">        System.out.println(list1);</span><br><span class="line">        System.out.println(list2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> List&lt;Employee&gt; <span class="title function_">filterEmployees</span><span class="params">(List&lt;Employee&gt; list, MyPredicate&lt;Employee&gt; mp)</span>&#123;</span><br><span class="line">        ArrayList&lt;Employee&gt; employees = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (Employee employee : list) &#123;</span><br><span class="line">            <span class="keyword">if</span> (mp.test(employee))&#123;</span><br><span class="line">                employees.add(employee);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> employees;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>优点：现在我们只需要唯一的一个方法<code>filterEmployees</code>就可以实现不同的比较需求。</p>
<p>缺点：每次想添加新的比较规则时，就必须创建一个新的比较规则类并实现<code>MyPredicate&lt;T&gt;</code>接口中的抽象方法。</p>
<ol start="4">
<li> 优化方式二：<strong>匿名内部类</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test05</span><span class="params">()</span>&#123;</span><br><span class="line"></span><br><span class="line">    List&lt;Employee&gt; list1 = filterEmployees(employees, <span class="keyword">new</span> <span class="title class_">MyPredicate</span>&lt;Employee&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> Boolean <span class="title function_">test</span><span class="params">(Employee employee)</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> employee.getAge() &gt; <span class="number">25</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    List&lt;Employee&gt; list2 = filterEmployees(employees, <span class="keyword">new</span> <span class="title class_">MyPredicate</span>&lt;Employee&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> Boolean <span class="title function_">test</span><span class="params">(Employee employee)</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> employee.getSalary() &gt; <span class="number">3000</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> List&lt;Employee&gt; <span class="title function_">filterEmployees</span><span class="params">(List&lt;Employee&gt; list, MyPredicate&lt;Employee&gt; mp)</span>&#123;</span><br><span class="line">        ArrayList&lt;Employee&gt; employees = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (Employee employee : list) &#123;</span><br><span class="line">            <span class="keyword">if</span> (mp.test(employee))&#123;</span><br><span class="line">                employees.add(employee);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> employees;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    System.out.println(list1);</span><br><span class="line">    System.out.println(list2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>优点：我们将创建具体的比较规则类这一步骤改用匿名内部类实现，这样就避免了每次都要创建 <code>MyPredicate&lt;T&gt;</code> 接口的实现类的过程。</p>
<p>缺点：显然，在匿名内部类中真正的功能性代码只有一行，所以我们可以继续使用 Lambda 表达式对匿名内部类进行优化。</p>
<ol start="5">
<li>优化方式三：<strong>Lambda表达式</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test06</span><span class="params">()</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> List&lt;Employee&gt; <span class="title function_">filterEmployees</span><span class="params">(List&lt;Employee&gt; list, MyPredicate&lt;Employee&gt; mp)</span>&#123;</span><br><span class="line">        ArrayList&lt;Employee&gt; employees = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (Employee employee : list) &#123;</span><br><span class="line">            <span class="keyword">if</span> (mp.test(employee))&#123;</span><br><span class="line">                employees.add(employee);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> employees;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    List&lt;Employee&gt; list1 = filterEmployees(employees, x-&gt;x.getAge()&gt;<span class="number">25</span>);</span><br><span class="line">    List&lt;Employee&gt; list2 = filterEmployees(employees, x-&gt;x.getSalary()&gt;<span class="number">4000</span>);</span><br><span class="line">    System.out.println(list1);</span><br><span class="line">    System.out.println(list2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ol start="6">
<li>优化方式四：<strong>Stream API + Lambda</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test07</span><span class="params">()</span>&#123;</span><br><span class="line">    employees.stream()</span><br><span class="line">        .filter(employee -&gt; employee.getAge()&gt;<span class="number">25</span>)</span><br><span class="line">        .forEach(System.out::println);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<hr>
<h2 id="Lambda-表达式语法"><a href="#Lambda-表达式语法" class="headerlink" title="Lambda 表达式语法"></a>Lambda 表达式语法</h2><blockquote>
<p><strong>格式</strong></p>
</blockquote>
<p>Lambda 表达式用于实现接口中的抽象方法，那么显然它应该包含 <strong>方法参数列表、方法实现体、返回值</strong> 三个部分。</p>
<p>Java8 中引入了一个新的操作符<code>-&gt;</code>，它将 Lambda 分为了两个部分：</p>
<ul>
<li>左侧：Lambda 表达式的<strong>参数列表</strong>；对应接口中抽象方法的参数列表；</li>
<li>右侧：Lambda 表达式的<strong>方法实现体</strong>；对应接口中抽象方法的实现类的方法体。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(parameters) -&gt; expression</span><br><span class="line"><span class="comment">// 或</span></span><br><span class="line">(parameters) -&gt;&#123; statements; &#125;</span><br></pre></td></tr></table></figure>



<blockquote>
<p><strong>Lambda 表达式对接口的要求</strong></p>
</blockquote>
<ul>
<li><p>需要函数式接口的支持。即<code>@FunctionalInterface</code>接口</p>
</li>
<li><p>因为函数式接口中有且仅有一个抽象方法，所以使用 Lambda 表达式实现的抽象方法是唯一确定的。</p>
</li>
</ul>
<blockquote>
<p><strong>Lambda表达式的特征</strong>：</p>
</blockquote>
<ul>
<li>可选的<strong>类型声明</strong>：不需要声明参数类型，因为JVM编译器可通过上下文推断出数据类型。</li>
<li>可选的<strong>参数圆括号</strong>：一个参数无需定义圆括号，但多个参数需要定义圆括号</li>
<li>可选的<strong>大括号</strong>：如果方法实现体只包含了一条语句，就不需要使用大括号。</li>
<li>可选的<strong>返回关键字</strong>：如果方法实现体只有一条语句且为返回值语句，则可以省略<code>return</code>关键字和大括号（<strong>return关键字和大括号要么全都省略，要么全都不省略</strong>）。</li>
</ul>
<blockquote>
<p><strong>Lambda 语法优化</strong></p>
</blockquote>
<ol>
<li>简化参数类型：可以不写参数类型，但是必须所有参数都不写参数类型</li>
<li>简化参数小括号，有且仅有一个参数时可以省略参数小括号。<ul>
<li>有多个参数不能省略小括号；</li>
<li>没有参数也不能省略小括号；</li>
</ul>
</li>
<li>简化方法体大括号，如果方法体中只有一条语句，则可以省略方法体大括号<ul>
<li>如果方法体中唯一的一条语句是 return 语句，则进行省略时需要把<strong>方法体大括号和return关键字</strong>一起省略。</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>Lambda 表达式只是实现了方法，但是并没有调用方法</strong>。</p>
</blockquote>
<blockquote>
<p><strong>Demo</strong></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 无参,1个返回值</span></span><br><span class="line">() -&gt; <span class="number">5</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// 1个参数，1个返回值</span></span><br><span class="line">x -&gt; <span class="number">2</span> * x  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// 2个参数，1个返回值</span></span><br><span class="line">(x, y) -&gt; x – y  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// 2个参数，1个返回值</span></span><br><span class="line">(<span class="type">int</span> x, <span class="type">int</span> y) -&gt; x + y  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// 1个参数，无返回值</span></span><br><span class="line">(String s) -&gt; System.out.print(s)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>eg.1</strong></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestLambda</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 需求：</span></span><br><span class="line"><span class="comment">     *  1、声明/调用函数式接口</span></span><br><span class="line"><span class="comment">     *  2、声明类 TestLambda ，类中编写方法使用接口作为参数，将一个字符串转换成大写，并作为方法的返回值</span></span><br><span class="line"><span class="comment">     *  3、再将这个字符串的第2个和第4个索引位置进行截取子串</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test03</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> <span class="string">&quot;good good study&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> operationStr(s, (x) -&gt; x.toUpperCase());</span><br><span class="line">        <span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> operationStr(s1, (x) -&gt; x.substring(<span class="number">2</span>, <span class="number">5</span>));</span><br><span class="line">        System.out.println(s1);</span><br><span class="line">        System.out.println(s2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">operationStr</span><span class="params">(String str, Function&lt;String, String&gt; function)</span>&#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">result</span> <span class="operator">=</span> function.apply(str);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<hr>
<h2 id="方法引用"><a href="#方法引用" class="headerlink" title="方法引用"></a>方法引用</h2><blockquote>
<p><strong>概念</strong></p>
</blockquote>
<p>在前面的学习中，Lambda 表达式中的方法的实现都是我们自己写的，但是究其本质，Lambda 表达式就是一个函数（方法），所以 Lambda 表达式中的方法实现并非一定要我们自己来实现，我们可以直接引用 Java 中现成的方法作为 Lambda 表达式的方法体，这就叫做<strong>方法引用</strong>！</p>
<p>可以理解为<strong>方法引用</strong>是 Lambda 表达式的另外一种表现形式。</p>
<blockquote>
<p><strong>语法格式</strong></p>
</blockquote>
<ul>
<li><code>对象::实例方法名</code></li>
<li><code>类名::静态方法名</code></li>
<li><code>类名::实例方法名</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、省略参数列表</span><br><span class="line">2、省略方法后跟的括号</span><br></pre></td></tr></table></figure>



<blockquote>
<p><strong>eg.1</strong></p>
</blockquote>
<p><code>Consumer&lt;T&gt;</code>是一个消费型接口，接口中的抽象方法是<code>void accept(T t)</code>，一个参数，无返回值。</p>
<ol>
<li>使用 Lambda 表达式后，<code>-&gt;</code>右侧的方法体中的<code>println</code>方法是Java已经实现好的，所以在这里我们就可以考虑使用<strong>方法引用</strong>。</li>
<li>System 中的 out 属性（<code>System.out</code>）本质上指向了一个<code>PrintStream</code>类的匿名实例对象，所以采用<code>对象::实例方法名</code>的格式。</li>
</ol>
<p>使用要求：</p>
<ul>
<li><code>Consumer&lt;T&gt;</code>接口中的抽象方法<code>accept()</code>有一个参数无返回值，所以对应的<code>println()</code>方法也要是一个参数无返回值的方法。</li>
<li>即：<strong>引用方法的参数列表和返回值类型 要和 函数式接口中抽象方法的参数列表和返回值的个数与类型 要一一对应，相当于用引用方法实现了接口中的抽象方法</strong>。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Lambda 表达式</span></span><br><span class="line">    Consumer&lt;String&gt; consumer1 = (x)-&gt; System.out.println(x);</span><br><span class="line">    consumer1.accept(<span class="string">&quot;对不起&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方法引用1</span></span><br><span class="line">    <span class="type">PrintStream</span> <span class="variable">ps</span> <span class="operator">=</span> System.out;</span><br><span class="line">    Consumer&lt;String&gt; consumer2 = ps::println;</span><br><span class="line">    consumer2.accept(<span class="string">&quot;谢谢&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方法引用2</span></span><br><span class="line">    Consumer&lt;String&gt; consumer3 = System.out::println;</span><br><span class="line">    consumer3.accept(<span class="string">&quot;你好&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>eg.2</strong></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test02</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">Employee</span> <span class="variable">employee</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">7</span>, <span class="string">&quot;田虎&quot;</span>, <span class="number">24</span>, <span class="number">9999.99</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Lambda 表达式</span></span><br><span class="line">    Supplier&lt;String&gt; supplier = ()-&gt; employee.getName();</span><br><span class="line">    <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> supplier.get();</span><br><span class="line">    System.out.println(name);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方法引用</span></span><br><span class="line">    Supplier&lt;Integer&gt; supplier2 = employee::getAge;</span><br><span class="line">    <span class="type">Integer</span> <span class="variable">age</span> <span class="operator">=</span> supplier2.get();</span><br><span class="line">    System.out.println(age);</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、Supplier&lt;T&gt; 接口中的抽象方法 T get() `无参数 || 一个返回值`</span></span><br><span class="line"><span class="comment">     * 2、所以 getName() 方法也要是 `无参数 || 一个返回值`，且类型一致</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>例3：<code>类名::静态方法名</code></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">Test03</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="comment">// Lambda 表达式</span></span><br><span class="line">       Comparator&lt;Integer&gt; comparator1 = (x, y)-&gt; Integer.compare(x, y);</span><br><span class="line">       <span class="type">int</span> <span class="variable">result1</span> <span class="operator">=</span> comparator1.compare(<span class="number">5</span>, <span class="number">1</span>);</span><br><span class="line">       System.out.println(result1);</span><br><span class="line"></span><br><span class="line">       <span class="comment">// 方法引用</span></span><br><span class="line">       Comparator&lt;Integer&gt; comparator2 = Integer::compare;</span><br><span class="line">       <span class="type">int</span> <span class="variable">result2</span> <span class="operator">=</span> comparator2.compare(<span class="number">5</span>, <span class="number">9</span>);</span><br><span class="line">       System.out.println(result2);</span><br><span class="line"></span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Comparator&lt;T&gt;接口中的抽象方法为：int compare(T o1, T o2);  2个参数，1个返回值；</span></span><br><span class="line"><span class="comment">        * 所以，Integer 类中的静态方法 compare() 也得是2个参数，一个返回值，且类型一致</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>例4：<code>类名::实例方法名</code></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 比较2个字符串是否相等</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test04</span><span class="params">()</span>&#123;</span><br><span class="line">       BiPredicate&lt;String , String&gt; predicate1 = (x, y)-&gt;x.equals(y);</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 对于 Lambda 表达式，如果参数列表中 第一个参数是实例方法的调用者，第二个参数是实例方法的参数 时，</span></span><br><span class="line"><span class="comment">        * 我们就可以使用 `类名::实例方法名` 的格式进行引用。</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       BiPredicate&lt;String , String&gt; predicate2 = String::equals;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 1、equals() 方法是 String 类中的一个实例方法</span></span><br><span class="line"><span class="comment">        * 2、public boolean equals(Object anObject) &#123;...&#125;</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       </span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>





<h2 id="构造器引用"><a href="#构造器引用" class="headerlink" title="构造器引用"></a>构造器引用</h2><blockquote>
<p>概念：</p>
</blockquote>
<p>构造器引用就是将创建对象的构造方法封装到 Lambda 表达式的方法体中。</p>
<p>我们需要声明一个函数式接口，该接口作为对象的生成器，当调用接口中的抽象方法时返回一个新创建的对象。</p>
<blockquote>
<p>语法：<code>类名::new</code></p>
</blockquote>
<p>通过<code>类名::new</code>的方式来引用构造器方法，然后调用接口中的抽象方法创建对象。</p>
<blockquote>
<p>例1：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">test05</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="comment">// Lambda 表达式形式</span></span><br><span class="line">       Supplier&lt;Employee&gt; supplier1 = ()-&gt;<span class="keyword">new</span> <span class="title class_">Employee</span>();</span><br><span class="line">       <span class="type">Employee</span> <span class="variable">employee1</span> <span class="operator">=</span> supplier1.get();</span><br><span class="line"></span><br><span class="line">       <span class="comment">// 构造器引用形式</span></span><br><span class="line">       Supplier&lt;Employee&gt; supplier2 = Employee::<span class="keyword">new</span>;</span><br><span class="line">       <span class="type">Employee</span> <span class="variable">employee2</span> <span class="operator">=</span> supplier2.get();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>存在的问题？</p>
<p><code>Employee</code>的构造方法不只一个，当使用<strong>构造器引用</strong>时，具体调用的是哪一个构造方法呢？</p>
</li>
<li><p>答案：</p>
<p>引用的构造器方法必须和函数式接口中的抽象方法的参数列表一致。在本例中，<code>Supplier&lt;T&gt;</code>接口中的抽象方法是<code>T get()</code>，无参数，所以引用的构造方法必然是无参构造方法。    如果使用<code>Function&lt;T, R&gt;</code>接口中的<code>R apply(T t)</code>抽象方法，那么引用的构造器就必须包含一个参数！</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 构造器引用</span></span><br><span class="line">Function&lt;String, Employee&gt; function = Employee::<span class="keyword">new</span>;</span><br><span class="line"><span class="comment">// 调用接口中的抽象方法</span></span><br><span class="line"><span class="type">Employee</span> <span class="variable">employee3</span> <span class="operator">=</span> function.apply(<span class="string">&quot;王八犊子&quot;</span>);</span><br><span class="line">System.out.println(employee3);</span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>Tip:</p>
</blockquote>
<p><strong>需要调用的构造器方法的参数列表要与函数式接口中抽象方法的参数列表保持一致！</strong></p>
<h2 id="数组引用"><a href="#数组引用" class="headerlink" title="数组引用"></a>数组引用</h2><blockquote>
<p>概念</p>
</blockquote>
<p>数组引用就是把创建数组的方法封装到 Lambda 表达式的方法体中。</p>
<p>我们需要声明一个函数式接口，该接口作为数组对象的生成器，当调用接口中的抽象方法时，就会调用 Lambda 方法体中创建数组的方法创建一个数组并返回。</p>
<blockquote>
<p>语法格式：<code>Type::new</code></p>
</blockquote>
<blockquote>
<p>示例：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span>	</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test06</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="comment">// Lambda 表达式</span></span><br><span class="line">       Function&lt;Integer, String[]&gt; function1 = x -&gt; <span class="keyword">new</span> <span class="title class_">String</span>[x];</span><br><span class="line">       String[] array1 = function1.apply(<span class="number">10</span>);</span><br><span class="line">       System.out.println(array1.length);</span><br><span class="line"></span><br><span class="line">       <span class="comment">// 数组引用</span></span><br><span class="line">       Function&lt;Integer, String[]&gt; function2 = String[]::<span class="keyword">new</span>;</span><br><span class="line">       String[] array2 = function2.apply(<span class="number">9</span>);</span><br><span class="line">       System.out.println(array2.length);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>









<hr>
<h1 id="Stream-API"><a href="#Stream-API" class="headerlink" title="Stream API"></a>Stream API</h1><blockquote>
<p>概念</p>
</blockquote>
<p><code>Stream</code>：流</p>
<p>Stream 是 Java8 中处理<strong>集合</strong>的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用 Stream API 对集合数据进行操作，就类似于使用 SQL 执行数据库查询。 也可以使用 Stream API 来并行执行操作。 简而言之，Stream API 提供了一种高效且易于使用的处理集合数据的方式。</p>
<p>Stream 用于操作数据源（集合、数组等）所生成的元素序列。</p>
<p><img src="/2021/01/29/Java8%E6%96%B0%E7%89%B9%E6%80%A7/Stream%E6%B5%81.png"></p>
<blockquote>
<p>包：<code>java.util.stream.*</code></p>
</blockquote>
<blockquote>
<p>Tip：</p>
</blockquote>
<ul>
<li>Stream 自己不会存储元素。</li>
<li><strong>Stream 不会改变源对象</strong>。相反，它会返回一个持有结果的新的 Stream 对象。</li>
<li>Stream 操作是延迟执行的，这意味着它们会等到需要结果的时候才执行。</li>
</ul>
<blockquote>
<p>Stream操作的三个步骤</p>
</blockquote>
<ol>
<li>创建Stream对象<ul>
<li>一个数据源（如：集合、数组）</li>
<li>获取一个流对象</li>
</ul>
</li>
<li>中间操作<ul>
<li>一个中间操作链，对包含数据源数据的流对象进行处理</li>
</ul>
</li>
<li>终止操作（终端操作）<ul>
<li>一个终止操作 ，执行中间操作链，并产生结果。</li>
</ul>
</li>
</ol>
<h2 id="创建Stream对象"><a href="#创建Stream对象" class="headerlink" title="创建Stream对象"></a>创建Stream对象</h2><blockquote>
<p>创建Stream对象的<strong>4种方法</strong></p>
</blockquote>
<ol>
<li>Java8 中的 <code>Collection</code> 接口被扩展，提供了两个获取流的方法。</li>
<li>通过 <code>Arrays</code> 中的的静态方法 <code>stream()</code> 可以获取数组流。</li>
<li>通过 <code>Stream</code> 类中的静态方法 <code>of()</code> 获取流对象</li>
<li>通过 <code>Stream</code> 类中的静态方法<code>iterate</code>或<code>generate</code>创建无限流。<ul>
<li>无限流就是如果不加限制 ，将会一直生成数据的流。</li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th align="center">类</th>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>Collection</code></td>
<td align="center"><code>default Stream&lt;E&gt; stream()</code></td>
<td align="center">返回一个顺序流</td>
</tr>
<tr>
<td align="center">-</td>
<td align="center"><code>default Stream&lt;E&gt; parallelStream()</code></td>
<td align="center">返回一个并行流</td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>Arrays</code></td>
<td align="center"><code>static &lt;T&gt; Stream&lt;T&gt; stream(T[] array)</code></td>
<td align="center">返回一个流</td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>Stream&lt;T&gt;</code></td>
<td align="center"><code>public static&lt;T&gt; Stream&lt;T&gt; of(T... values)</code></td>
<td align="center">返回一个流</td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>Stream&lt;T&gt;</code></td>
<td align="center"><code>public static&lt;T&gt; Stream&lt;T&gt; iterate(final T seed, final UnaryOperator&lt;T&gt; f)</code></td>
<td align="center">迭代</td>
</tr>
<tr>
<td align="center">-</td>
<td align="center"><code>public static&lt;T&gt; Stream&lt;T&gt; generate(Supplier&lt;T&gt; s)</code></td>
<td align="center">生成</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestStreamAPI1</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建Stream对象（4种方式）</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test1</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">// 1、可以通过 Collection 系列集合提供的 stream() 或 parallelStream() 方法获取流</span></span><br><span class="line">        ArrayList&lt;String&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        Stream&lt;String&gt; stream1 = list.stream();</span><br><span class="line">        Stream&lt;String&gt; stream2 = list.parallelStream();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、通过 Arrays 中的静态方法 stream() 获取数组流</span></span><br><span class="line">        Employee[] emps = <span class="keyword">new</span> <span class="title class_">Employee</span>[<span class="number">10</span>];</span><br><span class="line">        Stream&lt;Employee&gt; stream3 = Arrays.stream(emps);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、通过 Stream 类中的静态方法 of() 获取流对象</span></span><br><span class="line">        Stream&lt;String&gt; stream4 = Stream.of(<span class="string">&quot;aa&quot;</span>, <span class="string">&quot;bb&quot;</span>, <span class="string">&quot;cc&quot;</span>, <span class="string">&quot;dd&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、创建无限流</span></span><br><span class="line">        <span class="comment">// 迭代 iterate() 方法</span></span><br><span class="line">        Stream&lt;Integer&gt; stream5 = Stream.iterate(<span class="number">0</span>, (x) -&gt; x + <span class="number">2</span>);</span><br><span class="line">        stream5.limit(<span class="number">10</span>).forEach(System.out::println);</span><br><span class="line">        <span class="comment">// 结果：0 2 4 6 8 10 12 14 16 18     如果不加限制将会无限迭代</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 生成</span></span><br><span class="line">        Stream&lt;Double&gt; stream6 = Stream.generate(Math::random);</span><br><span class="line">        stream6.limit(<span class="number">5</span>).forEach(System.out::println);  </span><br><span class="line">        <span class="comment">// 结果：产生5个随机数。如果不加限制将会一直产生</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>只创建<code>Stream</code>对象并不会输出任何结果，只有在进行了终止操作后才会输出结果。</li>
</ul>
<h2 id="中间操作"><a href="#中间操作" class="headerlink" title="中间操作"></a>中间操作</h2><p>多个中间操作可以连起来形成一个流水线，除非流水线上触发终止操作，否则中间操作不会执行任何的处理！而在终止操作时一次性全部处理，称为“惰性求值”。</p>
<h3 id="筛选和切片"><a href="#筛选和切片" class="headerlink" title="筛选和切片"></a>筛选和切片</h3><table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">返回值</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>filter(Predicate predicate)</code></td>
<td align="center"><code>Stream</code></td>
<td align="center">接收一个 Lambda 表达式，从流中排除某些元素</td>
</tr>
<tr>
<td align="center"><code>distinct()</code></td>
<td align="center">~</td>
<td align="center">去重，通过流所生成元素的 <code>hashCode()</code> 和 <code>equals()</code> 去除重复元素</td>
</tr>
<tr>
<td align="center"><code>limit(long maxSize);</code></td>
<td align="center">~</td>
<td align="center">截断流，使其元素不超过给定数量</td>
</tr>
<tr>
<td align="center"><code>skip(long n)</code></td>
<td align="center">~</td>
<td align="center">跳过元素，返回一个扔掉了前 n 个元素的流。若流中元素不足 n 个，则返回一个空流。</td>
</tr>
</tbody></table>
<ul>
<li>在使用<code>distinct()</code>方法时，要想实现去重操作，必须重写待比较对象的<code>hashCode()</code> 和 <code>equals()</code>方法。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestStreamAPI2</span> &#123;</span><br><span class="line">	List&lt;Employee&gt; employees = Arrays.asList(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">1</span>, <span class="string">&quot;黄继光&quot;</span>, <span class="number">23</span>, <span class="number">3000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">2</span>, <span class="string">&quot;张三丰&quot;</span>, <span class="number">109</span>, <span class="number">3000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">3</span>, <span class="string">&quot;鳌拜&quot;</span>, <span class="number">57</span>, <span class="number">5000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">4</span>, <span class="string">&quot;猪猪熊&quot;</span>, <span class="number">2</span>, <span class="number">7000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">5</span>, <span class="string">&quot;泡泡龙&quot;</span>, <span class="number">5</span>, <span class="number">4000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">6</span>, <span class="string">&quot;小哪吒&quot;</span>, <span class="number">7</span>, <span class="number">8000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">6</span>, <span class="string">&quot;小哪吒&quot;</span>, <span class="number">7</span>, <span class="number">8000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">6</span>, <span class="string">&quot;小哪吒&quot;</span>, <span class="number">7</span>, <span class="number">8000.00</span>)</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 筛选与切片</span></span><br><span class="line"><span class="comment">     *  1、filter</span></span><br><span class="line"><span class="comment">     *  2、limit</span></span><br><span class="line"><span class="comment">     *  3、skip</span></span><br><span class="line"><span class="comment">     *  4、distinct</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">// 获取 Stream 流对象</span></span><br><span class="line">        Stream&lt;Employee&gt; stream = employees.stream();</span><br><span class="line">        <span class="comment">// 中间操作</span></span><br><span class="line">        Stream&lt;Employee&gt; employeeStream = stream.filter((x) -&gt; x.getAge() &gt; <span class="number">5</span>);</span><br><span class="line">        <span class="comment">/*中间操作是不会产生任何结果的，为了展示测试结果，进行终止操作打印结果*/</span></span><br><span class="line">        <span class="comment">// 终止操作</span></span><br><span class="line">        employeeStream.forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test02</span><span class="params">()</span>&#123;</span><br><span class="line">        employees.stream()</span><br><span class="line">           	 	<span class="comment">// 此处要想完成去重操作，必须重写 Employee 类中的 hashCode 和 equals 方法</span></span><br><span class="line">                .distinct()     <span class="comment">// 得到 1，2，3，4，5，6   </span></span><br><span class="line">                .filter(x-&gt;x.getSalary()&gt;<span class="number">4500</span>)  <span class="comment">// 得到 3，4，6</span></span><br><span class="line">                .limit(<span class="number">2</span>)   <span class="comment">// 得到 3，4</span></span><br><span class="line">                .skip(<span class="number">1</span>)    <span class="comment">// 得到 4</span></span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h3><table>
<thead>
<tr>
<th align="left">方法</th>
<th align="center">返回值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>map(Function mapper)</code></td>
<td align="center"><code>Stream</code></td>
<td align="left">接收一个函数作为参数，该函数会被应用到集合的<br>每个元素上，并将其映射成一个新的元素。</td>
</tr>
<tr>
<td align="left"><code>mapToDouble(ToDoubleFunction mapper)</code></td>
<td align="center"><code>DoubleStream</code></td>
<td align="left">接收一个函数作为参数，该函数会被应用到<br>每个元素上，产生一个新的 <code>DoubleStream</code></td>
</tr>
<tr>
<td align="left"><code>mapToInt(ToIntFunction mapper)</code></td>
<td align="center"><code>IntStream</code></td>
<td align="left">接收一个函数作为参数，该函数会被应用到<br>每个元素上，产生一个新的 <code>IntStream</code></td>
</tr>
<tr>
<td align="left"><code>mapToLong(ToLongFunction mapper)</code></td>
<td align="center"><code>LongStream</code></td>
<td align="left">接收一个函数作为参数，该函数会被应用到<br>每个元素上，产生一个新的 <code>LongStream</code></td>
</tr>
<tr>
<td align="left"><code>flatMap(Function mapper)</code></td>
<td align="center"><code>Stream</code></td>
<td align="left">接收一个函数作为参数，将流中的每个值都换成<br>另一个流，然后把所有流连接成一个流。</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 映射：</span></span><br><span class="line"><span class="comment">    *  1、map</span></span><br><span class="line"><span class="comment">    *  2、flatMap</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test03</span><span class="params">()</span>&#123;</span><br><span class="line">       List&lt;String&gt; list = Arrays.asList(<span class="string">&quot;aa&quot;</span>, <span class="string">&quot;bb&quot;</span>, <span class="string">&quot;cc&quot;</span>, <span class="string">&quot;dd&quot;</span>);</span><br><span class="line">       list.stream()</span><br><span class="line">               .map(String::toUpperCase)   <span class="comment">// 把集合中的元素全部转换为大写</span></span><br><span class="line">               .forEach(System.out::println);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test04</span><span class="params">()</span>&#123;</span><br><span class="line">       employees.stream()</span><br><span class="line">               .map(Employee::getName)     <span class="comment">// 提取每个员工的名字</span></span><br><span class="line">               .forEach(System.out::println);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test05</span><span class="params">()</span>&#123;</span><br><span class="line"></span><br><span class="line">       List&lt;String&gt; list = Arrays.asList(<span class="string">&quot;aa&quot;</span>, <span class="string">&quot;bb&quot;</span>, <span class="string">&quot;cc&quot;</span>, <span class="string">&quot;dd&quot;</span>);</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* 对于普通的 map() 方法来说，遍历有多重泛型嵌套的流是比较复杂的，因为只能输出最内层的内容 */</span></span><br><span class="line">       Stream&lt;Stream&lt;Character&gt;&gt; stream1 = list.stream()</span><br><span class="line">               .map(str -&gt; filterCharacter(str));</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 数据结构类似于：&#123;&#123;a,a&#125;, &#123;b,b&#125;, &#123;c,c&#125;, &#123;d,d&#125;&#125;</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       stream1.forEach(    </span><br><span class="line">               x-&gt;x.forEach(System.out::println)</span><br><span class="line">       );</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* 而对于 flatMap 来说，它会将一个流中的所有小的流整合成一个流，便于遍历*/</span></span><br><span class="line">       Stream&lt;Character&gt; stream2 = list.stream()</span><br><span class="line">               .flatMap(str -&gt; filterCharacter(str));</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 数据结构类似于：&#123;a,a, b,b, c,c, d,d&#125;</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       stream2.forEach(System.out::println);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 将 String 类型的数据转换成 Character 流</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> str</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> Stream&lt;Character&gt; <span class="title function_">filterCharacter</span><span class="params">(String str)</span>&#123;</span><br><span class="line">       ArrayList&lt;Character&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">       <span class="type">char</span>[] chars = str.toCharArray();</span><br><span class="line">       <span class="keyword">for</span> (<span class="type">char</span> aChar : chars) &#123;</span><br><span class="line">           list.add(aChar);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> list.stream();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>sorted()</code></td>
<td align="center">产生一个新流，按自然顺序排序</td>
</tr>
<tr>
<td align="center"><code>sorted(Comparator comparator)</code></td>
<td align="center">产生一个新流，按定制的比较器排序</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test06</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="comment">// 自然排序</span></span><br><span class="line">       List&lt;String&gt; list = Arrays.asList(<span class="string">&quot;aa&quot;</span>, <span class="string">&quot;aj&quot;</span>, <span class="string">&quot;ac&quot;</span>, <span class="string">&quot;ww&quot;</span>, <span class="string">&quot;dd&quot;</span>);</span><br><span class="line">       list.stream()</span><br><span class="line">               .sorted()</span><br><span class="line">               .forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">       <span class="comment">// 定制排序</span></span><br><span class="line">       employees.stream()</span><br><span class="line">               .sorted((x, y) -&gt;&#123;</span><br><span class="line">                   <span class="keyword">if</span> (x.getAge()==y.getAge())&#123;</span><br><span class="line">                       <span class="keyword">return</span> Double.compare(x.getSalary(), y.getSalary());</span><br><span class="line">                   &#125;</span><br><span class="line">                   <span class="keyword">return</span> Integer.compare(x.getAge(), y.getAge());</span><br><span class="line">               &#125;)</span><br><span class="line">               .forEach(System.out::println);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<h2 id="终止操作"><a href="#终止操作" class="headerlink" title="终止操作"></a>终止操作</h2><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>findFirst()</code></td>
<td align="left">返回第一个元素</td>
</tr>
<tr>
<td align="left"><code>findAny()</code></td>
<td align="left">返回当前流中的任意一个元素</td>
</tr>
<tr>
<td align="left"><code>count()</code></td>
<td align="left">返回流中元素总数</td>
</tr>
<tr>
<td align="left"><code>max(Comparator c)</code></td>
<td align="left">返回流中最大值</td>
</tr>
<tr>
<td align="left"><code>min(Comparator c)</code></td>
<td align="left">返回流中最小值</td>
</tr>
<tr>
<td align="left"><code>forEach(Consumer c)</code></td>
<td align="left">内部迭代(使用Stream API 已经实现的迭代方式，而不用自己去写迭代过程）</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 终止操作</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestStreamAPI3</span> &#123;</span><br><span class="line">    List&lt;Employee&gt; employees = Arrays.asList(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">1</span>, <span class="string">&quot;黄继光&quot;</span>, <span class="number">23</span>, <span class="number">3000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">2</span>, <span class="string">&quot;张三丰&quot;</span>, <span class="number">109</span>, <span class="number">3000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">3</span>, <span class="string">&quot;鳌拜&quot;</span>, <span class="number">57</span>, <span class="number">5000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">4</span>, <span class="string">&quot;猪猪熊&quot;</span>, <span class="number">2</span>, <span class="number">7000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">5</span>, <span class="string">&quot;泡泡龙&quot;</span>, <span class="number">5</span>, <span class="number">4000.00</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Employee</span>(<span class="number">6</span>, <span class="string">&quot;小哪吒&quot;</span>, <span class="number">7</span>, <span class="number">8000.00</span>)</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test02</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">// findFirst</span></span><br><span class="line">        Optional&lt;Employee&gt; optional1 = employees.stream()</span><br><span class="line">                .findFirst();</span><br><span class="line">        <span class="type">Employee</span> <span class="variable">employee</span> <span class="operator">=</span> optional1.get();</span><br><span class="line">        System.out.println(employee);</span><br><span class="line">        <span class="comment">/*---------------------------------------------------*/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// findAny + stream</span></span><br><span class="line">        Optional&lt;Employee&gt; optional2 = employees.stream()</span><br><span class="line">                .filter(x -&gt; x.getAge() &gt; <span class="number">15</span>)</span><br><span class="line">                .findAny();</span><br><span class="line">        System.out.println(optional2.get());</span><br><span class="line">        <span class="comment">/*---------------------------------------------------*/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// findAny + parallelStream</span></span><br><span class="line">        Optional&lt;Employee&gt; optional3 = employees.parallelStream()</span><br><span class="line">                .filter(x -&gt; x.getAge() &gt; <span class="number">15</span>)</span><br><span class="line">                .findAny();</span><br><span class="line">        System.out.println(optional3.get());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test03</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">// count</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">count</span> <span class="operator">=</span> employees.stream()</span><br><span class="line">                .count();</span><br><span class="line">        System.out.println(count);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// max  /   min</span></span><br><span class="line">        Optional&lt;Employee&gt; max = employees.stream()</span><br><span class="line">                .max((x, y) -&gt;</span><br><span class="line">                    Double.compare(x.getSalary(), y.getSalary()));</span><br><span class="line">        <span class="type">Employee</span> <span class="variable">employee</span> <span class="operator">=</span> max.get();</span><br><span class="line">        System.out.println(employee);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// foreach</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>findFirst()</code>方法的作用是返回返回当前流中的第一个对象。</p>
</li>
<li><p>而<code>findAny()</code>的作用则是返回当前流中的任意一个元素。</p>
<ul>
<li>如果与获取串行流的方法<code>stream()</code>配合使用，则每次获取的都是流中的第一个元素；</li>
<li>而如果与获取并行流的方法<code>parallelStream()</code>配合使用，则每次获取元素会是当前流中满足条件的任何一个元素。</li>
</ul>
</li>
<li><p><code>Optional&lt;T&gt;</code>类是一个容器类，是 Java8 中为了减少空指针异常而定义的一个类，我们可以使用该对象中的<code>get()</code>方法获取容器中的元素。</p>
</li>
</ul>
<hr>
<h3 id="匹配"><a href="#匹配" class="headerlink" title="匹配"></a>匹配</h3><table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>allMatch(Predicate p)</code></td>
<td align="center">检查是否匹配所有元素</td>
</tr>
<tr>
<td align="center"><code>anyMatch(Predicate p)</code></td>
<td align="center">检查是否至少匹配一个元素</td>
</tr>
<tr>
<td align="center"><code>noneMatch(Predicatep)</code></td>
<td align="center">检查是否没有匹配所有元素</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">boolean</span> <span class="variable">b1</span> <span class="operator">=</span> employees.stream()</span><br><span class="line">            .allMatch(x -&gt; x.getName().equals(<span class="string">&quot;黄继光&quot;</span>));</span><br><span class="line">    System.out.println(b1);     <span class="comment">// false</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*--------------------------------------------------*/</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">b2</span> <span class="operator">=</span> employees.stream()</span><br><span class="line">            .anyMatch(x -&gt; x.getName().equals(<span class="string">&quot;张三丰&quot;</span>));</span><br><span class="line">    System.out.println(b2);     <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*-------------------------------------------------*/</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">b3</span> <span class="operator">=</span> employees.stream()</span><br><span class="line">            .noneMatch(x -&gt; x.getName().equals(<span class="string">&quot;水月洞天&quot;</span>));</span><br><span class="line">    System.out.println(b3);     <span class="comment">// true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="规约"><a href="#规约" class="headerlink" title="规约"></a>规约</h3><table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>reduce(T iden, BinaryOperator b)</code></td>
<td align="center">可以将流中元素反复结合起来，得到一个值。返回T</td>
</tr>
<tr>
<td align="center"><code>reduce(BinaryOperator b)</code></td>
<td align="center">可以将流中元素反复结合起来，得到一个值。返回<code>Optional&lt;T&gt;</code></td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test04</span><span class="params">()</span>&#123;</span><br><span class="line">       List&lt;Integer&gt; numList = Arrays.asList(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>);</span><br><span class="line">       <span class="type">Integer</span> <span class="variable">result</span> <span class="operator">=</span> numList.stream()</span><br><span class="line">               .reduce(<span class="number">0</span>, (x, y) -&gt; x + y);</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 1、以 0 作为起始值，充当 Lambda 表达式的 x ， 从 numList 的流中取出第一个元素 1 充当 y，进行 x+y 运算，得到 (0+1)；</span></span><br><span class="line"><span class="comment">        * 2、将第一步得到的运算结果充当 x，从 numList 的流中取出第二个元素充当 y，进行 x+y 运算，得到 (0+1)+2；</span></span><br><span class="line"><span class="comment">        * 3、将第一步得到的运算结果充当 x，从 numList 的流中取出第三个元素充当 y，进行 x+y 运算，得到 ((0+1)+2)+3；</span></span><br><span class="line"><span class="comment">        * 4、以此类推....</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       System.out.println(result);     <span class="comment">// 45</span></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 计算当前公司所有员工工资的总额</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test05</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="type">Double</span> <span class="variable">sum</span> <span class="operator">=</span> employees.stream()</span><br><span class="line">               .map(x -&gt; x.getSalary())</span><br><span class="line">               .reduce(<span class="number">0.00</span>, (x, y) -&gt; x + y);</span><br><span class="line">       System.out.println(sum);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="收集"><a href="#收集" class="headerlink" title="收集"></a>收集</h3><table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>collect(Collector c)</code></td>
<td align="center">将流转换为其他形式。接收一个Collector接口的实现，用于给Stream中元素做汇总的方法</td>
</tr>
</tbody></table>
<p><code>Collector</code> 接口中方法的实现决定了如何对流执行收集操作（如收集到List、Set、Map）。但是<code>Collectors</code>工具类中提供了很多静态方法，可以方便地创建常见的收集器实例，具体的方法与实例如下表：</p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">返回值</th>
<th align="center">作用</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>toList</code></td>
<td align="center"><code>List&lt;T&gt;</code></td>
<td align="center">把流中元素收集到List</td>
</tr>
<tr>
<td align="center"><code>toSet</code></td>
<td align="center"><code>Set&lt;T&gt;</code></td>
<td align="center">把流中元素收集到Set</td>
</tr>
<tr>
<td align="center"><code>toCollection</code></td>
<td align="center"><code>Collection&lt;T&gt;</code></td>
<td align="center">把流中元素收集到创建的集合</td>
</tr>
<tr>
<td align="center"><code>counting</code></td>
<td align="center"><code>Long</code></td>
<td align="center">计算流中元素的个数</td>
</tr>
<tr>
<td align="center"><code>summingInt</code></td>
<td align="center"><code>Integer</code></td>
<td align="center">对流中元素的整数属性求和</td>
</tr>
<tr>
<td align="center"><code>averagingInt</code></td>
<td align="center"><code>Double</code></td>
<td align="center">计算流中元素Integer属性的平均值</td>
</tr>
<tr>
<td align="center"><code>summarizingInt</code></td>
<td align="center"><code>IntSummaryStatistics</code></td>
<td align="center">收集流中Integer属性的统计值。如：平均值/总数/总和等</td>
</tr>
<tr>
<td align="center"><code>joining</code></td>
<td align="center"><code>String</code></td>
<td align="center">连接流中每个字符串</td>
</tr>
<tr>
<td align="center"><code>maxBy</code></td>
<td align="center"><code>Optional&lt;T&gt;</code></td>
<td align="center">根据比较器选择最大值</td>
</tr>
<tr>
<td align="center"><code>minBy</code></td>
<td align="center"><code>Optional&lt;T&gt;</code></td>
<td align="center">根据比较器选择最小值</td>
</tr>
<tr>
<td align="center"><code>reducing</code></td>
<td align="center">归约产生的类型</td>
<td align="center">从一个作为累加器的初始值开始，利用BinaryOperator<br>与流中元素逐个结合，从而归约成单个值</td>
</tr>
<tr>
<td align="center"><code>collectingAndThen</code></td>
<td align="center">转换函数返回的类型</td>
<td align="center">包裹另一个收集器，对其结果转换函数</td>
</tr>
<tr>
<td align="center"><code>groupingBy</code></td>
<td align="center"><code>Map&lt;K,List&lt;T&gt;&gt;</code></td>
<td align="center">根据某属性值对流分组，属性为K，结果为V</td>
</tr>
<tr>
<td align="center"><code>partitioningBy</code></td>
<td align="center"><code>Map&lt;Boolean,List&lt;T&gt;&gt;</code></td>
<td align="center">根据true或false进行分区</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 需求：将当前公司中所有员工的名字提取出来，并放到一个集合中</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test06</span><span class="params">()</span>&#123;</span><br><span class="line">       </span><br><span class="line">       <span class="comment">// toList</span></span><br><span class="line">       List&lt;String&gt; nameList = employees.stream()</span><br><span class="line">               .map(x -&gt; x.getName())</span><br><span class="line">               .collect(Collectors.toList());</span><br><span class="line">       nameList.forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       <span class="comment">// toSet</span></span><br><span class="line">       Set&lt;String&gt; nameSet = employees.stream()</span><br><span class="line">               .map(x -&gt; x.getName())</span><br><span class="line">               .collect(Collectors.toSet());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       <span class="comment">// 想放到什么集合中就放到什么集合中</span></span><br><span class="line">       HashSet&lt;String&gt; hashSet = employees.stream()</span><br><span class="line">               .map(x -&gt; x.getName())</span><br><span class="line">               .collect(Collectors.toCollection(HashSet::<span class="keyword">new</span>));</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test07</span><span class="params">()</span>&#123;</span><br><span class="line">      <span class="comment">// 总数</span></span><br><span class="line">      <span class="type">Long</span> <span class="variable">count</span> <span class="operator">=</span> employees.stream()</span><br><span class="line">              .collect(Collectors.counting());</span><br><span class="line">      <span class="comment">// 平均值</span></span><br><span class="line">      <span class="type">Double</span> <span class="variable">avg</span> <span class="operator">=</span> employees.stream()</span><br><span class="line">              .collect(Collectors.averagingDouble(Employee::getSalary));</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 总和</span></span><br><span class="line">      <span class="type">Double</span> <span class="variable">sum</span> <span class="operator">=</span> employees.stream()</span><br><span class="line">              .collect(Collectors.summingDouble(Employee::getSalary));</span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">      <span class="comment">// 最大值/最小值</span></span><br><span class="line">      Optional&lt;Employee&gt; max = employees.stream()</span><br><span class="line">              .collect(Collectors.maxBy((x,y)-&gt;Double.compare(x.getSalary(), y.getSalary())));</span><br><span class="line">              </span><br><span class="line">              </span><br><span class="line">      Optional&lt;Double&gt; min = employees.stream()</span><br><span class="line">              .map(Employee::getSalary)</span><br><span class="line">              .collect(Collectors.minBy(Double::compare));</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test08</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="comment">// 分组</span></span><br><span class="line">       Map&lt;Integer, List&lt;Employee&gt;&gt; map = employees.stream()</span><br><span class="line">               .collect(Collectors.groupingBy(x -&gt; x.getAge()));<span class="comment">// 按照年龄分组</span></span><br><span class="line">       System.out.println(map);</span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">       <span class="comment">// 多级分组：先按年龄分，再按工资分</span></span><br><span class="line">       Map&lt;Integer, Map&lt;String, List&lt;Employee&gt;&gt;&gt; map2 = employees.stream()</span><br><span class="line">               .collect(</span><br><span class="line">                       Collectors.groupingBy(x -&gt; x.getAge(), </span><br><span class="line">                       Collectors.groupingBy(x -&gt; &#123;</span><br><span class="line">                           <span class="keyword">if</span> (x.getSalary() &gt; <span class="number">5000</span>) &#123;</span><br><span class="line">                               <span class="keyword">return</span> <span class="string">&quot;底薪&quot;</span>;</span><br><span class="line">                           &#125;</span><br><span class="line">                           <span class="keyword">return</span> <span class="string">&quot;中产&quot;</span>; &#125;)</span><br><span class="line">                       ));</span><br><span class="line">       System.out.println(map2);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 分区：满足条件的为一个区，不满足条件的为另一个区</span></span><br><span class="line"><span class="comment">    * 可以多级分区，原理与多级分组类似</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test09</span><span class="params">()</span>&#123;</span><br><span class="line">       Map&lt;Boolean, List&lt;Employee&gt;&gt; map = employees.stream()</span><br><span class="line">               .collect(Collectors.partitioningBy(x -&gt; x.getSalary() &gt; <span class="number">5000</span>));</span><br><span class="line">       System.out.println(map);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>练习</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 1、怎样用 map 和 reduce 数一数流中有多少个 Employee 呢？</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test02</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="type">Integer</span> <span class="variable">count</span> <span class="operator">=</span> employees.stream()</span><br><span class="line">               .map(x -&gt; <span class="number">1</span>)</span><br><span class="line">               .reduce(<span class="number">0</span>, (x, y) -&gt; x + y);</span><br><span class="line">       System.out.println(count);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<h2 id="并行流与串行流"><a href="#并行流与串行流" class="headerlink" title="并行流与串行流"></a>并行流与串行流</h2><p>并行流就是把一个内容分成多个数据块，并用不同的线程分别处理每个数据块的流。</p>
<p>Java8 中将并行进行了优化，我们可以很容易的对数据进行并行操作。Stream API 可以声明性的通过<code>parallel()</code>与<code>sequential()</code>在并行流和串行流之间进行切换。</p>
<h1 id="接口中的默认方法与静态方法"><a href="#接口中的默认方法与静态方法" class="headerlink" title="接口中的默认方法与静态方法"></a>接口中的默认方法与静态方法</h1><ul>
<li>  Java8 之前，接口中只允许定义抽象方法（只有方法的定义，而无方法的实现）；、</li>
<li>  从 Java8 开始，接口中可以存在方法的实现，但是这个方法必须被 <strong>default</strong> 关键字修饰。</li>
<li>  从 Java8 开始，接口中也可以定义静态方法。</li>
<li>  在接口中，静态方法（被 static 修饰的方法）和默认方法（被 default 修饰的方法）<strong>可以定义任意多个</strong>，不受数量的限制。</li>
</ul>
<p>接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.juc.day01;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2021/7/4 21:07</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Example</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">sayHello</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">default</span> <span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a+b;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">default</span> <span class="type">int</span> <span class="title function_">add2</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a+b;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">sub</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a-b;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">sub2</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a-b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>测试类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.juc.day01;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> lnd</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2021/7/4 21:09</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  1、函数式接口：</span></span><br><span class="line"><span class="comment"> *      1.1 使用 <span class="doctag">@FunctionalInterface</span> 注解可以校验一个接口是否为函数式接口</span></span><br><span class="line"><span class="comment"> *      1.2 函数式接口要求接口中只能有一个抽象方法</span></span><br><span class="line"><span class="comment"> *  2、从 JDK 8开始，接口中除了抽象方法外，还可以存在 default 和 static 修饰的方法</span></span><br><span class="line"><span class="comment"> *     默认方法（default 方法）和静态方法（static 方法）在接口中可以有任意多个</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestImpl</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// Lambda 表达式</span></span><br><span class="line">        <span class="type">Example</span> <span class="variable">example</span> <span class="operator">=</span> () -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;HelloWorld&quot;</span>);</span><br><span class="line">        &#125;;</span><br><span class="line">        example.sayHello();</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">add</span> <span class="operator">=</span> example.add(<span class="number">3</span>, <span class="number">4</span>);</span><br><span class="line">        <span class="type">int</span> <span class="variable">add2</span> <span class="operator">=</span> example.add2(<span class="number">3</span>, <span class="number">4</span>);</span><br><span class="line">        System.out.println(add);</span><br><span class="line">        System.out.println(add2);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">sub</span> <span class="operator">=</span> Example.sub(<span class="number">7</span>, <span class="number">3</span>);</span><br><span class="line">        <span class="type">int</span> <span class="variable">sub2</span> <span class="operator">=</span> Example.sub2(<span class="number">7</span>, <span class="number">3</span>);</span><br><span class="line">        System.out.println(sub);</span><br><span class="line">        System.out.println(sub2);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 输出结果：</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *      HelloWorld</span></span><br><span class="line"><span class="comment">     *      7</span></span><br><span class="line"><span class="comment">     *      7</span></span><br><span class="line"><span class="comment">     *      4</span></span><br><span class="line"><span class="comment">     *      4</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="新时间日期API"><a href="#新时间日期API" class="headerlink" title="新时间日期API"></a>新时间日期API</h1><h1 id="其它新特性"><a href="#其它新特性" class="headerlink" title="其它新特性"></a>其它新特性</h1>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/21/Lombok/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/01/21/Lombok/" class="post-title-link" itemprop="url">Lombok</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-01-21 20:42:07" itemprop="dateCreated datePublished" datetime="2021-01-21T20:42:07+08:00">2021-01-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-03-27 19:49:39" itemprop="dateModified" datetime="2021-03-27T19:49:39+08:00">2021-03-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/JavaUtils/" itemprop="url" rel="index"><span itemprop="name">JavaUtils</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     加了<span class="doctag">@Data</span>注解的类，编译后会自动给我们加上下列方法：</span></span><br><span class="line"><span class="comment">         所有属性的get和set方法</span></span><br><span class="line"><span class="comment">         toString 方法</span></span><br><span class="line"><span class="comment">         hashCode方法</span></span><br><span class="line"><span class="comment">         equals方法</span></span><br><span class="line"><span class="comment"> * */</span></span><br></pre></td></tr></table></figure>



<h1 id="Slf4j-的使用"><a href="#Slf4j-的使用" class="headerlink" title="@Slf4j 的使用"></a>@Slf4j 的使用</h1><p>如果不想每次都写 <code>private final Logger logger = LoggerFactory.getLogger(当前类名.class);</code>，可以用注解 <strong>@Slf4j</strong> ！</p>
<blockquote>
<ol>
<li>首先在 IDEA 中安装 Lombok 插件！</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>在 pom 文件中加入 Lombok 的依赖</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>在类上面添加 @Sl4j 注解，然后使用 log 打印日志</li>
</ol>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br></pre></td></tr></table></figure>

<p><img src="/2021/01/21/Lombok/Lombok%5C4724335-f1e94ef00d64bec5.png" alt="4724335-f1e94ef00d64bec5"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/18/SpringBoot-Restful%E5%B7%A5%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/01/18/SpringBoot-Restful%E5%B7%A5%E7%A8%8B/" class="post-title-link" itemprop="url">SpringBoot-Restful工程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2021-01-18 10:09:08 / Modified: 12:39:22" itemprop="dateCreated datePublished" datetime="2021-01-18T10:09:08+08:00">2021-01-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/SpringBoot/" itemprop="url" rel="index"><span itemprop="name">SpringBoot</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="RESTful-API"><a href="#RESTful-API" class="headerlink" title="RESTful API"></a>RESTful API</h2><table>
<thead>
<tr>
<th align="center">请求类型</th>
<th align="center">URL</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">GET</td>
<td align="center">/users</td>
<td align="center">查询用户列表</td>
</tr>
<tr>
<td align="center">POST</td>
<td align="center">/users</td>
<td align="center">创建一个用户</td>
</tr>
<tr>
<td align="center">GET</td>
<td align="center">/users/{id}</td>
<td align="center">根据id查询一个用户</td>
</tr>
<tr>
<td align="center">PUT</td>
<td align="center">/users/{id}</td>
<td align="center">根据id更新一个用户</td>
</tr>
<tr>
<td align="center">DELETE</td>
<td align="center">/users/{id}</td>
<td align="center">根据id删除一个用户</td>
</tr>
</tbody></table>
<h2 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.xsyu.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cn.xsyu.domain.User;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.*;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/users&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserController</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建线程安全的Map。[用于模拟数据库，保存user数据][全局变量]</span></span><br><span class="line">    <span class="keyword">static</span> Map&lt;Long, User&gt; users = Collections.synchronizedMap(<span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;Long, User&gt;());</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;/&quot;, method = RequestMethod.GET)</span></span><br><span class="line">    <span class="keyword">public</span> List&lt;User&gt; <span class="title function_">getUserList</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">// 处理“/users/”的GET请求，用来获取用户列表</span></span><br><span class="line">        <span class="comment">/*-- 还可以通过 @RequestParam 接收从页面中传递的参数来进行查询条件筛选或分页信息等 --*/</span></span><br><span class="line">        ArrayList&lt;User&gt; userArrayList = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(users.values());</span><br><span class="line">        <span class="keyword">return</span> userArrayList;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;/&quot;, method = RequestMethod.POST)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">postUser</span><span class="params">(<span class="meta">@ModelAttribute</span> User user)</span>&#123;</span><br><span class="line">        <span class="comment">// 处理“/users/”的POST请求，用来创建User</span></span><br><span class="line">        <span class="comment">/*-- 除了 @ModelAttribute 绑定请求参数之外，还可以通过 @RequestParam 接收从页面中传递的参数*/</span></span><br><span class="line">        users.put(user.getId(), user);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;sucess&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;/&#123;id&#125;&quot;, method = RequestMethod.GET)</span></span><br><span class="line">    <span class="keyword">public</span> User <span class="title function_">getUser</span><span class="params">(<span class="meta">@PathVariable</span> Long id)</span>&#123;</span><br><span class="line">        <span class="comment">// 处理“/users/&#123;id&#125;”的GET请求，用来获取url中id值的User信息</span></span><br><span class="line">        <span class="comment">/* -- url中的id可通过 @PathVariable 注解绑定到函数的参数中--*/</span></span><br><span class="line">        <span class="keyword">return</span> users.get(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;/&#123;id&#125;&quot;, method = RequestMethod.PUT)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">putUser</span><span class="params">(<span class="meta">@PathVariable</span> Long id, <span class="meta">@ModelAttribute</span> User user)</span>&#123;</span><br><span class="line">        <span class="comment">// 处理“/users/&#123;id&#125;”的PUT请求，用来更新User信息</span></span><br><span class="line">        <span class="type">User</span> <span class="variable">u</span> <span class="operator">=</span> users.get(id);</span><br><span class="line">        u.setName(user.getName());</span><br><span class="line">        u.setAge(user.getAge());</span><br><span class="line">        users.put(id, u);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;sucess&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;/&#123;id&#125;&quot;, method = RequestMethod.DELETE)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">deleteUser</span><span class="params">(<span class="meta">@PathVariable</span> Long id)</span>&#123;</span><br><span class="line">        <span class="comment">// 处理“users/&#123;id&#125;”的DELETE请求，用来删除User</span></span><br><span class="line">        users.remove(id);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;sucess&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>可使用PostMan等软件提交请求进行验证。</p>
</blockquote>
<hr>
<h2 id="运行SpringBoot-RESTful工程"><a href="#运行SpringBoot-RESTful工程" class="headerlink" title="运行SpringBoot-RESTful工程"></a>运行SpringBoot-RESTful工程</h2><blockquote>
<ol>
<li>数据库准备。<ul>
<li>创建数据库</li>
<li>创建表</li>
<li>插入数据</li>
</ul>
</li>
</ol>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<ol start="2">
<li></li>
</ol>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span> 处理请求地址映射。</span><br><span class="line">method - 指定请求的⽅法类型：POST/GET/DELETE/PUT 等</span><br><span class="line">value - 指定实际的请求地址</span><br><span class="line">consumes - 指定处理请求的提交内容类型，例如 Content-Type 头部设置application/json,</span><br><span class="line">text/html</span><br><span class="line">produces - 指定返回的内容类型</span><br><span class="line"><span class="meta">@PathVariable</span> URL 映射时，⽤于绑定请求参数到⽅法参数</span><br><span class="line"><span class="meta">@RequestBody</span> 这⾥注解⽤于读取请求体 boy 的数据，通过 HttpMessageConverter 解析绑定到对象</span><br><span class="line">中</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/17/SpringBoot%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/01/17/SpringBoot%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/" class="post-title-link" itemprop="url">SpringBoot与数据访问</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2021-01-17 23:09:30 / Modified: 23:49:28" itemprop="dateCreated datePublished" datetime="2021-01-17T23:09:30+08:00">2021-01-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/SpringBoot/" itemprop="url" rel="index"><span itemprop="name">SpringBoot</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="JDBC"><a href="#JDBC" class="headerlink" title="JDBC"></a>JDBC</h1><h1 id="1、整合JDBC"><a href="#1、整合JDBC" class="headerlink" title="1、整合JDBC"></a>1、整合JDBC</h1><h1 id="2、整合数据库连接池"><a href="#2、整合数据库连接池" class="headerlink" title="2、整合数据库连接池"></a>2、整合数据库连接池</h1><h1 id="3、整合MyBatis"><a href="#3、整合MyBatis" class="headerlink" title="3、整合MyBatis"></a>3、整合MyBatis</h1><blockquote>
<ol start="0">
<li>准备MySQL数据库</li>
</ol>
</blockquote>
<blockquote>
<ol>
<li>导入依赖</li>
</ol>
</blockquote>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--MyBatis启动依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis.spring.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>	</span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--MySql--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<ol start="2">
<li>配置数据库连接属性</li>
</ol>
</blockquote>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据库连接</span></span><br><span class="line"><span class="attr">spring.datasource.url</span>=<span class="string">jdbc:mysql://localhost:3306/springboot01?serverTimezone=Asia/Shanghai</span></span><br><span class="line"><span class="attr">spring.datasource.username</span>=<span class="string">root</span></span><br><span class="line"><span class="attr">spring.datasource.password</span>=<span class="string">root</span></span><br></pre></td></tr></table></figure>

<blockquote>
<ol start="3">
<li>创建一个Web项目</li>
</ol>
</blockquote>
<p><img src="/2021/01/17/SpringBoot%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/image-20210117233128526.png" alt="image-20210117233128526"></p>
<blockquote>
<ol start="4">
<li>使用<code>@Mapper</code>或<code>@MapperScan</code>将接口扫描装配到容器中</li>
</ol>
</blockquote>
<p>在MyBatis中，需要在类上使用<code>@Mapper</code>注解表明当前类是一个操作数据库的Mapper。</p>
<p><code>@Mapper</code>注解的源代码中包含了<code>@Component</code>注解。</p>
<p>对于一个复杂的项目，随着开发迭代的版本越来越多，代码越来越复杂，如果给每新增一个操作数据库的类都添加一次<code>@Mapper</code>注解，显然是非常不方便的，这时候就可以使用<code>@MapperScan</code>注解，该注解可以指定一个包，该包下的所有子类都相当于自动添加了一个<code>@Mapper</code>注解，我们一般把<code>@MapperScan</code>注解添加在SpringBoot的启动类上。</p>
<ul>
<li><strong>@Mapper</strong></li>
</ul>
<p><img src="/2021/01/17/SpringBoot%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/image-20210117233506600.png" alt="image-20210117233506600"></p>
<ul>
<li><strong>@MapperScan</strong></li>
</ul>
<p><img src="/2021/01/17/SpringBoot%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/image-20210117233800222.png" alt="image-20210117233800222"></p>
<blockquote>
<ol start="5">
<li>引入全局配置文件和映射配置文件<code>[只有使用Mapper.xml配置文件书写SQL语句时才需要]</code></li>
</ol>
<p>官网参考文档：<a target="_blank" rel="noopener" href="https://mybatis.org/mybatis-3/getting-started.html#">https://mybatis.org/mybatis-3/getting-started.html#</a></p>
</blockquote>
<p><img src="/2021/01/17/SpringBoot%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/image-20210117233252854.png" alt="image-20210117233252854"></p>
<ol>
<li>设置全局配置文件：<code>mybatis-config.xml</code></li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">configuration</span></span></span><br><span class="line"><span class="meta">        <span class="keyword">PUBLIC</span> <span class="string">&quot;-//mybatis.org//DTD Config 3.0//EN&quot;</span></span></span><br><span class="line"><span class="meta">        <span class="string">&quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>设置映射配置文件：<code>CityMapper.xml</code></li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">mapper</span></span></span><br><span class="line"><span class="meta">  <span class="keyword">PUBLIC</span> <span class="string">&quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;</span></span></span><br><span class="line"><span class="meta">  <span class="string">&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mapper</span> <span class="attr">namespace</span>=<span class="string">&quot;org.mybatis.example.BlogMapper&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;selectBlog&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;Blog&quot;</span>&gt;</span></span><br><span class="line">        select * from Blog where id = #&#123;id&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Spring boot读取MyBatis的两个配置文件</li>
</ol>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MyBatis全局配置文件位置</span></span><br><span class="line"><span class="attr">mybatis.config-location</span>=<span class="string">classpath:mybatis/mybatis-config.xml</span></span><br><span class="line"><span class="comment"># MyBatis映射配置文件位置</span></span><br><span class="line"><span class="attr">mybatis.mapper-locations</span>=<span class="string">classpath:mybatis/mapper/*.xml</span></span><br></pre></td></tr></table></figure>



<blockquote>
<ol start="6">
<li>在<code>CityDao接口</code>中定义操作数据库的抽象方法，在<code>CityMapper.xml</code>中定义具体的SQL语句。</li>
</ol>
</blockquote>
<blockquote>
<ol start="7">
<li>给自定义的实体类统一起别名</li>
</ol>
</blockquote>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 给自定义的实体类起别名</span></span><br><span class="line"><span class="attr">mybatis.type-aliases-package</span>=<span class="string">cn.xsyu.dao</span></span><br></pre></td></tr></table></figure>

<blockquote>
<ol start="8">
<li>其它配置</li>
</ol>
</blockquote>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#开启MyBatis驼峰式命名规则自动转换功能</span></span><br><span class="line"><span class="attr">mybatis.configuration.map-underscore-to-camel-case</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure>



<h1 id="4、整合SpringData-JPA"><a href="#4、整合SpringData-JPA" class="headerlink" title="4、整合SpringData JPA"></a>4、整合SpringData JPA</h1>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/16/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><span class="page-number current">17</span><a class="page-number" href="/page/18/">18</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" href="/page/18/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
