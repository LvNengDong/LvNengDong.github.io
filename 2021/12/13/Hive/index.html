<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="官网地址：https:&#x2F;&#x2F;hive.apache.org&#x2F; 第1章 Hive入门1.1 什么是HiveHive 是一个由 Facebook 开源的用于解决海量结构化数据统计分析的框架。 Hive 只能分析结构化的数据。所以在使用 Hive 之前，需要先对非结构化数据进行 ETL ，转换为结构化的数据。 Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive">
<meta property="og:url" content="http://example.com/2021/12/13/Hive/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="官网地址：https:&#x2F;&#x2F;hive.apache.org&#x2F; 第1章 Hive入门1.1 什么是HiveHive 是一个由 Facebook 开源的用于解决海量结构化数据统计分析的框架。 Hive 只能分析结构化的数据。所以在使用 Hive 之前，需要先对非结构化数据进行 ETL ，转换为结构化的数据。 Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/clip_image002.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20220124205740685.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/clip_image002-1639754524896.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/clip_image006.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211219121900037.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211219223705371.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211220102736063.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211220102924703.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211220103704244.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211220114355694.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211220122413669.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211220125128806.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211220125548362.png">
<meta property="og:image" content="http://example.com/2021/12/13/Hive/Hive/image-20211220175855162.png">
<meta property="article:published_time" content="2021-12-13T08:21:50.000Z">
<meta property="article:modified_time" content="2022-01-30T04:59:33.282Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/12/13/Hive/Hive/clip_image002.png">


<link rel="canonical" href="http://example.com/2021/12/13/Hive/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2021/12/13/Hive/","path":"2021/12/13/Hive/","title":"Hive"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hive | Hexo</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hexo</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC1%E7%AB%A0-Hive%E5%85%A5%E9%97%A8"><span class="nav-number">1.</span> <span class="nav-text">第1章 Hive入门</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E4%BB%80%E4%B9%88%E6%98%AFHive"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 什么是Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E7%9A%84%E6%9C%AC%E8%B4%A8"><span class="nav-number">1.1.1.</span> <span class="nav-text">Hive的本质</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-Hive%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 Hive的优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-1-%E4%BC%98%E7%82%B9"><span class="nav-number">1.2.1.</span> <span class="nav-text">1.2.1 优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-2-%E7%BC%BA%E7%82%B9"><span class="nav-number">1.2.2.</span> <span class="nav-text">1.2.2 缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-Hive%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 Hive架构原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-Hive%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AF%94%E8%BE%83"><span class="nav-number">1.4.</span> <span class="nav-text">1.4 Hive和数据库比较</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-1-%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80"><span class="nav-number">1.4.1.</span> <span class="nav-text">1.4.1 查询语言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-2-%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE"><span class="nav-number">1.4.2.</span> <span class="nav-text">1.4.2 数据存储位置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-3-%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0"><span class="nav-number">1.4.3.</span> <span class="nav-text">1.4.3 数据更新</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-4-%E7%B4%A2%E5%BC%95"><span class="nav-number">1.4.4.</span> <span class="nav-text">1.4.4 索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-5-%E6%89%A7%E8%A1%8C"><span class="nav-number">1.4.5.</span> <span class="nav-text">1.4.5 执行</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-6-%E6%89%A7%E8%A1%8C%E5%BB%B6%E8%BF%9F"><span class="nav-number">1.4.6.</span> <span class="nav-text">1.4.6 执行延迟</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-7-%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7"><span class="nav-number">1.4.7.</span> <span class="nav-text">1.4.7 可扩展性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-8-%E6%95%B0%E6%8D%AE%E8%A7%84%E6%A8%A1"><span class="nav-number">1.4.8.</span> <span class="nav-text">1.4.8 数据规模</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC2%E7%AB%A0-Hive%E5%AE%89%E8%A3%85"><span class="nav-number">2.</span> <span class="nav-text">第2章 Hive安装</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC3%E7%AB%A0-Hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">第3章 Hive数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 基本数据类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-%E9%9B%86%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 集合数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="nav-number">3.2.1.</span> <span class="nav-text">案例实操</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-%E7%B1%BB%E5%9E%8B%E8%BD%AC%E5%8C%96"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 类型转化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC4%E7%AB%A0-DDL"><span class="nav-number">4.</span> <span class="nav-text">第4章 DDL</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-%E5%BA%93%E6%93%8D%E4%BD%9C"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 库操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-1-%E5%A2%9E%EF%BC%9A%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">4.1.1.</span> <span class="nav-text">4.1.1 增：创建数据库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-2-%E5%88%A0%EF%BC%9A%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">4.1.2.</span> <span class="nav-text">4.1.2 删：删除数据库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-3-%E6%94%B9%EF%BC%9A%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">4.1.3.</span> <span class="nav-text">4.1.3 改：修改数据库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-4-%E6%9F%A5%EF%BC%9A%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">4.1.4.</span> <span class="nav-text">4.1.4 查：查询数据库</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E6%98%BE%E7%A4%BA%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">4.1.4.1.</span> <span class="nav-text">1、显示数据库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%8F%8F%E8%BF%B0%E4%BF%A1%E6%81%AF"><span class="nav-number">4.1.4.2.</span> <span class="nav-text">2、查看数据库的描述信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81%E5%88%87%E6%8D%A2%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="nav-number">4.1.4.3.</span> <span class="nav-text">3、切换数据库上下文</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-%E8%A1%A8%E6%93%8D%E4%BD%9C"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 表操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-%E5%A2%9E%EF%BC%9A%E5%88%9B%E5%BB%BA%E8%A1%A8"><span class="nav-number">4.2.1.</span> <span class="nav-text">4.2.1 增：创建表</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%86%85%E9%83%A8%E8%A1%A8%EF%BC%88%E7%AE%A1%E7%90%86%E8%A1%A8%EF%BC%89"><span class="nav-number">4.2.1.1.</span> <span class="nav-text">1 内部表（管理表）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="nav-number">4.2.1.2.</span> <span class="nav-text">2 外部表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%86%85%E9%83%A8%E8%A1%A8-lt-gt-%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="nav-number">4.2.1.3.</span> <span class="nav-text">3 内部表 &lt;&#x3D;&gt; 外部表</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-%E5%88%A0%EF%BC%9A%E5%88%A0%E9%99%A4%E8%A1%A8"><span class="nav-number">4.2.2.</span> <span class="nav-text">4.2.2 删：删除表</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BD%BB%E5%BA%95%E5%88%A0%E9%99%A4%E8%A1%A8"><span class="nav-number">4.2.2.1.</span> <span class="nav-text">彻底删除表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B8%85%E7%A9%BA%E8%A1%A8%E4%B8%AD%E6%95%B0%E6%8D%AE%EF%BC%8C%E4%BD%86%E4%BF%9D%E7%95%99%E8%A1%A8%E7%BB%93%E6%9E%84"><span class="nav-number">4.2.2.2.</span> <span class="nav-text">清空表中数据，但保留表结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-3-%E6%94%B9"><span class="nav-number">4.2.3.</span> <span class="nav-text">4.2.3 改</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-1-%E9%87%8D%E5%91%BD%E5%90%8D%E8%A1%A8"><span class="nav-number">4.2.3.1.</span> <span class="nav-text">4.2.3.1 重命名表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-2-%E5%A2%9E%E5%8A%A0%E3%80%81%E4%BF%AE%E6%94%B9%E5%92%8C%E5%88%A0%E9%99%A4%E8%A1%A8%E5%88%86%E5%8C%BA"><span class="nav-number">4.2.3.2.</span> <span class="nav-text">4.2.3.2 增加、修改和删除表分区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-3-%E5%A2%9E%E5%8A%A0-%E4%BF%AE%E6%94%B9-%E6%9B%BF%E6%8D%A2%E5%88%97%E4%BF%A1%E6%81%AF"><span class="nav-number">4.2.3.3.</span> <span class="nav-text">4.2.3.3 增加&#x2F;修改&#x2F;替换列信息</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-4-%E6%9F%A5"><span class="nav-number">4.2.4.</span> <span class="nav-text">4.2.4 查</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="nav-number">4.3.</span> <span class="nav-text">4.3 分区表</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-1-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">4.3.1.</span> <span class="nav-text">4.3.1 是什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-2-%E5%88%86%E5%8C%BA%E8%A1%A8%E8%AF%AD%E6%B3%95"><span class="nav-number">4.3.2.</span> <span class="nav-text">4.3.2 分区表语法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-3-%E5%88%86%E5%8C%BA%E8%A1%A8%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="nav-number">4.3.3.</span> <span class="nav-text">4.3.3 分区表基本操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="nav-number">4.3.3.1.</span> <span class="nav-text">1、准备数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81%E5%88%9B%E5%BB%BA%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="nav-number">4.3.3.2.</span> <span class="nav-text">2、创建分区表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%EF%BC%88%E5%A4%B1%E8%B4%A5%EF%BC%89"><span class="nav-number">4.3.3.3.</span> <span class="nav-text">3、导入数据（失败）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81%E5%A2%9E%E5%8A%A0%E5%88%86%E5%8C%BA"><span class="nav-number">4.3.3.4.</span> <span class="nav-text">4、增加分区</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B0%E5%A2%9E%E5%88%86%E5%8C%BA%EF%BC%88%E6%96%B9%E5%BC%8F%E4%B8%80%EF%BC%89%EF%BC%9A"><span class="nav-number">4.3.3.4.1.</span> <span class="nav-text">新增分区（方式一）：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A2%9E%E5%8A%A0%E5%88%86%E5%8C%BA%EF%BC%88%E6%96%B9%E5%BC%8F%E4%BA%8C%EF%BC%89"><span class="nav-number">4.3.3.4.2.</span> <span class="nav-text">增加分区（方式二）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5%E3%80%81%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%EF%BC%88%E6%88%90%E5%8A%9F%EF%BC%89"><span class="nav-number">4.3.3.5.</span> <span class="nav-text">5、导入数据（成功）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6%E3%80%81%E6%9F%A5%E8%AF%A2%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="nav-number">4.3.3.6.</span> <span class="nav-text">6、查询分区表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7%E3%80%81%E5%88%A0%E9%99%A4%E5%88%86%E5%8C%BA"><span class="nav-number">4.3.3.7.</span> <span class="nav-text">7、删除分区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8%E3%80%81%E6%9F%A5%E7%9C%8B%E5%88%86%E5%8C%BA%E8%A1%A8%E6%9C%89%E5%93%AA%E4%BA%9B%E5%88%86%E5%8C%BA"><span class="nav-number">4.3.3.8.</span> <span class="nav-text">8、查看分区表有哪些分区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9%E3%80%81%E6%9F%A5%E7%9C%8B%E5%88%86%E5%8C%BA%E8%A1%A8%E7%BB%93%E6%9E%84"><span class="nav-number">4.3.3.9.</span> <span class="nav-text">9、查看分区表结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-4-%E5%A4%9A%E7%BA%A7%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="nav-number">4.3.4.</span> <span class="nav-text">4.3.4 多级分区表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-5-%E8%87%AA%E5%8A%A8%E4%BF%AE%E5%A4%8D%E5%88%86%E5%8C%BA"><span class="nav-number">4.3.5.</span> <span class="nav-text">4.3.5 自动修复分区</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-4-%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="nav-number">4.4.</span> <span class="nav-text">4.4 分桶表</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-1-%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86"><span class="nav-number">4.4.1.</span> <span class="nav-text">4.4.1 理论知识</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-2-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="nav-number">4.4.2.</span> <span class="nav-text">4.4.2 案例实操</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E5%88%9B%E5%BB%BA%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="nav-number">4.4.2.1.</span> <span class="nav-text">1、创建分桶表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81%E5%88%9B%E5%BB%BA%E5%88%86%E6%A1%B6%E8%A1%A8%E6%97%B6%EF%BC%8C%E6%95%B0%E6%8D%AE%E9%80%9A%E8%BF%87%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AF%BC%E5%85%A5"><span class="nav-number">4.4.2.2.</span> <span class="nav-text">2、创建分桶表时，数据通过子查询的方式导入</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-2-%E5%88%86%E6%A1%B6%E6%8A%BD%E6%A0%B7%E6%9F%A5%E8%AF%A2"><span class="nav-number">4.4.3.</span> <span class="nav-text">4.4.2 分桶抽样查询</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC5%E7%AB%A0-DML%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C"><span class="nav-number">5.</span> <span class="nav-text">第5章 DML数据操作</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 数据导入</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-1-%E5%90%91%E8%A1%A8%E4%B8%AD%E8%A3%85%E8%BD%BD%E6%95%B0%E6%8D%AE%EF%BC%88Load%EF%BC%89"><span class="nav-number">5.1.1.</span> <span class="nav-text">5.1.1 向表中装载数据（Load）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-2-%E9%80%9A%E8%BF%87%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E5%90%91%E8%A1%A8%E4%B8%AD%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE%EF%BC%88Insert%EF%BC%89"><span class="nav-number">5.1.2.</span> <span class="nav-text">5.1.2    通过查询语句向表中插入数据（Insert）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-3-%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E4%B8%AD%E5%88%9B%E5%BB%BA%E8%A1%A8%E5%B9%B6%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%EF%BC%88As-Select%EF%BC%89"><span class="nav-number">5.1.3.</span> <span class="nav-text">5.1.3 查询语句中创建表并加载数据（As Select）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-4-%E5%88%9B%E5%BB%BA%E8%A1%A8%E6%97%B6%E9%80%9A%E8%BF%87-Location-%E6%8C%87%E5%AE%9A%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E8%B7%AF%E5%BE%84"><span class="nav-number">5.1.4.</span> <span class="nav-text">5.1.4 创建表时通过 Location 指定加载数据路径</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-5-Import%E6%95%B0%E6%8D%AE%E5%88%B0%E6%8C%87%E5%AE%9AHive%E8%A1%A8%E4%B8%AD"><span class="nav-number">5.1.5.</span> <span class="nav-text">5.1.5 Import数据到指定Hive表中</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 数据导出</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-1-Insert-%E5%AF%BC%E5%87%BA"><span class="nav-number">5.2.1.</span> <span class="nav-text">5.2.1 Insert 导出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-2-Hadoop%E5%91%BD%E4%BB%A4%E5%AF%BC%E5%87%BA%E5%88%B0%E6%9C%AC%E5%9C%B0"><span class="nav-number">5.2.2.</span> <span class="nav-text">5.2.2 Hadoop命令导出到本地</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-3-Hive-Shell-%E5%91%BD%E4%BB%A4%E5%AF%BC%E5%87%BA"><span class="nav-number">5.2.3.</span> <span class="nav-text">5.2.3    Hive Shell 命令导出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-4-Export-%E5%AF%BC%E5%87%BA%E5%88%B0-HDFS-%E4%B8%8A"><span class="nav-number">5.2.4.</span> <span class="nav-text">5.2.4    Export 导出到 HDFS 上</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-5-Sqoop-%E5%AF%BC%E5%87%BA"><span class="nav-number">5.2.5.</span> <span class="nav-text">5.2.5    Sqoop 导出</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-%E6%B8%85%E9%99%A4%E8%A1%A8%E4%B8%AD%E6%95%B0%E6%8D%AE%EF%BC%88Truncate%EF%BC%89"><span class="nav-number">5.3.</span> <span class="nav-text">5.3 清除表中数据（Truncate）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AC%AC-6-%E7%AB%A0-%E6%9F%A5%E8%AF%A2"><span class="nav-number">6.</span> <span class="nav-text">第 6 章    查询</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-%E5%9F%BA%E7%A1%80%E6%9F%A5%E8%AF%A2%EF%BC%88Select%E2%80%A6From%EF%BC%89"><span class="nav-number">6.1.</span> <span class="nav-text">6.1 基础查询（Select…From）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-1-%E5%85%A8%E8%A1%A8%E5%92%8C%E7%89%B9%E5%AE%9A%E5%88%97%E6%9F%A5%E8%AF%A2"><span class="nav-number">6.1.1.</span> <span class="nav-text">6.1.1 全表和特定列查询</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-2-%E5%88%97%E5%88%AB%E5%90%8D"><span class="nav-number">6.1.2.</span> <span class="nav-text">6.1.2 列别名</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-3-%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="nav-number">6.1.3.</span> <span class="nav-text">6.1.3 算术运算符</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-4-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="nav-number">6.1.4.</span> <span class="nav-text">6.1.4 常用函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-5-Limit-%E8%AF%AD%E5%8F%A5"><span class="nav-number">6.1.5.</span> <span class="nav-text">6.1.5 Limit 语句</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-Where%E8%AF%AD%E5%8F%A5"><span class="nav-number">6.2.</span> <span class="nav-text">6.2 Where语句</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-1-%E6%AF%94%E8%BE%83%E8%BF%90%E7%AE%97%E7%AC%A6%EF%BC%88Between-In-Is-Null%EF%BC%89"><span class="nav-number">6.2.1.</span> <span class="nav-text">6.2.1 比较运算符（Between &#x2F; In &#x2F; Is Null）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-2-Like-%E5%92%8C-RLike"><span class="nav-number">6.2.2.</span> <span class="nav-text">6.2.2 Like 和 RLike</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-3-%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6%EF%BC%88And-Or-Not%EF%BC%89"><span class="nav-number">6.2.3.</span> <span class="nav-text">6.2.3    逻辑运算符（And&#x2F;Or&#x2F;Not）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-%E5%88%86%E7%BB%84"><span class="nav-number">6.3.</span> <span class="nav-text">6.3    分组</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-1-Group-By%E8%AF%AD%E5%8F%A5"><span class="nav-number">6.3.1.</span> <span class="nav-text">6.3.1    Group By语句</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-2-Having-%E8%AF%AD%E5%8F%A5"><span class="nav-number">6.3.2.</span> <span class="nav-text">6.3.2    Having 语句</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-4-Join%E8%AF%AD%E5%8F%A5"><span class="nav-number">6.4.</span> <span class="nav-text">6.4 Join语句</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-1-%E7%AD%89%E5%80%BCJoin"><span class="nav-number">6.4.1.</span> <span class="nav-text">6.4.1 等值Join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-2-%E8%A1%A8%E7%9A%84%E5%88%AB%E5%90%8D"><span class="nav-number">6.4.2.</span> <span class="nav-text">6.4.2    表的别名</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-3-%E5%86%85%E8%BF%9E%E6%8E%A5"><span class="nav-number">6.4.3.</span> <span class="nav-text">6.4.3    内连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-4-%E5%B7%A6%E5%A4%96%E8%BF%9E%E6%8E%A5"><span class="nav-number">6.4.4.</span> <span class="nav-text">6.4.4    左外连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-5-%E5%8F%B3%E5%A4%96%E8%BF%9E%E6%8E%A5"><span class="nav-number">6.4.5.</span> <span class="nav-text">6.4.5    右外连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-6-%E5%85%A8%E5%A4%96%E8%BF%9E%E6%8E%A5"><span class="nav-number">6.4.6.</span> <span class="nav-text">6.4.6    全外连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-7-%E5%A4%9A%E8%A1%A8%E8%BF%9E%E6%8E%A5"><span class="nav-number">6.4.7.</span> <span class="nav-text">6.4.7    多表连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-8-%E7%AC%9B%E5%8D%A1%E5%B0%94%E7%A7%AF"><span class="nav-number">6.4.8.</span> <span class="nav-text">6.4.8    笛卡尔积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-9-%E8%BF%9E%E6%8E%A5%E8%B0%93%E8%AF%8D%E4%B8%AD%E4%B8%8D%E6%94%AF%E6%8C%81or"><span class="nav-number">6.4.9.</span> <span class="nav-text">6.4.9    连接谓词中不支持or</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-5-%E6%8E%92%E5%BA%8F"><span class="nav-number">6.5.</span> <span class="nav-text">6.5 排序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-1-%E5%85%A8%E5%B1%80%E6%8E%92%E5%BA%8F%EF%BC%88Order-By%EF%BC%89"><span class="nav-number">6.5.1.</span> <span class="nav-text">6.5.1    全局排序（Order By）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-2-%E6%8C%89%E7%85%A7%E5%88%AB%E5%90%8D%E6%8E%92%E5%BA%8F"><span class="nav-number">6.5.2.</span> <span class="nav-text">6.5.2    按照别名排序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-3-%E5%A4%8D%E5%90%88%E6%8E%92%E5%BA%8F"><span class="nav-number">6.5.3.</span> <span class="nav-text">6.5.3    复合排序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-4-%E9%83%A8%E5%88%86%E6%8E%92%E5%BA%8F%EF%BC%88Sort-By%EF%BC%89"><span class="nav-number">6.5.4.</span> <span class="nav-text">6.5.4    部分排序（Sort By）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-5-%E5%88%86%E5%8C%BA%E6%8E%92%E5%BA%8F%EF%BC%88Distribute-By%EF%BC%89"><span class="nav-number">6.5.5.</span> <span class="nav-text">6.5.5    分区排序（Distribute By）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-6-Cluster-By"><span class="nav-number">6.5.6.</span> <span class="nav-text">6.5.6    Cluster By</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">224</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">61</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/12/13/Hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Hive | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hive
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-12-13 16:21:50" itemprop="dateCreated datePublished" datetime="2021-12-13T16:21:50+08:00">2021-12-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-01-30 12:59:33" itemprop="dateModified" datetime="2022-01-30T12:59:33+08:00">2022-01-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>官网地址：<a target="_blank" rel="noopener" href="https://hive.apache.org/">https://hive.apache.org/</a></p>
<h1 id="第1章-Hive入门"><a href="#第1章-Hive入门" class="headerlink" title="第1章 Hive入门"></a>第1章 Hive入门</h1><h2 id="1-1-什么是Hive"><a href="#1-1-什么是Hive" class="headerlink" title="1.1 什么是Hive"></a>1.1 什么是Hive</h2><p>Hive 是一个由 Facebook 开源的用于解决海量<strong>结构化数据</strong>统计分析的框架。</p>
<p>Hive 只能分析结构化的数据。所以在使用 Hive 之前，需要先对非结构化数据进行 ETL ，转换为结构化的数据。</p>
<p>Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类 SQL 查询功能。</p>
<p><strong>Hive 的底层实现原理是：将 HQL 转化成 MapReduce 程序执行。</strong></p>
<p><img src="Hive/clip_image002.png" alt="img">   </p>
<ol>
<li> Hive 处理的数据存储在 HDFS 上。</li>
<li> Hive 分析数据底层的实现是 MapReduce</li>
<li> 执行程序运行在 Yarn 上</li>
</ol>
<h3 id="Hive的本质"><a href="#Hive的本质" class="headerlink" title="Hive的本质"></a>Hive的本质</h3><p>Hive 不提供存储功能，通过 Hive 创建的库/表中的业务数据都会以文件的形式存放在 HDFS 上。</p>
<p>与此同时，在建库/表后，会在 MySQL 中生成对应的 <code>schema</code> 数据库存储元数据信息。元数据信息以表的形式存储，常见的表有：</p>
<ul>
<li>  <code>tbls</code>：存放表相关的元数据信息</li>
<li>  <code>dbs</code>：存放库相关的元数据信息</li>
<li>  <code>column_v2</code>：存放列相关的元数据信息 </li>
</ul>
<p><img src="Hive/image-20220124205740685.png" alt="image-20220124205740685"></p>
<hr>
<h2 id="1-2-Hive的优缺点"><a href="#1-2-Hive的优缺点" class="headerlink" title="1.2 Hive的优缺点"></a>1.2 Hive的优缺点</h2><h3 id="1-2-1-优点"><a href="#1-2-1-优点" class="headerlink" title="1.2.1 优点"></a>1.2.1 优点</h3><ol>
<li> 操作接口采用类SQL语法，提供快速开发的能力（简单、容易上手）。</li>
<li> 避免了去写 MapReduce 程序，减少开发人员的学习成本。</li>
<li> Hive 的执行延迟比较高，因此 Hive 常用于数据分析，对实时性要求不高的场合。</li>
<li> Hive 的优势在于处理大数据，对于处理小数据没有优势，因为 Hive 的执行延迟比较高。</li>
<li> Hive 支持用户自定义函数，用户可以根据需求实现自己的函数。</li>
</ol>
<hr>
<h3 id="1-2-2-缺点"><a href="#1-2-2-缺点" class="headerlink" title="1.2.2 缺点"></a>1.2.2 缺点</h3><ol>
<li>Hive 的 HQL 表达能力有限<ul>
<li>  迭代式算法无法表达</li>
<li>  数据挖掘方面不擅长</li>
</ul>
</li>
<li>Hive 的效率比较低<ul>
<li>  Hive 自动生成的 MapReduce Job，通常情况下不够智能化</li>
<li>  Hive 调优比较困难，粒度较粗</li>
</ul>
</li>
</ol>
<hr>
<h2 id="1-3-Hive架构原理"><a href="#1-3-Hive架构原理" class="headerlink" title="1.3 Hive架构原理"></a>1.3 Hive架构原理</h2><p><img src="Hive/clip_image002-1639754524896.png" alt="img"></p>
<ol>
<li><strong>用户接口：Client</strong><ul>
<li>  CLI（Hive shell）、JDBC/ODBC（Java 访问 Hive）、WEBUI（浏览器访问 Hive）</li>
</ul>
</li>
<li><strong>元数据：Metastore</strong><ul>
<li>  元数据包括：表名、表所属的数据库（默认属于default数据库）、表的拥有者、列/分区字段、表的类型（是否为外部表）、表的数据所在目录等；</li>
<li>  元数据默认存储在 Hive 自带的 <code>derby</code> 数据库中。推荐使用 MySQL 的 <code>metastore</code> 数据库存储数据。</li>
</ul>
</li>
<li><strong>Hadoop</strong><ul>
<li>  使用 HDFS 存储业务数据，使用 MapReduce 进行计算。</li>
</ul>
</li>
<li><strong>驱动器：Driver</strong><ul>
<li>  <strong>解析器（SQL Parser）</strong>：将 SQL 字符串转换成抽象语法树 AST，这一步一般都用第三方工具库完成，比如 <code>antlr</code>；对 AST 进行语法分析，比如表是否存在、字段是否存在、SQL 语义是否有误。</li>
<li>  <strong>编译器（Physical Plan）</strong>：将 AST 编译，生成逻辑执行计划。</li>
<li>  <strong>优化器（Query Optimizer）</strong>：对逻辑执行计划进行优化。</li>
<li>  <strong>执行器（Execution）</strong>：把逻辑执行计划转换成可以运行的物理计划。对于 Hive 来说，就是 <code>MapReduce/Spark</code>。</li>
</ul>
</li>
</ol>
<p><img src="Hive/clip_image006.png" alt="img"></p>
<p>Hive 通过给用户提供的一系列交互接口，接收到用户的**指令(SQL)<strong>，使用自己的 <strong>Driver</strong>，结合</strong>元数据(MetaStore)**，将这些指令翻译成 MapReduce Job，提交到 Hadoop 中执行，最后，将执行返回的结果输出到用户交互接口。</p>
<hr>
<h2 id="1-4-Hive和数据库比较"><a href="#1-4-Hive和数据库比较" class="headerlink" title="1.4 Hive和数据库比较"></a>1.4 Hive和数据库比较</h2><p>由于 Hive 采用了类 SQL 查询语言 <code>HQL(Hive Query Language)</code>，因此很容易将 Hive 理解为数据库。其实从结构上来看，Hive 和数据库除了拥有类似的查询语言，再无类似之处。本文将从多个方面来阐述 Hive 和数据库的差异。数据库可以用在 Online 的应用中，但是Hive 是为数据仓库而设计的，清楚这一点，有助于从应用角度理解 Hive 的特性。</p>
<hr>
<h3 id="1-4-1-查询语言"><a href="#1-4-1-查询语言" class="headerlink" title="1.4.1 查询语言"></a>1.4.1 查询语言</h3><p>由于 SQL 被广泛的应用在数据仓库中，因此，专门针对 Hive 的特性设计了类 SQL 的查询语言 HQL。熟悉 SQL 开发的开发者可以很方便的使用 Hive 进行开发。</p>
<h3 id="1-4-2-数据存储位置"><a href="#1-4-2-数据存储位置" class="headerlink" title="1.4.2 数据存储位置"></a>1.4.2 数据存储位置</h3><p>Hive 是建立在 Hadoop 之上的，所有 Hive 的数据都是存储在 HDFS 中的。而数据库则可以将数据保存在块设备或者本地文件系统中。</p>
<h3 id="1-4-3-数据更新"><a href="#1-4-3-数据更新" class="headerlink" title="1.4.3 数据更新"></a>1.4.3 数据更新</h3><p>由于 Hive 是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，Hive 中不建议对数据的改写，所有的数据都是在加载的时候确定好的。而数据库中的数据通常是需要经常进行修改的，因此会经常使用 <code>INSERT INTO … VALUES</code> 添加数据，使用 <code>UPDATE … SET</code> 修改数据。</p>
<h3 id="1-4-4-索引"><a href="#1-4-4-索引" class="headerlink" title="1.4.4 索引"></a>1.4.4 索引</h3><p>Hive 在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些 key 建立索引。Hive 要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。</p>
<p>由于 MapReduce 的引入， Hive 可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive 仍然可以体现出优势。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了 Hive 不适合在线数据查询。</p>
<h3 id="1-4-5-执行"><a href="#1-4-5-执行" class="headerlink" title="1.4.5 执行"></a>1.4.5 执行</h3><p>Hive 中的查询操作默认是通过 Hadoop 提供的 MapReduce 计算框架来实现的。而数据库通常有自己的执行引擎。</p>
<h3 id="1-4-6-执行延迟"><a href="#1-4-6-执行延迟" class="headerlink" title="1.4.6 执行延迟"></a>1.4.6 执行延迟</h3><p>Hive 在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。</p>
<p>另外一个导致 Hive 执行延迟高的因素是 MapReduce 框架。由于 MapReduce 本身具有较高的延迟，因此在利用 MapReduce 执行 Hive 查询时，也会有较高的延迟。</p>
<p>相对的，数据库的执行延迟较低。当然这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力的时候，Hive 的并行计算显然能体现出优势。</p>
<h3 id="1-4-7-可扩展性"><a href="#1-4-7-可扩展性" class="headerlink" title="1.4.7 可扩展性"></a>1.4.7 可扩展性</h3><p>由于 Hive 是建立在 Hadoop 之上的，因此 Hive 的可扩展性是和 Hadoop 的可扩展性是一致的（世界上最大的 Hadoop 集群在 Yahoo，2009 年的规模在 4000 台节点左右）。而数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库 Oracle 在理论上的扩展能力也只有 100 台左右。</p>
<h3 id="1-4-8-数据规模"><a href="#1-4-8-数据规模" class="headerlink" title="1.4.8 数据规模"></a>1.4.8 数据规模</h3><p>由于 Hive 建立在集群上并可以利用 MapReduce 进行并行计算，因此可以支持很大规模的数据；</p>
<p>对应的，数据库可以支持的数据规模较小。</p>
<hr>
<h1 id="第2章-Hive安装"><a href="#第2章-Hive安装" class="headerlink" title="第2章 Hive安装"></a>第2章 Hive安装</h1><ul>
<li>  <a target="_blank" rel="noopener" href="https://lvnengdong.github.io/2021/12/17/Hive%E5%AE%89%E8%A3%85/">Hive安装</a></li>
</ul>
<hr>
<h1 id="第3章-Hive数据类型"><a href="#第3章-Hive数据类型" class="headerlink" title="第3章 Hive数据类型"></a>第3章 Hive数据类型</h1><p>Hive 是用 Java 语言实现的，所以 Hive 中的所有数据类型底层还是使用的 Java 数据类型。</p>
<h2 id="3-1-基本数据类型"><a href="#3-1-基本数据类型" class="headerlink" title="3.1 基本数据类型"></a>3.1 基本数据类型</h2><table>
<thead>
<tr>
<th>Hive数据类型</th>
<th>Java数据类型</th>
<th>长度</th>
</tr>
</thead>
<tbody><tr>
<td><code>TINYINT</code></td>
<td><code>byte</code></td>
<td><code>1byte</code></td>
</tr>
<tr>
<td><code>SMALLINT</code></td>
<td><code>short</code></td>
<td><code>2byte</code></td>
</tr>
<tr>
<td><code>INT</code></td>
<td><code>int</code></td>
<td><code>4byte</code></td>
</tr>
<tr>
<td><code>BIGINT</code></td>
<td><code>long</code></td>
<td><code>8byte</code></td>
</tr>
<tr>
<td><code>BOOLEAN</code></td>
<td><code>boolean</code></td>
<td></td>
</tr>
<tr>
<td><code>FLOAT</code></td>
<td><code>float</code></td>
<td>单精度浮点数</td>
</tr>
<tr>
<td><code>DOUBLE</code></td>
<td><code>double</code></td>
<td>双精度浮点数</td>
</tr>
<tr>
<td><code>STRING</code></td>
<td><code>string</code></td>
<td></td>
</tr>
<tr>
<td><code>TIMESTAMP</code></td>
<td></td>
<td>时间类型</td>
</tr>
<tr>
<td><code>BINARY</code></td>
<td></td>
<td>字节数组</td>
</tr>
</tbody></table>
<p>Hive 的 String 类型相当于数据库的 varchar 类型，该类型是一个可变的字符串，不过它不能声明其中最多能存储多少个字符，理论上它可以存储 2GB 的字符数。</p>
<hr>
<h2 id="3-2-集合数据类型"><a href="#3-2-集合数据类型" class="headerlink" title="3.2 集合数据类型"></a>3.2 集合数据类型</h2><table>
<thead>
<tr>
<th>数据类型</th>
<th>描述</th>
<th>语法示例</th>
</tr>
</thead>
<tbody><tr>
<td><strong>STRUCT</strong></td>
<td>和 C 语言中的 <code>struct</code> 类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是 <code>STRUCT&#123;first STRING, last STRING&#125;</code>，那么第 1 个元素可以通过 <code>字段.first</code> 来引用。</td>
<td><code>struct()</code></td>
</tr>
<tr>
<td><code>MAP</code></td>
<td>MAP 是一组键值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是 MAP，其中键值对是 <code>’first’-&gt;’John’</code> 和 <code>’last’-&gt;’Doe’</code>，那么可以通过 <code>字段名[‘last’]</code> 获取最后一个元素</td>
<td><code>map()</code></td>
</tr>
<tr>
<td><code>ARRAY</code></td>
<td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为 <code>[‘John’,  ‘Doe’]</code>，那么第 2 个元素可以通过 <code>数组名[1]</code> 进行引用。</td>
<td><code>Array()</code></td>
</tr>
</tbody></table>
<p>Hive 有三种复杂数据类型 <code>ARRAY</code>、<code>MAP</code> 和 <code>STRUCT</code>。<code>ARRAY</code> 和 <code>MAP</code> 与 Java 中的 <code>Array</code> 和 <code>Map</code> 类似，而 <code>STRUCT</code> 与 C 语言中的<code>Struct</code> 类似，它封装了一个命名字段集合，复杂数据类型允许任意层次的嵌套。</p>
<h3 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h3><ol>
<li><p>假设某表有如下一行，我们用 JSON 格式来表示其数据结构。在 <code>Hive</code> 下访问的格式为：</p>
 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;songsong&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;friends&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;bingbing&quot;</span> <span class="punctuation">,</span> <span class="string">&quot;lili&quot;</span><span class="punctuation">]</span> <span class="punctuation">,</span>       <span class="comment">//列表Array, </span></span><br><span class="line">    <span class="attr">&quot;children&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span>                      <span class="comment">//键值Map,</span></span><br><span class="line">        <span class="attr">&quot;xiao song&quot;</span><span class="punctuation">:</span> <span class="number">18</span> <span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;xiaoxiao song&quot;</span><span class="punctuation">:</span> <span class="number">19</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;address&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span>                      <span class="comment">//结构Struct,</span></span><br><span class="line">        <span class="attr">&quot;street&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hui long guan&quot;</span> <span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;city&quot;</span><span class="punctuation">:</span> <span class="string">&quot;beijing&quot;</span> </span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

</li>
<li><p>基于上述数据结构，我们在 Hive 里创建对应的表，并导入数据。</p>
<ul>
<li>  创建本地测试文件 <code>test.txt</code></li>
</ul>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijing</span><br><span class="line">yangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing</span><br></pre></td></tr></table></figure>

<ul>
<li>  注意：<code>MAP</code>，<code>STRUCT</code> 和 <code>ARRAY</code> 里的元素间的分隔符都可以用同一个字符表示，这里用 <code>_</code>。</li>
</ul>
</li>
<li><p>  <code>Hive</code> 上创建测试表 <code>test</code></p>
</li>
</ol>
<pre><code><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> test(</span><br><span class="line">    name string,</span><br><span class="line">    friends <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>,</span><br><span class="line">    children map<span class="operator">&lt;</span>string, <span class="type">int</span><span class="operator">&gt;</span>,</span><br><span class="line">    address struct<span class="operator">&lt;</span>street:string, city:string<span class="operator">&gt;</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">collection items terminated <span class="keyword">by</span> <span class="string">&#x27;_&#x27;</span></span><br><span class="line">map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span></span><br><span class="line">lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--------------</span></span><br><span class="line">字段解释：</span><br><span class="line"></span><br><span class="line">    <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> <span class="comment">-- 列分隔符</span></span><br><span class="line">    collection items terminated <span class="keyword">by</span> <span class="string">&#x27;_&#x27;</span>     <span class="comment">--MAP STRUCT 和 ARRAY 的分隔符(数据分割符号)</span></span><br><span class="line">    map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span>               <span class="comment">-- MAP中的key与value的分隔符</span></span><br><span class="line">    lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>;                  <span class="comment">-- 行分隔符</span></span><br><span class="line"><span class="comment">--------------</span></span><br></pre></td></tr></table></figure>
</code></pre>
<ol start="4">
<li><p>导入文本数据到测试表</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/home/lvnengdong/mytmp/test.txt&#x27; into table test;</span><br></pre></td></tr></table></figure></li>
<li><p>访问三种集合列里的数据，以下分别是 <code>ARRAY</code>，<code>MAP</code>，<code>STRUCT</code> 的访问方式</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	select friends[1],children[&#x27;xiao song&#x27;],address.city </span><br><span class="line">	from test</span><br><span class="line">	where name=&quot;songsong&quot;;</span><br><span class="line"></span><br><span class="line">OK</span><br><span class="line">_c0     _c1     city</span><br><span class="line">lili    18      beijing</span><br><span class="line">Time taken: 0.076 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h2 id="3-3-类型转化"><a href="#3-3-类型转化" class="headerlink" title="3.3 类型转化"></a>3.3 类型转化</h2><p><code>Hive</code> 的原子数据类型是可以进行隐式转换的，类似于 Java 的类型转换，例如某表达式使用 <code>INT</code> 类型，<code>TINYINT</code> 会自动转换为 <code>INT</code> 类型，但是 <code>Hive</code> 不会进行反向转化，例如，某表达式使用 <code>TINYINT</code> 类型，<code>INT</code> 不会自动转换为 <code>TINYINT</code> 类型，它会返回错误，除非使用 <code>CAST</code> 操作。</p>
<p><strong>一、隐式类型转换规则如下：</strong></p>
<ol>
<li> 任何整数类型都可以隐式地转换为一个范围更广的类型，如 <code>TINYINT</code> 可以转换成 <code>INT</code>，<code>INT</code> 可以转换成 <code>BIGINT</code>。</li>
<li> <code>所有整数类型</code>、<code>FLOAT</code> 和 <code>STRING</code> 类型都可以隐式地转换成 <code>DOUBLE</code>。</li>
<li> <code>TINYINT</code>、<code>SMALLINT</code>、<code>INT</code> 都可以转换为 <code>FLOAT</code>。</li>
<li> <code>BOOLEAN</code> 类型<strong>不可以</strong>转换为任何其它的类型。</li>
</ol>
<p><strong>二、可以使用 <code>CAST</code> 操作显式进行数据类型转换</strong></p>
<p>例如 <code>CAST(&#39;1&#39; AS INT)</code> 将把 <code>字符串&#39;1&#39;</code> 转换成 <code>整数1</code>；如果强制类型转换失败，如执行 <code>CAST(&#39;X&#39; AS INT)</code>，表达式返回空值 <code>NULL</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select cast(&quot;1&quot; AS int);</span><br></pre></td></tr></table></figure>



<hr>
<h1 id="第4章-DDL"><a href="#第4章-DDL" class="headerlink" title="第4章 DDL"></a>第4章 DDL</h1><blockquote>
<p>  <strong>DDL；Data Definition Language；数据定义语言</strong></p>
</blockquote>
<h2 id="4-1-库操作"><a href="#4-1-库操作" class="headerlink" title="4.1 库操作"></a>4.1 库操作</h2><h3 id="4-1-1-增：创建数据库"><a href="#4-1-1-增：创建数据库" class="headerlink" title="4.1.1 增：创建数据库"></a>4.1.1 增：创建数据库</h3><p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE [REMOTE] (DATABASE|SCHEMA) [IF NOT EXISTS] database_name		# DATABASE 和 SCHEMA 都表示创建数据库，DATABASE 在新版本中使用，SCHEMA 在老版本中使用</span><br><span class="line">  [COMMENT database_comment]	# 关于数据库的注释</span><br><span class="line">  [LOCATION hdfs_path]	# 数据库在 HDFS 上的路径</span><br><span class="line">  [MANAGEDLOCATION hdfs_path]</span><br><span class="line">  [WITH DBPROPERTIES (property_name=property_value, ...)];	# 库的 dbproperties 属性</span><br></pre></td></tr></table></figure>



<p><strong>Demo：</strong></p>
<ol>
<li><p>使用默认配置创建数据库。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create database if not exists db_hive;</span><br></pre></td></tr></table></figure>

<ul>
<li>  数据库在 HDFS 上的默认存储路径是 <code>/user/hive/warehouse/*.db</code></li>
</ul>
</li>
<li><p>创建数据库时手动指定数据库在 HDFS 上的存储路径。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">create database db_hive2 \</span><br><span class="line">location &#x27;/custom_hive.db&#x27;;</span><br></pre></td></tr></table></figure>

<p> <img src="Hive/image-20211219121900037.png" alt="image-20211219121900037"></p>
</li>
</ol>
<hr>
<h3 id="4-1-2-删：删除数据库"><a href="#4-1-2-删：删除数据库" class="headerlink" title="4.1.2 删：删除数据库"></a>4.1.2 删：删除数据库</h3><p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 情况1： </span><br><span class="line">drop database 库名;   # drop 只能删除空数据库</span><br><span class="line"></span><br><span class="line"># 情况2：</span><br><span class="line">drop database db_hive cascade;  # 强制删除，可以删除非空的库</span><br></pre></td></tr></table></figure>



<p><strong>Demo：</strong></p>
<ol>
<li><p>删除空数据库</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; drop database if exists db_hive;</span><br></pre></td></tr></table></figure></li>
<li><p>删除非空数据库。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; drop database db_hive;</span><br><span class="line">FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. InvalidOperationException(message:Database db_hive is not empty. One or more tables exist.)</span><br><span class="line"></span><br><span class="line"># 如果数据库不为空，可以采用 cascade 命令，强制删除数据库</span><br><span class="line">hive&gt; drop database db_hive cascade;</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="4-1-3-改：修改数据库"><a href="#4-1-3-改：修改数据库" class="headerlink" title="4.1.3 改：修改数据库"></a>4.1.3 改：修改数据库</h3><p>Hive 允许修改的数据库的部分元数据信息。可以修改的数据在不同的 Hive 版本中是不一样的。以下是一些常见的允许修改的数据库信息：</p>
<ol>
<li> <code>DBPROPERTIES</code>：数据库描述信息</li>
<li> <code>OWNER</code>：数据库属主</li>
<li> <code>LOCATION</code>：数据库保存的位置</li>
<li> <code>MANAGEDLOCATION</code>：数据库管理位置</li>
</ol>
<p>数据库的其它元数据信息都是不可更改的，包括数据库名等等。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ALTER (DATABASE|SCHEMA) database_name SET DBPROPERTIES (property_name=property_value, ...);   -- (Note: SCHEMA added in Hive 0.14.0)</span><br><span class="line"> </span><br><span class="line">ALTER (DATABASE|SCHEMA) database_name SET OWNER [USER|ROLE] user_or_role;   -- (Note: Hive 0.13.0 and later; SCHEMA added in Hive 0.14.0)</span><br><span class="line">  </span><br><span class="line">ALTER (DATABASE|SCHEMA) database_name SET LOCATION hdfs_path; -- (Note: Hive 2.2.1, 2.4.0 and later)</span><br><span class="line"> </span><br><span class="line">ALTER (DATABASE|SCHEMA) database_name SET MANAGEDLOCATION hdfs_path; -- (Note: Hive 4.0.0 and later)</span><br></pre></td></tr></table></figure>





<p><strong>Demo</strong></p>
<ol>
<li><p>使用 <code>ALTER DATABASE</code> 命令来修改数据库的 <code>DBPROPERTIES</code>信息。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	alter database db_hive set dbproperties(&#x27;createtime&#x27;=&#x27;20170830&#x27;);</span><br><span class="line">	# 新增 &#x27;createtime&#x27;=&#x27;20170830&#x27; 信息。</span><br></pre></td></tr></table></figure></li>
<li><p>在 <code>Hive</code> 中查看修改结果：<code>createtime=20170830</code> 是新增的属性。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc database extended db_hive;</span><br><span class="line">db_name comment location        owner_name      owner_type      parameters</span><br><span class="line">db_hive		hdfs://hadoop102:9000/hive/warehouse/db_hive.db	lvnengdong	USER    &#123;createtime=20170830&#125;</span><br></pre></td></tr></table></figure>

<p> <strong>注意：</strong>在修改 <code>DBPROPERTIES</code> 中的数据时，同名的属性值会覆盖，非同名的属性会新增。</p>
</li>
</ol>
<hr>
<h3 id="4-1-4-查：查询数据库"><a href="#4-1-4-查：查询数据库" class="headerlink" title="4.1.4 查：查询数据库"></a>4.1.4 查：查询数据库</h3><h4 id="1、显示数据库"><a href="#1、显示数据库" class="headerlink" title="1、显示数据库"></a>1、显示数据库</h4><ol>
<li><p>显示当前连接管理的所有数据库</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br></pre></td></tr></table></figure></li>
<li><p>过滤显示查询的数据库</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases like &#x27;db_hive*&#x27;;</span><br><span class="line">OK</span><br><span class="line">db_hive</span><br><span class="line">db_hive_1</span><br></pre></td></tr></table></figure></li>
<li><p>查看某个数据库中有哪些表</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 语法：show tables in database</span><br><span class="line"></span><br><span class="line">hive (default)&gt; show tables in default;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">person</span><br><span class="line">student</span><br><span class="line">test</span><br><span class="line">Time taken: 0.038 seconds, Fetched: 3 row(s)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h4 id="2、查看数据库的描述信息"><a href="#2、查看数据库的描述信息" class="headerlink" title="2、查看数据库的描述信息"></a>2、查看数据库的描述信息</h4><ol>
<li><p>查看数据库的描述信息</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;  desc database db_hive;</span><br><span class="line">OK</span><br><span class="line">db_name	comment	location	owner_name	owner_type	parameters</span><br><span class="line">db_hive		hdfs://hadoop102:9000/hive/warehouse/db_hive.db	lvnengdong	USER	</span><br><span class="line">Time taken: 0.026 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>

</li>
<li><p>显示数据库详细信息，<code>extended</code></p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    hive (default)&gt; desc database extended db_hive;</span><br><span class="line">    OK</span><br><span class="line">    db_name	comment	location	owner_name	owner_type	parameters</span><br><span class="line">    db_hive		hdfs://hadoop102:9000/hive/warehouse/db_hive.db	lvnengdong	USER	</span><br><span class="line">Time taken: 0.019 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h4 id="3、切换数据库上下文"><a href="#3、切换数据库上下文" class="headerlink" title="3、切换数据库上下文"></a>3、切换数据库上下文</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; use db_hive;</span><br></pre></td></tr></table></figure>





<hr>
<h2 id="4-2-表操作"><a href="#4-2-表操作" class="headerlink" title="4.2 表操作"></a>4.2 表操作</h2><h3 id="4-2-1-增：创建表"><a href="#4-2-1-增：创建表" class="headerlink" title="4.2.1 增：创建表"></a>4.2.1 增：创建表</h3><p><strong>理论知识：</strong></p>
<p>Hive 中元数据和业务数据是分开存储的，元数据存储在 MySQL 中，业务数据存储在 HDFS 上。</p>
<p>所以在执行<strong>建表</strong>语句时，</p>
<ol>
<li> Hive 会在 HDFS 上生成存储业务数据的目录，业务数据会以文件的形式存储在该目录下。</li>
<li> 同时 Hive 还会向 MySQL 的 metastore 数据库中插入表的元数据信息。</li>
</ol>
<p>在执行<strong>删除表</strong>的语句时：</p>
<ul>
<li>对于<strong>内部表</strong>，将会删除两个地方的数据。<ol>
<li> MySQL 的 metastore 数据库中的元数据信息；</li>
<li> HDFS 中对应目录下的业务数据文件。</li>
</ol>
</li>
<li>  对于<strong>外部表</strong>，只删除 MySQL 的 metastore 数据库中的元数据信息，而不会删除 HDFS 中的业务数据。</li>
</ul>
<p><strong>建表语法</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name </span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)] 	# 表中的字段信息（包括字段的注释）</span><br><span class="line">[COMMENT table_comment] # 表的注释信息</span><br><span class="line">[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] </span><br><span class="line">[CLUSTERED BY (col_name, col_name, ...) 	# 分桶表</span><br><span class="line">[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] # 分桶之后对桶中的数据排序</span><br><span class="line">[ROW FORMAT row_format] # 表中每行数据的格式</span><br><span class="line">[STORED AS file_format]	# 表中的数据要以哪种格式来存储（如：textfile/sequencefile 等，默认为textfile）</span><br><span class="line">[LOCATION hdfs_path]	# 表在 HDFS 上的位置</span><br></pre></td></tr></table></figure>



<p><strong>字段解释说明（部分）：</strong></p>
<ol>
<li><p><strong>EXTERNAL</strong>：声明要创建一个外部表。需要配合 <strong>LOCATION</strong> 共同使用，LOCATION 关键字的作用是指定保存业务数据的文件的存储路径。</p>
<blockquote>
<p>  <strong>外部表 vs. 内部表</strong></p>
<ol>
<li>建表时，如果不使用关键字 EXTERNAL，默认创建的表就是一个 MANAGED_TABLE（内部表/管理表）；如果建表时显式地使用了 EXTERNAL 关键字，那么创建的表就是一个外部表。</li>
<li>外部表和内部表的区别是：<ul>
<li>  内部表在执行删除操作时，会将表的元数据（schema）信息和表中的记录数据一起删除。</li>
<li>  外部表在执行删除操作时，只删除表的元数据（schema）信息。</li>
</ul>
</li>
<li>Hive 在创建内部表时，会将数据<strong>拷贝</strong>到 Location 关键字指向的路径。若创建外部表，则仅记录业务数据文件所在的路径，而不对数据文件做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</li>
</ol>
</blockquote>
</li>
<li><p> <strong>COMMENT</strong>：注释。</p>
</li>
<li><p> <strong>PARTITIONED BY</strong>：创建分区表</p>
</li>
<li><p> <strong>CLUSTERED BY</strong>：创建分桶表</p>
</li>
<li><p> <strong>SORTED BY</strong>：排序。</p>
</li>
<li><p><strong>ROW FORMAT</strong>：表中每行数据的格式</p>
<ul>
<li>  SerDe 是 Serialize/Deserilize 的简称，目的是用于序列化和反序列化。</li>
<li>  用户在建表的时候可以自定义 SerDe 或者使用默认的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用默认的 SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive 通过 SerDe 确定表的具体的列的数据。</li>
</ul>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DELIMITED </span><br><span class="line">[FIELDS TERMINATED BY char] </span><br><span class="line">[COLLECTION ITEMS TERMINATED BY char]</span><br><span class="line">[MAP KEYS TERMINATED BY char] </span><br><span class="line">[LINES TERMINATED BY char] </span><br><span class="line"> | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]</span><br></pre></td></tr></table></figure>

</li>
<li><p><strong>STORED AS</strong>：指定表中的数据以什么样的文件类型类型存储。常用的文件类型有：</p>
<ul>
<li>  SEQUENCEFILE（二进制序列文件）</li>
<li>  TEXTFILE（文本）</li>
<li>  RCFILE（列式存储格式文件）</li>
</ul>
<p> 如果文件数据是纯文本，可以使用 <code>STORED AS TEXTFILE</code>。如果数据需要压缩，使用 <code>STORED AS SEQUENCEFILE</code>。</p>
</li>
<li><p> <strong>LOCATION</strong>：用于指定当前表的业务数据文件在 HDFS 上的存储位置。</p>
</li>
<li><p> <strong>LIKE</strong>：允许用户复制现有的表结构，但不复制表数据。</p>
</li>
</ol>
<hr>
<h4 id="1-内部表（管理表）"><a href="#1-内部表（管理表）" class="headerlink" title="1 内部表（管理表）"></a>1 内部表（管理表）</h4><p><strong>理论</strong></p>
<p>Hive 默认创建的表都是<strong>管理表（内部表）</strong>，创建外部表需要显示使用 <strong>EXTERNAL</strong> 关键字。</p>
<p>对于内部表，Hive 控制着业务数据的生命周期。Hive 默认情况下会将表的业务数据文件存储在由配置属性 <code>hive.metastore.warehouse.dir</code> 所定义的目录的下，例如 <code>/user/hive/warehouse</code>。当我们删除一个内部表时，Hive 不仅会删除 MySQL 中 metastore 数据库中表的元数据信息，同时也会删除这个目录下的业务数据文件。</p>
<p>内部表不适合和其他工具共享数据。</p>
<p><strong>Demo</strong></p>
<ol>
<li><p>普通创建表（默认创建的就是一个内部表）</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student2</span><br><span class="line">	(  </span><br><span class="line">        id int, </span><br><span class="line">        name string  </span><br><span class="line">    )</span><br><span class="line">    row format delimited fields terminated by &#x27;\t&#x27;  </span><br><span class="line">    stored as textfile  </span><br><span class="line">    location &#x27;/user/hive/warehouse/student2&#x27;;    </span><br></pre></td></tr></table></figure>

</li>
<li><p>根据查询结果创建表，同时查询的结果集会添加到新创建的表中</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student3 </span><br><span class="line">as </span><br><span class="line">select id, name from student;  </span><br></pre></td></tr></table></figure>

</li>
<li><p>根据已经存在的表结构创建表</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student4 </span><br><span class="line">like student;</span><br></pre></td></tr></table></figure>

</li>
<li><p>查询表的描述信息</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student2;</span><br><span class="line">Table Type:       MANAGED_TABLE </span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h4 id="2-外部表"><a href="#2-外部表" class="headerlink" title="2 外部表"></a>2 外部表</h4><p><strong>理论</strong></p>
<p>对于外部表，Hive 并非完全拥有表的业务数据，所以在删除外部表时并不会删除业务数据，而只是删除描述表的元数据信息。</p>
<p>一般情况下，MySQL 数据库中的业务数据会以文件的格式上传到 HDFS 中的某个目录下。对于内部表而言，会将业务数据拷贝一份到 Hive 指定的目录下，所以可以说 Hive 拥有这份业务数据文件的所有权限，对该文件执行写/删除操作不会影响 HDFS 中最初的源文件。而对于外部表而言，Hive 直接引用 HDFS 上源文件的地址作为 Hive 读取业务数据的来源，所以 Hive 不能轻易去修改/删除这个源文件，因为该源文件很有可能还被其它程序使用。</p>
<p><strong>内部表和外部表的使用场景：</strong></p>
<p>每天将收集到的网站日志定期流入 HDFS 文本文件。在外部表（原始日志表）的基础上做大量的统计分析，用到的<strong>中间表、结果表</strong>使用内部表存储，数据通过 <code>SELECT+INSERT</code> 进入内部表。</p>
<p><strong>Demo：</strong></p>
<p>分别创建部门和员工外部表，并向表中导入数据。</p>
<ol>
<li><p>原始数据：</p>
<p> <code>/opt/module/datas/dept.txt</code></p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10	ACCOUNTING	1700</span><br><span class="line">20	RESEARCH	1800</span><br><span class="line">30	SALES	1900</span><br><span class="line">40	OPERATIONS	1700</span><br></pre></td></tr></table></figure>

<p> <code>/opt/module/datas/emp.txt</code></p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">7369	SMITH	CLERK	7902	1980-12-17	800.00		20</span><br><span class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.00	300.00	30</span><br><span class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.00	500.00	30</span><br><span class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.00		20</span><br><span class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.00	1400.00	30</span><br><span class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.00		30</span><br><span class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.00		10</span><br><span class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.00		20</span><br><span class="line">7839	KING	PRESIDENT		1981-11-17	5000.00		10</span><br><span class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.00	0.00	30</span><br><span class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.00		20</span><br><span class="line">7900	JAMES	CLERK	7698	1981-12-3	950.00		30</span><br><span class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.00		20</span><br><span class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.00		10</span><br></pre></td></tr></table></figure>

</li>
<li><p>建表语句</p>
<ul>
<li><p>创建部门表</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists default.dept</span><br><span class="line">	(  </span><br><span class="line">        deptno  int,  </span><br><span class="line">        dname  string,  </span><br><span class="line">        loc  int  </span><br><span class="line">    )  </span><br><span class="line">    row  format delimited fields terminated by &#x27;\t&#x27;;  </span><br></pre></td></tr></table></figure>

</li>
<li><p>创建员工表</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists default.emp</span><br><span class="line">	(  </span><br><span class="line">        empno  int,  </span><br><span class="line">        ename  string,  </span><br><span class="line">        job  string,  </span><br><span class="line">        mgr  int,  </span><br><span class="line">        hiredate  string,   </span><br><span class="line">        sal  double,   </span><br><span class="line">        comm  double,  </span><br><span class="line">        deptno  int</span><br><span class="line">    )  </span><br><span class="line">    row  format delimited fields terminated by &#x27;\t&#x27;;  </span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
<li><p>查看创建的表</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; show tables;</span><br><span class="line">OK</span><br><span class="line">tab_name</span><br><span class="line">dept</span><br><span class="line">emp</span><br></pre></td></tr></table></figure>

</li>
<li><p>向外部表中导入数据</p>
<ul>
<li>  导入数据</li>
</ul>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table default.dept;</span><br><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/emp.txt&#x27; into table default.emp;</span><br></pre></td></tr></table></figure>

<ul>
<li>  查询结果</li>
</ul>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line">hive (default)&gt; select * from dept;</span><br></pre></td></tr></table></figure>

</li>
<li><p>查看表格式化数据</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted dept;</span><br><span class="line">Table Type:       EXTERNAL_TABLE</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h4 id="3-内部表-lt-gt-外部表"><a href="#3-内部表-lt-gt-外部表" class="headerlink" title="3 内部表 &lt;=&gt; 外部表"></a>3 内部表 &lt;=&gt; 外部表</h4><p>想要实现内部表与外部表之间的相互转换，只需要切换表的 <code>Table Type: MANAGED_TABLE | EXTERNAL_TABLE</code> 属性就可以了。具体的实现方式如下：</p>
<ol>
<li><p>查询表的类型</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student2;</span><br><span class="line">Table Type:             MANAGED_TABLE	# 管理表，也就是内部表</span><br></pre></td></tr></table></figure></li>
<li><p>修改内部表 <code>student2</code> 为外部表</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table student2 set tblproperties(&#x27;EXTERNAL&#x27;=&#x27;TRUE&#x27;);	# 打开外部表的开关</span><br></pre></td></tr></table></figure></li>
<li><p>查询表的类型</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student2;</span><br><span class="line">Table Type:             EXTERNAL_TABLE	# 表的类型变成了外部表</span><br></pre></td></tr></table></figure></li>
<li><p>修改外部表 <code>student2</code> 为内部表</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table student2 set tblproperties(&#x27;EXTERNAL&#x27;=&#x27;FALSE&#x27;);	# 关闭外部表的开关，就会自动变为内部表了</span><br></pre></td></tr></table></figure></li>
<li><p>查询表的类型</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student2;</span><br><span class="line">Table Type:             MANAGED_TABLE</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>注意：</strong>在 Hive 中查询语句不区分大小写，但是在参数中严格区分大小写。所以 <code>(&#39;EXTERNAL&#39;=&#39;TRUE&#39;)</code> 和 <code>(&#39;EXTERNAL&#39;=&#39;FALSE&#39;)</code> 为固定写法，不能小写。</p>
<hr>
<h3 id="4-2-2-删：删除表"><a href="#4-2-2-删：删除表" class="headerlink" title="4.2.2 删：删除表"></a>4.2.2 删：删除表</h3><h4 id="彻底删除表"><a href="#彻底删除表" class="headerlink" title="彻底删除表"></a>彻底删除表</h4><p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop table 表名;</span><br></pre></td></tr></table></figure>

<p><strong>Demo：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; drop table dept_partition;</span><br></pre></td></tr></table></figure>





<h4 id="清空表中数据，但保留表结构"><a href="#清空表中数据，但保留表结构" class="headerlink" title="清空表中数据，但保留表结构"></a>清空表中数据，但保留表结构</h4><p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">truncate table 表名;</span><br></pre></td></tr></table></figure>

<p><strong>Demo：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; truncate table dept_partition;</span><br></pre></td></tr></table></figure>

<p><strong>Tip：</strong>只能清空内部表的业务的数据，无法清空外部表的业务数据，因为外部表的业务数据不属于 Hive 管理。</p>
<hr>
<h3 id="4-2-3-改"><a href="#4-2-3-改" class="headerlink" title="4.2.3 改"></a>4.2.3 改</h3><h4 id="4-2-3-1-重命名表"><a href="#4-2-3-1-重命名表" class="headerlink" title="4.2.3.1 重命名表"></a>4.2.3.1 重命名表</h4><p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name RENAME TO new_table_name</span><br></pre></td></tr></table></figure>

<p><strong>Demo：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition2 rename to dept_partition3;</span><br></pre></td></tr></table></figure>



<hr>
<h4 id="4-2-3-2-增加、修改和删除表分区"><a href="#4-2-3-2-增加、修改和删除表分区" class="headerlink" title="4.2.3.2 增加、修改和删除表分区"></a>4.2.3.2 增加、修改和删除表分区</h4><p>详见 4.6.1 分区表基本操作。</p>
<hr>
<h4 id="4-2-3-3-增加-修改-替换列信息"><a href="#4-2-3-3-增加-修改-替换列信息" class="headerlink" title="4.2.3.3 增加/修改/替换列信息"></a>4.2.3.3 增加/修改/替换列信息</h4><p><strong>语法</strong></p>
<ol>
<li><p>更新列</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name </span><br><span class="line">CHANGE [COLUMN] col_old_name col_new_name column_type </span><br><span class="line">[COMMENT col_comment] </span><br><span class="line">[FIRST|AFTER column_name]	# 调整列的顺序（FIRST表示调整到第一列）</span><br></pre></td></tr></table></figure></li>
<li><p>增加和重设列</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name</span><br><span class="line">&#123;ADD | REPLACE&#125; COLUMNS (col_name data_type [COMMENT col_comment], ...) </span><br><span class="line"></span><br><span class="line"># 注：ADD 代表新增一字段，字段位置在所有列后面(partition列前)，</span><br><span class="line"># REPLACE 则是表示重设表中所有字段。</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>Demo：</strong></p>
<ol>
<li><p>查询表结构</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc dept_partition;</span><br></pre></td></tr></table></figure></li>
<li><p>添加列</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition add columns(deptdesc string);</span><br></pre></td></tr></table></figure></li>
<li><p>更新列</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition change column deptdesc desc int;</span><br></pre></td></tr></table></figure></li>
<li><p>替换列</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	alter table dept_partition </span><br><span class="line">	replace columns(</span><br><span class="line">        deptno string, </span><br><span class="line">        dname string, </span><br><span class="line">        loc string</span><br><span class="line">    );</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="4-2-4-查"><a href="#4-2-4-查" class="headerlink" title="4.2.4 查"></a>4.2.4 查</h3><p><strong>一、查看表的描述（概要信息）</strong></p>
<ul>
<li><p><strong>语法：</strong> </p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc 表名;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Demo</strong></p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 查看 student 表的描述信息</span><br><span class="line">hive (default)&gt; desc student;</span><br><span class="line">OK</span><br><span class="line">col_name	data_type	comment</span><br><span class="line">id                  	int                 	                    </span><br><span class="line">name                	string              	                    </span><br><span class="line">Time taken: 0.133 seconds, Fetched: 2 row(s)</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>二、查看表的描述（详细信息）</strong></p>
<ul>
<li><p>语法：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc extended 表名;</span><br></pre></td></tr></table></figure></li>
<li><p>Demo：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc extended student;</span><br><span class="line">OK</span><br><span class="line">col_name	data_type	comment</span><br><span class="line">id                  	int                 	                    </span><br><span class="line">name                	string              	                    </span><br><span class="line">	 	 </span><br><span class="line">Detailed Table Information	Table(tableName:student, dbName:default, owner:lvnengdong, createTime:1639841380, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:name, type:string, comment:null)], location:hdfs://hadoop102:9000/user/hive/warehouse/student, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:&#123;serialization.format=1&#125;), bucketCols:[], sortCols:[], parameters:&#123;&#125;, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:&#123;&#125;), storedAsSubDirectories:false), partitionKeys:[], parameters:&#123;totalSize=12, numRows=-1, rawDataSize=-1, COLUMN_STATS_ACCURATE=false, numFiles=1, transient_lastDdlTime=1639841380&#125;, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)	</span><br><span class="line">Time taken: 0.096 seconds, Fetched: 4 row(s)</span><br></pre></td></tr></table></figure></li>
<li><p>  可以看到详情信息非常的乱，这时候就可以使用另一条命令以格式化的形式输出表的详情信息</p>
</li>
</ul>
<p><strong>三、查看表详情（以格式化后的形式展示在控制台上）</strong></p>
<ul>
<li><p>语法：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc formatted 表名;</span><br></pre></td></tr></table></figure></li>
<li><p>Demo：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student;</span><br><span class="line">OK</span><br><span class="line">col_name	data_type	comment</span><br><span class="line"># col_name            	data_type           	comment             </span><br><span class="line">	 	 </span><br><span class="line">id                  	int                 	                    </span><br><span class="line">name                	string              	                    </span><br><span class="line">	 	 </span><br><span class="line"># Detailed Table Information	 	 </span><br><span class="line">Database:           	default             	 </span><br><span class="line">Owner:              	lvnengdong          	 </span><br><span class="line">CreateTime:         	Sat Dec 18 23:29:40 CST 2021	 </span><br><span class="line">LastAccessTime:     	UNKNOWN             	 </span><br><span class="line">Protect Mode:       	None                	 </span><br><span class="line">Retention:          	0                   	 </span><br><span class="line">Location:           	hdfs://hadoop102:9000/user/hive/warehouse/student	 </span><br><span class="line">Table Type:         	MANAGED_TABLE       	</span><br><span class="line">Table Parameters:	 	 </span><br><span class="line">	COLUMN_STATS_ACCURATE	false               </span><br><span class="line">	numFiles            	1                   </span><br><span class="line">	numRows             	-1                  </span><br><span class="line">	rawDataSize         	-1                  </span><br><span class="line">	totalSize           	12                  </span><br><span class="line">	transient_lastDdlTime	1639841380          </span><br><span class="line">	 	 </span><br><span class="line"># Storage Information	 	 </span><br><span class="line">SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 </span><br><span class="line">InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 </span><br><span class="line">OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 </span><br><span class="line">Compressed:         	No                  	 </span><br><span class="line">Num Buckets:        	-1                  	 </span><br><span class="line">Bucket Columns:     	[]                  	 </span><br><span class="line">Sort Columns:       	[]                  	 </span><br><span class="line">Storage Desc Params:	 	 </span><br><span class="line">	serialization.format	1                   </span><br><span class="line">Time taken: 0.907 seconds, Fetched: 32 row(s)</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h2 id="4-3-分区表"><a href="#4-3-分区表" class="headerlink" title="4.3 分区表"></a>4.3 分区表</h2><h3 id="4-3-1-是什么？"><a href="#4-3-1-是什么？" class="headerlink" title="4.3.1 是什么？"></a>4.3.1 是什么？</h3><p>Hive 表中的业务数据文件保存在 HDFS 中。<strong>默认情况</strong>下（也就是没有显式指定分区的情况下），每张表映射到 HDFS 中有一个存储目录，业务数据就保存在该目录下。</p>
<p>因为 Hive 表是没有索引的，所以检索表中数据的方式只能是遍历。在某些情况下，我们执行的查询操作并不想要检索整张表，而只想要检索表的一部分数据，为了细化数据的粒度，Hive 引入了<code>分区</code>的概念。<strong>分区就是把整张表的数据根据业务需要分割成多个小的数据集，对应到 HDFS 上就是在表目录下再创建多个子目录（分区目录），将对应的子数据集存储在分区目录中。</strong>在执行查询语句时通过 WHERE 子句中的条件查询指定的分区，提高查询效率。</p>
<p><strong>Tip</strong></p>
<ul>
<li>  只有分区表才有分区目录（子目录）</li>
<li>  分区目录的名称由两部分决定：<code>分区列列名=分区列列值</code></li>
</ul>
<h3 id="4-3-2-分区表语法"><a href="#4-3-2-分区表语法" class="headerlink" title="4.3.2 分区表语法"></a>4.3.2 分区表语法</h3><p><strong>分区表语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] </span><br></pre></td></tr></table></figure>



<p>引入分区表（需要根据日期对日志进行管理）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/user/hive/warehouse/log_partition/20170702/20170702.log</span><br><span class="line">/user/hive/warehouse/log_partition/20170703/20170703.log</span><br><span class="line">/user/hive/warehouse/log_partition/20170704/20170704.log</span><br></pre></td></tr></table></figure>





<h3 id="4-3-3-分区表基本操作"><a href="#4-3-3-分区表基本操作" class="headerlink" title="4.3.3 分区表基本操作"></a>4.3.3 分区表基本操作</h3><h4 id="1、准备数据"><a href="#1、准备数据" class="headerlink" title="1、准备数据"></a>1、准备数据</h4><p>准备数据：<code>/opt/module/datas/dept.txt</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10	ACCOUNTING	1700</span><br><span class="line">20	RESEARCH	1800</span><br><span class="line">30	SALES	1900</span><br><span class="line">40	OPERATIONS	1700</span><br></pre></td></tr></table></figure>

<h4 id="2、创建分区表"><a href="#2、创建分区表" class="headerlink" title="2、创建分区表"></a>2、创建分区表</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	create table dept_partition(</span><br><span class="line">        deptno int, </span><br><span class="line">        dname string, </span><br><span class="line">        loc string</span><br><span class="line">    )</span><br><span class="line">    partitioned by (month string)	# 创建分区表时要额外指定分区信息</span><br><span class="line">    row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>



<h4 id="3、导入数据（失败）"><a href="#3、导入数据（失败）" class="headerlink" title="3、导入数据（失败）"></a>3、导入数据（失败）</h4><p>加载数据到分区表 <code>dept_partition</code> 中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table dept_partition;</span><br><span class="line">FAILED: SemanticException [Error 10062]: Need to specify partition columns because the destination table is partitioned</span><br><span class="line"># 导入数据失败，因为目标表是一个分区表，所以在导入数据时必须数据要导入到哪一个分区目录中</span><br></pre></td></tr></table></figure>

<p>如果当前表是一个分区表，在导入数据时，必须指定向哪个分区导入数据。因为对于分区表来说，在 HDFS 的表目录下还有多个分区目录，对应的数据应该导入到这些分区目录中。</p>
<h4 id="4、增加分区"><a href="#4、增加分区" class="headerlink" title="4、增加分区"></a>4、增加分区</h4><p><strong>增加分区</strong>：目前我们还没有创建分区，所以我们首先要在当前表下创建分区。</p>
<ul>
<li><p>创建单个分区</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># alter table 表名 add partition(分区字段名=分区字段值);</span><br><span class="line">hive (default)&gt; </span><br><span class="line">	hive (default)&gt; alter table dept_partition add partition(month=&#x27;202112&#x27;);</span><br></pre></td></tr></table></figure></li>
<li><p>同时创建多个分区</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	alter table dept_partition </span><br><span class="line">	add partition(month=&#x27;202111&#x27;) partition(month=&#x27;202110&#x27;);</span><br></pre></td></tr></table></figure></li>
</ul>
<h5 id="新增分区（方式一）："><a href="#新增分区（方式一）：" class="headerlink" title="新增分区（方式一）："></a>新增分区（方式一）：</h5><p>在给分区表新增分区时：</p>
<ol>
<li><p>在 HDFS 上会生成分区路径。查看 HDFS 的分区目录结构：</p>
<p> <img src="Hive/image-20211219223705371.png" alt="image-20211219223705371"></p>
</li>
<li><p>在 MySQL 中的 <code>metastore.partitions</code> 表中会生成分区相关的元数据信息</p>
<p> <img src="Hive/image-20211220102736063.png" alt="image-20211220102736063"></p>
<ul>
<li>  <strong>PART_NAME</strong>：保存了分区列的信息；</li>
<li>  <strong>TBL_ID</strong>：指定了分区所在的表的 ID，对应 <code>TBLS</code>表的主键</li>
</ul>
<p> <img src="Hive/image-20211220102924703.png" alt="image-20211220102924703"></p>
</li>
</ol>
<h5 id="增加分区（方式二）"><a href="#增加分区（方式二）" class="headerlink" title="增加分区（方式二）"></a>增加分区（方式二）</h5><p>我们还可以直接使用 <code>load</code> 命令向分区加载数据，如果分区不存在，load 时会自动帮我们生成分区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table dept_partition partition(month=202109);</span><br></pre></td></tr></table></figure>





<h4 id="5、导入数据（成功）"><a href="#5、导入数据（成功）" class="headerlink" title="5、导入数据（成功）"></a>5、导入数据（成功）</h4><p>加载数据到分区表的指定分区中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table dept_partition partition(month=&#x27;202110&#x27;);</span><br><span class="line">Loading data to table default.dept_partition partition (month=202110)</span><br><span class="line">Partition default.dept_partition&#123;month=202110&#125; stats: [numFiles=1, totalSize=65]</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.975 seconds</span><br></pre></td></tr></table></figure>

<ul>
<li>  在 HDFS 上查看上传的数据文件</li>
</ul>
<p><img src="Hive/image-20211220103704244.png" alt="image-20211220103704244"></p>
<h4 id="6、查询分区表"><a href="#6、查询分区表" class="headerlink" title="6、查询分区表"></a>6、查询分区表</h4><ol>
<li><p>将数据导入到指定的分区之后，数据会额外附加上分区列的信息。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition;</span><br><span class="line">OK</span><br><span class="line">dept_partition.deptno	dept_partition.dname	dept_partition.loc	dept_partition.month</span><br><span class="line">NULL	1700	NULL	202110</span><br><span class="line">20	RESEARCH	1800	202110</span><br><span class="line">30	SALES	1900	202110</span><br><span class="line">40	OPERATIONS	1700	202110</span><br><span class="line">Time taken: 0.47 seconds, Fetched: 4 row(s)</span><br><span class="line"></span><br><span class="line"># 分区列 dept_partition.month 的信息在源数据文件中是没有的，是在将数据分区表之后由 Hive 自动生成的</span><br></pre></td></tr></table></figure>

</li>
<li><p>可以通过分区列来对数据进行过滤，指定查找的目录</p>
<ul>
<li><p>单分区查询</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition where month = &quot;202110&quot;;</span><br><span class="line">OK</span><br><span class="line">dept_partition.deptno	dept_partition.dname	dept_partition.loc	dept_partition.month</span><br><span class="line">NULL	1700	NULL	202110</span><br><span class="line">20	RESEARCH	1800	202110</span><br><span class="line">30	SALES	1900	202110</span><br><span class="line">40	OPERATIONS	1700	202110</span><br><span class="line">Time taken: 0.388 seconds, Fetched: 4 row(s)</span><br></pre></td></tr></table></figure></li>
<li><p>多分区联合查询：通过关键字 union 联合查询多个分区</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	select * from dept_partition where month=&#x27;202110&#x27;</span><br><span class="line">	union</span><br><span class="line">	select * from dept_partition where month=&#x27;202111&#x27;</span><br><span class="line">	union</span><br><span class="line">	select * from dept_partition where month=&#x27;202112&#x27;;</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ol>
<h4 id="7、删除分区"><a href="#7、删除分区" class="headerlink" title="7、删除分区"></a>7、删除分区</h4><ul>
<li><p>删除单个分区</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	alter table dept_partition drop partition (month=&#x27;202110&#x27;);</span><br></pre></td></tr></table></figure></li>
<li><p>同时删除多个分区</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	alter table dept_partition </span><br><span class="line">	drop partition (month=&#x27;202110&#x27;), partition (month=&#x27;202111&#x27;);</span><br></pre></td></tr></table></figure></li>
</ul>
<p>在执行删除表操作时，首先会删除 MySQL 数据库中对应的元数据信息；并且如果当前表是内部表，还会删除 HDFS 上对应的数据信息。</p>
<h4 id="8、查看分区表有哪些分区"><a href="#8、查看分区表有哪些分区" class="headerlink" title="8、查看分区表有哪些分区"></a>8、查看分区表有哪些分区</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show partitions dept_partition;</span><br></pre></td></tr></table></figure>



<h4 id="9、查看分区表结构"><a href="#9、查看分区表结构" class="headerlink" title="9、查看分区表结构"></a>9、查看分区表结构</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc formatted dept_partition;</span><br></pre></td></tr></table></figure>







<hr>
<h3 id="4-3-4-多级分区表"><a href="#4-3-4-多级分区表" class="headerlink" title="4.3.4 多级分区表"></a>4.3.4 多级分区表</h3><p><strong>一、创建多级分区表</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	create table dept_partition2</span><br><span class="line">		(           </span><br><span class="line">            deptno int, </span><br><span class="line">            dname string,</span><br><span class="line">            loc string</span><br><span class="line">        )           </span><br><span class="line">        partitioned by (month string, day string)	# 二级分区，先按 month 分区，month 相等时再按 day 分区           </span><br><span class="line">        row format delimited fields terminated by &#x27;\t&#x27;;  </span><br></pre></td></tr></table></figure>



<p><strong>二、正常的加载数据</strong></p>
<ol>
<li><p>加载数据到二级分区表中</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table default.dept_partition2</span><br><span class="line">	partition(month=&#x27;202112&#x27;, day=&#x27;20&#x27;);</span><br></pre></td></tr></table></figure>

<ul>
<li>  对应的目录结构就是三级目录：<strong>表目录/一级分区目录/二级分区目录</strong>，在 HDFS 上的结构如下：</li>
</ul>
<p> <img src="Hive/image-20211220114355694.png" alt="image-20211220114355694"></p>
<ul>
<li>Tip：如果是多级分区表，数据必须位于最内层目录下。</li>
</ul>
</li>
<li><p>查询分区数据</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">              &gt; select * from dept_partition2</span><br><span class="line">              &gt; where month=&#x27;202112&#x27; and day=&#x27;20&#x27;;</span><br><span class="line">OK</span><br><span class="line">dept_partition2.deptno	dept_partition2.dname	dept_partition2.loc	dept_partition2.month	dept_partition2.day</span><br><span class="line">NULL	1700	NULL	202112	20</span><br><span class="line">20	RESEARCH	1800	202112	20</span><br><span class="line">30	SALES	1900	202112	20</span><br><span class="line">40	OPERATIONS	1700	202112	20</span><br><span class="line">Time taken: 0.106 seconds, Fetched: 4 row(s)</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="4-3-5-自动修复分区"><a href="#4-3-5-自动修复分区" class="headerlink" title="4.3.5 自动修复分区"></a>4.3.5 自动修复分区</h3><p>通常情况下，HDFS 上保存的数据是预先采集好的，再由 Hive 对 HDFS 上保存的数据进行分析。所以一般是先有数据后有表，所以 Hive 在建表时首先要读取 HDFS 上的数据，再根据数据建立对应的表。</p>
<p><strong>把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式：</strong></p>
<p><strong>方式一：上传数据后自动修复</strong></p>
<ul>
<li>  上传数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201709/day=12;</span><br><span class="line">hive (default)&gt; </span><br><span class="line">	dfs -put /opt/module/datas/dept.txt  /user/hive/warehouse/dept_partition2/month=201709/day=12;</span><br></pre></td></tr></table></figure>

<ul>
<li>  查询数据（查询不到刚上传的数据）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	select * from dept_partition2 where month=&#x27;201709&#x27; and day=&#x27;12&#x27;;</span><br></pre></td></tr></table></figure>

<ul>
<li>  <strong>执行修复命令</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; </span><br><span class="line">	msck repair table dept_partition2;</span><br></pre></td></tr></table></figure>

<ul>
<li>  再次查询数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	select * from dept_partition2 where month=&#x27;201709&#x27; and day=&#x27;12&#x27;;</span><br></pre></td></tr></table></figure>



<p><strong>方式二：上传数据后添加分区</strong></p>
<ul>
<li>  上传数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201709/day=11;</span><br><span class="line">hive (default)&gt; </span><br><span class="line">	dfs -put /opt/module/datas/dept.txt  /user/hive/warehouse/dept_partition2/month=201709/day=11;</span><br></pre></td></tr></table></figure>

<ul>
<li>  手动添加分区</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	alter table dept_partition2 add partition(month=&#x27;201709&#x27;,day=&#x27;11&#x27;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>  查询数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition2 where month=&#x27;201709&#x27; and day=&#x27;11&#x27;;</span><br></pre></td></tr></table></figure>



<p><strong>方式三：创建分区目录后load数据到指定分区</strong></p>
<ul>
<li>  创建目录</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201709/day=10;</span><br></pre></td></tr></table></figure>

<ul>
<li>  上传数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table dept_partition2 partition(month=&#x27;201709&#x27;,day=&#x27;10&#x27;);</span><br></pre></td></tr></table></figure>

<ul>
<li>  查询数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition2 where month=&#x27;201709&#x27; and day=&#x27;10&#x27;;</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="4-4-分桶表"><a href="#4-4-分桶表" class="headerlink" title="4.4 分桶表"></a>4.4 分桶表</h2><h3 id="4-4-1-理论知识"><a href="#4-4-1-理论知识" class="headerlink" title="4.4.1 理论知识"></a>4.4.1 理论知识</h3><p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    CLUSTERED BY (col_name, col_name, ...) 	# 分桶表	</span><br><span class="line">    [SORTED BY (col_name [ASC|DESC], ...)]  # 分桶之后对桶中的数据排序</span><br><span class="line">    INTO num_buckets BUCKETS</span><br><span class="line">] 	</span><br></pre></td></tr></table></figure>

<ul>
<li>  在创建分区表的时候，需要手动指定<strong>分区列名称</strong>和<strong>分区列类型</strong>；而在创建分桶表的时候，只需要手动指定<strong>分桶列名称</strong>就可以了。</li>
<li>  在创建分区表时，<strong>分区列名称</strong>和<strong>分区列类型</strong>会作为新的属性组追加到表中，而创建分桶表时，则是复用表中已有的字段作为分桶的依据。</li>
</ul>
<p><strong>是什么？</strong></p>
<ul>
<li>  如果在建表时，显式指定了 <code>CLUSTERED BY</code> 属性，那么这张表就称为分桶表。</li>
<li>  分桶就是把表数据分散到多个文件中。比如一张表中有 100W 条数据，存储在一个文件中。假如分成 4 个桶，这 100W 条数据就会分散到 4 个桶中存储，降低了单个文件的负担。</li>
<li>  分桶的意义是为了分散数据。在分桶后，可以结合 Hive 提供的抽样查询，只查询指定桶的数据。</li>
<li>  <strong>分区</strong>是把一张表中的数据分散存储到各个目录下，<strong>分桶</strong>是把一张表中的数据分散存储到各个文件中。</li>
</ul>
<p><strong>单个桶中数据的排序：</strong></p>
<ul>
<li>  在分桶后，可以将每个桶中的数据根据一定的规则进行排序。</li>
<li>  如果需要排序，可以通过 <code>SORTED BY</code> 关键字来显式指定排序的字段和规则。</li>
</ul>
<hr>
<h3 id="4-4-2-案例实操"><a href="#4-4-2-案例实操" class="headerlink" title="4.4.2 案例实操"></a>4.4.2 案例实操</h3><h4 id="1、创建分桶表"><a href="#1、创建分桶表" class="headerlink" title="1、创建分桶表"></a>1、创建分桶表</h4><ol>
<li><p>数据准备：<code>/opt/module/datas/student.txt</code></p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 学号	姓名</span><br><span class="line">1001	ss1</span><br><span class="line">1002	ss2</span><br><span class="line">1003	ss3</span><br><span class="line">1004	ss4</span><br><span class="line">1005	ss5</span><br><span class="line">1006	ss6</span><br><span class="line">1007	ss7</span><br><span class="line">1008	ss8</span><br><span class="line">1009	ss9</span><br><span class="line">1010	ss10</span><br><span class="line">1011	ss11</span><br><span class="line">1012	ss12</span><br><span class="line">1013	ss13</span><br><span class="line">1014	ss14</span><br><span class="line">1015	ss15</span><br><span class="line">1016	ss16</span><br></pre></td></tr></table></figure>

</li>
<li><p>创建分桶表</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">              &gt; create table stu_buck(id int, name string)</span><br><span class="line">              &gt; clustered by(id) into 4 buckets</span><br><span class="line">              &gt; row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看表结构</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted stu_buck;</span><br><span class="line">OK</span><br><span class="line">col_name	data_type	comment</span><br><span class="line"># col_name            	data_type           	comment             </span><br><span class="line">	 	 </span><br><span class="line">id                  	int                 	                    </span><br><span class="line">name                	string              	                    </span><br><span class="line">	 	 </span><br><span class="line"># Detailed Table Information	 	 </span><br><span class="line">Database:           	default             	 </span><br><span class="line">Owner:              	lvnengdong          	 </span><br><span class="line">CreateTime:         	Mon Dec 20 12:17:47 CST 2021	 </span><br><span class="line">LastAccessTime:     	UNKNOWN             	 </span><br><span class="line">Protect Mode:       	None                	 </span><br><span class="line">Retention:          	0                   	 </span><br><span class="line">Location:           	hdfs://hadoop102:9000/hive/warehouse/stu_buck	 </span><br><span class="line">Table Type:         	MANAGED_TABLE       	 </span><br><span class="line">Table Parameters:	 	 </span><br><span class="line">	transient_lastDdlTime	1639973867          </span><br><span class="line">	 	 </span><br><span class="line"># Storage Information	 	 </span><br><span class="line">SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 </span><br><span class="line">InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 </span><br><span class="line">OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 </span><br><span class="line">Compressed:         	No                  	 </span><br><span class="line">Num Buckets:        	4    # 桶数量              	 </span><br><span class="line">Bucket Columns:     	[id]     # 分桶的列名           	 </span><br><span class="line">Sort Columns:       	[]       # 排序字段      	 </span><br><span class="line">Storage Desc Params:	 	 </span><br><span class="line">	field.delim         	\t                  </span><br><span class="line">	serialization.format	\t                  </span><br><span class="line">Time taken: 0.089 seconds, Fetched: 28 row(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>导入数据到分桶表中</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/student.txt&#x27; into table  stu_buck;</span><br></pre></td></tr></table></figure></li>
<li><p>查看创建的分桶表中是否分成4个桶。</p>
<p> <img src="Hive/image-20211220122413669.png" alt="image-20211220122413669"></p>
<blockquote>
<p>  发现并没有分成 4 个桶。是什么原因呢？</p>
<ul>
<li>  向分桶表中导入数据时，必须运行 MapReduce 程序，才能实现分桶操作。</li>
<li>  load 方式只是简单的上传数据，类似于 put 操作，无法满足分桶表的导入数据。必须采用 insert into 方式导入数据才能实现分桶</li>
</ul>
</blockquote>
</li>
</ol>
<h4 id="2、创建分桶表时，数据通过子查询的方式导入"><a href="#2、创建分桶表时，数据通过子查询的方式导入" class="headerlink" title="2、创建分桶表时，数据通过子查询的方式导入"></a>2、创建分桶表时，数据通过子查询的方式导入</h4><ol>
<li><p>先建一个普通的 <code>stu</code> 表</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table stu(id int, name string)  row  format delimited fields terminated by &#x27;\t&#x27;;  </span><br></pre></td></tr></table></figure></li>
<li><p>向普通的 <code>stu</code> 表中导入数据</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/opt/module/datas/student.txt&#x27; into table stu;  </span><br></pre></td></tr></table></figure></li>
<li><p>清空 <code>stu_buck</code> 表中数据</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">truncate  table stu_buck;  select  * from stu_buck;  </span><br></pre></td></tr></table></figure></li>
<li><p>通过子查询的方式导入数据到分桶表。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into table stu_buck select id, name from stu;  </span><br></pre></td></tr></table></figure></li>
<li><p>发现还是只有一个分桶</p>
<p> <img src="Hive/image-20211220125128806.png" alt="image-20211220125128806"></p>
</li>
<li><p>需要设置一个属性</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 1、打开强制分桶开关：</span><br><span class="line">hive  (default)&gt; set hive.enforce.bucketing=true;</span><br><span class="line"># 2、mapreduce.job.reduces=-1 表示默认值，表示 Hive 会读取分桶表的设置的 numBuckets 来设置分桶值，</span><br><span class="line"># 但是该参数生效的前提是必须打开分桶开关</span><br><span class="line">hive  (default)&gt; set mapreduce.job.reduces=-1;  </span><br><span class="line">hive  (default)&gt; insert into table stu_buck  select  id, name from stu;  </span><br></pre></td></tr></table></figure></li>
<li><p>查询分桶的数据</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from stu_buck;</span><br><span class="line">OK</span><br><span class="line">stu_buck.id	stu_buck.name</span><br><span class="line">1016	ss16</span><br><span class="line">1012	ss12</span><br><span class="line">1008	ss8</span><br><span class="line">1004	ss4</span><br><span class="line">1009	ss9</span><br><span class="line">1005	ss5</span><br><span class="line">1001	ss1</span><br><span class="line">1013	ss13</span><br><span class="line">1010	ss10</span><br><span class="line">1002	ss2</span><br><span class="line">1006	ss6</span><br><span class="line">1014	ss14</span><br><span class="line">1003	ss3</span><br><span class="line">1011	ss11</span><br><span class="line">1007	ss7</span><br><span class="line">1015	ss15</span><br><span class="line">Time taken: 0.043 seconds, Fetched: 16 row(s)</span><br></pre></td></tr></table></figure></li>
<li><p>查看 HDFS 上的分桶结果</p>
<p> 表中的所有数据现在都根据 <code>id</code> 的 Hash 值分散在四个桶中了。Hash 是采用 MapReduce 默认的 Hash 分区器。</p>
<p> <img src="Hive/image-20211220125548362.png" alt="image-20211220125548362"></p>
</li>
</ol>
<hr>
<h3 id="4-4-2-分桶抽样查询"><a href="#4-4-2-分桶抽样查询" class="headerlink" title="4.4.2 分桶抽样查询"></a>4.4.2 分桶抽样查询</h3><p>对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。<code>Hive</code> 可以通过对表进行抽样来满足这个需求。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from 分桶表名 tablesample(bucket x out of y on 分桶字段);  </span><br></pre></td></tr></table></figure>

<p><strong>要求：</strong></p>
<ul>
<li><p>  抽样查询的表必须是分桶表</p>
</li>
<li><p>  假设当前表一共分了 <code>z</code> 个桶，<code>x</code> 表示从第 <code>x</code> 桶开始抽样，每间隔 <code>y</code> 桶抽一次，直到抽满 <code>z/y</code> 桶。</p>
</li>
<li><p>  <code>y</code> 必须是 <code>z</code> 的倍数或者因子。<code>Hive</code> 根据 <code>y</code> 的大小，决定抽样的比例。例如，<code>table</code> 总共分了 4 份，当 <code>y=2</code> 时，抽取 <code>(4/2)=2</code> 个 <code>bucket</code> 的数据，当 <code>y=8</code> 时，抽取 <code>(4/8)=1/2</code> 个 <code>bucket</code> 的数据。</p>
</li>
<li><p>  <code>x</code> 表示从第几个 <code>bucket</code> 开始抽取，如果需要取多个分区，以后的分区号为当前分区号加上 <code>y</code>。例如，<code>table</code> 总 <code>bucket</code> 数为 4， <code>tablesample(bucket 1 out of 2)</code>，表示总共抽取 <code>（4/2）= 2</code> 个 <code>bucket</code> 的数据，抽取第 1 个和第 3 个 <code>bucket</code> 的数据。</p>
</li>
<li><p>注意： <code>x</code> 的值必须小于等于 <code>y</code> 的值，否则会抛出异常。</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FAILED: SemanticException [Error 10061]: Numerator should not be bigger than denominator in sample clause for table stu_buck</span><br></pre></td></tr></table></figure>

</li>
</ul>
<ol>
<li><p>查询表 <code>stu_buck</code> 中的数据。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 当前表分了四桶（0~3号桶），当前次查询只查询第0号桶和2号桶中的数据</span><br><span class="line">hive (default)&gt; select * from stu_buck tablesample(bucket 1 out of 2 on id);</span><br><span class="line">OK</span><br><span class="line">stu_buck.id	stu_buck.name</span><br><span class="line">1016	ss16</span><br><span class="line">1012	ss12</span><br><span class="line">1008	ss8</span><br><span class="line">1004	ss4</span><br><span class="line">1010	ss10</span><br><span class="line">1002	ss2</span><br><span class="line">1006	ss6</span><br><span class="line">1014	ss14</span><br><span class="line">Time taken: 0.164 seconds, Fetched: 8 row(s)</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h1 id="第5章-DML数据操作"><a href="#第5章-DML数据操作" class="headerlink" title="第5章 DML数据操作"></a>第5章 DML数据操作</h1><h2 id="5-1-数据导入"><a href="#5-1-数据导入" class="headerlink" title="5.1 数据导入"></a>5.1 数据导入</h2><h3 id="5-1-1-向表中装载数据（Load）"><a href="#5-1-1-向表中装载数据（Load）" class="headerlink" title="5.1.1 向表中装载数据（Load）"></a>5.1.1 向表中装载数据（Load）</h3><p><strong>作用：</strong>将数据加载到 Hive 表中</p>
<p><strong>语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> load data [<span class="keyword">local</span>] inpath <span class="string">&#x27;/opt/module/datas/student.txt&#x27;</span> [overwrite] <span class="keyword">into</span> <span class="keyword">table</span> student [<span class="keyword">partition</span> (partcol1<span class="operator">=</span>val1,…)];</span><br><span class="line"></span><br><span class="line"><span class="comment">---------------------------</span></span><br><span class="line">（<span class="number">1</span>）load data：表示加载数据</span><br><span class="line">（<span class="number">2</span>）<span class="keyword">local</span>：如果导入的文件位于本地文件系统，则使用 <span class="keyword">local</span> 关键字，表示使用 put 的方式将本地文件上传到 Hive 上的表目录中；如果不加 <span class="keyword">local</span> 默认导入的文件位于 HDFS 上，通过 mv 的方式将源文件移动到 Hive 的表目录中。</span><br><span class="line">（<span class="number">3</span>）inpath：表示加载数据的路径</span><br><span class="line">（<span class="number">4</span>）overwrite：表示覆盖表中已有数据，否则表示追加</span><br><span class="line">（<span class="number">5</span>）<span class="keyword">into</span> <span class="keyword">table</span>：表示加载到哪张表</span><br><span class="line">（<span class="number">6</span>）student：表示具体的表名</span><br><span class="line">（<span class="number">7</span>）<span class="keyword">partition</span>：表示上传到指定分区</span><br><span class="line"><span class="comment">---------------------------</span></span><br></pre></td></tr></table></figure>





<p><strong>实操案例</strong></p>
<ol>
<li><p>创建一张表</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> student(id string, name string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure>

</li>
<li><p>加载本地文件到 Hive</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/datas/student.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> default.student;</span><br></pre></td></tr></table></figure>

</li>
<li><p>加载 HDFS 中的文件到 Hive 中</p>
<ul>
<li><p>上传文件到 HDFS</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> dfs <span class="operator">-</span>put <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>datas<span class="operator">/</span>student.txt <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>atguigu<span class="operator">/</span>hive;</span><br></pre></td></tr></table></figure></li>
<li><p>加载 HDFS 中的文件到 Hive 中</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data inpath <span class="string">&#x27;/user/atguigu/hive/student.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> default.student;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>加载数据覆盖表中已有的数据</p>
<ul>
<li><p>上传文件到 HDFS</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> dfs <span class="operator">-</span>put <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>datas<span class="operator">/</span>student.txt <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>atguigu<span class="operator">/</span>hive;</span><br></pre></td></tr></table></figure></li>
<li><p>加载 HDFS 上的数据覆盖表中已有的数据</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data inpath <span class="string">&#x27;/user/atguigu/hive/student.txt&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> default.student;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<hr>
<h3 id="5-1-2-通过查询语句向表中插入数据（Insert）"><a href="#5-1-2-通过查询语句向表中插入数据（Insert）" class="headerlink" title="5.1.2    通过查询语句向表中插入数据（Insert）"></a>5.1.2    通过查询语句向表中插入数据（Insert）</h3><p><code>insert</code> 方式运行 MapReduce 程序，通过程序将数据输出到表目录。</p>
<p>在某些场景，必须使用 <code>insert</code> 方式来导入数据。</p>
<ol>
<li> 向桶中插入数据</li>
<li> 如果想要使表中的数据以非文本的格式存储，需要使用 <code>insert</code> 的方式导入数据</li>
</ol>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">insert &#123;into | overwrite&#125; table 表名 &#123;select xxx | values(...)&#125;</span><br><span class="line"></span><br><span class="line"># insert into：追加写</span><br><span class="line"># insert overwrite：覆盖写</span><br><span class="line"></span><br><span class="line"># select xxx：将从MySQL中查到的数据写入到Hive中</span><br><span class="line"># values(...)：直接显式指定要插入的值，如 values(1,&#x27;张三&#x27;)</span><br></pre></td></tr></table></figure>





<p><strong>Demo</strong></p>
<ol>
<li><p>创建一张分区表</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> student(id <span class="type">int</span>, name string) partitioned <span class="keyword">by</span> (<span class="keyword">month</span> string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>基本插入数据</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> student <span class="keyword">partition</span>(<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201709&#x27;</span>) <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">&#x27;wangwu&#x27;</span>);</span><br></pre></td></tr></table></figure></li>
<li><p>基本模式插入（根据单张表查询结果）</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite <span class="keyword">table</span> student <span class="keyword">partition</span>(<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201708&#x27;</span>)</span><br><span class="line">             <span class="keyword">select</span> id, name <span class="keyword">from</span> student <span class="keyword">where</span> <span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201709&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>多插入模式（根据多张表查询结果）</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; from student</span><br><span class="line">              insert overwrite table student partition(month=&#x27;201707&#x27;)</span><br><span class="line">              select id, name where month=&#x27;201709&#x27;</span><br><span class="line">              insert overwrite table student partition(month=&#x27;201706&#x27;)</span><br><span class="line">              select id, name where month=&#x27;201710&#x27;;</span><br><span class="line">              </span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <strong>多插入模式（从一张源表查询，向多张目标表插入）</strong>。在上面的语句中就是：</p>
<ol>
<li> 查询 month=’201709’ 的数据插入到 student 表的 month=’201707’ 分区中；</li>
<li> 查询 month=’201710’ 的数据插入到 student 表的 month=’201706’ 分区中；</li>
</ol>
<p>  <strong>语法：</strong></p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from 源表</span><br><span class="line">insert into 目标表 select xxx</span><br><span class="line">insert overwrite 目标表 select xxx</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

</blockquote>
</li>
</ol>
<p>​    </p>
<hr>
<h3 id="5-1-3-查询语句中创建表并加载数据（As-Select）"><a href="#5-1-3-查询语句中创建表并加载数据（As-Select）" class="headerlink" title="5.1.3 查询语句中创建表并加载数据（As Select）"></a>5.1.3 查询语句中创建表并加载数据（As Select）</h3><p>详见 4.5.1 章创建表。</p>
<p>根据查询结果创建表（查询的结果会添加到新创建的表中）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student3</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> id, name <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="5-1-4-创建表时通过-Location-指定加载数据路径"><a href="#5-1-4-创建表时通过-Location-指定加载数据路径" class="headerlink" title="5.1.4 创建表时通过 Location 指定加载数据路径"></a>5.1.4 创建表时通过 Location 指定加载数据路径</h3><ol>
<li><p>创建表，并指定表数据在 Hive 上的位置</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student5(</span><br><span class="line">    id <span class="type">int</span>, name string</span><br><span class="line">)</span><br><span class="line">	<span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">	location <span class="string">&#x27;/user/hive/warehouse/student5&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</li>
<li><p>上传数据到 HDFS 上</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> dfs <span class="operator">-</span>put <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>datas<span class="operator">/</span>student.txt</span><br><span class="line"><span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>student5;</span><br></pre></td></tr></table></figure>

</li>
<li><p>查询数据</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student5;</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="5-1-5-Import数据到指定Hive表中"><a href="#5-1-5-Import数据到指定Hive表中" class="headerlink" title="5.1.5 Import数据到指定Hive表中"></a>5.1.5 Import数据到指定Hive表中</h3><ul>
<li>  <strong>import</strong> 不仅可以导入业务数据，同时还可以导入元数据。 </li>
<li>  注意：<strong>import</strong> 只能导入 <strong>export</strong> 导出的数据。</li>
</ul>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IMPORT [[EXTERNAL] TABLE new_or_original_tablename [PARTITION (part_column=&quot;value&quot;[, ...])]]</span><br><span class="line">  FROM &#x27;source_path&#x27;</span><br><span class="line">  [LOCATION &#x27;import_target_path&#x27;]</span><br></pre></td></tr></table></figure>

<ul>
<li><p>  向一张表中导入数据时，如果表不存在，Hive 会根据导入数据中的元数据信息自动创建表。</p>
</li>
<li><p>  如果表已经存在，在导入之前会先检查目标表的元数据与导入数据中的元数据信息是否一致。检查通过后才会执行导入。</p>
</li>
<li><p>不管表是否为空，目标表中的分区必须是不存在的。</p>
</li>
</ul>
<p><strong>Demo</strong></p>
<ol>
<li><p>通过 import 将数据导入指定的 Hive 表中</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; import table import_table1 from &#x27;/export&#x27;;</span><br></pre></td></tr></table></figure>

</li>
<li><p>查看导入后的表信息</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; show tables;</span><br><span class="line">OK</span><br><span class="line">import_table1</span><br><span class="line">student</span><br><span class="line">test</span><br><span class="line">Time taken: 0.018 seconds, Fetched: 8 row(s)</span><br></pre></td></tr></table></figure>

 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc import_table1;</span><br><span class="line">OK</span><br><span class="line">col_name	data_type	comment</span><br><span class="line">deptno              	int                 	                    </span><br><span class="line">dname               	string              	                    </span><br><span class="line">loc                 	string              	                    </span><br><span class="line">month               	string              	                    </span><br><span class="line">	 	 </span><br><span class="line"># Partition Information	 	 分区信息</span><br><span class="line"># col_name            	data_type           	comment             </span><br><span class="line">	 	 </span><br><span class="line">month               	string              	                    </span><br><span class="line">Time taken: 0.076 seconds, Fetched: 9 row(s)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h2 id="5-2-数据导出"><a href="#5-2-数据导出" class="headerlink" title="5.2 数据导出"></a>5.2 数据导出</h2><h3 id="5-2-1-Insert-导出"><a href="#5-2-1-Insert-导出" class="headerlink" title="5.2.1 Insert 导出"></a>5.2.1 Insert 导出</h3><ol>
<li><p>将查询的结果导出到本地</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite local directory &#x27;/opt/module/datas/export/student&#x27;</span><br><span class="line">            select * from student;</span><br></pre></td></tr></table></figure></li>
<li><p>将查询的结果<strong>格式化</strong>后导出到本地</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive(default)&gt;insert overwrite local directory &#x27;/opt/module/datas/export/student1&#x27;</span><br><span class="line">           ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;             </span><br><span class="line">           select * from student;</span><br></pre></td></tr></table></figure>

</li>
<li><p>将查询的结果导出到 HDFS 上（省略 local 关键字）</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite directory &#x27;/user/atguigu/student2&#x27;</span><br><span class="line">             ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27; </span><br><span class="line">             select * from student;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="5-2-2-Hadoop命令导出到本地"><a href="#5-2-2-Hadoop命令导出到本地" class="headerlink" title="5.2.2 Hadoop命令导出到本地"></a>5.2.2 Hadoop命令导出到本地</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -get /user/hive/warehouse/student/month=201709/000000_0</span><br><span class="line">/opt/module/datas/export/student3.txt;</span><br></pre></td></tr></table></figure>





<hr>
<h3 id="5-2-3-Hive-Shell-命令导出"><a href="#5-2-3-Hive-Shell-命令导出" class="headerlink" title="5.2.3    Hive Shell 命令导出"></a>5.2.3    Hive Shell 命令导出</h3><p>基本语法：<code>hive -f/-e 执行语句或者脚本 &gt; file</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hive]$ bin/hive -e <span class="string">&#x27;select * from default.student;&#x27;</span> &gt; </span><br><span class="line">/opt/module/datas/export/student4.txt;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="5-2-4-Export-导出到-HDFS-上"><a href="#5-2-4-Export-导出到-HDFS-上" class="headerlink" title="5.2.4    Export 导出到 HDFS 上"></a>5.2.4    Export 导出到 HDFS 上</h3><p><strong>Export：</strong></p>
<ul>
<li>  既能导出数据，还可以导入元数据</li>
<li>  <code>export</code> 只能导出到 HDFS 中，会在 HDFS 的导出目录中，生成数据和元数据文件。</li>
<li>  如果当前表是一个分区表，可以选择只导出表的部分分区数据及其元数据信息。</li>
</ul>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">EXPORT TABLE tablename [PARTITION (part_column=&quot;value&quot;[, ...])]</span><br><span class="line">  TO &#x27;export_target_path&#x27; [ FOR replication(&#x27;eventid&#x27;) ]</span><br></pre></td></tr></table></figure>





<p><strong>Demo：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> EXPORT <span class="keyword">TABLE</span> dept_partition <span class="keyword">TO</span> <span class="string">&#x27;/export&#x27;</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>查看 HDFS 上的文件结构</p>
<p>  <img src="Hive/image-20211220175855162.png" alt="image-20211220175855162"></p>
</li>
</ul>
<hr>
<h3 id="5-2-5-Sqoop-导出"><a href="#5-2-5-Sqoop-导出" class="headerlink" title="5.2.5    Sqoop 导出"></a>5.2.5    Sqoop 导出</h3><p>后续课程专门讲。</p>
<hr>
<h2 id="5-3-清除表中数据（Truncate）"><a href="#5-3-清除表中数据（Truncate）" class="headerlink" title="5.3 清除表中数据（Truncate）"></a>5.3 清除表中数据（Truncate）</h2><p>注意：<code>Truncate</code> 只能删除管理表，不能删除外部表中数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">truncate</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure>





<hr>
<h1 id="第-6-章-查询"><a href="#第-6-章-查询" class="headerlink" title="第 6 章    查询"></a>第 6 章    查询</h1><p>官网：<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select</a></p>
<p><strong>查询语句语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">WITH</span> CommonTableExpression (, CommonTableExpression)<span class="operator">*</span>]    (Note: <span class="keyword">Only</span> available starting <span class="keyword">with</span> Hive <span class="number">0.13</span><span class="number">.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_expr, select_expr, ...</span><br><span class="line"><span class="keyword">FROM</span> table_reference</span><br><span class="line">[<span class="keyword">WHERE</span> where_condition]</span><br><span class="line">[<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">[<span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">[CLUSTER <span class="keyword">BY</span> col_list <span class="operator">|</span> [DISTRIBUTE <span class="keyword">BY</span> col_list] [SORT <span class="keyword">BY</span> col_list]]</span><br><span class="line">[LIMIT number]</span><br></pre></td></tr></table></figure>





<hr>
<h2 id="6-1-基础查询（Select…From）"><a href="#6-1-基础查询（Select…From）" class="headerlink" title="6.1 基础查询（Select…From）"></a>6.1 基础查询（Select…From）</h2><h3 id="6-1-1-全表和特定列查询"><a href="#6-1-1-全表和特定列查询" class="headerlink" title="6.1.1 全表和特定列查询"></a>6.1.1 全表和特定列查询</h3><ol>
<li><p>全表查询</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure></li>
<li><p>特定列查询</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> empno, ename <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>注意：</strong></p>
<ol>
<li> SQL 语言大小写不敏感。</li>
<li>  SQL 可以写在一行或者多行。</li>
</ol>
<h3 id="6-1-2-列别名"><a href="#6-1-2-列别名" class="headerlink" title="6.1.2 列别名"></a>6.1.2 列别名</h3><p>列别名的规则与 MySQL 相同，可以紧跟列名，也可以在列名和别名之间加入关键字 AS。 </p>
<p>案例实操：查询名称和部门</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> ename <span class="keyword">AS</span> name, deptno dn <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="6-1-3-算术运算符"><a href="#6-1-3-算术运算符" class="headerlink" title="6.1.3 算术运算符"></a>6.1.3 算术运算符</h3><table>
<thead>
<tr>
<th align="center">运算符</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>A + B</code></td>
<td>A 加 B</td>
</tr>
<tr>
<td align="center"><code>A - B</code></td>
<td>A 减 B</td>
</tr>
<tr>
<td align="center"><code>A * B</code></td>
<td>A 乘 B</td>
</tr>
<tr>
<td align="center"><code>A / B</code></td>
<td>A 除 B</td>
</tr>
<tr>
<td align="center"><code>A % B</code></td>
<td>A 对 B 取余</td>
</tr>
<tr>
<td align="center"><code>A &amp; B</code></td>
<td>A 和 B 按位与</td>
</tr>
<tr>
<td align="center">`A</td>
<td>B`</td>
</tr>
<tr>
<td align="center"><code>A ^ B</code></td>
<td>A 和 B 按位异或</td>
</tr>
<tr>
<td align="center"><code>~A</code></td>
<td>A 按位取反</td>
</tr>
</tbody></table>
<p>案例实操：查询出所有员工的薪水后 <code>+1</code> 显示。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> sal <span class="operator">+</span><span class="number">1</span> <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>





<hr>
<h3 id="6-1-4-常用函数"><a href="#6-1-4-常用函数" class="headerlink" title="6.1.4 常用函数"></a>6.1.4 常用函数</h3><ol>
<li><p>求总行数（count）</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) cnt <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure></li>
<li><p>求工资的最大值（max）</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">max</span>(sal) max_sal <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure></li>
<li><p>求工资的最小值（min）</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">min</span>(sal) min_sal <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure></li>
<li><p>求工资的总和（sum）</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">sum</span>(sal) sum_sal <span class="keyword">from</span> emp; </span><br></pre></td></tr></table></figure></li>
<li><p>求工资的平均值（avg）</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="6-1-5-Limit-语句"><a href="#6-1-5-Limit-语句" class="headerlink" title="6.1.5 Limit 语句"></a>6.1.5 Limit 语句</h3><p>典型的查询会返回多行数据。LIMIT 子句用于限制返回的行数。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp limit <span class="number">5</span>;</span><br></pre></td></tr></table></figure>





<hr>
<h2 id="6-2-Where语句"><a href="#6-2-Where语句" class="headerlink" title="6.2 Where语句"></a>6.2 Where语句</h2><p>案例实操：查询出薪水大于 1000 的所有员工</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="operator">&gt;</span><span class="number">1000</span>;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="6-2-1-比较运算符（Between-In-Is-Null）"><a href="#6-2-1-比较运算符（Between-In-Is-Null）" class="headerlink" title="6.2.1 比较运算符（Between / In / Is Null）"></a>6.2.1 比较运算符（Between / In / Is Null）</h3><p>下面表中描述了谓词操作符，这些操作符同样可以用于 <code>JOIN…ON</code> 和 <code>HAVING</code> 语句中。</p>
<table>
<thead>
<tr>
<th>操作符</th>
<th>支持的数据类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>A=B</code></td>
<td>基本数据类型</td>
<td>如果 A 等于 B 则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td><code>A&lt;=&gt;B</code></td>
<td>基本数据类型</td>
<td>如果 A 和 B 都为 NULL，则返回TRUE；<br>如果任一为 NULL 则结果为 NULL；<br>其它的和等号（=）操作符的结果一致。</td>
</tr>
<tr>
<td><code>A&lt;&gt;B</code>，<code>A!=B</code></td>
<td>基本数据类型</td>
<td>A 或 B 为 NULL 则返回NULL；<br>如果 A 不等于 B，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td><code>A&lt;B</code></td>
<td>基本数据类型</td>
<td>A 或 B 为 NULL，则返回 NULL；<br>如果 A 小于 B，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td><code>A&lt;=B</code></td>
<td>基本数据类型</td>
<td>A 或 B 为 NULL，则返回 NULL；<br>如果 A 小于等于 B，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td><code>A&gt;B</code></td>
<td>基本数据类型</td>
<td>A 或 B 为 NULL，则返回 NULL；<br>如果 A 大于 B，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td><code>A&gt;=B</code></td>
<td>基本数据类型</td>
<td>A 或 B 为 NULL，则返回 NULL；<br>如果 A 大于等于 B，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td><code>A [NOT] BETWEEN B AND C</code></td>
<td>基本数据类型</td>
<td>如果 A、B 或 C 任一为 NULL，则结果为NULL。<br>如果 A 的值大于等于 B 而且小于或等于 C，则结果为 TRUE，<br>反之为 FALSE。如果使用 NOT 关键字则可达到相反的效果</td>
</tr>
<tr>
<td><code>A IS NULL</code></td>
<td>所有数据类型</td>
<td>如果 A 等于 NULL，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td><code>A IS NOT NULL</code></td>
<td>所有数据类型</td>
<td>如果 A 不等于 NULL，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td><code>IN(数值1, 数值2) </code></td>
<td>所有数据类型</td>
<td>使用 IN 运算显示列表中的值</td>
</tr>
<tr>
<td><code>A [NOT] LIKE B</code></td>
<td>STRING 类型</td>
<td>B 是一个 SQL 下的简单正则表达式，如果 A 与其匹配的话，则返回TRUE；<br>反之返回 FALSE。B 的表达式说明如下：<code>x%</code> 表示 A 必须以字母 <code>x</code> 开头，<br><code>%x</code> 表示 A 必须以字母 <code>x</code> 结尾，而 <code>%x%</code> 表示 A 包含有字母 <code>x</code>，可以位于开头，<br>结尾或者字符串中间。如果使用 NOT 关键字则可达到相反的效果。</td>
</tr>
<tr>
<td><code>A RLIKE B, A REGEXP B</code></td>
<td>STRING 类型</td>
<td>B 是一个正则表达式，如果 A 与其匹配，则返回 TRUE；反之返回 FALSE。<br>匹配使用的是 JDK 中的正则表达式接口实现的，因为正则也依据其中的规则。<br>例如，正则表达式必须和整个字符串 A 相匹配，而不是只需与其字符串匹配</td>
</tr>
</tbody></table>
<p><strong>案例实操</strong></p>
<ol>
<li><p>查询出薪水等于 5000 的所有员工</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="operator">=</span><span class="number">5000</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>查询工资在 500 到 1000 的员工信息</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="keyword">between</span> <span class="number">500</span> <span class="keyword">and</span> <span class="number">1000</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>查询 <code>comm</code> 为空的所有员工信息</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> comm <span class="keyword">is</span> <span class="keyword">null</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>查询工资是 1500 或 5000 的员工信息</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="keyword">IN</span> (<span class="number">1500</span>, <span class="number">5000</span>);</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="6-2-2-Like-和-RLike"><a href="#6-2-2-Like-和-RLike" class="headerlink" title="6.2.2 Like 和 RLike"></a>6.2.2 Like 和 RLike</h3><ol>
<li> 使用 LIKE 运算选择类似的值</li>
<li>选择条件可以包含字符或数字：<ul>
<li>  <code>%</code> 代表零个或多个字符(任意个字符)。</li>
<li>  <code>_</code> 代表一个字符。</li>
</ul>
</li>
<li> <code>RLIKE</code> 子句是 Hive 中这个功能的一个扩展，其可以通过 Java 的正则表达式这个更强大的语言来指定匹配条件。</li>
</ol>
<p><strong>案例实操</strong></p>
<ol>
<li><p>查找以 2 开头薪水的员工信息</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="keyword">LIKE</span> <span class="string">&#x27;2%&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>查找第二个数值为 2 的薪水的员工信息</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="keyword">LIKE</span> <span class="string">&#x27;_2%&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>查找薪水中含有 2 的员工信息</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal RLIKE <span class="string">&#x27;[2]&#x27;</span>;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="6-2-3-逻辑运算符（And-Or-Not）"><a href="#6-2-3-逻辑运算符（And-Or-Not）" class="headerlink" title="6.2.3    逻辑运算符（And/Or/Not）"></a>6.2.3    逻辑运算符（And/Or/Not）</h3><table>
<thead>
<tr>
<th align="center">操作符</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">AND</td>
<td align="center">与</td>
</tr>
<tr>
<td align="center">OR</td>
<td align="center">或</td>
</tr>
<tr>
<td align="center">NOT</td>
<td align="center">非</td>
</tr>
</tbody></table>
<p><strong>案例实操</strong></p>
<ol>
<li><p>查询薪水大于 1000，部门是 30</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal<span class="operator">&gt;</span><span class="number">1000</span> <span class="keyword">and</span> deptno<span class="operator">=</span><span class="number">30</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>查询薪水大于 1000，或者部门是30</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal<span class="operator">&gt;</span><span class="number">1000</span> <span class="keyword">or</span> deptno<span class="operator">=</span><span class="number">30</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>查询除了 20 部门和 30 部门以外的员工信息</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> deptno <span class="keyword">not</span> <span class="keyword">IN</span>(<span class="number">30</span>, <span class="number">20</span>);</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h2 id="6-3-分组"><a href="#6-3-分组" class="headerlink" title="6.3    分组"></a>6.3    分组</h2><h3 id="6-3-1-Group-By语句"><a href="#6-3-1-Group-By语句" class="headerlink" title="6.3.1    Group By语句"></a>6.3.1    Group By语句</h3><p><code>GROUP BY</code> 语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p>
<p><strong>案例实操：</strong></p>
<ol>
<li><p>计算 <code>emp</code> 表每个部门的平均工资</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> t.deptno, <span class="built_in">avg</span>(t.sal) avg_sal <span class="keyword">from</span> emp t <span class="keyword">group</span> <span class="keyword">by</span> t.deptno;</span><br></pre></td></tr></table></figure></li>
<li><p>计算 <code>emp</code> 每个部门中每个岗位的最高薪水</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> t.deptno, t.job, <span class="built_in">max</span>(t.sal) max_sal <span class="keyword">from</span> emp t <span class="keyword">group</span> <span class="keyword">by</span> t.deptno, t.job;</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="6-3-2-Having-语句"><a href="#6-3-2-Having-语句" class="headerlink" title="6.3.2    Having 语句"></a>6.3.2    Having 语句</h3><p><strong><code>having</code> 与 <code>where</code> 不同点：</strong></p>
<ol>
<li> <code>where</code> 针对表中的列发挥作用，查询数据；<code>having</code> 针对查询结果中的列发挥作用，筛选数据。</li>
<li> <code>where</code> 后面不能写分组函数，而 <code>having</code> 后面可以使用分组函数。</li>
<li> <code>having</code> 只用于 <code>group by</code> 分组统计语句。</li>
</ol>
<p><strong>案例实操</strong>：求所有部门中平均薪水大于 2000 的部门</p>
<ol>
<li><p>求每个部门的平均工资</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> deptno, <span class="built_in">avg</span>(sal) <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno;</span><br></pre></td></tr></table></figure></li>
<li><p>求所有部门中平均薪水大于 2000 的部门</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> deptno, <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno <span class="keyword">having</span> avg_sal <span class="operator">&gt;</span> <span class="number">2000</span>;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h2 id="6-4-Join语句"><a href="#6-4-Join语句" class="headerlink" title="6.4 Join语句"></a>6.4 Join语句</h2><h3 id="6-4-1-等值Join"><a href="#6-4-1-等值Join" class="headerlink" title="6.4.1 等值Join"></a>6.4.1 等值Join</h3><p>Hive 支持常用的 <code>SQL JOIN</code> 语句，但是只支持等值连接，不支持非等值连接。</p>
<p><strong>案例实操</strong></p>
<ol>
<li><p>根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门名称；</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> </span><br><span class="line">	<span class="keyword">select</span> e.empno, e.ename, d.deptno, d.dname </span><br><span class="line">	<span class="keyword">from</span> emp e <span class="keyword">join</span> dept d</span><br><span class="line">	<span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="6-4-2-表的别名"><a href="#6-4-2-表的别名" class="headerlink" title="6.4.2    表的别名"></a>6.4.2    表的别名</h3><p><strong>好处：</strong></p>
<ol>
<li> 使用别名可以简化查询。</li>
<li> 使用表名前缀可以提高执行效率。</li>
</ol>
<p><strong>案例实操</strong></p>
<ol>
<li><p>合并员工表和部门表</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> </span><br><span class="line">	<span class="keyword">select</span> e.empno, e.ename, d.deptno </span><br><span class="line">	<span class="keyword">from</span> emp e <span class="keyword">join</span> dept d </span><br><span class="line">	<span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="6-4-3-内连接"><a href="#6-4-3-内连接" class="headerlink" title="6.4.3    内连接"></a>6.4.3    内连接</h3><p><strong>内连接：</strong>只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> </span><br><span class="line">	<span class="keyword">select</span> e.empno, e.ename, d.deptno </span><br><span class="line">	<span class="keyword">from</span> emp e <span class="keyword">join</span> dept d </span><br><span class="line">	<span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="6-4-4-左外连接"><a href="#6-4-4-左外连接" class="headerlink" title="6.4.4    左外连接"></a>6.4.4    左外连接</h3><p><strong>左外连接：</strong>JOIN 操作符左边表中符合 WHERE 子句的所有记录将会被返回。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> </span><br><span class="line">	<span class="keyword">select</span> e.empno, e.ename, d.deptno </span><br><span class="line">	<span class="keyword">from</span> emp e <span class="keyword">left</span> <span class="keyword">join</span> dept d </span><br><span class="line">	<span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>





<hr>
<h3 id="6-4-5-右外连接"><a href="#6-4-5-右外连接" class="headerlink" title="6.4.5    右外连接"></a>6.4.5    右外连接</h3><p><strong>右外连接：</strong>JOIN 操作符右边表中符合 WHERE 子句的所有记录将会被返回。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> </span><br><span class="line">	<span class="keyword">select</span> e.empno, e.ename, d.deptno </span><br><span class="line">	<span class="keyword">from</span> emp e <span class="keyword">right</span> <span class="keyword">join</span> dept d </span><br><span class="line">	<span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="6-4-6-全外连接"><a href="#6-4-6-全外连接" class="headerlink" title="6.4.6    全外连接"></a>6.4.6    全外连接</h3><p><strong>全外连接：</strong>将会返回所有表中符合 WHERE 语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用 NULL 值替代。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> </span><br><span class="line">	<span class="keyword">select</span> e.empno, e.ename, d.deptno </span><br><span class="line">	<span class="keyword">from</span> emp e <span class="keyword">full</span> <span class="keyword">join</span> dept d </span><br><span class="line">	<span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="6-4-7-多表连接"><a href="#6-4-7-多表连接" class="headerlink" title="6.4.7    多表连接"></a>6.4.7    多表连接</h3><p><strong>注意：</strong>连接 <code>n</code> 个表，至少需要 <code>n-1</code> 个连接条件。例如：连接三个表，至少需要两个连接条件。</p>
<p><strong>数据准备</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1700	Beijing</span><br><span class="line">1800	London</span><br><span class="line">1900	Tokyo</span><br></pre></td></tr></table></figure>



<ol>
<li><p>创建位置表</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> default.location(</span><br><span class="line">    loc <span class="type">int</span>,</span><br><span class="line">    loc_name string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>导入数据</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/datas/location.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> default.location;</span><br></pre></td></tr></table></figure></li>
<li><p>多表连接查询</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br><span class="line">    <span class="keyword">SELECT</span> e.ename, d.deptno, l. loc_name</span><br><span class="line">    <span class="keyword">FROM</span>   emp e </span><br><span class="line">    <span class="keyword">JOIN</span>   dept d</span><br><span class="line">    <span class="keyword">ON</span>     d.deptno <span class="operator">=</span> e.deptno </span><br><span class="line">    <span class="keyword">JOIN</span>   location l</span><br><span class="line">    <span class="keyword">ON</span>     d.loc <span class="operator">=</span> l.loc;</span><br></pre></td></tr></table></figure></li>
</ol>
<p>大多数情况下，Hive 会对每对 <code>JOIN</code> 连接对象启动一个 <code>MapReduce</code> 任务。本例中会首先启动一个 <code>MapReduce job</code> 对表 <code>e</code> 和表 <code>d</code> 进行连接操作，然后会再启动一个 <code>MapReduce job</code> 将第一个 <code>MapReduce job</code> 的输出和表 <code>l</code> 进行连接操作。</p>
<p>注意：为什么不是表 <code>d</code> 和表 <code>l</code> 先进行连接操作呢？这是因为 Hive 总是按照从左到右的顺序执行的。</p>
<hr>
<h3 id="6-4-8-笛卡尔积"><a href="#6-4-8-笛卡尔积" class="headerlink" title="6.4.8    笛卡尔积"></a>6.4.8    笛卡尔积</h3><p>笛卡尔集会在下面条件下产生：</p>
<ol>
<li> 省略连接条件</li>
<li> 连接条件无效</li>
<li> 所有表中的所有行互相连接</li>
</ol>
<p><strong>案例实操</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> empno, dname <span class="keyword">from</span> emp, dept;</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="6-4-9-连接谓词中不支持or"><a href="#6-4-9-连接谓词中不支持or" class="headerlink" title="6.4.9    连接谓词中不支持or"></a>6.4.9    连接谓词中不支持or</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	select e.empno, e.ename, d.deptno </span><br><span class="line">	from emp e join dept d </span><br><span class="line">	on e.deptno = d.deptno or e.ename=d.ename;   # 错误的</span><br></pre></td></tr></table></figure>





<hr>
<h2 id="6-5-排序"><a href="#6-5-排序" class="headerlink" title="6.5 排序"></a>6.5 排序</h2><p>Hive 的本质是 MapReduce，所以 Hive 的排序和 MapReduce 中的排序相关。在 MapReduce 中，排序可分为：</p>
<ul>
<li>  全排序：结果只有一个（只有一个分区），所有的数据整体有序</li>
<li>  部分排序：结果有多个（有多个分区），每个分区内部有序</li>
</ul>
<p>排序是在 Shuffle 阶段完成的，在 Reduce 阶段开始前就已经完成了。</p>
<h3 id="6-5-1-全局排序（Order-By）"><a href="#6-5-1-全局排序（Order-By）" class="headerlink" title="6.5.1    全局排序（Order By）"></a>6.5.1    全局排序（Order By）</h3><ol>
<li> <code>Order By</code>：全排序，只有一个分区，使用一个 <code>ReducTask</code> 进程</li>
<li>使用 <code>ORDER BY</code> 子句排序<ul>
<li>  <code>ASC（ascend）</code>: 升序（默认）</li>
<li>  <code>DESC（descend）</code>: 降序</li>
</ul>
</li>
<li> <code>ORDER BY</code> 子句在 <code>SELECT</code> 语句的结尾</li>
</ol>
<p><strong>案例实操</strong></p>
<ol>
<li><p>查询员工信息按工资升序排列</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp order by sal;</span><br></pre></td></tr></table></figure></li>
<li><p>查询员工信息按工资降序排列</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp order by sal desc;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="6-5-2-按照别名排序"><a href="#6-5-2-按照别名排序" class="headerlink" title="6.5.2    按照别名排序"></a>6.5.2    按照别名排序</h3><ol>
<li><p>按照员工薪水的 2 倍排序</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename, sal*2 twosal from emp order by twosal;</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="6-5-3-复合排序"><a href="#6-5-3-复合排序" class="headerlink" title="6.5.3    复合排序"></a>6.5.3    复合排序</h3><p>按照多个列的值进行排序</p>
<ol>
<li><p>按照部门号和工资升序排序</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename, deptno, sal from emp order by deptno, sal ;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="6-5-4-部分排序（Sort-By）"><a href="#6-5-4-部分排序（Sort-By）" class="headerlink" title="6.5.4    部分排序（Sort By）"></a>6.5.4    部分排序（Sort By）</h3><p><code>Sort By</code>：每个分区内部排序，对全局结果集来说不是排序。对于多个分区需要设置 <code>reduceTaskNum &gt; 1</code>。</p>
<ol>
<li><p>设置 <code>reduceTaskNum</code> 的数量，决定了分区的个数</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces=3;</span><br></pre></td></tr></table></figure>

</li>
<li><p>查看 <code>reduceTaskNum</code> 的值</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces;</span><br></pre></td></tr></table></figure>

</li>
<li><p>根据部门编号降序查看员工信息</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp sort by empno desc;</span><br></pre></td></tr></table></figure>

</li>
<li><p>将查询结果导入到文件中（按照部门编号降序排序）</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; </span><br><span class="line">	insert overwrite local directory &#x27;/opt/module/datas/sortby-result&#x27;</span><br><span class="line">	select * from emp sort by deptno desc;</span><br></pre></td></tr></table></figure></li>
</ol>
<p><code>Hive</code> 底层调用了 <code>MapReduce</code>，对于 <code>MapReduce</code> 来说，默认的分区器是 <code>Hash</code> 分区器，并且采用键值对数据中 key 的 <code>hash</code> 值来进行分区。对于使用 <code>sort by</code> 进行分区内排序的记录，我们无法确定哪一个字段将会作为 <code>hash</code> 分区器的 key，所以说 <code>sort by</code> 是随机分区，能够作为 <code>key</code> 的字段是随机的。如果希望能够显式指定一个表中的字段作为 <code>key</code>，则需要使用 <code>Distribute By</code> 关键字来进行分区间的排序。</p>
<hr>
<h3 id="6-5-5-分区排序（Distribute-By）"><a href="#6-5-5-分区排序（Distribute-By）" class="headerlink" title="6.5.5    分区排序（Distribute By）"></a>6.5.5    分区排序（Distribute By）</h3><p><code>Distribute By</code>：指定按照哪个字段分区。类似 <code>MR</code> 中 <code>partition</code>，进行分区，结合 <code>sort by</code> 使用。</p>
<p><strong>注意</strong>：<code>Hive</code> 要求 <code>DISTRIBUTE BY</code> 语句要写在 <code>SORT BY</code> 语句之前。</p>
<p>对于 <code>distribute by</code> 进行测试，一定要分配多 <code>reduce</code> 进行处理，否则无法看到 <code>distribute by</code> 的效果。</p>
<p><strong>案例实操：</strong></p>
<ol>
<li><p>先按照部门编号分区，再按照员工编号降序排序。</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   hive (default)&gt; set mapreduce.job.reduces=3;</span><br><span class="line">   hive (default)&gt; </span><br><span class="line">   	insert overwrite local directory &#x27;/opt/module/datas/distribute-result&#x27; </span><br><span class="line">   	select * from emp </span><br><span class="line">   	distribute by deptno 	# 指定作为分区器key的字段</span><br><span class="line">sort by empno desc;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="6-5-6-Cluster-By"><a href="#6-5-6-Cluster-By" class="headerlink" title="6.5.6    Cluster By"></a>6.5.6    Cluster By</h3><p>如果用于分区的字段和用于排序的字段相同时，可以简写为 <code>cluster by</code> 。</p>
<p>当 <code>distribute by</code> 和 <code>sorts by</code> 排序的字段相同时，可以使用 <code>cluster by</code> 的方式。</p>
<p><code>cluster by</code> 除了具有 <code>distribute by</code> 的功能外还兼具 <code>sort by</code> 的功能。但是排序只能是升序排序，不能指定排序规则为 <code>ASC</code> 或者 <code>DESC</code>。</p>
<ul>
<li><p>以下两种写法等价</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp cluster by deptno;</span><br></pre></td></tr></table></figure>

  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp distribute by deptno sort by deptno;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>注意：按照部门编号分区，不一定就是固定死的数值，可以是20号和30号部门分到一个分区里面去。</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/12/11/Spark-Streaming/" rel="prev" title="Spark_Streaming">
                  <i class="fa fa-chevron-left"></i> Spark_Streaming
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/12/17/Hive%E5%AE%89%E8%A3%85/" rel="next" title="Hive安装">
                  Hive安装 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
